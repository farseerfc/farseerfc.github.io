{"pages":[{"title":"關於","text":"關於這個Blog 我會儘量用中文(Chinese, zh)，日語(Japanese, jp)，英語(English, en)這 三門語言同時寫這個blog，在有意義的情況下。中文有繁體(zh)與簡體(zhs) 之分，我以繁體撰寫，再以 OpenCC 將繁體轉化爲對應的簡體。 近況 我叫 楊嘉晨 1989年6月生 目前任職於 大阪大學大學院 國際公共政策研究科 ( http://www.osipp.osaka-u.ac.jp/ ) 博士就讀於 大阪大學大學院 情報科學研究科 計算機科學專攻 ( http://sdl.ist.osaka-u.ac.jp/ ) 本科畢業於 上海交通大學 軟件學院 軟件工程專業 F0703701班 ( http://se.sjtu.edu.cn/ ) 聯繫方式 生活中你可以通過這些方式找到我： 手機: +81-80-3853-2770 網絡上你可以通過這些方式找到我： Skype: farseerfc GMail: farseerfc@gmail.com Github: https://github.com/farseerfc facebook: http://www.facebook.com/farseerfc telegram: http://telegram.me/farseerfc pgp: 4B1D E545 A801 D454 9BFD 3FEF 90CB 3D62 C13D 4796 關於現在用的頭像 這個頭像來自 HUG 大大 繪製的 十六夜 ( いざよい ) 咲夜 ( さくや ) ， pixiv id=41143207 因爲實在太喜歡了所以就擅自拿來作爲頭像了。十六夜是東方系列正傳 妖々夢 ( ようようむ ) 、 永夜抄 ( えいやしょう ) 和格鬥類 緋想天 ( ひそうてん ) 、 非想天則 ( ひそうてんそく ) 等作裏用得最順手的角色。","tags":"pages","url":"//farseerfc.me/pages/about.html"},{"title":"友情鏈接","text":"以下列出我在網上認識的好 朋友 ( jī yǒu ) 們，排名不分先後。歡迎交換友鏈。 lilydjwg 依雲 百合仙子 #archlinuxcn 社區管理者之一。 felixonmars 火星貓大大 archlinux官方開發者， #archlinuxcn 社區管理者之一。 phoenixlzx 鳳凰菊苣 #archlinuxcn 社區管理者之一， #nyaacat MC喵窩 管理員之一。 fixme 水源技站，本科同窗，內核貢獻者。 LQYMGT ID是irc上的中文社區鎮社之寶的可愛學弟。 quininer 純JavaScript的帥氣博客。 無奎寧妄言安全 。 acgtyrant 御宅暴君，維護着他個人的和Arch的兩個博客。 przhu OS X 骨灰用戶，Haskell大牛，好像什麼都知道。 mazk 我的完整博客模板的第一個用戶，似乎還是高中生，前途無量呀。 wicast TNT醬 Golang大大的漂亮Hugo博客。 LastAvengers 谷月轩 有 自己寫的內核 的厲害的LA的博客。 ヨイツの賢狼ホロ 來自約伊茲的萌狼，博客 是用 MediaWiki 搭的 也換到 Pelican 啦 ，是個萌物。 Frantic1048 Chino Kafuu 萌萌的智乃，喜歡一切萌物，前端技藝精湛，C++ 作業都用 Emscripten 轉換到前端去的高手。貌似正在構建新的博客框架，翹首以待中。 Peter Cai 颠倒的阿卡林型次元 PeterCxy 彼得蔡，據說高中用 AIDE 在手機上徒手擼出了 BlackLight 的大大，博客 用漂亮的 MD 主題 幾經改版每一次都越來越漂亮 。 CS Slayer 老K 另一個博客是 恋符「Master Spark」 Fcitx 開發者 ， KDE 開發者， Chakra 開發者， ikde 社區 維護者。強悍的開源貢獻實力無人能出其右。有個剛出生的小女兒叫 Alice （下一個叫 Marisa ） ，新博客是魔理沙主題的。 VOID 001 頭像是夏娜，/dev/horo 絕讚開發中。 PoiScript 萌萌噠 Poi ，博客引擎是自己寫的 Solomon 和我的博客是情侶色 。 不過不用 Arch 用 openSUSE。 南浦月 南老師，在線直播，聲音甜美。アスナ粉，自稱裝機民工的 linux 桌面環境開發者。修了 powerline 的 fontpatcher 。 Xuanwo 漩渦的 Hugo 博客很乾淨也很技術，厲害的後端工程師！ 老婆是路人 。 艾雨寒 | 艾穎初 初等記憶體 文藝的工科生 ( 技術過硬的文科生 ) ，萌妹體質，溫柔體貼會做飯，和很多來自 AOSC 的成員一樣對 Arch Linux CN 社區貢獻卓著。 告訴 ( 餵給 ) 我 很多人和事 ( 成噸的狗糧 ) ， 令人羨慕 。 桜庭 ( さくらば ) 雨音 ( あまね ) | 鳶一 ( とびいち ) 雨音 ( あまね ) 余忆留声机 中文說得比日文溜的日本土著，靈夢廚，日共黨員毛派，軍武知識豐富。被 雨寒 拉入社區前是單兵遊勇的 Arch 用戶，霊夢式 シェル使い ( shell編程師 ) 。 還有很多不符年齡迷之屬性不過這裏寫不下了 ， 有歸宿 。 新一 metal A-wing 前端 後端 全棧工程師！ 又是 一個夏娜廚，親手打造了 lilac 的打包狀態頁 KISS2UI 。 AlynxZhou 電磁炮廚， Hexo 的博客也 換成了自己寫的 Hikaru 還是 很漂亮，Arch Linux CN 社區中珍貴的 Gnome 用戶。喜歡 C 語言甚至在 B站 直播教學。CS:GO 玩家。 OriginCode 小學 初中生，使用電腦的時間嚴重受限，想起我當年的水平完全自愧不如，前途無量。 NoirGif 深藏不露的 USTC 菊苣，似乎玩了很多 gal game，博客更新很勤奮並且雙語。萌。 Megumi Fox 恵狐 強調自己是新人卻很快就融入了社區的恵狐醬，新搭的博客要多寫內容 才不至於像我這兒這麼荒廢 呀。說起來社區裏有百合狐可以結伴呢。 quanbrew 釀泉 いまさら イマココ 不應該鴨 說話萌萌噠總覺得是個萌妹子，自稱是一位 奧術師 ( Arcanist ) ， 精神 ( 神經 ) Arch 用戶， rust 使い。 Kiri 萌到鬼觸 （？） 的 Kiri ，Python使い， 圓角 ( 賺錢錢 ) 大佬，萌點見博客 Love Kiri 。 鹹魚大佬 說是鹹魚，本質非常大佬，混跡 AOSC ，善用 Gentoo 。手持大量稀奇設備。RAmen 教徒 所以是敵人 。 Zhu Chuang 把 pacvis 移植到了 Debian 系統上做了 AptVis ，博客是基於 MDC 的，看起來很漂亮。 szclsya Leo Shen Leo Shen 的 Hugo 博客，還有個 szclsya 的 nick 似乎還沒寫什麼東西 每篇都有英語和中文兩種呢。似乎也是 AOSC 常客，是 Emacs 用戶。","tags":"pages","url":"//farseerfc.me/pages/links.html"},{"title":"SSD 就是大U盤？聊聊閃存類存儲的轉換層","text":"上篇 「柱面-磁頭-扇區尋址的一些舊事」 整理了一下我對磁盤類存儲設備（包括軟盤、硬盤，不包括光盤、磁帶）的一些理解， 算是爲以後討論文件系統作鋪墊；這篇整理一下我對閃存類存儲設備的理解。 這裏想要討論的閃存類存儲是指 SSD 、SD卡、U盤、手機內置閃存等基於 NAND 又有閃存轉換層的存儲設備（下文簡稱閃存盤），但不包括裸 NAND 設備、3D Xpoint （Intel Optane）等相近物理結構但是沒有類似的閃存轉換層的存儲設備。 閃存類存儲設備這幾年發展迅猛，SD卡和U盤早就替代軟盤成爲數據交換的主流， SSD 大有替代硬盤的趨勢。 因爲發展迅速，所以其底層技術變革很快，不同於磁盤類存儲技術有很多公開資料可以獲取， 閃存類存儲的技術細節通常是廠商們的祕密，互聯網上能找到很多外圍資料， 但是關於其如何運作的細節卻很少提到。所以我想先整理一篇筆記，記下我蒐集到的資料，加上我自己的理解。 本文大部分信息來源是 Optimizing Linux with cheap flash drives 和 A Summary on SSD & FTL ，加上我的理解，文中一些配圖也來自這兩篇文章。 1 NAND Flash 原理 比 NAND Flash 更早的 EEPROM 等存儲技術 曾經用過 NOR Flash cell ，用於存儲主板配置信息等少量數據已經存在 PC 中很久了。後來 NAND Flash 的微型化使得 NAND Flash 可以用於存儲大量數據，急劇降低了存儲成本，所以以 NAND Flash 爲基礎的存儲技術能得以替代硬盤等存儲設備。 Tutorial: Why NAND Flash Breaks Down 這裏不想涉及太多 NAND Flash 硬件細節，有個演講 Tutorial: Why NAND Flash Breaks Down 和 YouTube 視頻 介紹了其原理，感興趣的可以參考一下。只羅列一下視頻中提到的一些 NAND Flash 的特點： NAND Flash 使用 floating gate 中束縛電子來保存二進制數據，對這些 Cell 有讀取（Read）、 寫入（Programming）、擦除（Erase）的操作。擦寫次數叫 P/E cycle。 電子的量導致的電勢差可以區別 1 和 0 ，這是 Single Level Cell (SLC) 的存儲方式。 或者可以用不同的電勢差區分更多狀態保存更多二進制位，從而有 Multi-Level Cell (MLC)， TLC， QLC 等技術。可以對 MLC 的 Flash Cell 使用類似 SLC 的寫入模式，物理區別只是參考電壓， 只是 SLC 模式寫入下容量減半。 高密度設計下，一組 NAND Flash Cell 可以同時併發讀寫。所以有了讀寫頁 2KiB/4KiB 這樣的容量。 頁面越大，存儲密度越高，爲了降低成本廠商都希望提高讀寫頁的大小。 爲了避免添加額外導線，NAND Flash Cell 是使用基板上加負電壓的方式擦除 floating gate 中的二進制位的，所以擦除操作沒法通過地址線選擇特定 Cell 或者讀寫頁，於是整塊擦除有塊大小。 寫入操作對 SLC 單個 Cell 而言，就是把 1 置 0 ，而擦除操作則是把整塊置 1 。SLC 可以通過地址線單獨選擇要寫入的 Cell ，MLC 則把不同頁的二進制放入一個 Cell ，放入時有順序要求， 先寫處於高位的頁，再寫低位的。所以 MLC 中不同頁面地址的頁面是交錯在同一組 Cell 中的。 SLC 其實並沒有特別要求擦除塊中的寫入順序，只是要求僅寫一次（從 1 到 0）。 MLC 則有先寫高位頁再寫低位頁的要求。廠商規格中的要求更嚴格，擦除塊中必須滿足按頁面編號順序寫入。 寫入和擦除操作是通過量子隧道效應把電子困在 floating gate 中的，所以是個概率事件。通過多次脈衝 可以縮小發生非預期概率事件的可能性，但是沒法完全避免，所以需要 ECC 校驗糾錯。 根據 ECC 強度通常有三種 ECC 算法，強度越強需要越多算力： 漢民碼 可根據 n bit 探測 \\(2&#94;n - n -1\\) 中的 2 bit 錯誤，修正 1 bit 錯誤。 BCH碼 可根據 \\(n*m\\) bit 糾錯 \\(2&#94;n\\) bit 中的 m bit 錯誤。 LDPC 原理上類似擴展的漢民碼，能做到使用更少校驗位糾錯更多錯誤。 因爲 ECC 的存在，所以讀寫必須至少以 ECC 整塊爲單位，比如 256 字節或者整個頁面。 也因爲 ECC 的存在， \\(ECC(\\texttt{0xFF}) \\ne \\texttt{0xFF}\\) ，空頁（擦除後全1的頁面）必須特殊處理。所以需要區分寫了數據全 1 的頁和空頁。 ECC校驗多次失敗的頁面可以被標記爲壞頁，出廠時就可能有一些壞頁，這些由轉換層隱藏起來。 斷電後，也有小概率下束縛的電子逃逸出 floating gate ，時間越長越可能發生可以探測到的位反轉。 所以基於 NAND Flash 的存儲設備應該避免作爲存檔設備離線保存。 電子逃逸的概率也和溫度有關，溫度越高越容易逃逸，所以高溫使用下會有更高的校驗錯誤率。 讀取時，因爲用相對較高的電壓屏蔽沒有讀取的地址線，有一定概率影響到沒被讀取的頁面中存儲的數據。 控制器可能考慮週期性地刷新這些寫入後多次讀取的頁面，這可能和後文的靜態擦寫均衡一起做。 正在寫入或者擦除中突然斷電的話下，寫入中的一整頁數據可能並不穩定，比如短期內能正常讀取但是難以持續很長時間。 MLC 擦寫次數與錯誤率 上篇講硬盤的筆記中提到過，硬盤物理存儲也有越來越強的校驗機制，不過相比之下 NAND Flash 出現臨時性校驗失敗的可能性要高很多，需要控制器對校驗出錯誤的情況有更強的容忍能力。 廠商們製作存儲設備的時候，有一個需要達到的錯誤率目標（比如每 \\(10&#94;{-14}\\) bit 出現一次位反轉），針對這個目標和實際物理錯誤率，相應地設計糾錯強度。校驗太強會浪費存儲密度和算力， 從而提升成本，這裏會根據市場細分找折衷點。 2 封裝結構 從外部來看，一個閃存盤可能有這樣的結構： ssd-enclosure.svg 從上往下，我們買到的一個閃存盤可能一層層分級： 整個閃存盤有個控制器，其中含有一部分 RAM 。然後是一組 NAND Flash 封装芯片（chip）。 每個封装芯片可能還分多個 Device ，每個 Device 分多個 Die ，這中間有很多術語我無法跟上，大概和本文想討論的事情關係不大。 每個 Die 分多個平面（Plane），平面之間可以並行控制，每個平面相互獨立。從而比如在一個平面內 做某個塊的擦除操作的時候，別的平面可以繼續讀寫而不受影響。 每個平面分成多個段（Segment)，段是擦除操作的基本單位，一次擦除一整個段。 每個段分成多個頁面（Page），頁面是讀寫操作的基本單位，一次可以讀寫一整頁。 頁面內存有多個單元格（Cell），單元格是存儲二進制位的基本單元，對應 SLC/MLC/TLC/QLC 這些， 每個單元格可以存儲一個或多個二進制位。 以上這些名字可能不同廠商不同文檔的稱法都各有不同，比如可能有的文檔把擦除塊叫 page 或者叫 eraseblock 。隨着容量不斷增大，廠商們又新造出很多抽象層次，比如 chip device die 這些， 不過這些可能和本文關係不大。如果看別的文檔注意區別術語所指概念，本文中我想統一成以上術語。 重要的是有並行訪問單元的平面（Plane）、擦除單元的段（Segment）、讀寫單元的頁（Page）這些概念。 抽象地列舉概念可能沒有實感，順便說一下這些概念的數量級： 每个 SSD 可以有数个封装芯片。 每个芯片有多个 Die 。 每个 Die 有多个平面。 每个平面有幾千個段。比如 2048 個。 每個段有數百個頁到幾千頁，比如 128~4096 頁，可能外加一些段內元数据。 每個頁面是 2KiB~8KiB 這樣的容量，外加幾百字節的元數據比如 ECC 校驗碼。 和硬盤相比，一個閃存頁面大概對應一個到數個物理扇區大小，現代硬盤也逐漸普及 4KiB 物理扇區， 文件系統也基本普及 4KiB 或者更大的邏輯塊（block）或者簇（cluster）大小，可以對應到一個閃存頁面。 每次讀寫都可以通過地址映射直接對應到某個閃存頁面，這方面沒有硬盤那樣的尋址開銷。 閃存盤的一個頁面通常配有比硬盤扇區更強的 ECC 校驗碼，因爲 NAND 單元格喪失數據的可能性比磁介質高了很多。 閃存有寫入方式的限制，每次寫入只能寫在「空」的頁面上，不能覆蓋寫入已有數據的頁面。 要重複利用已經寫過的頁面，需要對頁面所在段整個做擦除操作，每個段是大概 128KiB 到 8MiB 這樣的數量級。每個擦除段需要統計校驗失敗率或者跟蹤擦除次數，以進行擦寫均衡（Wear Leveling）。 3 擦寫均衡（Wear Leveling）和映射層（Flash Translation Layer） Animation: wear leveling on SSD drives 擦除段的容量大小是個折衷，更小的擦除段比如 128KiB 更適合隨機讀寫， 因爲每隨機修改一部分數據時需要垃圾回收的粒度更小；而使用更大的擦除段可以減少元數據和地址映射的開銷。 從擦除段的大小這裏，已經開始有高端閃存和低端閃存的差異，比如商用 SSD 可能比 U 盤和 SD 卡使用更小的擦除段大小。 閃存盤中維護一個邏輯段地址到物理段地址的映射層，叫閃存映射層（Flash Translation Layer ）。每次寫一個段的時候都新分配一個空段， 寫完後在映射表中記錄其物理地址。映射表用來在讀取時做地址轉換，所以映射表需要保存在閃存盤控制器的 RAM 中，同時也需要記錄在閃存內。具體記錄方式要看閃存盤控制器的實現，可能是類似日誌的方式記錄的。 「段地址映射表」的大小可以由段大小和存儲設備容量推算出來。比如對一個 64GiB 的 SD 卡，如果使用 4MiB 的段大小，那麼需要至少 16K 個表項。假設映射表中只記錄 2B 的物理段地址， 那麼需要 32KiB 的 RAM 存儲段地址映射表。對一個 512GiB 的 SSD ，如果使用 128KiB 的段大小， 那麼至少需要 4M 個表項。記錄 4B 的物理段地址的話，需要 16MiB 的 RAM 存儲地址映射， 或者需要動態加載的方案只緩存一部分到 RAM 裏。控制器中的 RAM 比 NAND 要昂貴很多，這裏可以看出成本差異。 除了地址映射表，每個物理段還要根據擦除次數或者校驗錯誤率之類的統計數據，做擦寫均衡。有兩種擦寫均衡： 動態擦寫均衡（Dynamic Wear Leveling）：每次寫入新段時選擇擦除次數少的物理段。 靜態擦寫均衡（Static Wear Leveling）：空閒時，偶爾將那些許久沒有變化的邏輯段搬運到 多次擦除的物理段上。 低端閃存比如 SD 卡和 U 盤可能只有動態擦寫均衡，更高端的 SSD 可能會做靜態擦寫均衡。 靜態擦寫均衡想要解決的問題是：盤中寫入的數據可以根據寫入頻率分爲冷熱， 總有一些冷數據寫入盤上就不怎麼變化了，它們佔用着的物理段有比較低的擦除計數。 只做動態擦寫均衡的話，只有熱數據的物理段被頻繁擦寫，加速磨損， 通過靜態擦寫均衡能將冷數據所在物理段釋放出來，讓整體擦寫更平均。 但是靜態擦寫均衡搬運數據本身也會磨損有限的擦寫次數，這需要優秀的算法來折衷。 除了擦寫均衡用的統計數據外， FTL 也要做壞塊管理。閃存盤出廠時就有一定故障率，可能有一部分壞塊。 隨着消耗擦寫週期、閒置時間、環境溫度等因素影響，也會遇到一些無法再保證寫入正確率的壞塊。 NAND Flash 上因爲量子隧道效應，偶爾會有臨時的校驗不一致，遇到這種情況，除了根據 ECC 校驗恢復數據， FTL 也負責嘗試對同一個物理段多次擦除和讀寫，考察它的可用性。排除了臨時故障後， 如果校驗不一致的情況仍然持續，那麼需要標註它爲壞塊，避免今後再寫入它。 出廠時，閃存盤配有的物理段數量就高於標稱的容量，除了出廠時的壞塊之外，剩餘的可用物理段可以用於 擦寫均衡，這種行爲稱作 Over Provisioning 。除了盤內預留的這些空間，用戶也可以主動通過分區的方式或者文件系統 TRIM 的方式預留出更多可用空間， 允許 FTL 更靈活地均衡擦寫。 4 段內寫入順序與垃圾回收策略 段是閃存盤的擦寫單元，考慮到段是 128KiB ~ 8MiB 這樣的數量級，現實中要求每次連續寫入一整段的話， 這樣的塊設備接口不像硬盤的接口，不方便普通文件系統使用。所以在段的抽象之下有了更小粒度的頁面抽象， 頁面對應到文件系統用的邏輯塊大小，是 2KiB~8KiB 這樣的數量級，每次以頁面爲單位讀寫。 寫入頁面時有段內連續寫入的限制，於是需要段內映射和垃圾回收算法，提供對外的隨機寫入接口。 寫入操作時， FTL 控制器內部先「打開（open）」一個段，等寫入完成，再執行垃圾回收「關閉(close)」一個段。 寫入過程中處於打開狀態的段需要一些額外資源（RAM等）跟蹤段內的寫入狀況，所以閃存盤同時能「打開」 的段數量有限。並且根據不同的垃圾回收算法，需要的額外資源也不盡相同，在 Optimizing Linux with cheap flash drives 一文中介紹幾種可能的垃圾回收算法： 4.1 線性寫入優化 Animations: linear-access optimized 假設寫入請求大部分都是連續寫入，很少有地址跳轉，那麼可以使用線性優化算法。 Open：當第一次打開一個段，寫入其中一頁時，分配一個新段。如果要寫入的頁不在段的開頭位置，那麼搬運寫入頁面地址之前的所有頁面到新段中。 Write: 在 RAM 中跟蹤記錄當前寫入位置，然後按順序寫下新的頁面。 Close: 最後搬運同段中隨後地址上的頁面，並關閉整段，調整段映射表。 如果在段內寫入了幾頁之後，又跳轉到之前的位置，那需要在跳轉時關閉當前段寫入（並完整搬運剩下的頁面）， 然後重新打開這一段，搬運調轉地址之前的頁面，從跳轉的頁面位置開始寫入。 線性優化算法的好處在於：沒有複雜的頁面地址映射，段內的邏輯頁面地址就是物理頁面地址。 讀一頁的時候根據頁面偏移和當前寫入位置就能判斷讀新物理段還是老物理段。遇到突然斷電之類的情況， 即使丟失最近寫入的新物理段，老物理段的數據仍然還在，所以沒必要保存 RAM 中的地址映射到閃存元數據中。 線性優化算法的壞處是:每遇到一次亂序的寫入，都要整段執行一次搬運，造成 寫入放大（Write Amplification） 。 一些文檔中，將這種地址映射垃圾回收方式叫做「段映射（Segment Mapping）」，因爲從 FTL 全局來看只維護了擦寫段的地址映射關係。 4.2 段內地址映射 Animations: block remapping 對需要隨機亂序寫入的數據，可以使用段內地址映射。方式是額外在段外的別的閃存區域維護一張段內地址映射表， 像段地址一樣，通過查表間接訪問頁面地址。 Open: 分配一塊新的段，同時分配一個新的段內映射表。 Write: 每寫入一頁，在段內映射表記錄頁面的在新段中的物理地址。 Close: 複製老段中沒有被覆蓋寫入的頁到新段，並記錄在段內映射表中，然後釋放老段和老的段內映射表。 也就是說同時維護兩塊不同大小的閃存空間，一塊是記錄段數據的，一塊是記錄段內地址映射表的， 兩塊閃存空間有不同的寫入粒度。可以在每個物理段內額外留出一些空間記錄段內地址映射表，也可以在 FTL 全局維護一定數量的段內地址映射表。 每次讀取段內的數據時，根據映射表的內容，做地址翻譯。新段中頁面的排列順序將是寫入的順序， 而不是地址順序。 根據實現細節，段內地址映射可以允許覆蓋寫入老段中的頁面，但是可能不允許覆蓋寫入新段（正在寫入的段） 中已經寫入的頁面，遇到一次連續的寫請求中有重複寫入某一頁面的時候，就需要關閉這一段的寫入，然後重新打開。 段內地址映射的優點是：支持隨機寫入，並且只要段處於打開狀態，隨機寫入不會造成寫入放大（Write Amplification）。 缺點是：首先地址映射這層抽象有性能損失。其次遇到突然斷電之類的情況， 下次上電後需要掃描所有正打開的段並完成段的關閉操作。 和「段映射」術語一樣，在一些文檔中，將這種段內地址映射的方式叫做「頁面映射（Page Mapping）」，因爲從 FTL 全局來看跳過了擦寫段這一層，直接映射了頁面的地址映射。 4.3 日誌式寫入 Animations: data logging 除了大量隨機寫入和大量連續寫入這兩種極端情況，大部分文件系統的寫入方式可能會是對某個地址空間 進行一段時間的隨機寫入，然後就長時間不再修改，這時適合日誌式的寫入方式。 日誌式的寫入方式中寫入一段採用三個物理段：老物理段，用於日誌記錄的新物理段，和垃圾回收後的段。 Open: 分配一塊新的段。可能額外分配一個用於記錄日誌的段，或者將日誌信息記錄在數據段內。 Write：每寫入一頁，同時記錄頁面地址到日誌。 Close：再分配一個新段執行垃圾回收。按日誌中記錄的地址順序將數據段中（新寫入）的頁面或者老段中 沒有被覆蓋的頁面複製到垃圾回收結束的新段中。 日誌式寫入在寫入過程中像段內地址映射的方式一樣，通過日誌記錄維護頁面地址映射關係， 在寫入結束執行垃圾回收之後，則像線性寫入的方式一樣不再需要維護頁面映射。 可以說日誌式寫入某種程度上綜合了前面兩種寫入方式的優點。 日誌式寫入的優點：允許隨機順序寫入，並且在執行垃圾回收之後，不再有間接訪問的地址轉換開銷。 日誌式寫入的缺點：觸發垃圾回收的話，可能比段地址映射有更大的寫入放大（Write Amplification）。 在一些文檔中，將這種日誌式寫入方式稱作「混合映射（Hybrid Mapping）」，因爲在段開啓寫入期間行爲像頁面映射， 在段關閉寫入後行爲像段映射。 5 針對特定寫入模式的優化 上述三種地址映射和垃圾回收方式，各有不同的優缺點，根據數據塊的寫入模式可能需要挑選相應的策略。 並且「全局段地址映射表」、「段內頁面地址映射表」、「寫入頁面地址日誌」之類的元數據因爲頻繁修改， FTL 也可能需要用不同的策略來記錄這些元數據。這裏面向不同使用場景的閃存設備可能有不同的 FTL 策略，並且 FTL 可能根據邏輯地址來選擇哪種策略。 5.1 混合垃圾回收策略 Performance measurements on a class 10 SDHC card 用來記錄照片、視頻等的 SD 卡、microSD、U盤等設備可能根據數據的邏輯地址，爲特定文件系統佈局優化， 這裏特定文件系統主要是指 FAT32 和 exFAT 這兩個 FAT 系文件系統。 FAT 系文件系統的特點在於， 地址前端有一塊空間被用來放置 文件分配表(File Allocation Table) ，可以根據文件系統簇大小和設備存儲容量推算出 FAT 表佔用大小，這塊表內空間需要頻繁隨機讀寫。 對 FTL 自身的元數據，和 FAT 表的邏輯地址空間，需要使用「段內地址映射」來保證高效的隨機讀寫， 而對隨後的數據空間可使用「線性寫入優化」的策略。 右側上圖有張性能曲線，測量了一個 class 10 SDHC 卡上，不同讀寫塊大小時，順序讀取、順序寫入、隨機寫入、 對 FAT 區域的寫入之類的性能差異。下圖是測量的讀取延遲。可以看出 FAT 區域的隨機寫入和其餘邏輯地址上有明顯不同的性能表現。 爲容納普通操作系統設計的 eMMC 和 SSD 難以預測文件系統的讀寫模式，可能需要使用更複雜的地址映射和垃圾回收策略。 比如一開始假定寫入會是順序寫入，採用「線性優化」方式；當發生亂序寫入時，轉變成類似「日誌式寫入」 的方式記錄寫入地址並做地址映射；關閉段時，再根據積累的統計數據判斷，可能將記錄的日誌與亂序的數據 合併（merge）成順序的數據塊，也可能保持頁面映射轉變成類似「段內地址映射」的策略。 5.2 利用 NAND Flash 物理特性的優化 再考慮 NAND Flash 的物理特性，因爲 MLC 要不斷調整參考電壓做寫入， MLC 的寫入比 SLC 慢一些，但是可以對 MLC Flash 使用 SLC 式的寫入， FTL 控制器也可能利用這一點，讓所有新的寫入處於 SLC 模式，直到關閉整段做垃圾回收時把積攢的 SLC 日誌段回收成 MLC 段用於長期保存。 一些網頁將這種寫入現象稱作「SLC 緩存」甚至稱之爲作弊，需要理解這裏並不是用單獨的 SLC Flash 芯片做 writeback 緩存，更不是用大 RAM 做緩存，處於 SLC 模式的寫入段也是持久存儲的。 5.3 同時打開段數 上述地址映射和垃圾回收策略都有分別的打開（open）、寫入（write）、關閉（close）時的操作， 閃存盤通常允許同時打開多個段，所以這三種操作不是順序進行的，某一時刻可能同時有多個段處在打開的狀態， 能接受寫入。不過一個平面（Plane）通常只能進行一種操作（讀、寫、擦除），所以打開寫入段時， FTL 會儘量讓寫入分部在不同的平面上。還可能有更高層次的抽象比如 Device、 Chip 、 Die 等等，可能對應閃存盤內部的 RAID 層級。 閃存盤能同時打開的段不光受平面之類的存儲結構限制，還受控制器可用內存（RAM）限制之類的。 爲 FAT 和順序寫入優化的 FTL ，可能除了 FAT 區域之外，只允許少量（2~8）個併發寫入段， 超過了段數之後就會對已經打開的段觸發關閉操作（close），執行垃圾回收調整地址映射，進而接受新的寫入。 更高端的 SSD 的 FTL 如果採用日誌式記錄地址的話，同時打開的段數可能不再侷限於可用內存限制， 連續的隨機寫入下按需動態加載段內地址映射到內存中，在空閒時或者剩餘空間壓力下才觸發垃圾回收。 5.4 預格式化 FTL 可能爲某種文件系統的寫入模式做優化，同時如果文件系統能得知 FTL 的一些具體參數（比如擦除段大小、 讀寫頁大小、隨機寫入優化區域），那麼可能更好地安排數據結構，和 FTL 相互配合。 F2FS 和 exFAT 這些文件系統都在最開頭的文件系統描述中包含了一些區域，記錄這些閃存介質的物理參數。 閃存盤出廠時，可能預先根據優化的文件系統做好格式化，並寫入這些特定參數。 5.5 TRIM 和 discard 另一種文件系統和 FTL 相互配合的機制是 TRIM 指令。TRIM 由文件系統發出，告訴底層閃存盤（ 或者別的類型的 thin provisioning 塊設備）哪些空間已經不再使用， FTL 接受 TRIM 指令之後可以避免一些數據搬運時的寫入放大。關於 TRIM 指令在 Linux 內核中的實現，有篇 The best way to throw blocks away 介紹可以參考。 考慮到 FTL 的上述地址映射原理， TRIM 一塊連續空間對 FTL 而言並不總是有幫助的。 如果被 TRIM 的地址位於正在以「段內地址映射」或「日誌式映射」方式打開的寫入段中，那麼 TRIM 掉一些頁面可能減少垃圾回收時搬運的頁面數量。但是如果 TRIM 的地址發生在已經垃圾回收結束的段中， 此時如果 FTL 選擇立刻對被 TRIM 的段執行垃圾回收，可能造成更多寫入放大， 如果選擇不回收只記錄地址信息，記錄這些地址信息也需要耗費一定的 Flash 寫入。 所以 FTL 的具體實現中，可能只接受 TRIM 請求中，整段擦除段的 TRIM ，而忽略細小的寫入頁的 TRIM 。 可見 FTL 對 TRIM 的實現是個黑盒操作，並且 TRIM 操作的耗時也非常難以預測，可能立刻返回， 也可能需要等待垃圾回收執行結束。 對操作系統和文件系統實現而言，有兩種方式利用 TRIM ： 通過 discard 掛載選項，每當釋放一些數據塊時就執行 TRIM 告知底層塊設備。 通過 fstrim 等外部工具，收集連續的空塊並定期發送 TRIM 給底層設備。 直覺來看可能 discard 能讓底層設備更早得知 TRIM 區域的信息並更好利用，但是從實現角度來說， discard 不光影響文件系統寫入性能，還可能發送大量被設備忽略掉的小塊 TRIM 區域。可能 fstrim 方式對連續大塊的區間執行 TRIM 指令更有效。 6 TL;DR 低端 vs 高端 標題中的疑問「SSD就是大U盤？」相信看到這裏已經有一些解答了。 即使 SSD 和U盤中可以採用類似的 NAND Flash 存儲芯片，由於他們很可能採用不同的 FTL 策略，導致在讀寫性能和可靠性方面都有不同的表現。（何況他們可能採用不同品質的 Flash ）。 如果不想細看全文，這裏整理一張表，列出「高端」閃存盤和「低端」閃存盤可能採取的不同策略。 實際上大家買到的盤可能處於這些極端策略中的一些中間點，市場細分下並不是這麼高低端分明。 比如有些標明着「爲視頻優化」之類宣傳標語的「外置SSD」，對消費者來說可能會覺得爲視頻優化的話一定性能好， 但是理解了 FTL 的差異後就可以看出這種「優化」只針對線性寫入，不一定適合放系統文件根目錄的文件系統。 參數 低端 高端 段大小 8MiB 128KiB 段地址映射 靜態段映射 日誌式映射 隨機寫入範圍 FTL元數據與FAT表區域 全盤 同時打開段數 4~8 全盤 物理段統計信息 無（隨機挑選空閒段） 擦除次數、校驗錯誤率等 擦寫均衡 動態均衡（僅寫入時分配新段考慮） 靜態均衡（空閒時考慮搬運） 寫入單元模式 TLC 長期存儲 MLC， 模擬 SLC 日誌 介紹完閃存類存儲，下篇來講講文件系統的具體磁盤佈局，考察一下常見文件系統如何使用 HDD/SSD 這些不同讀寫特性的設備。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"//farseerfc.me/flash-storage-ftl-layer.html"},{"title":"柱面-磁頭-扇區尋址的一些舊事","text":"在 SSD 這種新興存儲設備普及之前，很長一段時間硬盤是個人計算機的主要存儲設備。 更往前的磁帶機不常見於個人計算機，軟盤的地位很快被硬盤取代，到 SSD 出現爲止像 MiniDisc 、 DVD-RAM 等存儲設備也從未能挑戰過硬盤的地位。硬盤作爲主要存儲設備，自然也影響了文件系統的設計。 這篇筆記稍微聊一聊硬盤這種存儲設備的尋址方式對早期文件系統設計的一些影響，特別是 柱面-磁頭-扇區尋址（Cylinder-head-sector addressing, 簡稱CHS尋址）的起源和發展。 大部分內容來自維基百科 Cylinder-head-sector 詞條 這裏只是記錄筆記。現今的硬盤已經不再採用 CHS 尋址，其影響卻還能在一些文件系統設計中看到影子。 柱面、磁頭、扇區以及相關術語 磁盤示意圖（來自維基百科 Cylinder-head-sector 詞條 ） chs-illustrate-trans.svg 如右圖所示，一塊硬盤(Hard Disk Drive, HDD)是一個圓柱體轉軸上套着一些磁碟片(platter)， 然後有一條磁頭臂(actuator arm)插入磁碟片間的位置，加上一組控制芯片（controller）。 每個磁碟片有上下兩面塗有磁性材質，磁頭臂上有一組磁頭（head），每個磁頭對應磁盤的一個面， 所以比如一個 3 碟的硬盤會有 6 個磁頭。 每個磁碟片上定義了很多同心圓的磁頭軌道，叫做磁道（track），磁道位於盤面上不同半徑的位置， 通過旋轉磁碟臂能讓磁頭移動到特定的半徑上，從而讓讀寫磁頭在不同的磁道間跳轉。 不同磁頭上同磁道的同心圓共同組成一個柱面（cylinder），或者說移動磁碟臂能選定磁盤中的一個柱面。 磁道上按等角度切分成多個小段，叫做扇區（sector），每個扇區是讀寫數據時採用的最小單元。 早期在 IBM 大型機之類上使用的硬盤的扇區大小比較小，到 IBM PC 開始個人計算機用的硬盤扇區基本被統一到 512 字節。現代硬盤內部可能採用 Advanced Format 使用 4K 字節扇區。 在早期軟盤和硬盤的尋址方式被稱作「柱面-磁頭-扇區尋址」，簡稱 CHS 尋址， 是因爲這三個參數是軟件交給硬件定位到某個具體扇區單元時使用的參數。 首先柱面參數讓磁頭臂移動到某個半徑上，尋址到某個柱面，然後激活某個磁頭，然後隨着盤面旋轉， 磁頭定位到某個扇區上。 「柱面-磁頭-扇區」這個尋址方式，聽起來可能不太符合直覺，尤其是柱面的概念。直覺上， 可能更合理的尋址方式是「盤片-盤面-磁道-扇區」，而柱面在這裏是同磁道不同盤片盤面構成的一個集合。 不過理解了磁盤的機械結構的話，柱面的概念就比較合理了，尋址時先驅動磁頭臂旋轉， 磁頭臂上多個磁頭一起飛到某個磁道上，從而運動磁頭臂的動作定義了一個柱面。 柱面和磁頭（CH）組合起來能定位到某個特定的磁道，畫張圖大概如下圖所示： tikz diagram 上圖中值得注意的是磁道的編號方式，我用相同的顏色畫出了相同的磁道。因爲按照 CHS 的順序尋址，所以先定位柱面，然後選定磁頭。磁盤上按半徑從外向內定義柱面的編號，最外圈的磁道位於 0號柱面，由0號磁頭開始。隨着柱面編號增加，逐步從外圈定位到內圈。 物理 CHS 尋址 以上術語中，柱面號和磁頭號直接對應了硬盤上的物理組成部分，所以在物理 CHS 尋址方式下，通過扇區地址的寫法能對應到扇區的具體物理位置。之所以這樣描述扇區， 是因爲早期的軟盤和硬盤驅動器沒有內置的控制芯片，可以完全由宿主系統執行驅動程序驅動。 在 IBM PC 上，驅動軟盤和硬盤的是 CPU 執行位於主板 BIOS (Basic Input/Output System) 中的程序，具體來說操作系統（比如DOS）和應用程序調用 INT 13H 中斷，通過 AH=02H/03H 選擇讀/寫操作，BIOS 在中斷表中註冊的 13H 中斷處理程序執行在 CPU 上完成讀寫請求。調用 INT 13H 讀寫扇區的時候，CPU 先通過 INT 13H AH=0CH 控制硬盤的磁頭臂旋轉到特定柱面上，然後選定具體磁頭，讓磁頭保持在磁道上讀數據， 通過忙輪訓的方式等待要讀寫的扇區旋轉到磁頭下方，從而讀到所需扇區的數據。在 DOS 之後的操作系統， 比如早期的 Windows 和 Linux 和 BSD 能以覆蓋中斷程序入口表的方式提供升級版本的這些操作替代 BIOS 的程序。 以上過程中可以看出兩點觀察： CHS 尋址下，跨磁道的尋址（不同 CH 值），和磁道內的尋址（同 CH 不同 S ），是本質上不同的操作。跨磁道的尋址有移動磁頭臂的動作，會比磁道內尋址花費更多時間。 通過扇區號的磁道內尋址是個忙輪訓操作，需要佔用完整 CPU 週期。這也隱含扇區號在一個磁道內的物理排列不必是連續的。 實際上扇區號的物理排列的確不是連續的，每個物理扇區中除了用512字節記錄扇區本身的數據， 還有扇區的開始記錄和結束記錄，寫有扇區編號和扇區校驗碼。每讀到一個扇區， CPU 可能需要做一些額外操作（比如計算比對校驗、寫入內存緩衝區、調整內存段頁映射） 後纔能繼續讀下一個扇區，如果物理排列上連續編號扇區，可能等 CPU 做完這些事情後磁頭已經旋轉到之後幾個扇區上了。所以出廠時做磁盤低級格式化的時候， 會跳躍着給扇區編號，給 CPU 留足處理時間。比如下圖： tikz diagram 上圖中假設有3個柱面，每個柱面6個磁頭，每個磁道內11個扇區，並且畫出了三種不同的扇區編號跳轉情況， 分別是磁道內的扇區跳轉（+3），柱面內的磁頭跳轉（+5），以及柱面間跳轉（+10）。 實際磁盤上的柱面數、扇區數要多很多，尋址時需要跳轉的距離也可能更長，這裏只是舉例說明。 圖中和實際情況相同的是，柱面號和磁頭號從 0 開始編號，而扇區號從 1 開始編號， 所以做邏輯地址換算的時候要考慮編號差異。 早期 IBM PC 的 BIOS 使用 24bit 的 CHS 地址，其中 10bit 柱面(C)、 8bit 磁頭(H)、 6bit 扇區(S)。從而用物理 CHS 尋址方式的軟盤和硬盤驅動器最多可以尋址 1024 個柱面，256 個磁頭， 63 個扇區，其中扇區數因爲從 1 開始編號所以少了 1 個可尋址範圍。比如 3.5 吋高密度（HD）軟盤有雙面， 出廠時每面 80 磁道，每磁道 18 扇區，從而能算出 1,474,560 字節的容量。 如此跳躍編號扇區之後，不是總能給磁道中所有扇區編號，可能在磁道的末尾位置留幾個沒有使用的扇區空間， 這些是磁道內的保留扇區，可以在發現壞扇區後使用這些隱藏扇區作爲替代扇區。當然讀寫替代扇區的時候 因爲扇區尋址不連續可能會有一定性能損失。 因爲物理 CHS 尋址下，磁盤由 CPU 執行驅動程序來驅動，所以以上扇區跳躍的長短實際是由 CPU 的速度等因素決定的，理論上 CPU 越快，跳躍間隔可以越短，從而磁盤讀寫速度也能加快。磁盤出廠時， 廠商並不知道使用磁盤的計算機會是怎樣的性能，所以只能保守地根據最慢的 CPU 比如 IBM 初代 PC 搭配的 8086 的速度來決定跳躍間隔。所以在當年早期玩家們流傳着這樣一個操作：買到新硬盤， 或者升級了電腦配置之後，對硬盤做一次 低級格式化(Low level formating) ，聰明的低級格式化程序能智能安排扇區編號，提升硬盤讀寫速度，也能跳過已知壞道位置繼續編號， 甚至可能將更多保留扇區暴露成可用扇區。這對現代有硬盤控制器的硬盤而言已經沒有意義了。 邏輯 CHS 尋址 隨着硬盤容量不斷增加， BIOS 中用來 CHS 尋址的地址空間逐漸不夠用了。早期 24bit 地址按 C H S 的順序分爲 10 8 6 的位數，用 8bit 來尋址磁頭最多可以有 256 個磁頭，而只有 10bit 來尋址柱面，就只能有 1024 個柱面。最初 IBM 這麼劃分是因爲早期用於 IBM 大型機之類的硬盤可以有 厚厚一疊的盤片組，同樣的尋址方式就直接用於了 IBM PC 。而 PC 用的硬盤迫於硬盤倉空間大小， 有厚度限制，硬盤中物理盤面可能只有四五個盤片，硬盤容量增加主要是增加盤片表面的數據密度而非增加盤片數量。 於是逐漸地，硬盤廠商開始對 CHS 尋址的地址空間做一些手腳。比如最初的簡單想法是重新定義 CH ，將一些磁頭數挪用做柱面數。從而有了邏輯 CHS 尋址，其中 CH 是固定一組，通過簡單換算從 CH 值找到物理的柱面和磁頭數。結合 CH 而不映射 S 的優勢在於，從操作系統和文件系統來看依然能根據邏輯 CHS 地址估算出地址跳轉所需大概的時間，只是原本一次切換磁頭的動作可能變成一次短距離的切換柱面。 此時的操作系統和文件系統已經開始出現針對 CHS 尋址特點的優化方式， 儘量減少跨磁道的尋址能一定程度提升讀寫速度，跨磁道時的磁道間距離也會影響尋道時間， 文件系統可能會根據CHS地址來安排數據結構，優化這些尋址時間。 即便使用沒有針對 CHS 尋址方式優化過的操作系統和文件系統，比如侷限在早期 Windows 和 FAT 系文件系統上，早期這些桌面系統用戶們仍然能自己優化磁盤讀寫性能：通過分區。 分區是硬盤上連續的一段空間，早期由於 BIOS 和 bootloader 的一些技術限制， 每個分區必須對齊到柱面大小上。早期 PC 玩家們通過把一個大硬盤切分成多個小分區， 使用時儘量保持近期讀寫針對同一個分區，就可以減少尋址時的額外開銷，改善讀寫速度。 於是隱含地，CHS 尋址導致底層硬盤和上層操作系統之間有一層性能約定： 連續讀寫保證最快的讀寫速度 。硬盤實現 CHS 尋址時，調整扇區編號方式讓連續的 CHS 地址有最快讀寫速度，文件系統也根據這個約定， 按照 CHS 地址的跳躍來估算讀寫速度耗時並針對性優化。 區位記錄（Zone bit recoding, ZBR） 以上物理 CHS 尋址，其實依賴一個假設： 每個磁道上有同樣數量的扇區 。早期硬盤上也的確遵循這個假設， 所以我們上面的圖示裏纔能把一個盤面上的扇區展開成一張長方形的表格，因爲每個磁道的扇區數是一樣的。 實際上當時的硬盤都是恆定角速度（constant angular velocity, CAV）的方式讀寫，無論磁頭在哪兒， 盤片都旋轉保持恆定的轉速，所以對磁頭來說在單位時間內轉過的角度影響讀寫二進制位的數量， 而磁頭掃過的面積在這裏沒有影響。 區位記錄（來自維基百科 Zone bit recording 詞條 ） DiskStructure.svg 不過隨着硬盤容量增加，盤面的數據密度也隨之增加，單位面積中理論能容納的二進制位數量有限。 理論上，如果保持相同密度的話，盤片外圈能比內圈容納更多數據。因此硬盤廠商們開始在盤面上將磁道劃分出 區塊（zone），外圈區塊中的磁道可以比內圈區塊中的磁道多放入一些扇區。這種方式下生產出的硬盤叫 區位記錄硬盤（Zone bit recoding, ZBR），相對的傳統固定磁道中扇區數的硬盤就被叫做恆定角速度（CAV） 硬盤。 如右圖所示，區位記錄在硬盤上將多個柱面組合成一個區塊，區塊內的磁道有相同數量的扇區， 而不同區塊的磁道可以有不同數量的扇區，外圈區塊比內圈區塊有更多扇區。 顯然要支持 ZBR ，物理 CHS 尋址方式不再有效，於是 ZBR 硬盤將原本簡單的地址換算電路升級爲更複雜的磁盤控制器芯片，替代 CPU 來驅動硬盤，把來自文件系統的邏輯 CHS 地址通過換算轉換到物理 CHS 地址，並且驅動磁頭做跳轉和尋址。 從而有了獨立的控制芯片之後，硬盤讀寫扇區的速度不再受 CPU 速度影響。有了完整的邏輯-物理地址轉換後， 邏輯扇區編號不再對應物理扇區編號，上述編號跳轉和壞扇區處理之類的事情都由磁盤控制芯片代爲完成。 從而 CHS 地址已經喪失了物理意義，只留下 連續讀寫保證最快的讀寫速度 這樣的性能約定。 有了 ZBR 之後，硬盤讀寫速度也不再恆定，雖然仍然保持恆定轉速，但是讀寫外圈磁道時單位時間掃過的扇區 多於讀寫內圈磁道時掃過的扇區。所以 ZBR 硬盤的低端地址比高端地址有更快的讀寫速度， 通過硬盤測速軟件能觀察到階梯狀的「掉速」現象。 邏輯地址轉換也會造成邏輯 CHS 尋址能訪問到的扇區數少於物理 CHS 尋址的現象， 磁盤中扇區被重新編號後可能有一些扇區剩餘，於是 ZBR 硬盤的出廠低級格式化可能會均分這些訪問不到的扇區 給每個磁道作爲保留扇區，留作壞扇區後備。 另外有了獨立磁盤控制器芯片之後，扇區內的校驗算法也不再受制於 BIOS INT 13H 接口。 原本 BIOS 的 INT 13H 接口定義了每個扇區 512 字節，額外配有 4 字節校驗， 32bit 的校驗碼對 4096bit 的數據來說，只能允許一些簡單的校驗算法，比如 32bit CRC ，或者比如 漢明碼 對 4096bit 的數據需要 13bit 的校驗。突破了校驗算法限制後硬盤可以在物理扇區中放更多校驗位，使用更複雜的 ECC 算法，提供更強的容錯性。 IDE/SATA 接口的硬盤由內部控制器負責計算和比對校驗，而 SAS 接口的硬盤（主要用於服務器）可以讀取 520/528 字節長度的扇區，包含額外校驗位。 通過 ZBR ，邏輯 CHS 尋址不再侷限在具體每磁道扇區數等物理限制上，但是仍然侷限在 CHS 總位數。 24bit 的 CHS 地址能尋址 \\(1024*256*63 = 16515072\\) 個扇區，也就是 8064MiB 的空間。 於是早期很多操作系統有 7.8G 硬盤大小的限制。後來 ATA/IDE 標準提升了 CHS 尋址數量，從 24bit 到 28bit 到 32bit ，不過在系統引導早期仍然依賴 BIOS 最基本的 24bit CHS 尋址能力，於是那時候安裝系統時要求引導程序裝在前 8G 範圍內也是這個原因。 從 CHS 到 LBA 隨着硬盤大小不斷提升，無論是操作系統軟件層，還是硬盤廠商硬件層，都逐漸意識到邏輯 CHS 尋址是兩邊相互欺騙對方的騙局：文件系統根據假的 CHS 地址的提示苦苦優化，而硬盤控制器又要把物理 CHS 模擬到假的 CHS 地址上以兼容 BIOS 和操作系統。和 CS 領域太多別的事情一樣， CHS 尋址過早地暴露出太多底層抽象細節，而上層軟件又轉而依賴於這些暴露出的細節進行優化， 底層細節的變動使得上層優化不再是有意義的優化。 於是 ATA 標準 引入了 邏輯塊尋址（Logical Block Addressing, LBA） 來替代 CHS 尋址，解決其中的混亂。LBA 的思路其實就是邏輯 CHS 尋址的簡單換算，因爲 CHS 尋址下 S 從 1 開始計算，而 LBA 使用連續扇區編號，從 0 開始編號，所以換算公式如下： \\begin{equation*} LBA 地址 = ( C \\times 磁頭數 + H ) \\times 扇區數 + ( S - 1 ) \\end{equation*} 使用 LBA 尋址，操作系統和文件系統直接尋址一個連續地址空間中的扇區號， 不應該關心柱面和磁頭之類的物理參數，將這些物理細節交由磁盤控制器。 對操作系統和文件系統這些上層軟件而言，LBA尋址的抽象仍然保證了 連續讀寫提供最快的讀寫速度 ，文件系統仍然會嘗試根據 LBA 地址優化，儘量連續讀寫從而減少尋道時間。 從 CHS 尋址切換到 LBA 尋址，需要硬盤和操作系統兩方面的努力，所以很長一段時間， 硬盤同時支持兩種尋址方式，在控制器內部做轉換。最後需要放棄支持的是深植了 CHS 尋址的 BIOS ，使用 BIOS 引導的 MBR 引導程序還在用 CHS 尋址方式讀取數據加載操作系統，直到大家都切換到 UEFI 。 並且隨着硬盤使用 LBA 尋址，導致上層軟件很難預測底層硬件實際切換柱面切換磁頭之類的時機， 潛在地導致一些性能不確定性。於是硬盤控制器在除了負責實際驅動物理磁盤之外， 還開始負責維護一塊盤內緩衝區，實現盤內的 IO 隊列。緩衝區的存在允許磁盤控制器同時接收更多來自上層軟件 的讀寫請求，轉換成實際物理佈局參數，並根據磁盤物理佈局來調整讀寫順序，增加總體吞吐率。 比如 ATA TCQ 和 SATANCQ 就是這樣的盤內隊列協議。 當然有緩衝區和盤內隊列的存在也使得突然斷電之類的情況下更難保證數據一致性，於是 SCSI/SATA 標準開始約定特殊的請求，從操作系統能發送命令讓底層設備清空自己的讀寫隊列。 疊瓦磁記錄（Shingled Magnetic Recording, SMR） 逐漸從歷史講到了現在，隨着硬盤記錄密度的不斷增加，硬盤廠商們也在不斷發明新技術嘗試突破磁盤記錄的物理極限。 因爲有了在硬盤上獨立的控制器，並且切換到了邏輯塊地址（LBA）的尋址方式， 操作系統大部分時候不用再關心底層硬盤的物理技術革新，比如垂直寫入技術（perpendicular magnetic recording, PMR）將磁頭記錄方式從水平轉換成垂直記錄，增加了記錄密度，但不影響尋址方式。 疊瓦磁記錄（來自 The Feasibility of Magnetic Recording at 10 Terabits Per Square Inch on Conventional Media ） 不過技術革新中也有影響尋址方式的技術，比如 疊瓦磁記錄技術（Shingled Magnetic Recording, SMR） 。 SMR 技術基於一個技術事實：物理上磁頭的寫入頭（write head）需要比讀取頭(read head )佔用更大面積，如果按照寫入頭的物理極限放置磁記錄，那麼對於讀取頭會有很多空間浪費。從而 SMR 試圖讓相鄰磁道的寫入有部分重疊，從而增加記錄密度。即便重疊了相鄰磁道，讀取磁道還是能隨機定位， 而寫入磁道會覆蓋它後面疊加上的磁道，所以寫入磁道必須嚴格按地址順序寫入。爲了滿足隨機順序寫入的需要， SMR 硬盤把連續的幾個磁道組織成區塊（zone），在一個區塊內必須按順序寫入。 這裏的區塊可以和區位記錄（ZBR）是同樣的區塊，也可以獨立於 ZBR 做不同大小的區塊分割。 這種區塊內連續寫入的要求，很像是 SSD 這種基於閃存介質的記錄方式， SMR 硬盤也同樣像 SSD 一樣在磁盤控制器內引入 日誌結構式的記錄方式，採用類似的 GC 算法 ，收到隨機寫入請求的時候，在區塊間執行 GC 搬運數據塊，對操作系統提供可以任意寫入的抽象接口。 當然這種類似閃存介質的 FTL 的抽象有對讀寫性能的直接影響。SMR 硬盤可以將這些細節完全隱藏起來（ Device Managed），或者完全暴露給宿主系統（Host Managed ），或者在讀寫時隱藏細節的同時在宿主想查詢的時候提供接口查詢（Host Aware）。和 SSD 一樣，消費級的 SMR 硬盤通常選擇隱藏細節只在被詢問時暴露，完全暴露細節的設備通常只在企業服務器級別 的產品中看到。 可以期待，隨着 SMR 硬盤的逐漸普及，文件系統設計中也將更多考慮 SMR 的特性加以優化。這些優化可能參考 對 SSD 的優化（比如儘量連續寫入），但是又不能完全照搬（比如 SSD 需要考慮寫平衡而 SMR 硬盤不需要，比如 SSD 不用擔心隨機尋道時間而 SMR 硬盤需要）。這些對現在和未來文件系統的設計提供了更多挑戰。 4KiB 扇區大小 不侷限於硬盤，存儲設備發展中另一個方向是增加扇區大小。如前所述，在應用於 PC 之前的硬盤設計也曾有過比 512 字節更小的扇區大小，而自從 PC 普及之後 512 字節扇區逐漸成爲主流， 甚至到了揮之不去的地步。隨着硬盤容量提升，直接尋址 512 字節的扇區顯得不再那麼高效， 文件系統內部也早已把多個扇區合併成一個邏輯簇（cluster）或者塊（block），按簇或塊的粒度管理。 在底層硬件同樣也是按照 512 字節大小劃分扇區，每個扇區都要獨立計算校驗，如果能增大扇區大小到比如 4KiB，將能更經濟地安排扇區校驗碼，從而得到更多可用容量。可見 512 字節扇區大小這一設計，和 CHS 尋址一樣，逐漸成爲了操作系統和硬盤廠商彼此間互相努力維護的謊言。 硬盤物理扇區提升爲 4KiB 大小的設計，叫做「 先進格式化（Advanced Format） 」，這樣的硬盤叫做先進格式化硬盤（AFD）。在此基礎上，硬盤控制器可以提供模擬 512 字節扇區的模擬層， 叫做 512e ，也可以直接提供 4K 大小的扇區給操作系統，叫做 4K native (4Kn)。 操作系統和文件系統要儘量避免依賴 512e 以提供最優性能，支持 4Kn 扇區尋址也是現在和未來 文件系統設計中一個重要挑戰。 雙磁頭臂（Dual Actuator） 雙磁頭臂（來自 Seagate Storage Update - LOC Designing Storage Architecture for Digital Collections ） 除了提升容量，硬盤發展的另一個方向是提升讀寫速度。通過上述 CHS 尋址方式可見， 傳統方式下提升硬盤讀寫速度有兩種方式： 提升磁記錄密度 提升（磁頭臂和盤片）轉速 第一種方式提升記錄密度，在增加容量的同時也能提升硬盤讀寫速度，所以是長久以來硬盤廠商的主要方式。 第二種方式提升轉速則很快就遇到了物理瓶頸，硬盤以前是 5400rpm 現在最高能到 15000rpm 附近，高速旋轉的盤片就像一個螺旋槳一樣，外圈線速度已經到了接近聲速，很難再往上提升。 以及盤片轉速影響連續讀寫速度，而磁頭臂轉速影響尋道速度，高速尋道對磁頭臂旋轉有極高精度要求。 所以長久以來，衡量硬盤速度有兩項指標：連續讀寫速度和每秒操作數(IOPS)，隨着容量提升， 也在提升連續讀寫速度，但是很難提升 IOPS ，相對而言隨機尋道所需的開銷越來越昂貴。 目前硬盤廠商們在嘗試一種新的方式提升硬盤 IOPS ：增加一條磁頭臂。一個硬盤驅動器內封入兩組甚至多組 磁頭臂，每個磁頭臂能獨立旋轉，從而能獨立尋址定位。這樣的硬盤叫雙/多磁頭臂（Dual/Multi Actuator）硬盤。 從操作系統角度來看，雙磁頭臂硬盤更像是一根連接線上接有等容量的兩個獨立驅動器， 可以在盤內控制器上組 RAID0 ，或者把兩個磁頭臂都暴露給操作系統，由操作系統組 RAID0 或更智能地使用獨立尋址的能力。 結論（TL;DR）和預告 軟件層面的優化與硬件層面的革新一直是一組矛盾。長久以來文件系統和硬盤設備在關於尋址方式的磨合中， 逐漸演化出一條真理，也是我文中一直在強調的： 連續讀寫提供最快的讀寫速度 。文件系統總是能根據底層設備暴露出的一些抽象泄漏，比如物理 CHS 佈局，比如 512 字節扇區大小， ，針對性做更多優化，但是隨着底層設備的技術革新這些優化也隨之成爲泡影。 從 SMR 技術中也能看出， 硬盤的讀寫接口也在逐漸向 SSD 的接口靠攏，從而文件系統的「優化」也在逐漸 向這種「傾向順序寫入」的方向優化。關於這些發展趨勢待我有空再談。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"//farseerfc.me/history-of-chs-addressing.html"},{"title":"Btrfs vs ZFS 實現 snapshot 的差異","text":"zfs 這個東西倒是名不符實。叫 z storage stack 明顯更符合。 叫 fs 但不做 fs 自然確實會和 btrfs 有很大出入。 我反而以前還好奇為什麼 btrfs 不弄 zvol ， 直到我意識到這東西真是一個 fs ，名符奇實。 —— 某不愿透露姓名的 Ext2FSD 開發者 Btrfs 和 ZFS 都是開源的寫時拷貝（Copy on Write, CoW）文件系統，都提供了相似的子卷管理和 快照(snapshot）的功能。網上有不少文章都評價 ZFS 實現 CoW FS 的創新之處，進而想說「 Btrfs 只是 Linux/GPL 陣營對 ZFS 的拙劣抄襲」。或許（在存儲領域人盡皆知而在領域外）鮮有人知，在 ZFS 之前就有 NetApp 的商業產品 WAFL (Write Anywhere File Layout) 實現了 CoW 語義的文件系統，並且集成了快照和卷管理之類的功能。描述 btrfs 原型設計的 論文 和 發表幻燈片 也明顯提到 WAFL 比提到 ZFS 更多一些，應該說 WAFL 這樣的企業級存儲方案纔是 ZFS 和 btrfs 共同的靈感來源，而無論是 ZFS 還是 btrfs 在其設計中都汲取了很多來自 WAFL 的經驗教訓。 我一開始也帶着「 Btrfs 和 ZFS 都提供了類似的功能，因此兩者必然有類似的設計」這樣的先入觀念，嘗試去使用這兩個文件系統， 卻經常撞上兩者細節上的差異，導致使用時需要不盡相同的工作流， 或者看似相似的用法有不太一樣的性能表現，又或者一邊有的功能，比如 ZFS 的在線去重（in-band dedup） ， Btrfs 的 reflink ，在另一邊沒有的情況，進而需要不同細粒度的子卷劃分方案。後來看到了 LWN 的這篇 《A short history of btrfs》 讓我意識到 btrfs 和 ZFS 雖然表面功能上看起來類似，但是實現細節上完全不一樣， 所以需要不一樣的用法，適用於不一樣的使用場景。 爲了更好地理解這些差異，我四處蒐羅這兩個文件系統的實現細節，於是有了這篇筆記， 記錄一下我查到的種種發現和自己的理解。 （或許會寫成一個系列？還是先別亂挖坑不填。） 只是自己的筆記，所有參閱的資料文檔都是二手資料，沒有深挖過源碼，還參雜了自己的理解， 於是難免有和事實相違的地方，如有寫錯，還請留言糾正。 1 Btrfs 的子卷和快照 關於寫時拷貝（CoW）文件系統的優勢，我們爲什麼要用 btrfs/zfs 這樣的寫時拷貝文件系統， 而不是傳統的文件系統設計，或者寫時拷貝文件系統在使用時有什麼區別之類的，網上同樣也能找到很多介紹 ，這裏不想再討論。這裏假設你用過 btrfs/zfs 至少一個的快照功能，知道它該怎麼用， 並且想知道更多細節，判斷怎麼用那些功能才合理。 先從兩個文件系統中（表面上看起來）比較簡單的 btrfs 的子卷（subvolume）和快照（snapshot）說起。 關於子卷和快照的常規用法、推薦佈局之類的話題就不細說了，網上能找到很多不錯的資料，比如 btrfs wiki 的 SysadminGuide 頁 和 Arch wiki 上 Btrfs#Subvolumes 頁都有不錯的參考價值。 1.1 子卷和快照的術語 在 btrfs 中，存在於存儲媒介中的只有「子卷」的概念，「快照」只是個創建「子卷」的方式， 換句話說在 btrfs 的術語裏，子卷（subvolume）是個名詞，而快照（snapshot）是個動詞。 如果脫離了 btrfs 術語的上下文，或者不精確地稱呼的時候，也經常有文檔把 btrfs 的快照命令創建出的子卷叫做一個快照，所以當提到快照的時候，根據上下文判斷這裏是個動詞還是名詞， 把名詞的快照當作用快照命令創建出的子卷就可以了。或者我們可以理解爲， 互相共享一部分元數據（metadata）的子卷互爲彼此的快照（名詞） ， 那麼按照這個定義的話，在 btrfs 中創建快照（名詞）的方式其實有兩種： 用 btrfs subvolume snapshot 命令創建快照 用 btrfs send 命令並使用 -p 參數發送快照，並在管道另一端接收 btrfs send 命令的 -p 與 -c 這裏也順便提一下 btrfs send 命令的 -p 參數和 -c 參數的差異。 只看 btrfs-send(8) 的描述的話： -p <parent> send an incremental stream from parent to subvol -c <clone-src> use this snapshot as a clone source for an incremental send (multiple allowed) 看起來這兩個都可以用來生成兩個快照之間的差分，只不過 -p 只能指定一個「parent」， 而 -c 能指定多個「clone source」。在 unix stackexchange 上有人寫明了這兩個的異同 。使用 -p 的時候，產生的差分首先讓接收端用 subvolume snapshot 命令對 parent 子卷創建一個快照， 然後發送指令將這個快照修改成目標子卷的樣子，而使用 -c 的時候，首先在接收端用 subvolume create 創建一個空的子卷，隨後發送指令在這個子卷中填充內容，其數據塊儘量共享 clone source 已有的數據。 所以 btrfs send -p 在接收端產生是有共享元數據的快照，而 btrfs send -c 在接收端產生的是僅僅共享數據而不共享元數據的子卷。 定義中「互相共享一部分 元數據 」比較重要，因爲除了快照的方式之外， btrfs 的子卷間也可以通過 reflink 的形式共享數據塊。我們可以對一整個子卷（甚至目錄）執行 cp -r --reflink=always ，創建出一個副本，副本的文件內容通過 reflink 共享原本的數據，但不共享元數據，這樣創建出的就不是快照。 說了這麼多，其實關鍵的只是 btrfs 在傳統 Unix 文件系統的「目錄/文件/inode」 這些東西之外只增加了一個「子卷」的新概念，而子卷間可以共享元數據或者數據， 用快照命令創建出的子卷就是共享一部分元數據。 1.2 於是子卷在存儲介質中是如何記錄的呢？ 首先要說明， btrfs 中大部分長度可變的數據結構都是 CoW B-tree ，一種經過修改適合寫時拷貝的B樹結構，所以在 on-disk format 中提到了很多個樹。這裏的樹不是指文件系統中目錄結構樹，而是寫時拷貝B樹（CoW B-tree，下文簡稱B樹） ，如果不關心B樹細節的話可以把 btrfs 所說的一棵樹理解爲關係數據庫中的一個表， 和數據庫的表一樣 btrfs 的樹的長度可變，然後表項內容根據一個 key 排序。 B樹結構由索引 key 、中間節點和葉子節點構成。每個 key 是一個 (uint64_t object_id, uint8_t item_type, uint64_t item_extra) 這樣的三元組，三元组每一项的具体含义由 item_type 定義。 key 三元組構成了對象的概念，每個對象（object）在樹中用一個或多個表項（item）描述，同 object_id 的表項共同描述一個對象。B樹中的 key 只用來比較大小而不必連續，從而 object_id 也不必連續，只是按大小排序。有一些預留的 object_id 不能用作別的用途，他們的編號範圍是 -255ULL 到 255ULL，也就是表中前 255 和最後 255 個編號預留。 B樹中間節點和葉子節點結構大概像是這個樣子： btree_nodes btree_node header TREE_NODE key0: address key1: address key2: address ... free space btree_leaf1 header LEAF_NODE key0: offset size key1: offset size key2: offset size ... keyN offset size free space dataN ... data2 data1 data0 btree_node:key0->btree_leaf1:label btree_leaf1:e->btree_leaf1:e btree_leaf1:w->btree_leaf1:w btree_leaf1:e->btree_leaf1:e 由此，每個中間節點保存一系列 key 到葉子節點的指針，而葉子節點內保存一系列 item ，每個 item 固定大小，並指向節點內某個可變大小位置的 data 。從而邏輯上一棵B樹可以包含任何類型的 item ，每個 item 都可以有可變大小的附加數據。通過這樣的B樹結構，可以緊湊而靈活地表達很多數據類型。 有這樣的背景之後，比如在 SysadminGuide 這頁的 Flat 佈局 有個子卷佈局的例子。 toplevel (volume root directory, not to be mounted by default) +-- root (subvolume root directory, to be mounted at /) +-- home (subvolume root directory, to be mounted at /home) +-- var (directory) | \\-- www (subvolume root directory, to be mounted at /var/www) \\-- postgres (subvolume root directory, to be mounted at /var/lib/postgresql) 用圓柱體表示子卷的話畫成圖大概是這個樣子： Flat_layout toplevel toplevel root root toplevel->root home home toplevel->home var var toplevel->var postgres postgres toplevel->postgres www www var->www 上圖例子中的 Flat 佈局在 btrfs 中大概是這樣的數據結構， 其中實線箭頭是B樹一系列中間節點和葉子節點，邏輯上指向一棵B樹，虛線箭頭是根據 inode 號之類的編號的引用： Flat_layout_on_disk superblock SUPERBLOCK ... root_tree ... roottree ROOT_TREE 2: extent_tree 3: chunk_tree 4: dev_tree 5: fs_tree 6: root_dir \"default\" -> ROOT_ITEM 256 10: free_space_tree 256: fs_tree \"root\" 257: fs_tree \"home\" 258: fs_tree \"www\" 259: fs_tree \"postgres\" -7: tree_log_tree -5: orphan_root superblock:sn_root->roottree:label roottree:e->roottree:e toplevel FS_TREE \"toplevel\" 256: inode_item DIR 256: dir_item: \"root\" -> ROOT_ITEM 256 256: dir_item: \"home\" -> ROOT_ITEM 257 256: dir_item: \"var\" -> INODE_ITEM 257 256: dir_item: \"postgres\" -> ROOT_ITEM 259 257: inode_item DIR 257: dir_item: \"www\" -> ROOT_ITEM 258 roottree:root_fs->toplevel:label root FS_TREE \"root\" 256: inode_item DIR roottree:root_sub_root->root:label home FS_TREE \"home\" 256: inode_item DIR roottree:root_sub_home->home:label www FS_TREE \"www\" 256: inode_item DIR roottree:root_sub_www->www:label postgres FS_TREE \"postgres\" 256: inode_item DIR roottree:root_sub_postgres->postgres:label toplevel:toplevel_dir_root->roottree:root_sub_root toplevel:toplevel_dir_home->roottree:root_sub_home toplevel:toplevel_dir_postgres->roottree:root_sub_postgres toplevel:toplevel_dir_www->roottree:root_sub_www toplevel:e->toplevel:e 上圖中已經隱去了很多和本文無關的具體細節，所有這些細節都可以通過 btrfs inspect-internal 的 dump-super 和 dump-tree 查看到。 ROOT_TREE 中記錄了到所有別的B樹的指針，在一些文檔中叫做 tree of tree roots 。「所有別的B樹」 舉例來說比如 2 號 extent_tree ，3 號 chunk_tree ， 4 號 dev_tree ，10 號 free_space_tree ，這些B樹都是描述 btrfs 文件系統結構非常重要的組成部分，但是在本文關係不大， 今後有機會再討論它們。在 ROOT_TREE 的 5 號對象有一個 fs_tree ，它描述了整個 btrfs pool 的頂級子卷，也就是圖中叫 toplevel 的那個子卷（有些文檔用定冠詞稱 the FS_TREE 的時候就是在說這個 5 號樹，而不是別的子卷的 FS_TREE ）。除了頂級子卷之外，別的所有子卷的 object_id 在 256ULL 到 -256ULL 的範圍之間，對子卷而言 ROOT_TREE 中的這些 object_id 也同時是它們的 子卷 id ，在內核掛載文件系統的時候可以用 subvolid 找到它們，別的一些對子卷的操作也可以直接用 subvolid 表示一個子卷。 ROOT_TREE 的 6 號對象描述的不是一棵樹，而是一個名叫 default 的特殊目錄，它指向 btrfs pool 的默認掛載子卷。最初 mkfs 的時候，這個目錄指向 ROOT_ITEM 5 ，也就是那個頂級子卷，之後可以通過命令 btrfs subvolume set-default 修改它指向別的子卷，這裏它被改爲指向 ROOT_ITEM 256 亦即那個名叫 \"root\" 的子卷。 每一個子卷都有一棵自己的 FS_TREE （有的文檔中叫 file tree），一個 FS_TREE 相當於傳統 Unix 文件系統中的一整個 inode table ，只不過它除了包含 inode 信息之外還包含所有文件夾內容。在 FS_TREE 中， object_id 同時也是它所描述對象的 inode 號，所以 btrfs 的 子卷有互相獨立的 inode 編號 ，不同子卷中的文件或目錄可以擁有相同的 inode 。 或許有人不太清楚子卷間 inode 編號獨立意味着什麼，簡單地說，這意味着你不能跨子卷創建 hard link ，不能跨子卷 mv 移動文件而不產生複製操作。不過因爲 reflink 和 inode 無關， 可以跨子卷創建 reflink ，也可以用 reflink + rm 的方式快速「移動」文件（這裏移動加引號是因爲 inode 變了，傳統上不算移動）。 FS_TREE 中一個目錄用一個 inode_item 和多個 dir_item 描述， inode_item 是目錄自己的 inode ，那些 dir_item 是目錄的內容。 dir_item 可以指向別的 inode_item 來描述普通文件和子目錄， 也可以指向 root_item 來描述這個目錄指向一個子卷。有人或許疑惑，子卷就沒有自己的 inode 麼？其實如果看 數據結構定義 的話 struct btrfs_root_item 結構在最開頭的地方包含了一個 struct btrfs_inode_item 所以 root_item 也同時作爲子卷的 inode ，不過用戶通常看不到這個子卷的 inode ，因爲子卷在被（手動或自動地）掛載到目錄上之後， 用戶會看到的是子卷的根目錄的 inode 。 比如上圖 FS_TREE toplevel 中，有兩個對象，第一個 256 是（子卷的）根目錄，第二個 257 是 \"var\" 目錄，256 有4個子目錄，其中 \"root\" \"home\" \"postgres\" 這三個指向了 ROOT_TREE 中的對應子卷，而 \"var\" 指向了 inode 257 。然後 257 有一個子目錄叫 \"www\" 它指向了 ROOT_TREE 中 object_id 爲 258 的子卷。 1.3 那麼快照又是如何記錄的呢？ 以上是子卷、目錄、 inode 在 btrfs 中的記錄方式，你可能想知道，如何記錄一個快照呢？ 特別是，如果對一個包含子卷的子卷創建了快照，會得到什麼結果呢？如果我們在上面的佈局基礎上執行： btrfs subvolume snapshot toplevel toplevel/toplevel@s1 那麼產生的數據結構大概如下所示： Flat_layout_on_disk superblock SUPERBLOCK ... root_tree ... roottree ROOT_TREE 2: extent_tree 3: chunk_tree 4: dev_tree 5: fs_tree 6: root_dir \"default\" -> ROOT_ITEM 256 10: free_space_tree 256: fs_tree \"root\" 257: fs_tree \"home\" 258: fs_tree \"www\" 259: fs_tree \"postgres\" 260: fs_tree \"toplevel@s1\" -7: tree_log_tree -5: orphan_root superblock:sn_root->roottree:label roottree:e->roottree:e toplevel FS_TREE \"toplevel\" 256: inode_item DIR 256: dir_item: \"root\" -> ROOT_ITEM 256 256: dir_item: \"home\" -> ROOT_ITEM 257 256: dir_item: \"var\" -> INODE_ITEM 257 256: dir_item: \"postgres\" -> ROOT_ITEM 259 256: dir_item: \"toplevel@s1\" -> ROOT_ITEM 260 257: inode_item DIR 257: dir_item: \"www\" -> ROOT_ITEM 258 roottree:root_fs->toplevel:label toplevels1 FS_TREE \"toplevel@s1\" 256: inode_item DIR 256: dir_item: \"root\" -> ROOT_ITEM 256 256: dir_item: \"home\" -> ROOT_ITEM 257 256: dir_item: \"var\" -> INODE_ITEM 257 256: dir_item: \"postgres\" -> ROOT_ITEM 259 257: inode_item DIR 257: dir_item: \"www\" -> ROOT_ITEM 258 roottree:root_sub_s1->toplevels1:label root FS_TREE \"root\" 256: inode_item DIR roottree:root_sub_root->root:label home FS_TREE \"home\" 256: inode_item DIR roottree:root_sub_home->home:label www FS_TREE \"www\" 256: inode_item DIR roottree:root_sub_www->www:label postgres FS_TREE \"postgres\" 256: inode_item DIR roottree:root_sub_postgres->postgres:label toplevel:toplevel_dir_root->roottree:root_sub_root toplevel:toplevel_dir_home->roottree:root_sub_home toplevel:toplevel_dir_postgres->roottree:root_sub_postgres toplevel:toplevel_dir_toplevels1->roottree:root_sub_s1 toplevel:toplevel_dir_www->roottree:root_sub_www toplevel:e->toplevel:e 在 ROOT_TREE 中增加了 260 號子卷，其內容複製自 toplevel 子卷，然後 FS_TREE toplevel 的 256 號 inode 也就是根目錄中增加一個 dir_item 名叫 toplevel@s1 它指向 ROOT_ITEM 的 260 號子卷。這裏看似是完整複製了整個 FS_TREE 的內容，這是因爲 CoW b-tree 當只有一個葉子節點時就複製整個葉子節點。如果子卷內容再多一些，除了葉子之外還有中間節點， 那麼只有被修改的葉子和其上的中間節點需要複製。從而創建快照的開銷基本上是 O( level of FS_TREE )，而B樹的高度一般都能維持在很低的程度，所以快照創建速度近乎是常數開銷。 從子卷和快照的這種實現方式，可以看出： 雖然子卷可以嵌套子卷，但是對含有嵌套子卷的子卷做快照的語義有些特別 。上圖中我沒有畫 toplevel@s1 下的各個子卷到對應 ROOT_ITEM 之間的虛線箭頭， 是因爲這時候如果你嘗試直接跳過 toplevel 掛載 toplevel@s1 到掛載點， 會發現那些子卷沒有被自動掛載，更奇怪的是那些子卷的目錄項也不是個普通目錄， 嘗試往它們中放東西會得到無權訪問的錯誤，對它們能做的唯一事情是手動將別的子卷掛載在上面。 推測原因在於這些子目錄並不是真的目錄，沒有對應的目錄的 inode ，試圖查看它們的 inode 號會得到 2 號，而這是個保留號不應該出現在 btrfs 的 inode 號中。 每個子卷創建時會記錄包含它的上級子卷，用 btrfs subvolume list 可以看到每個子卷的 top level subvolid ，猜測當掛載 A 而 A 中嵌套的 B 子卷記錄的上級子卷不是 A 的時候， 會出現上述奇怪行爲。嵌套子卷的快照還有一些別的奇怪行爲，大家可以自己探索探索。 建議用平坦的子卷佈局 因爲上述嵌套子卷在做快照時的特殊行爲， 我個人建議是 保持平坦的子卷佈局 ，也就是說： 只讓頂層子卷包含其它子卷，除了頂層子卷之外的子卷只做手工掛載，不放嵌套子卷 只在頂層子卷對其它子卷做快照，不快照頂層子卷 雖然可以在頂層子卷放子卷之外的東西（文件或目錄），不過因爲想避免對頂層子卷做快照， 所以避免在頂層子卷放普通文件。 btrfs 的子卷可以設置「可寫」或者「只讀」，在創建一個快照的時候也可以通過 -r 參數創建出一個只讀快照。通常只讀快照可能比可寫的快照更有用，因爲 btrfs send 命令只接受只讀快照作爲參考點。子卷可以有兩種方式切換它是否只讀的屬性，可以通過 btrfs property set <subvol> ro 直接修改是否只讀，也可以對只讀子卷用 btrfs subvolume snapshot 創建出可寫子卷，或者反過來對可寫子卷創建出只讀子卷。 只讀快照也有些特殊的限制，在 SysadminGuide#Special_Cases 就提到一例，你不能把只讀快照用 mv 移出包含它的目錄，雖然你能用 mv 給它改名或者移動包含它的目錄 到別的地方。 btrfs wiki 上給出這個限制的原因是子卷中記錄了它的上級， 所以要移動它到別的上級需要修改這個子卷，從而只讀子卷沒法移動到別的上級（ 不過我還沒搞清楚子卷在哪兒記錄了它的上級，記錄的是上級目錄還是上級子卷）。不過這個限制可以通過 對只讀快照在目標位置創建一個新的只讀快照，然後刪掉原位置的只讀快照來解決。 2 ZFS 的文件系統、快照、克隆及其它 Btrfs 給傳統文件系統只增加了子卷的概念，相比之下 ZFS 中類似子卷的概念有好幾個，據我所知有這些： 數據集（dataset） 文件系統（filesystem） 快照（snapshot） 克隆（clone） 書籤（bookmark）：從 ZFS on Linux v0.6.4 開始 檢查點（checkpoint）：從 ZFS on Linux v0.8.0 開始 梳理一下這些概念之間的關係也是最初想寫下這篇筆記的初衷。先畫個簡圖，隨後逐一講講這些概念： 上圖中，假設我們有一個 pool ，其中有 3 個文件系統叫 fs1~fs3 和一個 zvol 叫 zv1 ，然後文件系統 fs1 有兩個快照 s1 和 s2 ，和兩個書籤 b1 和 b2。pool 整體有兩個檢查點 cp1 和 cp2 。這個簡圖將作爲例子在後面介紹這些概念。 2.1 ZFS 設計中和快照相關的一些術語和概念 數據集 ZFS 中把文件系統、快照、克隆、zvol 等概念統稱爲數據集（dataset）。 一些文檔和介紹中把文件系統叫做數據集，大概因爲在 ZFS 中，文件系統是最先創建並且最有用的數據集。 在 ZFS 的術語中，把底層管理和釋放存儲設備空間的叫做 ZFS 存儲池（pool）， 簡稱 zpool ，其上可以容納多個數據集，這些數據集用類似文件夾路徑的語法 pool_name/​dataset_path@snapshot_name 這樣來稱呼。 存儲池中的數據集一同共享可用的存儲空間，每個數據集單獨跟蹤自己所消耗掉的存儲空間。 數據集之間有類似文件夾的層級父子關係，這一點有用的地方在於可以在父級數據集上設定一些 ZFS 參數， 這些參數可以被子級數據集繼承，從而通過層級關係可以方便地微調 ZFS 參數。在 btrfs 中目前還沒有類似的屬性繼承的功能。 zvol 的概念和本文關係不大，可以參考我上一篇 ZFS 子系統筆記中 ZVOL 的說明 。用 zvol 能把 ZFS 當作一個傳統的卷管理器，繞開 ZFS 的 ZPL（ZFS Posix filesystem Layer） 層。在 Btrfs 中可以用 loopback 塊設備某種程度上模擬 zvol 的功能。 文件系統 創建了 ZFS 存儲池後，首先要在其中創建文件系統（filesystem），才能在文件系統中存儲文件。 容易看出 ZFS 文件系統的概念直接對應 btrfs 中的子卷。文件系統（filesystem）這個術語， 從命名方式來看或許是想要和（像 Solaris 的 SVM 或者 Linux 的 LVM 這樣的）傳統的卷管理器 與其上創建的多個文件系統（Solaris UFS 或者 Linux ext）這樣的上下層級做類比。 從 btrfs 的子卷在內部結構中叫作 FS_TREE 這一點可以看出，至少在 btrfs 早期設計中大概也是把子卷稱爲 filesystem 做過類似的類比的。 和傳統的卷管理器與傳統文件系統的上下層級不同的是， ZFS 和 btrfs 中由存儲池跟蹤和管理可用空間， 做統一的數據塊分配和釋放，沒有分配的數據塊算作整個存儲池中所有 ZFS 文件系統或者 btrfs 子卷的可用空間。 與 btrfs 的子卷不同的是， ZFS 的文件系統之間是完全隔離的，（除了後文會講的 dedup 方式之外）不可以共享任何數據或者元數據。一個文件系統還包含了隸屬於其中的快照（snapshot）、 克隆（clone）和書籤（bookmark）。在 btrfs 中一個子卷和對其創建的快照之間雖然有父子關係， 但是在 ROOT_TREE 的記錄中屬於平級的關係。 上面簡圖中 pool 裏面包含 3 個文件系統，分別是 fs1~3 。 快照 ZFS 的快照對應 btrfs 的只讀快照，是標記數據集在某一歷史時刻上的只讀狀態。 和 btrfs 的只讀快照一樣， ZFS 的快照也兼作 send/receive 時的參考點。 快照隸屬於一個數據集，這說明 ZFS 的文件系統或者 zvol 都可以創建快照。 ZFS 中快照是排列在一個時間線上的，因爲都是只讀快照，它們是數據集在歷史上的不同時間點。 這裏說的時間不是系統時鐘的時間，而是 ZFS 中事務組（TXG, transaction group）的一個序號。 整個 ZFS pool 的每次寫入會被合併到一個事務組，對事務組分配一個嚴格遞增的序列號， 提交一個事務組具有類似數據庫中事務的語義：要麼整個事務組都被完整提交，要麼整個 pool 處於上一個事務組的狀態，即使中間發生突然斷電之類的意外也不會破壞事務語義。 因此 ZFS 快照就是數據集處於某一個事務組時的狀態。 如果不滿於對數據集進行的修改，想把整個數據集恢復到之前的狀態，那麼可以回滾（rollback ）數據集到一個快照。回滾操作會撤銷掉對數據集的所有更改，並且默認參數下只能回滾到最近的一個快照。 如果想回滾到更早的快照，可以先刪掉最近的幾個，或者可以使用 zfs rollback -r 參數刪除中間的快照並回滾。 除了回滾操作，還可以直接只讀訪問到快照中的文件。 ZFS 的文件系統中有個隱藏文件夾叫 \".zfs\" ，所以如果只想回滾一部分文件，可以從 \".zfs/snapshots/SNAPSHOT-NAME\" 中把需要的文件複製出來。 比如上面簡圖中 fs1 就有 pool/​fs1@s1 和 pool/​fs1@s2 這兩個快照， 那麼可以在 fs1 掛載點下 .zfs/​snapshots/​s1 的路徑直接訪問到 s1 中的內容。 克隆 ZFS 的克隆（clone）有點像 btrfs 的可寫快照。因爲 ZFS 的快照是只讀的，如果想對快照做寫入，那需要先用 zfs clone 從快照中建出一個克隆，創建出的克隆和快照共享元數據和數據， 然後對克隆的寫入不影響數據集原本的寫入點。 創建了克隆之後，作爲克隆參考點的快照會成爲克隆的依賴，克隆存在期間無法刪除掉作爲其依賴的快照。 一個數據集可以有多個克隆，這些克隆都獨立於數據集當前的寫入點。使用 zfs promote 命令可以把一個克隆「升級」成爲數據集的當前寫入點，從而數據集原本的寫入點會調轉依賴關係， 成爲這個新寫入點的一個克隆，被升級的克隆原本依賴的快照和之前的快照會成爲新數據集寫入點的快照。 比如上面簡圖中 fs1 有 c1 的克隆，它依賴於 s2 這個快照，從而 c1 存在的時候就不能刪除掉 s2 。 書籤 這是 ZFS 一個比較新的特性，ZFS on Linux 分支從 v0.6.4 開始支持創建書籤的功能。 書籤（bookmark）特性存在的理由是基於這樣的事實：原本 ZFS 在 send 兩個快照間的差異的時候，比如 send S1 和 S2 之間的差異，在發送端實際上只需要 S1 中記錄的時間戳（TXG id），而不需要 S1 快照的數據， 就可以計算出 S1 到 S2 的差異。在接收端則需要 S1 的完整數據，在其上根據接收到的數據流創建 S2 。 因此在發送端，可以把快照 S1 轉變成書籤，只留下時間戳元數據而不保留任何目錄結構或者文件內容。 書籤只能作爲增量 send 時的參考點，並且在接收端需要有對應的快照，這種方式可以在發送端節省很多存儲。 通常的使用場景是，比如你有一個筆記本電腦，上面有 ZFS 存儲的數據，然後使用一個服務器上 ZFS 作爲接收端，定期對筆記本上的 ZFS 做快照然後 send 給服務器。在沒有書籤功能的時候， 筆記本上至少得保留一個和服務器上相同的快照，作爲 send 的增量參考點， 而這個快照的內容已經在服務器上，所以筆記本中存有相同的快照只是在浪費存儲空間。 有了書籤功能之後，每次將定期的新快照發送到服務器之後，就可以把這個快照轉化成書籤，節省存儲開銷。 檢查點 這也是 ZFS 的新特性， ZFS on Linux 分支從 v0.8.0 開始支持創建檢查點。 簡而言之，檢查點（checkpoint）可以看作是整個存儲池級別的快照，使用檢查點能快速將整個存儲池都恢復到上一個狀態。 這邊有篇文章介紹 ZFS checkpoint 功能的背景、用法和限制 ，可以看出當存儲池中有檢查點的時候很多存儲池的功能會受影響（比如不能刪除 vdev 、不能處於 degraded 狀態、不能 scrub 到當前存儲池中已經釋放而在檢查點還在引用的數據塊）， 於是檢查點功能設計上更多是給系統管理員準備的用於調整整個 ZFS pool 時的後悔藥， 調整結束後日用狀態下應該刪除掉所有檢查點。 2.2 ZFS 的概念與 btrfs 概念的對比 先說書籤和檢查點，因爲這是兩個 btrfs 目前完全沒有的功能。 書籤功能完全圍繞 ZFS send 的工作原理，而 ZFS send 位於 ZFS 設計中的 DSL 層面，甚至不關心它 send 的快照的數據是來自文件系統還是 zvol 。在發送端它只是從目標快照遞歸取數據塊，判斷 TXG 是否老於參照點的快照，然後把新的數據塊全部發往 send stream ；在接收端也只是完整地接收數據塊， 不加以處理，。與之不同的是 btrfs 的 send 的工作原理是工作在文件系統的只讀子卷層面， 發送端在內核代碼中根據目標快照的 b 樹和參照點快照的 generation 生成一個 diff （可以通過 btrfs subvolume find-new 直接拿到這個 diff ），然後在用戶態代碼中根據 diff 和參照點、目標快照的兩個只讀子卷的數據產生一連串修改文件系統的指令， 指令包括創建文件、刪除文件、讓文件引用數據塊（保持 reflink ）等操作；在接收端則完全工作在用戶態下， 根據接收到的指令重建目標快照。可見 btrfs send 需要在發送端讀取參照點快照的數據（比如找到 reflink 引用），從而 btrfs 沒法（或者很難）實現書籤功能。 檢查點也是 btrfs 目前沒有的功能。 btrfs 目前不能對頂層子卷做遞歸的 snapshot ，btrfs 的子卷也沒有類似 ZFS 數據集的層級關係和可繼承屬性，從而沒法實現類似檢查點的功能。 除了書籤和檢查點之外，剩下的概念可以在 ZFS 和 btrfs 之間有如下映射關係： ZFS 文件系統: btrfs 子卷 ZFS 快照: btrfs 只讀快照 ZFS 克隆: btrfs 可寫快照 對 ZFS 數據集的操作，大部分也可以找到對應的對 btrfs 子卷的操作。 zfs list: btrfs subvolume list zfs create: btrfs subvolume create zfs destroy: btrfs subvolume delete zfs rename: mv zfs snapshot: btrfs subvolume snapshot -r zfs rollback: 這個在 btrfs 需要對只讀快照創建出可寫的快照（用 snapshot 命令，或者直接修改讀寫屬性），然後改名或者調整掛載點 zfs diff: btrfs subvolume find-new zfs clone: btrfs subvolume snapshot zfs promote: 和 rollback 類似，可以直接調整 btrfs 子卷的掛載點 可見雖然功能上類似，但是至少從管理員管理的角度而言， zfs 對文件系統、快照、克隆的劃分更爲清晰， 對他們能做的操作也更爲明確。這也是很多從 ZFS 遷移到 btrfs ，或者反過來從 btrfs 換用 zfs 時，一些人困惑的起源（甚至有人據此說 ZFS 比 btrfs 好在 cli 設計上）。 不過 btrfs 子卷的設計也使它在系統管理上有了更大的靈活性。比如在 btrfs 中刪除一個子卷不會受制於別的子卷是否存在，而在 zfs 中要刪除一個快照必須先保證先摧毀掉依賴它的克隆。 再比如 btrfs 的可寫子卷沒有主次之分，而 zfs 中一個文件系統和其克隆之間有明顯的區別，所以需要 promote 命令調整差異。還有比如 ZFS 的文件系統只能回滾到最近一次的快照， 要回滾到更久之前的快照需要刪掉中間的快照，並且回滾之後原本的文件系統數據和快照數據就被丟棄了； 而 btrfs 中因爲回滾操作相當於調整子卷的掛載，所以不需要刪掉快照， 並且回滾之後原本的子卷和快照還可以繼續保留。 加上 btrfs 有 reflink ，這給了 btrfs 在使用中更大的靈活性，可以有一些 zfs 很難做到的用法。 比如想從快照中打撈出一些虛擬機鏡像的歷史副本，而不想回滾整個快照的時候，在 btrfs 中可以直接 cp --reflink=always 將鏡像從快照中複製出來，此時的複製將和快照共享數據塊； 而在 zfs 中只能用普通 cp 複製，會浪費很多存儲空間。 2.3 ZFS 中是如何存儲這些數據集的呢 要講到存儲細節，首先需要 瞭解一下 ZFS 的分層設計 。不像 btrfs 基於現代 Linux 內核，有許多現有文件系統已經實現好的基礎設施可以利用， 並且大體上只用到一種核心數據結構（CoW的B樹）； ZFS 則脫胎於 Solaris 的野心勃勃， 設計時就分成很多不同的子系統，逐步提升抽象層次， 並且每個子系統都發明了許多特定需求下的數據結構來描述存儲的信息。 在這裏和本文內容密切相關的是 ZPL 、 DSL 、 DMU 這些 ZFS 子系統。 Sun 曾經寫過一篇 ZFS 的 On disk format 對理解 ZFS 如何存儲在磁盤上很有幫助，雖然這篇文檔是針對 Sun 還在的時候 Solaris 的 ZFS ，現在 ZFS 的內部已經變化挺大，不過對於理解本文想講的快照的實現方式還具有參考意義。這裏藉助這篇 ZFS On Disk Format 中的一些圖示來解釋 ZFS 在磁盤上的存儲方式。 ZFS 的塊指針 ZFS 中用的 128 字節塊指針 zfs-block-pointer.svg 要理解 ZFS 的磁盤結構首先想介紹一下 ZFS 中的塊指針（block pointer, blkptr_t ），結構如右圖所示。 ZFS 的塊指針用在 ZFS 的許多數據結構之中，當需要從一個地方指向任意另一個地址的時候都會 插入這樣的一個塊指針結構。大多數文件系統中也有類似的指針結構，比如 btrfs 中有個8字節大小的邏輯地址（logical address），一般也就是個 4字節 到 16字節 大小的整數寫着扇區號、塊號或者字節偏移，在 ZFS 中的塊指針則是一個巨大的128字節（不是 128bit !）的結構體。 128字節塊指針的開頭是3個數據虛擬地址（DVA, Data Virtual Address），每個 DVA 是 128bit ，其中記錄這塊數據在什麼設備（vdev）的什麼偏移（offset）上佔用多大（asize)，有 3個 DVA 槽是用來存儲最多3個不同位置的副本。然後塊指針還記錄了這個塊用什麼校驗算法（ cksum ）和什麼壓縮算法（comp），壓縮前後的大小（PSIZE/LSIZE），以及256bit的校驗和（checksum）。 當需要間接塊（indirect block）時，塊指針中記錄了間接塊的層數（lvl），和下層塊指針的數量（fill）。 一個間接塊就是一個數據塊中包含一個塊指針的數組，當引用的對象很大需要很多塊時，間接塊構成一棵樹狀結構。 塊指針中還有和本文關係很大的一個值 birth txg ，記錄這個塊指針誕生時的整個 pool 的 TXG id 。一次 TXG 提交中寫入的數據塊都會有相同的 birth txg ，這個相當於 btrfs 中 generation 的概念。 實際上現在的 ZFS 塊指針似乎記錄了兩個 birth txg ，分別在圖中的9行和a行的位置， 一個 physical 一個 logical ，用於 dedup 和 device removal 。值得注意的是塊指針裏只有 birth txg ，沒有引用計數或者別的機制做引用，這對後面要講的東西很關鍵。 DSL 的元對象集 理解塊指針和 ZFS 的子系統層級之後，就可以來看看 ZFS 存儲在磁盤上的具體結構了。 因爲涉及的數據結構種類比較多，所以先來畫一張邏輯上的簡圖，其中箭頭只是某種引用關係不代表塊指針， 方框也不是結構體細節： zfs_layout_simple uberblock UBERBLOCK ... mos_blkptr mos Meta Object Set root dataset config ... uberblock:ub_rootbp->mos:mos_label root_dataset ROOT dataset dataset1 directory dataset2 directory ... mos:mos_root_dataset->root_dataset:rd_label ds1_directory DSL Directory ds1 property ZAP object ds1 child ZAP object ds1 dataset (active) ds1 snapshot1 ds1 snapshot2 ... root_dataset:rd_ds1->ds1_directory:ds1_label ds1_dataset ds1 DMU Object Set ... ds1_directory:ds1_dataset->ds1_dataset:ds1_ds_label ds1_snapshot1 ds1 snapshot1 DMU Object Set ... ds1_directory:ds1_s1->ds1_snapshot1:ds1_s1_label 如上簡圖所示，首先 ZFS pool 級別有個 uberblock ，具體每個 vdev 如何存儲和找到這個 uberblock 今後有空再聊，這裏認爲整個 zpool 有唯一的一個 uberblock 。從 uberblock 有個指針指向元對象集（MOS, Meta Object Set），它是個 DMU 的對象集，它包含整個 pool 的一些配置信息，和根數據集（root dataset）。根數據集再包含整個 pool 中保存的所有頂層數據集，每個數據集有一個 DSL Directory 結構。然後從每個數據集的 DSL Directory 可以找到一系列子數據集和一系列快照等結構。最後每個數據集有個 active 的 DMU 對象集，這是整個文件系統的當前寫入點，每個快照也指向一個各自的 DMU 對象集。 DSL 層的每個數據集的邏輯結構也可以用下面的圖表達（來自 ZFS On Disk Format ）： zfs-dsl-infrastructure.svg ZFS On Disk Format 中 4.1 節的 DSL infrastructure ZFS On Disk Format 中 4.2 節的 Meta Object Set zfs-metaobjectset.svg 需要記得 ZFS 中沒有類似 btrfs 的 CoW b-tree 這樣的統一數據結構，所以上面的這些設施是用各種不同的數據結構表達的。 尤其每個 Directory 的結構可以包含一個 ZAP 的鍵值對存儲，和一個 DMU 對象。 可以理解爲， DSL 用 DMU 對象集（Objectset）表示一個整數（uinit64_t 的 dnode 編號）到 DMU 對象的映射，然後用 ZAP 對象表示一個名字到整數的映射，然後又有很多額外的存儲於 DMU 對象中的 DSL 結構體。如果我們畫出不同的指針和不同的結構體，那麼會得到一個稍顯複雜的圖，見右邊「ZFS On Disk Format 中 4.2 節的 Meta Object Set」，圖中還只畫到了 root_dataset 爲止。 看到這裏，大概可以理解在 ZFS 中創建一個 ZFS 快照的操作其實很簡單：找到數據集的 DSL Directory 中當前 active 的 DMU 對象集指針，創建一個表示 snapshot 的 DSL dataset 結構，指向那個 DMU 對象集，然後快照就建好了。因爲今後對 active 的寫入會寫時複製對應的 DMU 對象集，所以 snapshot 指向的 DMU 對象集不會變化。 3 創建快照這麼簡單麼？那麼刪除快照呢？ 按上面的存儲格式細節來看， btrfs 和 zfs 中創建快照似乎都挺簡單的，利用寫時拷貝，創建快照本身沒什麼複雜操作。 如果你也聽到過別人介紹 CoW 文件系統時這麼講，是不是會覺得似乎哪兒少了點什麼。創建快照是挺簡單的， 直到你開始考慮如何刪除快照 …… 或者不侷限在刪除單個快照上， CoW 文件系統因爲寫時拷貝，每修改一個文件內容或者修改一個文件系統結構， 都是分配新數據塊，然後考慮是否要刪除這個數據替換的老數據塊，此時如何決定老數據塊能不能刪呢？ 刪除快照的時候也是同樣，快照是和別的文件系統有共享一部分數據和元數據的， 所以顯然不能把快照引用到的數據塊都直接刪掉，要考察快照引用的數據塊是否還在別的地方被引用着， 只能刪除那些沒有被引用的數據。 深究「如何刪快照」這個問題，就能看出 WAFL 、 btrfs 、 ZFS 甚至別的 log-structured 文件系統間的關鍵區別，從而也能看到另一個問題的答案： 爲什麼 btrfs 只需要子卷的抽象，而 zfs 搞出了這麼多抽象概念？ 帶着這兩個疑問，我們來研究一下這些文件系統的塊刪除算法。 3.1 日誌結構文件系統中用的垃圾回收算法 講 btrfs 和 zfs 用到的刪除算法之前，先講一下日誌結構（log-structured）文件系統中的垃圾回收（ GC, Garbage Collection）算法。對熟悉編程的人來說，講到空間釋放算法，大概首先會想到 GC ，因爲這裏要解決的問題乍看起來很像編程語言的內存管理中 GC 想要解決的問題：有很多指針相互指向很多數據結構，找其中沒有被引用的垃圾然後釋放掉。 首先要澄清一下 日誌結構文件系統（log-structured file system） 的定義，因爲有很多文件系統用日誌，而用了日誌的不一定是日誌結構文件系統。 在維基百科上有個頁面介紹 日誌結構文件系統 ，還有個 列表列出了一些日誌結構文件系統 。通常說，整個文件系統的存儲結構都組織成一個大日誌的樣子，就說這個文件系統是日誌結構的， 這包括很多早期學術研究的文件系統，以及目前 NetBSD 的 LFS 、Linux 的 NILFS ，用在光盤介質上的 UDF ，還有一些專門爲閃存優化的 JFFS 、 YAFFS 以及 F2FS 。日誌結構文件系統不包括那些用額外日誌保證文件系統一致性，但文件系統結構不在日誌中的 ext4 、 xfs 、 ntfs 、 hfs+ 。 簡單來說，日誌結構文件系統就是把存儲設備當作一個大日誌，每次寫入數據時都添加在日誌末尾， 然後用寫時複製重新寫入元數據，最後提交整個文件系統結構。因爲這裏用了寫時複製，原本的數據塊都還留着， 所以可以很容易實現快照之類的功能。從這個特徵上來說，寫時拷貝文件系統（CoW FS）像 btrfs/zfs 這些在一些人眼中也符合日誌結構文件系統的特徵， 所以也有人說寫時拷貝文件系統算是日誌結構文件系統的一個子類。不過日誌結構文件系統的另一大特徵是利用 GC 回收空間，這裏是本文要講的區別，所以在我看來不用 GC 的 btrfs 和 zfs 不算是日誌結構文件系統。 舉個例子，比如下圖是一個日誌結構文件系統的磁盤佔用，其中綠色是數據，藍色是元數據（比如目錄結構和 inode），紅色是文件系統級關鍵數據（比如最後的日誌提交點），一開始可能是這樣，有9個數據塊， 2個元數據塊，1個系統塊： 現在要覆蓋 2 和 3 的內容，新寫入 n2 和 n3 ，再刪除 4 號的內容 ，然後修改 10 裏面的 inode 變成 n10 引用這些新數據，然後寫入一個新提交 n12 ，用黃色表示不再被引用的垃圾，提交完大概是這樣： 日誌結構文件系統需要 GC 比較容易理解，寫日誌嘛，總得有一個「添加到末尾」的寫入點，比如上面圖中的 n12 就是當前的寫入點。空盤上連續往後寫而不 GC 總會遇到空間末尾，這時候就要覆蓋寫空間開頭， 就很難判斷「末尾」在什麼地方，而下一次寫入需要在哪裏了。 這時文件系統也不知道需要回收哪些塊（圖中的 o2 o3 o4 o10 和 o12），因爲這些塊可能被別的地方還繼續 引用着，需要等到 GC 時掃描元數據來判斷。 和內存管理時的 GC 不同的一點在於，文件系統的 GC 肯定不能停下整個世界跑 GC ，也不能把整個地址空間對半分然後 Mark-and-Sweep ，這些在內存中還尚可的簡單策略直接放到文件系統中絕對是性能災難。所以文件系統的 GC 需要並行的後臺 GC ，並且需要更細粒度的分塊機制能在 Mark-and-Sweep 的時候保持別的地方可以繼續寫入數據而維持文件系統的正常職能。 通常文件系統的 GC 是這樣，先把整個盤分成幾個段（segment）或者區域(zone)，術語不同不過表達的概念類似， 然後 GC 時挑一個老段，掃描文件系統元數據找出要釋放的段中還被引用的數據塊，搬運到日誌末尾，最後整個釋放一段。 搬運數據塊時，也要調整文件系統別的地方對被搬運的數據塊的引用。 物理磁盤上一般有扇區的概念，通常是 512B 或者 4KiB 的大小，在文件系統中一般把連續幾個物理塊作爲一個數據塊， 大概是 4KiB 到 1MiB 的數量級，然後日誌結構文件系統中一個段(segment)通常是連續的很多塊，數量級來看大約是 4MiB 到 64MiB 這樣的數量級。相比之下 ufs/ext4/btrfs/zfs 的分配器通常還有 block group 的概念， 大概是 128MiB 到 1GiB 的大小。可見日誌結構文件系統的段，是位於數據塊和其它文件系統 block group 中間的一個單位。段大小太小的話，會顯著增加空間管理需要的額外時間空間開銷，而段大小太大的話， 又不利於利用整個可用空間，這裏的抉擇有個平衡點。 繼續上面的例子，假設上面文件系統的圖示中每一列的4塊是一個段，想要回收最開頭那個段， 那麼需要搬運還在用的 1 到空閒空間，順帶修改引用它的 n10 ，最後提交 n12 ： 要掃描並釋放一整段，需要掃描整個文件系統中別的元數據（圖中的 n12 和 n10 和 11）來確定有沒有引用到目標段中的地址，可見釋放一個段是一個 \\(O(N)\\) 的操作，其中 N 是元數據段的數量，按文件系統的大小增長， 於是刪除快照之類可能要連續釋放很多段的操作在日誌文件系統中是個 \\(O(N&#94;2)\\) 甚至更昂贵的操作。 在文件系統相對比較小而系統內存相對比較大的時候，比如手機上或者PC讀寫SD卡，大部分元數據塊（ 其中包含塊指針）都能放入內存緩存起來的話，這個掃描操作的開銷還是可以接受的。 但是對大型存儲系統顯然掃描並釋放空間就不合適了。 段的抽象用在閃存類存儲設備上的一點優勢在於，閃存通常也有擦除塊的概念，比寫入塊的大小要大， 是連續的多個寫入塊構成，從而日誌結構的文件系統中一個段可以直接對應到閃存的一個擦除塊上。 所以閃存設備諸如U盤或者 SSD 通常在底層固件中用日誌結構文件系統模擬一個塊設備，來做寫入平衡。 大家所說的 SSD 上固件做的 GC ，大概也就是這樣一種操作。 基於段的 GC 還有一個顯著缺陷，需要掃描元數據，複製搬運仍然被引用到的塊，這不光會增加設備寫入， 還需要調整現有數據結構中的指針，調整指針需要更多寫入，同時又釋放更多數據塊， F2FS 等一些文件系統設計中把這個問題叫 Wandering Tree Problem ，在 F2FS 設計中是通過近乎「作弊」的 NAT 轉換表 放在存儲設備期待的 FAT 所在位置，不僅能讓需要掃描的元數據更集中，還能減少這種指針調整導致的寫入。 不過基於段的 GC 也有一些好處，它不需要複雜的文件系統設計，不需要特殊構造的指針， 就能很方便地支持大量快照。一些日誌結構文件系統比如 NILFS 用這一點支持了「連續快照（continuous snapshots）」，每次文件系統提交都是自動創建一個快照，用戶可以手動標記需要保留哪些快照， GC 算法則排除掉用戶手動標記的快照之後，根據快照創建的時間，先從最老的未標記快照開始回收。 即便如此， GC 的開銷（CPU時間和磁盤讀寫帶寬）仍然是 NILFS 最爲被人詬病的地方，是它難以被廣泛採用的原因。 爲了加快 NILFS 這類日誌文件系統的 GC 性能讓他們能更適合於普通使用場景，也有許多學術研究致力於探索和優化 GC ，使用更先進的數據結構和算法跟蹤數據塊來調整 GC 策略，比如這裏有一篇 State-of-the-art Garbage Collection Policies for NILFS2 。 3.2 WAFL 早期使用的可用空間位圖數組 從日誌結構文件系統使用 GC 的困境中可以看出，文件系統級別實際更合適的， 可能不是在運行期依賴掃描元數據來計算空間利用率的 GC ，而是在創建快照時或者寫入數據時就預先記錄下快照的空間利用情況， 從而可以細粒度地跟蹤空間和回收空間，這也是 WAFL 早期實現快照的設計思路。 WAFL 早期記錄快照佔用數據塊的思路從表面上來看也很「暴力」，傳統文件系統一般有個叫做「位圖（bitmap ）」的數據結構，用一個二進制位記錄一個數據塊是否佔用，靠掃描位圖來尋找可用空間和已用空間。 WAFL 的設計早期中考慮既然需要支持快照，那就把記錄數據塊佔用情況的位圖，變成快照的數組。 於是整個文件系統有個 256 大小的快照利用率數組，數組中每個快照記錄自己佔用的數據塊位圖， 文件系統中最多能容納 255 個快照。 上面每個單元格都是一個二進制位，表示某個快照有沒有引用某個數據塊。有這樣一個位圖的數組之後， 就可以直接掃描位圖判斷出某個數據塊是否已經佔用，可以找出尚未被佔用的數據塊用作空間分配， 也可以方便地計算每個快照引用的空間大小或者獨佔的空間大小，估算刪除快照後可以釋放的空間。 需要注意的是，文件系統中可以有非常多的塊，從而位圖數組比位圖需要更多的元數據來表達。 比如估算一下傳統文件系統中一塊可以是 4KiB 大小，那麼跟蹤空間利用的位圖需要 1bit/4KiB ， 1TiB 的盤就需要 32MiB 的元數據來存放位圖； 而 WAFL 這種位圖數組即便限制了快照數量只能有255個，仍需要 256bit/4KiB 的空間開銷， 1TiB 的盤需要的元數據開銷陡增到 8GiB ，這些還只是單純記錄空間利用率的位圖數組，不包括別的元數據。 使用這麼多元數據表示快照之後，創建快照的開銷也相應地增加了，需要複製整個位圖來創建一個新的快照， 按上面的估算 1TiB 的盤可能需要複製 32MiB 的位圖，這不再是一瞬能完成的事情， 期間可能需要停下所有對文件系統的寫入等待複製完成。 位圖數組在存儲設備上的記錄方式也很有講究，當刪除快照時希望能快速讀寫上圖中的一整行位圖， 於是可能希望每一行位圖的存儲方式在磁盤上都儘量連續， 而在普通的寫入操作需要分配新塊時，想要按列的方式掃描位圖數組，找到沒有被快照佔用的塊， 從而上圖中按列的存儲表達也希望在磁盤上儘量連續。 WAFL 的設計工程師們在位圖數組的思路下，實現了高效的數據結構讓上述兩種維度的操作都能快速完成， 但是這絕不是一件容易的事情。 位圖數組的表達方式也有其好處，比如除了快照之外，也可以非常容易地表達類似 ZFS 的克隆和獨立的文件系統這樣的概念，這些東西和快照一樣，佔用僅有的 256 個快照數量限制。 這樣表達的克隆可以有數據塊和別的文件系統共享，文件系統之間也可以有類似 reflink 的機制共享數據塊，在位圖數組的相應位置將位置1即可。 使用位圖數組的做法，也只是 WAFL 早期可能採用的方式，由於 WAFL 本身是閉源產品， 難以獲知它具體的工作原理。哈佛大學和 NetApp 的職員曾經在 FAST10 (USENIX Conference on File and Storage Technologies) 上發表過一篇講解高效跟蹤和使用 back reference 的論文，叫 Tracking Back References in a Write-Anywhere File System ，可以推測在新一代 WAFL 的設計中可能使用了類似 btrfs backref 的實現方式，接下來會詳細介紹。 3.3 ZFS 中關於快照和克隆的空間跟蹤算法 How ZFS snapshots really work And why they perform well (usually) 幻燈片可以從這裏下載 OpenZFS 的項目領導者，同時也是最初設計 ZFS 中 DMU 子系統的作者 Matt Ahrens 在 DMU 和 DSL 中設計並實現了 ZFS 獨特的快照的空間跟蹤算法。他也在很多地方發表演講，講過這個算法的思路和細節， 比如右側就是他在 BSDCan 2019 做的演講 How ZFS snapshots really work And why they perform well (usually) 的 YouTube 視頻。 其中 Matt 講到了三個刪除快照的算法，分別可以叫做「🐢烏龜算法」、「🐰兔子算法」、「🐆豹子算法」， 接下來簡單講講這些算法背後的思想和實現方式。 🐢烏龜算法：概念上 ZFS 如何刪快照 烏龜算法沒有實現在 ZFS 中，不過方便理解 ZFS 在概念上如何考慮快照刪除這個問題，從而幫助理解 後面的🐰兔子算法和🐆豹子算法。 要刪除一個快照， ZFS 需要找出這個快照引用到的「獨佔」數據塊，也就是那些不和別的數據集或者快照共享的 數據塊。 ZFS 刪除快照基於這幾點條件： ZFS 快照是只讀的。創建快照之後無法修改其內容。 ZFS 的快照是嚴格按時間順序排列的，這裏的時間指 TXG id ，即記錄文件系統提交所屬事務組的嚴格遞增序號。 ZFS 不存在 reflink 之類的機制，從而在某個時間點刪除掉的數據塊，不可能在比它更後面的快照中「復活」。 第三點關於 reflink 造成的數據復活現象可能需要解釋一下，比如在（支持 reflink 的） btrfs 中有如下操作： btrfs subvolume snapshot -r fs s1 rm fs/somefile btrfs subvolume snapshot -r fs s2 cp --reflink = always s1/somefile fs/somefile btrfs subvolume snapshot -r fs s3 我們對 fs 創建了 s1 快照，刪除了 fs 中某個文件，創建了 s2 快照，然後用 reflink 把剛剛刪除的文件從 s1 中複製出來，再創建 s3 。如此操作之後，按時間順序有 s1、s2、s3 三個快照： 其中只有 s2 不存在 somefile ，而 s1 、 s3 和當前的 fs 都有，並且都引用到了同一個數據塊。 於是從時間線來看， somefile 的數據塊在 s2 中「死掉」了，又在 s3 中「復活」了。 而 ZFS (目前還）不支持 reflink ，所以沒法像這樣讓數據塊復活。一旦某個數據塊在某個快照中「死」了， 就意味着它在隨後的所有快照中都不再被引用到了。 ZFS 的快照具有的上述三點條件，使得 ZFS 的快照刪除算法可以基於 birth time 。回顧上面 ZFS 的塊指針 中講到， ZFS 的每個塊指針都有一個 birth txg 屬性，記錄這個塊誕生時 pool 所在的 txg 。於是可以根據這個 birth txg 找到快照所引用的「獨佔」數據塊然後釋放掉它們。 具體來說，🐢烏龜算法可以這樣刪除一個快照： 在 DSL 層找出要刪除的快照（我們叫他 s ），它的前一個快照（叫它 ps ），後一個快照（叫它 ns ），分別有各自的 birth txg 叫 s.birth, ps.birth, ns.birth 。 遍歷 s 的 DMU 對象集指針所引出的所有塊指針。 這裏所有塊指針在邏輯上構成一個由塊指針組成的樹狀結構，可以有間接塊組成的指針樹，可以有對象集的 dnode 保存的塊指針，這些都可以看作是樹狀結構的中間節點。 每個樹節點的指針 bp，考察如果 bp.birth <= ps.birth ，那麼這個指針和其下所有指針都還被前一個快照引用着，需要保留這個 bp 引出的整個子樹。 按定義 bp.birth 不可能 > s.birth 。 對所有滿足 ps.birth < bp.birtu <= s.birth 的 bp ，需要去遍歷 ns 的相應塊指針（同樣文件的同樣偏移位置），看是否還在引用 bp 。 如果存在，繼續遞歸往下考察樹狀結構中 bp 的所有子節點指針。因爲可能共享了這個 bp 但 CoW 了新的子節點。 如果不存在，說明下一個快照中已經刪了 bp 。這時可以確定地說 bp 是 s 的「獨佔」數據塊。 釋放掉所有找到的 s 所「獨佔」的數據塊。 上述算法的一些邊角情況可以自然地處理，比如沒有後一個快照時使用當前數據集的寫入點， 沒有前一個快照時那麼不被後一個快照引用的數據塊都是當前要刪除快照的獨佔數據塊。 分析一下烏龜算法的複雜度的話，算法需要分兩次，讀 s 和 ns 中引用到的所有 ps 之後創建的數據塊的指針，重要的是這些讀都是在整個文件系統範圍內的隨機讀操作，所以速度非常慢…… 🐰兔子算法：死亡列表算法（ZFS早期） 可以粗略地認爲🐢烏龜算法算是用 birth txg 優化代碼路徑的 GC 算法，利用了一部分元數據中的 birth txg 信息來避免掃描所有元數據，但是概念上仍然是在掃描元數據找出快照的獨佔數據塊， 而非記錄和跟蹤快照的數據塊，在最壞的情況下仍然可能需要掃描幾乎所有元數據。 🐰兔子算法基於🐢烏龜算法的基本原理，在它基礎上跟蹤快照所引用數據塊的一些信息， 從而很大程度上避免了掃描元數據的開銷。ZFS 在早期使用這個算法跟蹤數據集和快照引用數據塊的情況。 🐰兔子算法爲每個數據集（文件系統或快照）增加了一個數據結構，叫死亡列表（dead list）， 記錄 前一個快照中還活着，而當前數據集中死掉了的數據塊指針 ，換句話說就是在本數據集中「殺掉」的數據塊。舉例畫圖大概是這樣 上圖中有三個快照和一個文件系統，共 4 個數據集。每個數據集維護自己的死亡列表， 死亡列表中是那些在該數據集中被刪掉的數據塊。於是🐰兔子算法把🐢烏龜算法所做的操作分成了兩部分， 一部分在文件系統刪除數據時記錄死亡列表，另一部分在刪除快照時根據死亡列表釋放需要釋放的塊。 在當前文件系統刪除數據塊（不再被當前文件系統引用）時，負責比對 birth txg 維護當前文件系統的死亡列表。每刪除一個數據塊，指針爲 bp 時，判斷 bp.birth 和文件系統最新的快照（上圖爲 s3）的 birth： bp.birth <= s3.birth： 說明 bp 被 s3 引用，於是將 bp 加入 fs1 的 deadlist bp.birth > s3.birth：說明 bp 指向的數據塊誕生於 s3 之後，可以直接釋放 bp 指向的塊。 創建新快照時，將當前文件系統（圖中 fs1）的死亡列表交給快照，文件系統可以初始化一個空列表。 刪除快照時，我們有被刪除的快照 s 和前一個快照 ps 、後一個快照 ns ，需要讀入當前快照 s 和後一個快照 ns 的死亡列表： 對 s.deadlist 中的每個指針 bp 複製 bp 到 ns.deadlist 對 ns.deadlist 中的每個指針 bp （其中包含了上一步複製來的） 如果 bp.birth > ps.birth ，釋放 bp 的空間 否則保留 bp 換個說法的話， 死亡列表記錄的是每個數據集需要負責刪除，但因爲之前的快照還引用着所以不能刪除的數據塊列表 。從當前文件系統中刪除一個數據塊時，這個職責最初落在當前文件系統身上，隨後跟着創建新快照職責被轉移到新快照上。 每個負責的數據集根據數據塊的出生時間是否早於之前一個快照來判斷現在是否能立刻釋放該塊， 刪除一個快照時則重新評估自己負責的和下一個快照負責的數據塊的出生時間。 從所做的事情來看，🐰兔子算法並沒有比🐢烏龜算法少做很多事情。🐢烏龜算法刪除一個快照， 需要遍歷當前快照和後一個快照兩組數據塊指針中，新寫入的部分； 🐰兔子算法則需要遍歷當前快照和後一個快照兩個死亡列表中，新刪除的塊指針。 但是實際🐰兔子算法能比🐢烏龜算法快不少，因爲維護死亡列表的操作只在文件系統刪除數據時和刪除快照時， 順序寫入，並且刪除快照時也只需要順序讀取死亡列表。在磁盤這種塊設備上，順序訪問能比隨機訪問有數量級的差異。 不過記錄死亡列表也有一定存儲開銷。最差情況下，比如把文件系統寫滿之後，創建一個快照， 再把所有數據都刪掉，此時文件系統引用的所有數據塊的塊指針都要保存在文件系統的死亡列表中。 按 ZFS 默認的 128KiB 數據塊大小，每塊需要 128 字節的塊指針，存儲這些死亡列表所需開銷可能要 整個文件系統大小的 1/1024 。如果用 4KiB 的數據塊大小，所需開銷則是 1/32 ， 1TiB 的盤會有 32GiB 拿來存放這些塊指針，將高於用位圖數組所需的存儲量。 🐆豹子算法：死亡列表的子列表 🐆豹子算法是 ZFS 後來在 2009 年左右實現的算法。在🐰兔子算法中就可以看到，每次刪除快照操作死亡列表的時候， 都需要掃描死亡列表中的塊指針，根據指針中記錄的 birth txg 做判斷是否能直接釋放或是需要保留到另一個快照的死亡列表。 於是🐆豹子算法的思路是，在死亡列表中記錄塊指針時，就把其中的塊指針按 birth txg 分成子列表（sublist）。 比如上面🐰兔子算法中那4個死亡列表，可以這樣拆成子列表： 這樣拆成子列表之後，每次從死亡列表中釋放數據塊都能根據出生時間找到對應的子列表， 然後連續釋放整個子列表。每次合併死亡列表時，也能直接用單鏈表穿起需要合併的子列表，不需要複製塊指針。 死亡列表並不在跟蹤快照的獨佔大小，而是在跟蹤快照所需負責刪除的數據塊大小， 從這個數值可以推算出快照的獨佔大小之類的信息。 有了按出生時間排列的死亡列表子列表之後，事實上給任何一個出生時間到死亡時間的範圍， 都可以找出對應的幾個子列表，從而根據子列表的大小可以快速計算出每個快照範圍的「獨佔」數據塊、 「共享」數據塊等大小，這不光在刪除快照時很有用，也可以用來根據大小估算 zfs send 或者別的基於快照操作時需要的時間。 從直覺上理解，雖然 ZFS 沒有直接記錄每個數據塊屬於哪個數據集，但是 ZFS 跟蹤記錄了每個數據塊的歸屬信息，也就是說由哪個數據集負責釋放這個數據塊。 在文件系統中刪除數據塊或者快照時，這個歸屬信息跟着共享數據塊轉移到別的快照中，直到最終被釋放掉。 生存日誌：ZFS 如何管理克隆的空間佔用 Fast Clone Deletion by Sara Hartse 以上三種算法負責在 ZFS 中跟蹤快照的空間佔用，它們都基於數據塊的誕生時間，所以都假設 ZFS 中對數據塊的分配是位於連續的快照時間軸上。但是明顯 ZFS 除了快照和文件系統， 還有另一種數據集可能分配數據塊，那就是 克隆 ，於是還需要在克隆中使用不同的算法單獨管理因克隆而分配的數據塊。 OpenZFS Summit 2017 有個演講 Fast Clone Deletion by Sara Hartse 解釋了其中的細節。 首先克隆的存在本身會鎖住克隆引用到的快照，不能刪除這些被依賴的快照， 所以克隆無須擔心靠快照共享的數據塊的管理問題。因此克隆需要管理的，是從快照分離之後， 新創建的數據塊。 和🐢烏龜算法一樣，原理上刪除克隆的時候可以遍歷克隆引用的整個 DMU 對象集，找出其中晚於快照的誕生時間的數據塊，然後釋放它們。也和🐢烏龜算法一樣， 這樣掃描整個對象集的開銷很大，所以使用一個列表來記錄數據塊指針。 克隆管理新數據塊的思路和快照的🐰兔子算法維持死亡列表的思路相反， 記錄所有新誕生的數據塊，這個列表叫做「生存日誌（livelist）」。 克隆不光要記錄新數據塊的誕生，還要記錄新數據塊可能的死亡，所以磁盤上保存的生存日誌雖然叫 livelist ，但不像死亡列表那樣是列表的形式，而是日誌的形式，而內存中保存的生存日誌則組織成了棵 自平衡樹（AVLTree） 來加速查找。 磁盤上存儲的生存日誌如上圖，每個表項記錄它是分配（A）或者刪除（F）一個數據塊，同時記錄數據塊的地址。 這些記錄在一般情況下直接記錄在日誌末尾，隨着對克隆的寫入操作而不斷增長，長到一定程度則從內存中的 AVL Tree 直接輸出一個新的生存日誌替代掉舊的，合併其中對應的分配和刪除操作。 生存日誌可以無限增長，從而要將整個生存列表載入內存也有不小的開銷，這裏的解決方案有點像快照管理中用 🐆豹子算法改進🐰兔子算法的思路，把一個克隆的整個生存日誌也按照數據塊的誕生時間拆分成子列表。 Sara Hartse 的演講 Fast Clone Deletion 中繼續解釋了其中的細節和優化方案，感興趣的可以看看。 3.4 btrfs 的空間跟蹤算法：引用計數與反向引用 理解了 ZFS 中根據 birth txg 管理快照和克隆的算法之後，可以發現它們基於的假設難以用於 WAFL 和 btrfs 。 ZFS 嚴格區分文件系統、快照、克隆，並且不存在 reflink ，從而可以用 birth txg 判斷數據塊是否需要保留，而 WAFL 和 btrfs 中不存在 ZFS 的那些數據集分工，又想支持 reflink ，可見單純基於 birth txg 不足以管理 WAFL 和 btrfs 子卷。 讓我們回到一開始日誌結構文件系統中基於垃圾回收（GC）的思路上來，作爲程序員來看， 當垃圾回收的性能不足以滿足當前需要時，大概很自然地會想到：引用計數（reference counting）。 編程語言中用引用計數作爲內存管理策略的缺陷是：強引用不能成環， 這在文件系統中看起來不是很嚴重的問題，文件系統總體上看是個樹狀結構，或者就算有共享的數據也是個 上下層級分明的有向圖，很少會使用成環的指針，以及文件系統記錄指針的時候也都會區分指針的類型， 根據指針類型可以分出強弱引用。 EXTENT_TREE 和引用計數 btrfs 中就是用引用計數的方式跟蹤和管理數據塊的。引用計數本身不能保存在 FS_TREE 或者指向的數據塊中，因爲這個計數需要能夠變化，對只讀快照來說整個 FS_TREE 都是只讀的。 所以這裏增加一層抽象， btrfs 中關於數據塊的引用計數用一個單獨的 CoW B樹來記錄，叫做 EXTENT_TREE ，保存於 ROOT_TREE 中的 2 號對象位置。 btrfs 中每個塊都是按 區塊（extent） 的形式分配的，區塊是一塊連續的存儲空間，而非 zfs 中的固定大小。每個區塊記錄存儲的位置和長度， 以及這裏所說的引用計數。所以本文最開始講 Btrfs 的子卷和快照 中舉例的那個平坦佈局，如果畫上 EXTENT_TREE 大概像是下圖這樣，其中每個粗箭頭是一個區塊指針，指向磁盤中的邏輯地址，細箭頭則是對應的 EXTENT_TREE 中關於這塊區塊的描述： Flat_layout_extents_on_disk superblock SUPERBLOCK ... root_tree ... roottree ROOT_TREE 2: extent_tree 3: chunk_tree 4: dev_tree 5: fs_tree 6: root_dir \"default\" -> ROOT_ITEM 256 10: free_space_tree 256: fs_tree \"root\" 257: fs_tree \"home\" 258: fs_tree \"www\" 259: fs_tree \"postgres\" -7: tree_log_tree -5: orphan_root superblock:sn_root->roottree:label toplevel FS_TREE \"toplevel\" 256: inode_item DIR 256: dir_item: \"root\" -> ROOT_ITEM 256 256: dir_item: \"home\" -> ROOT_ITEM 257 256: dir_item: \"var\" -> INODE_ITEM 257 256: dir_item: \"postgres\" -> ROOT_ITEM 259 257: inode_item DIR 257: dir_item: \"www\" -> ROOT_ITEM 258 roottree:root_fs->toplevel:label root FS_TREE \"root\" 256: inode_item DIR roottree:root_sub_root->root:label home FS_TREE \"home\" 256: inode_item DIR roottree:root_sub_home->home:label www FS_TREE \"www\" 256: inode_item DIR roottree:root_sub_www->www:label postgres FS_TREE \"postgres\" 256: inode_item DIR roottree:root_sub_postgres->postgres:label extent_tree EXTENT_TREE 0x2000 len=0x1000 : ref=1 gen=8 0x3000 len=0x1000 : ref=1 gen=8 0x11000 len=0x1000 : ref=1 gen=8 0x12000 len=0x1000 : ref=1 gen=6 0x13000 len=0x1000 : ref=1 gen=6 0x14000 len=0x1000 : ref=1 gen=6 0x15000 len=0x1000 : ref=1 gen=7 ... roottree:root_extent->extent_tree:label roottree:label->extent_tree:extent_roottree toplevel:label->extent_tree:extent_toplevel root:label->extent_tree:extent_root home:label->extent_tree:extent_home www:label->extent_tree:extent_www postgres:label->extent_tree:extent_postgres extent_tree:extent_extent->extent_tree:label btrfs 中關於 chattr +C 關閉了 CoW 的文件的處理 2020年2月20日補充 這裏從 EXTENT_TREE 的記錄可以看出，每個區塊都有引用計數記錄。對用 chattr +C 關閉了 CoW 的文件而言，文件數據同樣還是有引用計數，可以和別的文件或者快照共享文件數據的。 這裏的特殊處理在於，每次寫入一個 nocow 的文件的時候，考察這個文件指向區塊的引用計數， 如果引用計數 >1 ，表示這個文件的區塊發生過 reflink ，那會對文件內容做一次 CoW 斷開 reflink 並寫入新位置；如果引用計數 =1 ，那麼直接原地寫入文件內容而不 CoW 。於是 nocow 的文件仍然能得到 reflink 和 snapshot 的功能， 使用這些功能仍然會造成文件碎片並伴隨性能損失，只是在引用計數爲 1 的時候不發生 CoW 。 包括 ROOT_TREE 和 EXTENT_TREE 在內，btrfs 中所有分配的區塊（extent）都在 EXTENT_TREE 中有對應的記錄，按區塊的邏輯地址索引。從而給定一個區塊，能從 EXTENT_TREE 中找到 ref 字段描述這個區塊有多少引用。不過 ROOT_TREE 、 EXTENT_TREE 和別的一些 pool-wide 數據結構本身不依賴引用計數的，這些數據結構對應的區塊的引用計數總是 1 ，不會和別的樹共享區塊；從 FS_TREE 開始的所有樹節點都可以共享區塊，這包括所有子卷的元數據和文件數據，這些區塊對應的引用計數可以大於 1 表示有多處引用。 EXTENT_TREE 按區塊的邏輯地址索引，記錄了起始地址和長度，所以 EXTENT_TREE 也兼任 btrfs 的空間利用記錄，充當別的文件系統中 block bitmap 的指責。比如上面例子中的 extent_tree 就表示 [0x2000,0x4000) [0x11000,0x16000) 這兩段連續的空間是已用空間， 剩下的空間按定義則是可用空間。爲了加速空間分配器， btrfs 也有額外的 free space cache 記錄在 ROOT_TREE 的 10 號位置 free_space_tree 中，不過在 btrfs 中這個 free_space_tree 記錄的信息只是緩存，必要時可以通過 btrfs check --clear-space-cache 扔掉這個緩存重新掃描 extent_tree 並重建可用空間記錄。 比如我們用如下命令創建了兩個文件，通過 reflink 讓它們共享區塊，然後創建兩個快照， 然後刪除文件系統中的 file2 ： write fs/file1 cp --reflink = always fs/file1 fs/file2 btrfs subvolume snapshot fs sn1 btrfs subvolume snapshot fs sn2 rm fs/file2 經過以上操作之後，整個 extent_tree 的結構中記錄的引用計數大概如下圖所示： btrfs_reflink_backref root ROOT_TREE sn1 sn2 fs sn1 FS_TREE sn1 leaf_node root:sn1->sn1:label sn2 FS_TREE sn2 leaf_node root:sn2->sn2:label fs FS_TREE fs leaf_node root:fs->fs:label extent EXTENT_TREE extent_tree root_tree : ref 1 sn1 fs_tree : ref 1 sn2 fs_tree : ref 1 sn1 sn2 leaf_node: ref 2 fs fs_tree : ref 1 fs leaf_node : ref 1 file1 : ref 3 root:label->extent:root snleaf FS_TREE leaf_node file1 file2 sn1:leaf->snleaf:label sn1:label->extent:sn1 sn2:leaf->snleaf:label sn2:label->extent:sn2 fsleaf FS_TREE leaf_node file1 fs:leaf->fsleaf:label fs:label->extent:fs snleaf:label->extent:snleaf snleaf:f1->extent:f1 snleaf:f2->extent:f1 fsleaf:label->extent:fsleaf fsleaf:f1->extent:f1 上圖簡化了一些細節，實際上每個文件可以引用多個區塊（文件碎片）， 其中每個對區塊的引用都可以指明引用到具體某個區塊記錄的某個地址偏移和長度， 也就是說文件引用的區塊可以不是區塊記錄中的一整個區塊，而是一部分內容。 圖中可見，整個文件系統中共有5個文件路徑可以訪問到同一個文件的內容，分別是 sn1/​file1, sn1/​file2, sn2/​file1, sn2/​file2, fs/​file1 ， 在 extent_tree 中， sn1 和 sn2 可能共享了一個 B樹 葉子節點，這個葉子節點的引用計數爲 2 ，然後每個文件的內容都指向同一個 extent ，這個 extent 的引用計數爲 3 。 刪除子卷時，通過引用計數就能準確地釋放掉子卷所引用的區塊。具體算法挺符合直覺的： 從子卷的 FS_TREE 往下遍歷 遇到引用計數 >1 的區塊，減小該塊的計數即可，不需要再遞歸下去 遇到引用計數 =1 的區塊，就是子卷獨佔的區塊，需要釋放該塊並遞歸往下繼續掃描 大體思路挺像上面介紹的 ZFS 快照刪除的🐢烏龜算法 ，只不過根據引用計數而非 birth txg 判斷是否獨佔數據塊。性能上說， btrfs 的B樹本身內容就比較緊湊，FS_TREE 一個結構就容納了文件 inode 和引用的區塊信息， EXTENT_TREE 按地址排序也比較緊湊，所以刪除算法的隨機讀寫不像 ZFS 的🐢烏龜算法那麼嚴重， 實際實現代碼裏面也可能通過 btrfs generation 做一些類似基於 birth txg 優化的快速代碼路徑。 即便如此，掃描 FS_TREE 仍然可能需要耗時良久，這個遞歸的每一步操作都會記錄在 ROOT_TREE 中專門的結構，也就是說刪除一個子卷的操作可以執行很長時間並跨越多個 pool commit 。 btrfs subvolume delete 命令默認也只是記錄下這個刪除操作，然後就返回一句類似： Delete subvolume (no-commit): /​subvolume/​path 的輸出，不會等刪除操作執行結束。 相比之下 ZFS 那邊刪除一個快照或文件系統必須在一個 txg 內執行完，沒有中間過程的記錄， 所以如果耗時很久會影響整個 pool 的寫入，於是 ZFS 那邊必須對這些操作優化到能在一個 txg 內執行完的程度(摧毀克隆方面 ZFS 還有 async_destroy 優化 可能有些幫助)。 只需要引用計數就足夠完成快照的創建、刪除之類的功能，也能支持 reflink 了（仔細回想， reflink 其實就是 reference counted link 嘛），普通讀寫下也只需要引用計數。 但是只有引用計數不足以知道區塊的歸屬，不能用引用計數統計每個子卷分別佔用多少空間， 獨佔多少區塊而又共享多少區塊。上面的例子就可以看出，所有文件都指向同一個區塊，該區塊的引用計數爲 3 ，而文件系統中一共有 5 個路徑能訪問到該文件。可見從區塊根據引用計數反推子卷歸屬信息不是那麼一目瞭然的。 反向引用（back reference） 單純從區塊的引用計數難以看出整個文件系統所有子卷中有多少副本。 也就是說單有引用計數的一個數字還不夠，需要記錄具體反向的從區塊往引用源頭指的引用，這種結構在 btrfs 中叫做「反向引用（back reference，簡稱 backref）」。所以在上圖中每一個指向 EXTENT_TREE 的單向箭頭，在 btrfs 中都有記錄一條反向引用，通過反向引用記錄能反過來從被指針指向的位置找回到記錄指針的地方。 反向引用（backref）是 btrfs 中非常關鍵的機制，在 btrfs kernel wiki 專門有一篇頁面 Resolving Extent Backrefs 解釋它的原理和實現方式。 對上面的引用計數的例子畫出反向引用的指針大概是這樣： btrfs_reflink_backref root ROOT_TREE sn1 sn2 fs sn1 FS_TREE sn1 leaf_node root:sn1->sn1:label sn2 FS_TREE sn2 leaf_node root:sn2->sn2:label fs FS_TREE fs leaf_node root:fs->fs:label extent EXTENT_TREE extent_tree root_tree : ref 1 sn1 fs_tree : ref 1 backref ROOT_TREE sn1 sn2 fs_tree : ref 1 backref ROOT_TREE sn2 sn1 sn2 leaf_node: ref 2 backref sn1 FS_TREE node backref sn2 FS_TREE node fs fs_tree : ref 1 backref ROOT_TREE fs fs leaf_node : ref 1 backref fs FS_TREE node file1 : ref 3 backref sn1 FS_TREE leaf_node file1 backref sn1 FS_TREE leaf_node file2 backref fs FS_TREE leaf_node file1 snleaf FS_TREE leaf_node file1 file2 sn1:leaf->snleaf:label sn2:leaf->snleaf:label fsleaf FS_TREE leaf_node file1 fs:leaf->fsleaf:label extent:br1->root:label extent:br2->root:label extent:br5->root:label extent:br3->sn1:label extent:br4->sn2:label extent:br6->fs:label extent:br7->snleaf:label extent:br8->snleaf:label extent:br9->fsleaf:label EXTENT_TREE 中每個 extent 記錄都同時記錄了引用到這個區塊的反向引用列表。反向引用有兩種記錄方式： 普通反向引用（Normal back references）。記錄這個指針來源所在是哪顆B樹、 B樹中的對象 id 和對象偏移。 對文件區塊而言，就是記錄文件所在子卷、inode、和文件內容的偏移。 對子卷的樹節點區塊而言，就是記錄該區塊的上級樹節點在哪個B樹的哪個位置開始。 共享反向引用（Shared back references）。記錄這個指針來源區塊的邏輯地址。 無論對文件區塊而言，還是對子卷的樹節點區塊而言，都是直接記錄了保存這個區塊指針的上層樹節點的邏輯地址。 有兩種記錄方式是因爲它們各有性能上的優缺點： 普通反向引用: 因爲通過對象編號記錄，所以當樹節點 CoW 改變了地址時不需要調整地址， 從而在普通的讀寫和快照之類的操作下有更好的性能， 但是在解析反向引用時需要額外一次樹查找。 同時因爲這個額外查找，普通反向引用也叫間接反向引用。 共享反向引用: 因爲直接記錄了邏輯地址，所以當這個地址的節點被 CoW 的時候也需要調整這裏記錄的地址。 在普通的讀寫和快照操作下，調整地址會增加寫入從而影響性能，但是在解析反向引用時更快。 通常通過普通寫入、快照、 reflink 等方式創建出來的引用是普通反向引用， 由於普通反向引用記錄了包含它的B樹，從而可以說綁在了某棵樹比如某個子卷上， 當這個普通反向引用指向的對象不再存在，而這個反向引用還在通過別的途徑共享時， 這個普通反向引用會轉換共享反向引用；共享反向引用在存在期間不會變回普通反向引用。 比如上圖反向引用的例子中，我們先假設所有畫出的反向引用都是普通反向引用，於是圖中標爲 file1 引用數爲 3 的那個區塊有 3 條反向引用記錄，其中前兩條都指向 sn1 裏面的文件，分別是 sn1/file1 和 sn1/file2 ，然後 sn1 和 sn2 共享了 FS_TREE 的葉子節點。 假設這時我們刪除 sn1/file2，執行了代碼 rm sn1/​file2 之後： btrfs_reflink_shared_backref root ROOT_TREE sn1 sn2 fs sn1 FS_TREE sn1 leaf_node root:sn1->sn1:label sn2 FS_TREE sn2 leaf_node root:sn2->sn2:label fs FS_TREE fs leaf_node root:fs->fs:label extent EXTENT_TREE extent_tree root_tree : ref 1 sn1 fs_tree : ref 1 backref ROOT_TREE sn1 sn2 fs_tree : ref 1 backref ROOT_TREE sn2 sn1 sn2 leaf_node: ref 2 backref sn1 FS_TREE node backref sn2 FS_TREE node fs fs_tree : ref 1 backref ROOT_TREE fs fs leaf_node : ref 1 backref fs FS_TREE node file1 : ref 4 backref FS_TREE leaf_node file1 backref FS_TREE leaf_node file2 backref fs FS_TREE leaf_node file1 backref sn1 FS_TREE leaf_node file1 sn1leaf FS_TREE leaf_node file1 sn1:leaf->sn1leaf:label snleaf FS_TREE leaf_node file1 file2 sn2:leaf->snleaf:label fsleaf FS_TREE leaf_node file1 fs:leaf->fsleaf:label extent:br1->root:label extent:br2->root:label extent:br5->root:label extent:br3->sn1:label extent:br4->sn2:label extent:br6->fs:label extent:br10->sn1leaf:label extent:br7->snleaf:label extent:br8->snleaf:label extent:br9->fsleaf:label 那麼 sn1 會 CoW 那個和 sn2 共享的葉子節點，有了新的屬於 sn1 的葉子，從而斷開了原本 file1 中對這個共享葉子節點的兩個普通反向引用，轉化成共享反向引用（圖中用虛線箭頭描述）， 並且插入了一個新的普通反向引用指向新的 sn1 的葉子節點。 遍歷反向引用(backref walking) 有了反向引用記錄之後，可以給定一個邏輯地址，從 EXTENT_TREE 中找到地址的區塊記錄， 然後從區塊記錄中的反向引用記錄一步步往回遍歷，直到遇到 ROOT_TREE ，最終確定這個邏輯地址的區塊在整個文件系統中有多少路徑能訪問它。 這個遍歷反向引用的操作，在 btrfs 文檔和代碼中被稱作 backref walking 。 比如還是上面的反向引用圖例中 sn1 和 sn2 完全共享葉子節點的那個例子，通過 backref walking ，我們能從 file1 所記錄的 3 個反向引用，推出全部 5 個可能的訪問路徑。 backref walking 作爲很多功能的基礎設施，從 btrfs 相當早期（3.3內核）就有，很多 btrfs 的功能實際依賴 backref walking 的正確性。列舉一些需要 backref walking 來實現的功能： qgroup btrfs 的子卷沒有記錄子卷的磁盤佔用開銷，靠引用計數來刪除子卷， 所以也不需要詳細統計子卷的空間佔用情況。不過對一些用戶的使用場景，可能需要統計子卷空間佔用。由於 可能存在的共享元數據和數據，子卷佔用不能靠累計加減法的方式算出來，所以 btrfs 有了 qgroup 和 quota 功能，用來統計子卷或者別的管理粒度下的佔用空間情況。爲了實現 qgroup ，需要 backref walking 來計算區塊共享的情況。 send btrfs send 在計算子卷間的差異時，也通過 backref walking 尋找能靠 reflink 共享的區塊，從而避免傳輸數據。 balance/scrub balance 和 scrub 都會調整區塊的地址，通過 backref walking 能找到所有引用到這個地址的位置並正確修改地址。 check 當需要打印診斷信息的時候，除了提供出錯的數據所在具體地址之外，通過 backref walking 也能提供受影響的文件路徑之類的信息。 btrfs 的 reflink-aware defrag 這裏想提一下 btrfs 一直計劃中，但是還沒有成功實現的 reflink-aware defrag 。文件碎片一直是 CoW 文件系統的大問題，對 btrfs 和對 ZFS 都是同樣。ZFS 完全不支持碎片整理， 而 btrfs 目前只提供了文件級別的碎片整理，這會切斷現有的 reflink 。計劃中的 reflink-aware defrag 也是基於 backref walking ，根據區塊引用的碎片程度，整理碎片而某種程度上保持 reflink 。btrfs 曾經實現了這個，但是因爲 bug 太多不久就取消了相關功能，目前這個工作處於停滯階段。 可見 backref walking 的能力對 btrfs 的許多功能都非常重要（不像 ZPL 的 dnode 中記錄的 parent dnode 那樣只用於診斷信息 ）。不過 backref walking 根據區塊共享的情況的不同，也可能導致挺大的運行期開銷，包括算法時間上的和內存佔用方面的開銷。 比如某個子卷中有 100 個文件通過 reflink 共享了同一個區塊，然後對這個子卷做了 100 個快照， 那麼對這一個共享區塊的 backref walking 結果可能解析出 10000 個路徑。可見隨着使用 reflink 和快照， backref walking 的開銷可能爆炸式增長。最近 btrfs 郵件列表也有一些用戶彙報，在大量子卷 和通過 reflink 做過 dedup 的 btrfs 文件系統上 send 快照時，可能導致內核分配大量內存甚至 panic 的情形，在 5.5 內核中 btrfs send 試圖控制 send 時 clone reference 的數量上限來緩解這種邊角問題。 值得再強調的是，在沒有開啓 qgroup 的前提下，正常創建刪除快照或 reflink ，正常寫入和覆蓋區塊之類的文件系統操作，只需要引用計數就足夠，雖然可能需要調整反向引用記錄（ 尤其是共享反向引用的地址），但是不需要動用 backref walking 這樣的重型武器。 4 ZFS vs btrfs 的 dedup 功能現狀 上面討論 ZFS 的快照和克隆如何跟蹤數據塊時，故意避開了 ZFS 的 dedup 功能，因爲要講 dedup 可能需要先理解引用計數在文件系統中的作用，而 btrfs 正好用了引用計數。 於是我們再回來 ZFS 這邊，看看 ZFS 的 dedup 是具體如何運作的。 稍微瞭解過 btrfs 和 ZFS 兩者的人，或許有不少 btrfs 用戶都眼饞 ZFS 有 in-band dedup 的能力，可以在寫入數據塊的同時就去掉重複數據，而 btrfs 只能「退而求其次」地選擇第三方 dedup 方案，用外部工具掃描已經寫入的數據，將其中重複的部分改爲 reflink 。又或許有不少 btrfs 用戶以爲 zfs 的 dedup 就是在內存和磁盤中維護一個類似 Bloom filter 的結構，然後根據結果對數據塊增加 reflink ，從而 zfs 內部大概一定有類似 reflink 的設施，進一步質疑爲什麼 btrfs 還遲遲沒有實現這樣一個 Bloom filter 。 或許還有從 btrfs 轉移到 ZFS 的用戶有疑惑， 爲什麼 ZFS 還沒有暴露出 reflink 的用戶空間接口 ，或者既然 ZFS 已經有了 dedup ， 能不能臨時開關 dedup 來提供類似 reflink 式的共享數據塊 而避免 ZFS 長期開 dedup 導致的巨大性能開銷。 看過上面 ZFS 中關於快照和克隆的空間跟蹤算法 之後我們會發現，其實 ZFS 中並沒有 能對應 btrfs reflink 的功能，而是根據數據塊指針中的 birth txg 來跟蹤快照和克隆的共享數據塊的。這引來更多疑惑： 4.1 ZFS 是如何實現 dedup 的？ Dedup Performance by Matt Ahrens ZFS 是在 Sun/OpenSolaris 壽命相當晚期的 2009 年獲得的 dedup 功能，就在 Oracle 收購 Sun ，OpenSolaris 分裂出 Illumos 從而 ZFS 分裂出 Oracle ZFS 和 OpenZFS 的時間點之前。因此 關於 ZFS dedup 如何實現的文檔相對匱乏 ，大部分介紹 ZFS 的文檔或者教程會講到 ZFS dedup 的用法，但是對 dedup 的實現細節、性能影響、乃至使用場景之類的話題就很少提了（甚至很多教程講了一堆用法之後說類似， 「我評估之後覺得我不需要開 dedup ，你可以自己評估一下」這樣的建議）。 OpenZFS Summit 2017 上 Matt 有個演講，主要內容關於今後如何改進 dedup 性能的計劃，其中講到的計劃還沒有被具體實現，不過可以窺探一下 dedup 現在在 ZFS 中是如何工作的。 Chris 的博客也有兩篇文章《 What I can see about how ZFS deduplication seems to work on disk 》和《 An important addition to how ZFS deduplication works on the disk 》介紹了他對此的認識，在這裏我也嘗試來總結一下 ZFS dedup 特性如何工作。 ZFS dedup 是存儲池級別（pool-wide）開關的特性，所以大概在 MOS 之類的地方有存儲一個特殊的數據結構， 叫 DeDup Table 簡稱 DDT 。DDT 目前是存儲設備上的一個 hash table ，因爲是存儲池級別的元數據， 所以在 ZFS 中存儲了三份完全一樣的 DDT ，DDT 的內容是大概如下結構： Checksum DVA(Data Virtual Address) Refcount 0x12345678 vdev=1 addr=0x45671234 3 0x5678efab vdev=2 addr=0x37165adb 0 0x98765432 vdev=1 addr=0xac71be12 1 0xabcd1234 vdev=0 addr=0xc1a2231d 5 ... ... ... ... ... ... DDT 中對每個數據塊存有3個東西：數據塊的 checksum 、DVA （就是 ZFS 的塊指針 中的 DVA）和引用計數。在存儲池開啓 dedup 特性之後，每次新寫入一個數據塊，都會先計算出數據塊的 checksum ，然後查找 DDT ，存在的話增加 DDT 條目的引用計數，不存在的話插入 DDT 條目。每次釋放一個數據塊，同樣需要查找 DDT 調整引用計數。 除了 DDT 之外，文件系統中記錄的塊指針中也有個特殊標誌位記錄這個塊是否經過了 DDT 。讀取數據不需要經過 DDT ，但是子卷、克隆或者文件系統正常刪除數據塊的時候， 需要根據塊指針中的標誌位判斷是否需要檢查和調整 DDT 。 從而關於 dedup 的實現可以得知以下一些特點： 開啓 dedup 之後，每個寫入操作放大成 3+1 個隨機位置的寫入操作，每個刪除操作變成 1 個寫入操作。沒有 dedup 時刪除塊並不需要立刻寫入，只需要記錄在內存中並在 MOS 提交的時候調整磁盤佔用情況即可。 只有開啓 dedup 期間寫入的數據塊纔會參與 dedup 。對已經有數據的存儲池，後來開啓的 dedup 不會影響已經寫好的數據，從而即使後來新的寫入與之前的寫入有重複也得不到 dedup 效果。 DDT 中沒有記錄的數據塊不會參與 dedup 。換句話說 DDT 中那些引用計數爲 1 的記錄也是必須存在的，否則這些數據塊沒有機會參與 dedup 。 關閉 dedup 之後，只要 DDT 中還存有數據，那麼對這些數據的刪除操作仍然有性能影響。 從直覺上可以這樣理解：在 ZFS 中每個數據塊都有其「歸屬」，沒有 dedup 的時候，數據塊歸屬於某個數據集（文件系統、快照、克隆）， 該數據集需要負責釋放該數據塊或者把從屬信息轉移到別的數據集（快照）上。 而在開啓 dedup 期間，產生的寫入的數據塊實際歸屬於 DDT 而不是任何一個數據集，數據集需要查詢和調整 DDT 中記錄的引用計數來決定是否能釋放數據塊。 乍看起來 DDT 貌似挺像 btrfs 的 EXTENT_TREE ，但是本質上 EXTENT_TREE 是根據區塊地址排序的， 而 DDT 因爲是個 hashtable 所以是根據 checksum 排序的。並且 EXTENT_TREE 中記錄的區塊可以是任意大小，而 DDT 中記錄的數據塊是固定大小的，所以碎片不嚴重的情況下 DDT 要比 EXTENT_TREE 多記錄很多數據塊。這些區別都非常影響操作 DDT 時的性能。 DDT 本身是個 DMU 對象，所以對 DDT 的讀寫也是經過 DMU 的 CoW 讀寫，從而也經過 ARC 的緩存。想要有比較合理的 dedup 性能，需要整個 DDT 都儘量保持在內存 ARC 或者 L2ARC 緩存中， 於是 dedup 特性也有了非常佔用內存的特點。每個 DDT 表項需要大概 192 字節來描述一個（ 默認 128KiB 大小的）數據塊，由此可以估算一下平均每 2TiB 的數據需要 3GiB 的內存來支持 dedup 的功能。 Matt 的視頻中後面講到優化 ZFS dedup 的一些思路，大體上未來 ZFS 可以做這些優化： DDT 在內存中仍然是 hashtable ，在存儲介質上則換成類似 ZIL 的日誌結構，讓 DDT 儘量保持在內存中，並且繞過 DMU 減少寫入放大。 給 DDT 表項瘦身，從192字節縮減到接近64字節。 當遇到內存壓力時，從 DDT 中隨機剔除掉引用計數爲 1 的表項。被剔除的表項沒有了未來參與 dedup 的可能性，但是能減輕內存壓力。剔除引用計數爲 1 的表項仍然可以維持數據塊的歸屬信息（ 處理上當作是沒有 dedup 的形式），但是引用計數更高的表項沒法剔除。 這些優化策略目的是想讓 dedup 的性能損失能讓更多使用場景接受。不過因爲缺乏開發者意願， 目前這些策略還只是計劃，沒有實現在 ZFS 的代碼中。 因爲以上特點， ZFS 目前 dedup 特性的適用場景極爲有限，只有在 IO 帶寬、內存大小都非常充裕， 並且可以預見到很多重複的數據的時候適合。聽說過的 ZFS dedup 的成功案例是，比如提供虛擬機服務的服務商，在宿主文件系統上用 ZFS 的 zvol 寄宿虛擬機的磁盤鏡像，客戶在虛擬機內使用其它文件系統。大部分客戶可能用類似版本的操作系統， 從而宿主機整體來看有很多 dedup 的潛質。不過這種應用場景下，服務商很可能偏向選擇 CephFS 這樣的分佈式文件系統提供虛擬機鏡像存儲，而不是 ZFS 這樣侷限在單系統上的本地文件系統。 4.2 btrfs 的 dedup btrfs 目前沒有內建的 dedup 支持，但是因爲有 reflink 所以可以通過第三方工具在事後掃描文件塊來實現 dedup 。這一點乍看像是某種將就之策，實際上瞭解了 ZFS dedup 的實現之後可以看出這個狀況其實更靈活。 在 btrfs 中實現 in-band dedup 本身不算很複雜，增加一個內存中的 bloom filter 然後按情況插入 reflink 的正常思路就夠了。在 btrfs kernel wiki 中有篇筆記 提到已經有了實驗性的 in-band dedup 內核支持的實現。這個實現已經越來越成熟，雖然還有諸多使用限制， 不過實現正確性上問題不大，遲遲沒有辦法合併進主線內核的原因更多是性能上的問題。 如果 btrfs 有了 in-band dedup 這樣系統性的 dedup 方案，那麼不可避免地會增加文件系統中使用 reflink 的數量。這將會暴露出 backref walking 這樣的基礎設施中許多潛在的邊角情況下的性能瓶頸。 前面解釋過 backref walking 操作是個挺大開銷的操作，並且開銷隨着快照和 reflink 的使用而爆炸式增長。直到最近的 btrfs 更新仍然在試圖優化和改善現有 backref walking 的性能問題，可以預測 btrfs 的內建 dedup 支持將需要等待這方面更加成熟。 5 結論和展望 不知不覺圍繞 btrfs 和 zfs 的快照功能寫了一大篇，前前後後寫了一個半月， 文中提及的很多細節我自己也沒有自信，如果有錯誤還請指出。 稍微列舉一些我覺得比較重要的結論，算是 TL;DR 的 takeaway notes 吧： ZFS 的快照非常輕量。完全可以像 NILFS2 的連續快照那樣，每小時一個快照，每天24小時，每年 365天不間斷地創建快照，實際似乎也有公司是這樣用的。如此頻繁的快照不同於 NILFS2 等文件系統提供的連續快照，但是也沒有那些日誌結構文件系統實現連續快照所需承擔的巨大 GC 開銷。 並且 ZFS 可以沒有額外開銷地算出快照等數據集的空間佔用之類的信息。 btrfs 的快照相對也很輕量，比 LVM 和 dm-thin 的快照輕便很多，但是不如 ZFS 的快照輕，因爲 btrfs 有維護反向引用的開銷。 btrfs 要得知子卷的空間佔用情況需要開啓 qgroup 特性，這會對一些需要 backref walking 的操作有一些額外性能損失。 btrfs 對快照和 reflink 沒有限制，日常桌面系統下使用也不太會遇到性能問題。 不過系統性地（自動化地）大量使用快照和 reflink ，在一些操作下可能會有性能問題，值得注意。 因爲沒有 reflink ， ZFS 的數據集劃分需要一些前期計劃。 ZFS 中共享元數據的方式只有快照， 所以要儘量多細分文件系統，方便以後能利用到快照特性，劃分的粒度大致按照可能要回滾快照的粒度來。 btrfs 有 reflink ，於是這裏有很多自由度，即便前期計劃不夠詳細也可以通過 reflink 相對快速調整子卷結構。 dedup 在 zfs 和 btrfs 都是個喜憂參半的特性，開啓前要仔細評估可能的性能損失。ZFS dedup 的成功案例是，比如虛擬機服務的服務商，在宿主文件系統上用 ZFS 寄宿虛擬機的磁盤鏡像，客戶在虛擬機可能用類似版本的操作系統，從而宿主機整體來看有很多 dedup 的潛質。一般桌面場景下 dedup 的收益不明顯，反而有巨大內存和IO帶寬開銷。 相比 btrfs ，ZFS 更嚴格地遵守 CoW 文件系統「僅寫一次」的特點，甚至就算遇到了數據塊損壞， 修復數據塊的時候也只能在原位寫入。 btrfs 因爲有反向引用所以在這方面靈活很多。 ZFS 不支持對單個文件關閉 CoW ，所有文件（以及所有 zvol）都經過 DMU 層有 CoW 語義，這對一些應用場景有性能影響。btrfs 可以對單個文件關閉 CoW ，但是關閉 CoW 同時也丟失了寫文件的事務性語義。 ZFS 不支持碎片整理，靠 ARC 加大緩存來解決碎片帶來的性能問題。 btrfs 有 defrag ，但是目前的實現會切斷 reflink 。 最後關於 ZFS 沒有 reflink 也沒有反向引用的情況，想引用幾段話。 FreeBSD 的發起人之一，FreeBSD 的 FFS 維護者， Kirk McKusick 曾經在 OpenZFS developer summit 2015 這麼說過： I decided I'd add a wish list since I have a whole bunch of people here that could actually possibly consider doing this. Both competitors of ZFS, which are basically WAFL and BTRFS, kind of maintained back pointers. And back pointers allow a lot of things like disk migration, you can go through and tune up file layout, if you're working with direct-mapped flash it allows you to do that effectively. This has been a long -- and I understand big debate with the ZFS people and I'm not going to try and talk about that -- but there's a very nice paper that I've cited here, \"Tracking Back References in a Write Anywhere File System\", that is it integrates keeping track of the back pointers in a way that would work very well with ZFS. And so the cost is low, the cost of actually using it is a little higher, but it's not unreasonable. So there's the reference to that paper and if any of you are contemplating that you should read the paper because if nothing else it's a great paper. Kirk McKusick 呼籲 ZFS 開發者們考慮在 ZFS 中實現類似 backref 的基礎設施，從而可能在未來獲得更多有用的特性。 和 ZFS 實現 backref 相關的一點是目前 ZFS 的塊指針的組織結構。對此 ZFS 的 ZPL 層原作者之一的 Mark Shellenbaum 在 OpenZFS developer summit 2016 也曾說過這樣的話： (Q: Are there any things that we that we have regretted we did?) A: I guess not so much on the ZPL, but with the way block pointers maybe weren't fully virtualized, you know that things like that. 以及 ZFS 的最初的作者 Jeff 在 OpenZFS developer summit 2015 也曾說過： ... and then certainly one thing i'd always wish we had done but there really were always implementation difficulties was true virtual block addressing. Because it would made dedup simpler, or would have made you know compression of data, defragging, all that kind of stuff simpler. That would have been really nice to have. But we never did the way that was sort of tracable in terms of both the cost and the transactional semantics. ZFS 這些開發者元老們都希望 ZFS 能有某種類似 backref 的機制，或者讓塊指針記錄的地址更抽象的機制。 關於這一點，ZFS 最重要的作者 Matt 如何看的呢？ Matt 近期似乎沒有發表過看法，但是熟悉 ZFS 的人可能聽到過 Matt 一直在計劃的另一項 ZFS 特性中看出些端倪，叫 BP rewrite ，或者 BP virtualization 。從 Matt 還在 Sun 的時候開始，就試圖在 ZFS 中實現 BP rewrite 特性，提供某種系統性的基礎設施，能夠快速地找到並改寫大量數據塊指針。 在網上搜索很多 ZFS 功能的實現細節，最終都會帶到關於 BP rewrite 的討論（甚至可以說論戰）中。 Matt 最近給 OpenZFS 實現的兩項功能， toplevel vdev removal 和 raidz expansion 如果有 BP rewrite 將會容易很多，而他們目前是在沒有 BP rewrite 的前提下，通過一連串額外抽象實現的。 從 BP rewrite 這個兔子洞中，還能引出更多 btrfs 和 ZFS 關於設備管理的差異，這個有待今後再談。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"//farseerfc.me/btrfs-vs-zfs-difference-in-implementing-snapshots.html"},{"title":"ZFS 分層架構設計","text":"2020年2月9日更新過 ZFS 在設計之初源自於 Sun 內部多次重寫 UFS 的嘗試，背負了重構 Solaris 諸多內核子系統的重任，從而不同於 Linux 的文件系統只負責文件系統的功能而把其餘功能（比如內存髒頁管理， IO調度）交給內核更底層的子系統， ZFS 的整體設計更層次化並更獨立，很多部分可能和 Linux/FreeBSD 內核已有的子系統有功能重疊。 似乎很多關於 ZFS 的視頻演講和幻燈片有講到子系統架構，但是找了半天也沒找到網上關於這個的說明文檔。 於是寫下這篇筆記試圖從 ZFS 的早期開發歷程開始，記錄一下 ZFS 分層架構中各個子系統之間的分工。 也有幾段 OpenZFS Summit 視頻佐以記錄那段歷史。 早期架構 早期 ZFS 在開發時大體可以分爲上下三層，分別是 ZPL， DMU 和 SPA ，這三層分別由三組人負責。 最初在 Sun 內部帶領 ZFS 開發的是 Jeff Bonwick ，他首先有了對 ZFS 整體架構的構思，然後遊說 Sun 高層，親自組建起了 ZFS 開發團隊，招募了當時剛從大學畢業的 Matt Ahrens 。作爲和 Sun 高層談妥的條件， Jeff 也必須負責 Solaris 整體的 Storage & Filesystem Team ，於是他又從 Solaris 的 Storage Team 抽調了 UFS 部分的負責人 Mark Shellenbaum 和 Mark Maybee 來開發 ZFS 。而如今昔日昇陽已然日落， Jeff 成立了獨立公司繼續開拓服務器存儲領域， Matt 是 OpenZFS 項目的負責人，兩位 Mark 則留在了 Sun/Oracle 成爲了 Oracle ZFS 分支的維護者。 The Birth of ZFS by Jeff Bonwick Story Time (Q&A) with Matt and Jeff ZFS First Mount by Mark Shellenbaum ZFS past & future by Mark Maybee 在開發早期，作爲分工， Jeff 負責 ZFS 設計中最底層的 SPA ，提供多個存儲設備組成的存儲池抽象； Matt 負責 ZFS 設計中最至關重要的 DMU 引擎，在塊設備基礎上提供具有事務語義的對象存儲； 而兩位 Mark 負責 ZFS 設計中直接面向用戶的 ZPL ，在 DMU 基礎上提供完整 POSIX 文件系統語義。 ZFS 設計中這最初的分工也體現在了 ZFS 現在子系統分層的架構上，繼續影響（增強或者限制） ZFS 今後發展的方向。 子系統整體架構 首先 ZFS 整體架構如下圖，其中圓圈是 ZFS 給內核層的外部接口，方框是 ZFS 內部子系統（ 我給方框的子系統加上了超鏈接）： ZFS_Layer_Architecture clusterTOL TOL clusterSPA SPA Filesystem API Filesystem API VFS VFS Filesystem API->VFS Block device API Block device API /dev/zvol/... /dev/zvol/... Block device API->/dev/zvol/... ZFS Management API (libzfs) ZFS Management API (libzfs) /dev/zfs ioctl /dev/zfs ioctl ZFS Management API (libzfs)->/dev/zfs ioctl NFS/Samba API (libshare) NFS/Samba API (libshare) NFS/CIFS vop_rwlock NFS/CIFS vop_rwlock NFS/Samba API (libshare)->NFS/CIFS vop_rwlock VFS->NFS/CIFS vop_rwlock ZPL ZPL VFS->ZPL ZVOL ZVOL /dev/zvol/...->ZVOL DSL DSL /dev/zfs ioctl->DSL VDEV VDEV /dev/zfs ioctl->VDEV DMU DMU NFS/CIFS vop_rwlock->DMU ZAP ZAP ZPL->ZAP ZPL->DMU ZIL ZIL ZPL->ZIL ZVOL->DMU DSL->ZAP DSL->DMU ZAP->DMU ARC ARC DMU->ARC MetaSlab MetaSlab DMU->MetaSlab ZIO ZIO ARC->ZIO L2ARC L2ARC ARC->L2ARC ZIL->ZIO SLOG SLOG ZIL->SLOG ZIO->MetaSlab ZIO->VDEV L2ARC->ZIO L2ARC->VDEV SLOG->VDEV MetaSlab->VDEV physical storage devices physical storage devices VDEV->physical storage devices 接下來從底層往上介紹一下各個子系統的全稱和職能。 SPA Storage Pool Allocator 從內核提供的多個塊設備中抽象出存儲池的子系統。 SPA 進一步分爲 ZIO 和 VDEV 兩大部分和其餘一些小的子系統。 SPA 對 DMU 提供的接口不同於傳統的塊設備接口，完全利用了 CoW 文件系統對寫入位置不敏感的特點。 傳統的塊設備接口通常是寫入時指定一個寫入地址，把緩衝區寫到磁盤指定的位置上，而 DMU 可以讓 SPA 做兩種操作： write ， DMU 交給 SPA 一個數據塊的內存指針， SPA 負責找設備寫入這個數據塊，然後返回給 DMU 一個 block pointer 。 read ，DMU 交給 SPA 一個 block pointer ，SPA 讀取設備並返回給 DMU 完整的數據塊。 也就是說，在 DMU 讓 SPA 寫數據塊時， DMU 還不知道 SPA 會寫入的地方，這完全由 SPA 判斷， 這一點通常被稱爲 Write Anywhere ，在別的 CoW 文件系統比如 Btrfs 和 WAFL 中也有這個特點。 反過來 SPA 想要對一個數據塊操作時，也完全不清楚這個數據塊用於什麼目的，屬於什麼文件或者文件系統結構。 VDEV Virtual DEVice VDEV 在 ZFS 中的作用相當於 Linux 內核的 Device Mapper 層或者 FreeBSD GEOM 層，提供 Stripe/Mirror/RAIDZ 之類的多設備存儲池管理和抽象。 ZFS 中的 vdev 形成一個樹狀結構，在樹的底層是從內核提供的物理設備， 其上是虛擬的塊設備。每個虛擬塊設備對上對下都是塊設備接口，除了底層的物理設備之外，位於中間層的 vdev 需要負責地址映射、容量轉換等計算過程。 除了用於存儲數據的 Stripe/Mirror/RAIDZ 之類的 VDEV ，還有一些特殊用途的 VDEV ，包括提供二級緩存的 L2ARC 設備，以及提供 ZIL 高速日誌的 SLOG 設備。 ZIO ZIO Pipeline by George Wilson ZFS I/O 作用相當於內核的 IO scheduler 和 pagecache write back 機制。 OpenZFS Summit 有个演讲整理了 ZIO 流水线的工作原理。 ZIO 內部使用流水線和事件驅動機制，避免讓上層的 ZFS 線程阻塞等待在 IO 操作上。 ZIO 把一個上層的寫請求轉換成多個寫操作，負責把這些寫操作合併到 transaction group 提交事務組。 ZIO 也負責將讀寫請求按同步還是異步分成不同的讀寫優先級並實施優先級調度， 在 OpenZFS 項目 wiki 頁有一篇描述 ZIO 調度 的細節。 除了調度之外， ZIO 層還負責在讀寫流水線中拆解和拼裝數據塊。上層 DMU 交給 SPA 的數據塊有固定大小， 目前默認是 128KiB ，pool 整體的參數可以調整塊大小在 4KiB 到 8MiB 之間。ZIO 拿到整塊大小的數據塊之後，在流水線中可以對數據塊做諸如以下操作： 用壓縮算法，壓縮/解壓數據塊。 查詢 dedup table ，對數據塊去重。 加密/解密數據塊。 計算數據塊的校驗和。 如果底層分配器不能分配完整的 128KiB （或 zpool 設置的大小），那麼嘗試分配多個小塊，然後用多個 512B 的指針間接塊連起多個小塊的，拼裝成一個虛擬的大塊，這個機制叫 gang block 。通常 ZFS 中用到 gang block 時，整個存儲池處於極度空間不足的情況，由 gang block 造成嚴重性能下降，而 gang block 的意義在於在空間接近要滿的時候也能 CoW 寫入一些元數據，釋放亟需的存儲空間。 可見經過 ZIO 流水線之後，數據塊不再是統一大小，這使得 ZFS 用在 4K 對齊的磁盤或者 SSD 上有了一些新的挑戰。 MetaSlab MetaSlab Allocation Performance by Paul Dagnelie MetaSlab 是 ZFS 的塊分配器。 VDEV 把存儲設備抽象成存儲池之後， MetaSlab 負責實際從存儲設備上分配數據塊，跟蹤記錄可用空間和已用空間。 叫 MetaSlab 這個名字是因爲 Jeff 最初同時也給 Solaris 內核寫過 slab 分配器 ，一開始設計 SPA 的時候 Jeff 想在 SPA 中也利用 Solaris 的 slab 分配器對磁盤空間使用類似的分配算法。後來 MetaSlab 逐漸不再使用 slab 算法，只有名字留了下來。 MetaSlab 的結構很接近於 FreeBSD UFS 的 cylinder group ，或者 ext2/3/4 的 block group ，或者 xfs 的 allocation group ，目的都是讓存儲分配策略「局域化」， 或者說讓近期分配的數據塊的物理地址比較接近。在存儲設備上創建 zpool 的時候，首先會儘量在存儲設備上分配 200 個左右的 MetaSlab ，隨後給 zpool 增加設備的話使用接近的 MetaSlab 大小。每個 MetaSlab 是連續的一整塊空間，在 MetaSlab 內對數據塊空間做分配和釋放。磁盤中存儲的 MetaSlab 的分配情況是按需載入內存的，系統 import zpool 時不需要載入所有 MetaSlab 到內存，而只需加載一小部分。當前載入內存的 MetaSlab 剩餘空間告急時，會載入別的 MetaSlab 嘗試分配，而從某個 MetaSlab 釋放空間不需要載入 MetaSlab 。 OpenZFS Summit 也有一個對 MetaSlab 分配器性能的介紹，可以看到很多分配器內的細節。 ARC ELI5: ZFS Caching Explain Like I'm 5: How the ZFS Adaptive Replacement Cache works Adaptive Replacement Cache ARC 的作用相當於 Linux/Solaris/FreeBSD 中傳統的 page/buffer cache 。 和傳統 pagecache 使用 LRU (Least Recently Used) 之類的算法剔除緩存頁不同， ARC 算法試圖在 LRU 和 LFU(Least Frequently Used) 之間尋找平衡，從而複製大文件之類的線性大量 IO 操作不至於讓緩存失效率猛增。最近 FOSDEM 2019 有一個介紹 ZFS ARC 工作原理的視頻。 不過 ZFS 採用它自有的 ARC 一個顯著缺點在於，不能和內核已有的 pagecache 機制相互配合，尤其在 系統內存壓力很大的情況下，內核與 ZFS 無關的其餘部分可能難以通知 ARC 釋放內存。所以 ARC 是 ZFS 消耗內存的大戶之一（另一個是可選的 dedup table），也是 ZFS 性能調優 的重中之重。 當然， ZFS 採用 ARC 不依賴於內核已有的 pagecache 機制除了 LFU 平衡的好處之外，也有別的有利的一面。 系統中多次讀取因 snapshot 或者 dedup 而共享的數據塊的話，在 ZFS 的 ARC 機制下，同樣的 block pointer 只會被緩存一次；而傳統的 pagecache 因爲基於 inode 判斷是否有共享， 所以即使這些文件有共享頁面（比如 btrfs/xfs 的 reflink 形成的），也會多次讀入內存。 Linux 的 btrfs 和 xfs 在 VFS 層面有共用的 reflink 機制之後，正在努力着手改善這種局面，而 ZFS 因爲 ARC 所以從最初就避免了這種浪費。 和很多傳言所說的不同， ARC 的內存壓力問題不僅在 Linux 內核會有，在 FreeBSD 和 Solaris/Illumos 上也是同樣，這個在 ZFS First Mount by Mark Shellenbaum 的問答環節 16:37 左右有提到 。其中 Mark Shellenbaum 提到 Matt 覺得讓 ARC 併入現有 pagecache 子系統的工作量太大，難以實現。 因爲 ARC 工作在 ZIO 上層，所以 ARC 中緩存的數據是經過 ZIO 從存儲設備中讀取出來之後解壓、解密等處理之後的，原始的數據。最近 ZFS 的版本有支持一種新特性叫 Compressed ARC ，打破 ARC 和 VDEV 中間 ZIO 的壁壘，把壓縮的數據直接緩存在 ARC 中。這麼做是因爲壓縮解壓很快的情況下，壓縮的 ARC 能節省不少內存，讓更多數據保留在 ARC 中從而提升緩存利用率，並且在有 L2ARC 的情況下也能增加 L2ARC 能存儲的緩存。 L2ARC Level 2 Adaptive Replacement Cache 這是用 ARC 算法實現的二級緩存，保存於高速存儲設備上。常見用法是給 ZFS pool 配置一塊 SSD 作爲 L2ARC 高速緩存，減輕內存 ARC 的負擔並增加緩存命中率。 SLOG Separate intent LOG SLOG 是額外的日誌記錄設備。 SLOG 之於 ZIL 有點像 L2ARC 之餘 ARC ， L2ARC 是把內存中的 ARC 放入額外的高速存儲設備，而 SLOG 是把原本和別的數據塊存儲在一起的 ZIL 放到額外的高速存儲設備。 TOL Transactional Object Layer 這一部分子系統在數據塊的基礎上提供一個事務性的對象語義層，這裏事務性是指， 對對象的修改處於明確的狀態，不會因爲突然斷電之類的原因導致狀態不一致。TOL 中最主要的部分是 DMU 層。 DMU Data Management Unit 在塊的基礎上提供「對象（object）」的抽象。每個「對象」可以是一個文件，或者是別的 ZFS 內部需要記錄的東西。 DMU 這個名字最初是 Jeff 想類比於操作系統中內存管理的 MMU(Memory Management Unit)， Jeff 希望 ZFS 中增加和刪除文件就像內存分配一樣簡單，增加和移除塊設備就像增加內存一樣簡單， 由 DMU 負責從存儲池中分配和釋放數據塊，對上提供事務性語義，管理員不需要管理文件存儲在什麼存儲設備上。 這裏事務性語義指對文件的修改要麼完全成功，要麼完全失敗，不會處於中間狀態，這靠 DMU 的 CoW 語義實現。 DMU 實現了對象級別的 CoW 語義，從而任何經過了 DMU 做讀寫的子系統都具有了 CoW 的特徵， 這不僅包括文件、文件夾這些 ZPL 層需要的東西，也包括文件系統內部用的 spacemap 之類的設施。 相反，不經過 DMU 的子系統則可能沒法保證事務語義。這裏一個特例是 ZIL ，一定程度上繞過了 DMU 直接寫日誌。說一定程度是因爲 ZIL 仍然靠 DMU 來擴展長度，當一個塊寫滿日誌之後需要等 DMU 分配一個新塊，在分配好的塊內寫日誌則不需要經過 DMU 。所有經過 DMU 子系統的對象都有 CoW 語義，也意味着 ZFS 中不能對某些文件可選地關閉 CoW ，不能提供數據庫應用的 direct IO 之類的接口。 「對象（object）」抽象是 DMU 最重要的抽象，一個對象的大小可變，佔用一個或者多個數據塊（ 默認一個數據塊 128KiB ）。上面提到 SPA 的時候也講了 DMU 和 SPA 之間不同於普通塊設備抽象的接口，這使得 DMU 按整塊的大小分配空間。當對象使用多個數據塊存儲時， DMU 提供間接塊（indirect block）來引用這些數據塊。 間接塊很像傳統 Unix 文件系統（Solaris UFS 或者 Linux ext2）中的一級二級三級間接塊， 一個間接塊存儲很多塊指針（block pointer），多個間接塊形成樹狀結構，最終一個塊指針可以引用到一個對象。 更現代的文件系統比如 ext4/xfs/btrfs/ntfs 提供了 extent 抽象，可以指向一個連續範圍的存儲塊， 而 ZFS 不使用類似 extent 的抽象。DMU 採用間接塊而不是 extent ，使得 ZFS 的空間分配更趨向碎片化，爲了避免碎片化造成的性能影響，需要儘量延遲寫入使得一次寫入能在磁盤上 儘量連續，這裏 ARC 提供的緩存和 ZIO 提供的流水線對延遲寫入避免碎片有至關重要的幫助。 有了「對象（object）」的抽象之後， DMU 進一步實現了「對象集（objectset）」的抽象， 一個對象集中保存一系列按順序編號的 dnode （ ZFS 中類似 inode 的數據結構），每個 dnode 有足夠空間 指向一個對象的最多三個塊指針，如果對象需要更多數據塊可以使用間接塊，如果對象很小也可以直接壓縮進 dnode 。隨後 DSL 又進一步用對象集來實現數據集（dataset）抽象，提供比如文件系統（filesystem ）、快照（snapshot）、克隆（clone）之類的抽象。一個對象集中的對象可以通過 dnode 編號相互引用， 就像普通文件系統的硬鏈接引用 inode 編號那樣。 上面也提到因爲 SPA 和 DMU 分離， SPA 完全不知道數據塊用於什麼目的；這一點其實對 DMU 也是類似， DMU 雖然能從某個對象找到它所佔用的數據塊，但是 DMU 完全不知道這個對象在文件系統或者存儲池中是 用來存儲什麼的。當 DMU 讀取數據遇到壞塊（block pointer 中的校驗和與 block pointer 指向的數據塊內容不一致）時，它知道這個數據塊在哪兒（具體哪個設備上的哪個地址）， 但是不知道這個數據塊是否和別的對象共享，不知道搬動這個數據塊的影響，也沒法從對象反推出文件系統路徑， （除了明顯開銷很高地掃一遍整個存儲池）。所以 DMU 在遇到讀取錯誤（普通的讀操作或者 scrub/resilver 操作中）時，只能選擇在同樣的地址，原地寫入數據塊的備份（如果能找到或者推算出備份的話）。 或許有人會疑惑，既然從 SPA 無法根據數據地址反推出對象，在 DMU 也無法根據對象反推出文件，那麼 zfs 在遇到數據損壞時是如何在診斷信息中給出損壞的文件路徑的呢？這其實基於 ZPL 的一個黑魔法： 在 dnode 記錄父級 dnode 的編號 。因爲是個黑魔法，這個記錄不總是對的，所以只能用於診斷信息，不能基於這個實現別的文件系統功能。 ZAP ZFS Attribute Processor 在 DMU 提供的「對象」抽象基礎上提供緊湊的 name/value 映射存儲， 從而文件夾內容列表、文件擴展屬性之類的都是基於 ZAP 來存。 ZAP 在內部分爲兩種存儲表達： microZAP 和 fatZAP 。 一個 microZAP 佔用一整塊數據塊，能存 name 長度小於 50 字符並且 value 是 uint64_t 的表項， 每個表項 64 字節。 fatZAP 則是個樹狀結構，能存更多更複雜的東西。 fatZAP 是個 on disk 的散利表，指針表中是 64bit 對 name 的 hash ，指向單鏈表的子節點列表，子節點中的 value 可以是任意類型的數據（不光是 uint64_t ）。 可見 microZAP 非常適合表述一個普通大小的文件夾裏面包含到很多普通文件 inode （ZFS 是 dnode）的引用。 fatZAP 則不光可以用於任意大小的文件夾，還可以表達 ZFS 的配置屬性之類的東西，非常靈活。 在 ZFS First Mount by Mark Shellenbaum 的8:48左右 提到，最初 ZPL 中關於文件的所有屬性（包括訪問時間、權限、大小之類所有文件都有的）都是基於 ZAP 來存，也就是說每個文件都有個 ZAP ，其中有叫做 size 呀 owner 之類的鍵值對，就像是個 JSON 對象那樣，這讓 ZPL 一開始很容易設計原型並且擴展。然後文件夾內容列表有另一種數據結構 ZDS（ZFS Directory Service），後來常見的文件屬性在 ZPL 有了專用的緊湊數據結構，而 ZDS 則漸漸融入了 ZAP 。 這些變化詳見下面 ZPL 。 DSL Dataset and Snapshot Layer 數據集和快照層，負責創建和管理快照、克隆等數據集類型，跟蹤它們的寫入大小，最終刪除它們。 由於 DMU 層面已經負責了對象的寫時複製語義和對象集的概念，所以 DSL 層面不需要直接接觸寫文件之類來自 ZPL 的請求，無論有沒有快照對 DMU 層面一樣採用寫時複製的方式修改文件數據。 不過在刪除快照和克隆之類的時候，則需要 DSL 參與計算沒有和別的數據集共享的數據塊並且刪除它們。 DSL 管理數據集時，也負責管理數據集上附加的屬性。ZFS 每個數據集有個屬性列表，這些用 ZAP 存儲， DSL 則需要根據數據集的上下級關係，計算出繼承的屬性，最終指導 ZIO 層面的讀寫行爲。 除了管理數據集， DSL 層面也提供了 zfs 中 send/receive 的能力。 ZFS 在 send 時從 DSL 層找到快照引用到的所有數據塊，把它們直接發往管道，在 receive 端則直接接收數據塊並重組數據塊指針。 因爲 DSL 提供的 send/receive 工作在 DMU 之上，所以在 DSL 看到的數據塊是 DMU 的數據塊，下層 SPA 完成的數據壓縮、加密、去重等工作，對 DMU 層完全透明。所以在最初的 send/receive 實現中，假如數據塊已經壓縮，需要在 send 端經過 SPA 解壓，再 receive 端則重新壓縮。最近 ZFS 的 send/receive 逐漸打破 DMU 與 SPA 的壁壘，支持了直接發送已壓縮或加密的數據塊的能力。 ZIL ZFS Intent Log 記錄兩次完整事務語義提交之間的日誌，用來加速實現 fsync 之類的文件事務語義。 原本 CoW 的文件系統不需要日誌結構來保證文件系統結構的一致性，在 DMU 保證了對象級別事務語義的前提下，每次完整的 transaction group commit 都保證了文件系統一致性，掛載時也直接找到最後一個 transaction group 從它開始掛載即可。 不過在 ZFS 中，做一次完整的 transaction group commit 是個比較耗時的操作， 在寫入文件的數據塊之後，還需要更新整個 object set ，然後更新 meta-object set ，最後更新 uberblock ，爲了滿足事務語義這些操作沒法並行完成，所以整個 pool 提交一次需要等待好幾次磁盤寫操作返回，短則一兩秒，長則幾分鐘， 如果事務中有要刪除快照等非常耗時的操作可能還要等更久，在此期間提交的事務沒法保證一致。 對上層應用程序而言，通常使用 fsync 或者 fdatasync 之類的系統調用，確保文件內容本身的事務一致性。 如果要讓每次 fsync/fdatasync 等待整個 transaction group commit 完成，那會嚴重拖慢很多應用程序，而如果它們不等待直接返回，則在突發斷電時沒有保證一致性。 從而 ZFS 有了 ZIL ，記錄兩次 transaction group 的 commit 之間發生的 fsync ，突然斷電後下次 import zpool 時首先找到最近一次 transaction group ，在它基礎上重放 ZIL 中記錄的寫請求和 fsync 請求，從而滿足 fsync API 要求的事務語義。 顯然對 ZIL 的寫操作需要繞過 DMU 直接寫入數據塊，所以 ZIL 本身是以日誌系統的方式組織的，每次寫 ZIL 都是在已經分配的 ZIL 塊的末尾添加數據，分配新的 ZIL 塊仍然需要經過 DMU 的空間分配。 傳統日誌型文件系統中對 data 開啓日誌支持會造成每次文件系統寫入操作需要寫兩次到設備上， 一次寫入日誌，再一次覆蓋文件系統內容；在 ZIL 實現中則不需要重複寫兩次， DMU 讓 SPA 寫入數據之後 ZIL 可以直接記錄新數據塊的 block pointer ，所以使用 ZIL 不會導致傳統日誌型文件系統中雙倍寫入放大的問題。 ZVOL ZFS VOLume 有點像 loopback block device ，暴露一個塊設備的接口，其上可以創建別的 FS 。對 ZFS 而言實現 ZVOL 的意義在於它是比文件更簡單的接口，所以在實現完整 ZPL 之前，一開始就先實現了 ZVOL ，而且 早期 Solaris 沒有 thin provisioning storage pool 的時候可以用 ZVOL 模擬很大的塊設備，當時 Solaris 的 UFS 團隊用它來測試 UFS 對 TB 級存儲的支持情況 。 因爲 ZVOL 基於 DMU 上層，所以 DMU 所有的文件系統功能，比如 snapshot / dedup / compression 都可以用在 ZVOL 上，從而讓 ZVOL 上層的傳統文件系統也具有類似的功能。並且 ZVOL 也具有了 ARC 緩存的能力，和 dedup 結合之下，非常適合於在一個宿主機 ZFS 上提供對虛擬機文件系統鏡像的存儲，可以節省不少存儲空間和內存佔用開銷。 ZPL ZFS Posix Layer 提供符合 POSIX 文件系統語義的抽象，也就是包括文件、目錄、軟鏈接、套接字這些抽象以及 inode 訪問時間、權限那些抽象，ZPL 是 ZFS 中對一個普通 FS 而言用戶直接接觸的部分。 ZPL 可以說是 ZFS 最複雜的子系統，也是 ZFS 作爲一個文件系統而言最關鍵的部分。 ZPL 的實現中直接使用了 ZAP 和 DMU 提供的抽象，比如每個 ZPL 文件用一個 DMU 對象表達，每個 ZPL 目錄用一個 ZAP 對象表達，然後 DMU 對象集對應到 ZPL 下的一個文件系統。 也就是說 ZPL 負責把操作系統 VFS 抽象層的那些文件系統操作接口，翻譯映射到基於 DMU 和 ZAP 的抽象上。傳統 Unix 中的管道、套接字、軟鏈接之類的沒有什麼數據內容的東西則在 ZPL 直接用 dnode 實現出來。 ZPL 也需要進一步實現文件權限、所有者、訪問日期、擴展屬性之類雜七雜八的文件系統功能。 2020年2月9日添加 繼續上述 ZAP 格式變化的討論，在 ZPL 拋棄早期用 ZAP 的設計之後， ZPL 中 znode （ZPL 擴展的 dnode） 保存文件屬性的機制成爲了一個小的子系統，叫 ZFS System Attributes 。 SA 的設計照顧了舊版 ZPL znode 格式兼容問題，有新舊兩代格式。舊版 znode 格式是固定偏移位置存取屬性的 SA ，因此透過預先註冊好的描述舊版 znode 格式的固定映射表， SA 依然能用同樣的代碼路徑存取舊版的 znode 。而後來 靈活的新設計下的 SA 更有意思 ，ZFS 認識到，大部分 znode 的屬性都可以用有限的幾種屬性集來表达， 比如普通文件有一組類似的屬性（權限、所有者之類的）， zvol 有另一組（明顯 zvol 不需要很多 ZPL 文件的屬性），整個 ZFS dataset 可以「註冊」幾種屬性佈局，然後讓每個 znode 引用其中一種佈局， 這樣 znode 保存的屬性仍然是可以任意變化的，又不需要在每個 znode 中都記錄所有屬性的名字。 SA 的出現提升了 ZPL 的可擴展性。 ZPL 爲了應付不同的操作系統之間文件系統 API 的差異，可以使用 SA 在 znode 之中加入針對不同操作系統和應用場景的屬性。例如，在支持 NFSv4 ACL 的操作系統上，ZFS 既可以用現有方式把 DACL ACEs 放在獨立於文件對象的單獨對象中，也可以把 DACL ACEs 放在 SA 內。 在 ZFS First Mount by Mark Shellenbaum 中介紹了很多在最初實現 ZPL 過程中的坎坷， ZPL 的困難之處在於需要兼容現有應用程序對傳統文件系統 API 的使用方式，所以他們需要大量兼容性測試。視頻中講到非常有意思的一件事是， ZFS 在設計時不想重複 Solaris UFS 設計中的很多缺陷，於是實現 VFS API 時有諸多取捨和再設計。 其中他們遇到了 VOP_RWLOCK ，這個是 UFS 提供的文件級別讀寫鎖。對一些應用尤其是 NFS 而言，文件讀寫鎖能保證應用層的一致性，而對另一些應用比如數據庫而言， 文件鎖的粒度太大造成了性能問題。在設計 ZPL 的時候他們不想在 ZFS 中提供 VOP_RWLOCK ，這讓 NFS 開發者們很難辦（要記得 NFS 也是 Solaris 對 Unix 世界貢獻的一大發明）。 最終 ZFS 把 DMU 的內部細節也暴露給了 NFS ，讓 NFS 基於 DMU 的對象創建時間（ TXG id ）而不是文件鎖來保證 NFS 的一致性。結果是現在 ZFS 中也有照顧 NFS 的代碼，後來也加入了 Samba/CIFS 的支持，從而在 ZFS 上設置 NFS export 時是通過 ZFS 的機制而非系統原生的 NFS export 機制。","tags":"tech","url":"//farseerfc.me/zfs-layered-architecture-design.html"},{"title":"和萌狼交換問題","text":"很抱歉萌狼很早就提過交換問題的事，被我一直咕咕了許久。 拖延症晚期有藥麼 我的提問和萌狼的回答 可以去萌狼的博客上看呀 Q1：除了博客的「关于」页面以外，还愿意再向咱介绍一下自己嘛？ 介紹自己啊。 寫了刪刪了寫，不知道該介紹點啥 就說點自己的興趣？ 喜歡自由開源軟件，喜歡 Arch Linux 。喜歡這些倒不是出於 RMS 和 FSF 那樣道義上的原因， 我覺得商業軟件公司要賺錢吃飯也是無可厚非的。 喜歡自由軟件是因爲，當我需要知道它到底怎麼工作的時候，有可能去挖代碼，必要的話能去改代碼。 當然我一個人肯定不能讀所有在用的軟件，但是我知道我有讀和修改代碼的權利的話， 那麼我認識的朋友們也同樣有這樣的權利，我不認識的廣大社區有千千萬萬的人也同樣有這樣的權利， 從而我相信當我遇到問題的時候不至於卡在某些人某些公司某些集體的決策上而無法解決。 基於這個理由，我對開源社區也同樣有公開全部細節的期待。我喜歡 Arch Linux 因爲即便它的內部決策只是一小波人，但是導致決策的討論以及決策的執行方式全是公開的，可以在網上翻閱， 可以追根溯源，這讓我有種安心感。就像我不喜歡 Manjaro 的一點是它有太多細節是翻閱不到的， 雖然它也是開源社區，但是打包細節翻閱不到，包列表翻閱不到，決策的制定和執行的過程也翻閱不到， 通常就只是在他們的論壇上發個通知了事，這我很不喜歡。 除了喜歡自由開源軟件之外，可能我在網上比較有特點的地方是用繁體字了吧， 也曾經年幼時在水木社區和別人因爲這個吵過嘴，也在 知乎上寫過篇「在知乎用繁體字是怎樣一種體驗」 。 致力於在我存在的地方爲繁體字愛好者們提供一個安逸的環境，不過好像最近也不見很多反對的聲音了。 除了網上之外，現實中的自己嘛，特點可能算是不知道自己屬於哪兒了……一個漂泊的人。 小時候8歲前在陝西長大，把自己當作陝西人，但是身邊的鄰里街坊們卻以河南人和江浙人居多。 廠辦環境，好幾個大型重工都從江浙搬到了陝西秦川一帶，加上國共內戰的時候河南黃河缺口造成的難民慌西逃， 構成了當時廠辦的主要人口拿着城市戶口，反而是當地的陝西人都是農民戶口， 於是和廠辦子弟們形成了鮮明的隔閡。我對社會主義，對蘇式廠辦，對整個國家結構的理解大概也是從那兒來的。 跟着鄰里們學會了河南話，在家裏說普通話，從老一輩們身上又學會了江浙的語調。 都說一個廠辦是一個社會的縮影，那時候的環境可能算聚集了全國東南西北的樣子吧。 8、9歲左右隨父母到了上海，因爲不會說上海話受同學們排擠，倒也不是很在意，漸漸和同學們學起了上海話， 可能還參雜點爺爺奶奶的江蘇方言。十多年後考入大學，五湖四海的同學都有，就不算是在上海了。 大學畢業來了日本，一晃又是7年過去。至此我大概比起同齡人接觸到更多全國各地的人， 也分不清自己的歸屬地了。但有一條，我知道自己是個中國人，爲自己是個中國人自豪，覺得雖在他鄉， 該爲中國做點自己的貢獻。 Q2：现在这个名字是怎么想到的呢？ farseerfc 這個名字嘛，來自 firechild 這個更早的網名，和魔獸爭霸裏面 farseer 這個英雄。 farseer 本算是 Anglish ，以日耳曼語系的構詞法再造的英語詞，對應拉丁構詞法的話 far = tele ， seer = visioner ，於是 farseer 也就是 tele-visioner ，看得遠的人，電視一詞 television 的原本的詞幹的衍生詞。 不過說爲什麼選 farseer 這個名字，更多是爲了符合 fc 這個縮寫，而 fc 來自 firechild 這個詞。 再深挖黑歷史也不再有什麼意義了， farseerfc 作爲網名只是一直以來的習慣吧。 Q3：觉得咱俩之间最令汝印象深刻的时候是什么？ 近期來看，印象最深刻的可能算是起草 Arch Linux 中文社区交流群指引 吧，看得出萌狼對社區發展的熱心和好意。 再往前，印象深刻的時候可能是萌狼用 Pelican 搭博客吧，最初認識萌狼的時候覺得是 MediaWiki 方面的行家，還以爲博客也會繼續用 MediaWiki 打造，沒想到能吃了 Pelican 的安利，外加萌狼寫博文的產量着實讓人望塵莫及。 然後 ArchWiki 上 Beginner's Guide 被刪除之後，萌狼的博客多了一篇爲新人們寫的入門安裝手冊， 配有完整截圖指引，詳盡程度令人感嘆。感覺得到萌狼作爲一個「過來人」對新人們的照顧。 每次羣中鬧起爭執，老用戶們對新人發起調侃的時候，也是萌狼站出來爲新人們解圍， 幫助有能力的人適應羣裏的討論環境。或許最初寫交流羣指引的時候也是出於這樣的良苦用心吧。 Q4：对咱的印象怎么样？ 最早來 Arch Linux CN 的時候，似乎萌狼還不叫萌狼？不記得那時候用的名字了。只記得來自 AOSC ，和那邊一衆談笑風聲，着實令人羨慕，經常跑他們的聚會也令人羨慕。 後來有了萌狼的名字，群裏的狼們也漸漸多了起來，一時間都分不清哪個狼是哪個了。 不過萌狼的口癖和說話方式總是在狼羣中非常有標誌性。 後來似乎發生了好多事情，我不知道的事情，也不敢妄加揣測。萌狼開始變身音遊大佬， 羣裏的別的狼們漸漸也各忙東西。不知道什麼原因，萌狼會偶爾退群，想問下前因後果， 又覺得自己不該多管閒事。不過無論萌狼退羣多少次，總是在默默關心着社區發展， 關心着新人融入社區的環境。 似乎萌狼加入了 FSF ？玩起了 Parabola ，玩起了 linux-libre 。有能跑起完全自由的發行版的設備， 這一點也非常令人羨慕。似乎有很多設備，但是似乎又很不滿於現狀。看得出萌狼爲了理想放棄了很多東西， 或許大家都是如此吧，也或許只是我多心。 還有就是萌狼用 Gnome ，感覺 AOSC 那邊很多人都用 Gnome ，給 Gnome 貢獻翻譯之類的， 萌狼或許也是其中一員。DE 黨爭是水羣久勝不衰的話題，或許我也有些責任，但是我覺得以發行版角度而言 DE 多樣性非常重要，萌狼在社區中的作用也不可或缺。 Q5：在汝用过的 GNU/Linux 发行版之间汝最喜欢的是哪一个，为啥咧？ 最喜歡的當然是 Arch Linux 啦，喜歡的理由前面 Q1 算是提到了一些。其實別的發行版的很多特性也很眼饞， 眼饞 Fedora Silverblue 的 A/B 更新機制，眼饞 Fedora 的 SELinux 和諸多企業級特性支援，眼饞 openSUSE 的 OBS 和 btrfs 支持，眼饞 debian 的小巧和細化打包，眼饞 NixOS 的函數式包管理， 眼饞 Gentoo 的可定製性，眼饞 Parabola / GuixSD 的完全自由。 但是總得來說， Arch Linux 提供的基礎足夠讓我折騰系統成自己喜歡的方式，足夠順手， 也在需要軟件的時候足夠自己打包使用，不需要等待某些遠在天邊的議會做決策，或許是讓我留在 Arch Linux 的原因吧（當然更大原因可能是因爲慣性）。發行版之間的技術區別可能並不那麼重要， 重要的是該幹活的時候能找到幹活的人，這一點 Arch Linux 還是有很多人在認真做事情的。 沒有繁瑣的議會投票表決，沒有細碎的打包步驟，用最快的方式把活幹了，這在我看來是最重要的。 或許有一天，幹活的人沒了，或者我想要的特殊特性因爲太複雜沒人想帶頭幹，而別的發行版有， 那時可能我會換去別的發行版吧。又或許我會自己幹，誰知道呢。 比起發行版之爭，甚至比起 Linux/Windows/macOS 的桌面系統地位之爭，可能日後更關鍵的是別的平臺 比如 Android 在手持設備甚至物聯網設備上的興起導致的 PC 桌面的衰落。雖然這些新設備大多都是跑着 Linux 的內核，但是其上的生態環境不能說像 GNU/Linux 那樣自由。這一點上，自由軟件該如何發揮優勢 爭取用戶和生態可能是更關鍵的。 當然這些都於我而言過於遙遠，一人之力難挽狂瀾……我只希望自己和朋友們所在的自由的土地能保持下去， 或許我也僅能做到這些。 Q6：在 Arch Linux 做 Trusted Users 时有没有什么心得？ 說來非常慚愧，做 TU 這麼4年了，實際做的事情着實有限，只能隔幾天打打包而已。要做的事情太多， 而自己上面也說了有幹活的人最重要，設身處地深刻體會到在開源社區的諸位志願者們大家都不容易。 TU 應該做的事情，細數一下除了給 community 打包之外，還有處理包的 bug ，處理 AUR 的爭議， 測試新包給反饋，以及溝通和反饋上游。反觀自己做的事情，真的太少了。比起肥貓和其他 TU 們的辛勤， 總覺得自己不夠格。「精力有限，憑着志願者熱情」，什麼的說辭可以說很多， 但是良心上對着自己熱愛的事情卻不能百分百撲上去做，真的沒有顏面腆着臉說…… 打包和溝通上游之類的心得倒是有不少，也一直想寫點筆記記錄一下，挖坑卻沒時間填上。該說， 或許應該換個本職工作了，又想，孰重孰輕哪邊是本行需要自己掂量。 Q7：有什么话要对咱说嘛？ 不知何時起，不知萌狼經歷了什麼，有時候感覺萌狼傲嬌的性格讓人看不透，不過事後能看出萌狼都是本着好心。 或許，如果能更坦誠一些的話，也能更融入大家吧。雖然我也沒資格這麼說。 像前面寫的，隱約能感覺到萌狼似乎爲了理想放棄了很多，孰重孰輕是每個人自己的權衡。 以及還有感謝，感謝萌狼把我當作朋友，感謝萌狼的耐心。 最後還有抱歉，這篇拖了太久，是該治治我的拖延症了。","tags":"life","url":"//farseerfc.me/question-exchange-horo.html"},{"title":"東方歌詞翻譯遷移至 sak.uy","text":"最近幾個月在這個博客發了不少歌詞翻譯 似乎有要轉型成音樂博主的趨勢 ，前段時間買了個新域名 sak.uy ，準備專門用來放這些東方歌曲的歌詞翻譯，於是分設了單獨的博客「 Sakuya的音樂盒 」。主博客這邊右側邊欄會有到音樂盒的鏈接。 曾經在這邊的那些歌儘量保持 URL 跳轉過去，新的歌詞翻譯會發到那邊去，還想繼續聽歌的話請繼續訂閱那邊的 RSS 呀。 主博客這邊還是像往常一樣保持記錄生活點滴和技術經驗好了。說道介紹技術， 有人問過我那些日語歌詞上給漢字標註的假名都是我一個個手輸的麼？ 一開始是手輸的，後來發現了不錯的自動化方案，於是這裏介紹一下。 首先是 python-furigana 這是個 python 寫的小程序（嚴格說是庫），可以把一段日文轉換成標準的 HTML 形式的 <ruby> 標籤的振假名( 振 ( ふ ) り 仮名 ( かな ) )。 它本身只是個方便的格式化庫，實際工作是用 python-mecab 這個 binding 去查詢 mecab 這個著名的日語語料分析庫。要用它還得配合一些開源的 mecab 詞典，這些在 [archlinuxcn] 都有打好的包了，直接安裝： $ sudo pacman -Syu python-furigana mecab-git python-mecab mecab-ipadic 裝好之後用法也很直接，甚至沒有 binary 直接調用 python 的 module 就可以： $ python -m furigana.furigana \"振り仮名の例\" <ruby><rb>振</rb><rt>ふ</rt></ruby>り<ruby><rb>仮名</rb><rt>かめい</rt></ruby>の<ruby><rb>例</rb><rt>れい</rt></ruby> 就是提供日語作爲輸入，然後輸出 HTML 形式的 <ruby> 標籤而已。 像上面的例子中出現的錯誤（「振り仮名」完整的一個詞中「仮名」意思是「平仮名」應該發音「がな」而非意爲「假的人名」的「かめい」） 可以看出其實標註的準確率還是有些問題的。嘛日語作爲一個非常依賴上下文判斷的語言， 經常日本人都會搞錯某些漢字的發音，這些也不能強求機械化的算法能 100% 正確實現。 好在單純的詞典匹配也能滿足大部分標註的需要了，用這個標註總體來說 95% 以上的情況都是正確的（歌詞的話正確率低一些，畢竟歌詞中古語啦当て字啦訓読み這些情況很常見）。 把輸出插入我的博客 然後我的博客用 reStructuredText 語法寫，不能直接用 HTML 標籤（雖然我加了 :html: 這個 行內角色 ( inline role ) 但是大量用也不方便）。這個博客一開始用 Pelican 重寫主題的時候 我就實現了個自己的 :ruby: 行內角色 ( inline role ) 用來標發音，於是一段 sed 就能把 python-furigana 的輸出轉換成我用的 rst 語法： $ which clipboard Co Ci Ct clipboard: aliased to xclip -selection clipboard Co: aliased to clipboard -o Ci: aliased to clipboard -i Ct () { t=$(mktemp /tmp/furigana-XXXX) python -m furigana.furigana $(Co) | sed 's@<ruby><rb>@ :ruby:`@g;s@</rb><rt>@|@g;s@</rt></ruby>@` @g' | sponge $t cat $t | tee /dev/tty | perl -pe 'chomp if eof' | Ci } 上面這些 alias 在我的 .bashrc 中。有了這些之後， 我只要把需要標註的日語文本放入剪切版，執行 Ct ，再粘帖結果就好了。 $ echo \"振り仮名の例\" | Ci $ Ct :ruby:`振|ふ` り :ruby:`仮名|かめい` の :ruby:`例|れい` 然後所有那些歌詞上標註的假名都是這樣一句一句標註好之後，再手動校對修改的。","tags":"life","url":"//farseerfc.me/move-lyrics-to-sakuy.html"},{"title":"用 usbip 轉發 raspberry pi 的 USB 鍵盤鼠標給 Arch Linux 的 PC","text":"惠狐 megumifox 寫了篇 用PulseAudio將電腦的聲音用手機放出來 ，文末提到想知道我怎麼用樹莓派轉發 USB 的，於是寫篇文章記錄一下。 起因 家裏有個裝了 Arch Linux ARM 的樹莓派3B 閒置着，裝了 Arch Linux ARM 偶爾上電更新一下， 不過因爲性能實在不適合做別的事情於是一直在吃灰。某日 給老婆安利幻想萬華鏡 和老婆看片 的時候， 老婆不吃安利於是遷怒鍵盤鼠標 鍵盤鼠標被長長的 USB 線扯着感覺很難受 ，於是偶發奇想，能不能利用一下樹莓派的多達 4 個 USB 2.0 端口接鼠標鍵盤呢， 這樣鼠標鍵盤就可以跟着樹莓派來回走，不用拖着長長的 USB 線了。 上網搜了一下， Linux 環境有個 usbip 工具正好能做到這個。原理也很直觀， usbip 能把 USB 端口上的數據封裝成 IP 協議通過網絡轉發出去，從而兩個網絡間相互聯通的電腦就可以遠程轉發 USB 了。 設置好的話，就像是一臺 PC 多了幾個位於樹莓派上的 USB 端口，插上樹莓派的 USB 設備統統作爲 PC 的設備。 這篇文章假設有一個裝了 Arch Linux 的 PC ，和一個裝了 Arch Linux ARM 的樹莓派， 並且兩者間能通過網絡互相訪問到。別的發行版上大概也可以這麼做，只是我沒有試過。 usbip 工具似乎普遍被發行版打包了，除此之外需要的也只是 Linux 內核提供好的功能而已。 設置 Arch Linux ARM 的樹莓派端 假設樹莓派上面網絡已經設置妥當，開機插電就能自動聯網。接下來安裝 usbip 工具： $ sudo pacman -Syu usbip 然後需要記錄一下樹莓派的 IP 地址： $ ip addr 3: wlan0: ...... inet 192.168.0.117/24 brd 192.168.0.255 scope global noprefixroute wlan0 ...... 接下來給 udev 添加一個規則，當插入 usb 設備的時候，執行我的腳本 usbipall.sh 把 usb 設備通過 usbip 共享出去： $ cat /etc/udev/rules.d/usbipall.rules ACTION==\"add\", SUBSYSTEM==\"usb\", RUN+=\"/usr/bin/bash /usr/local/bin/usbipall.sh\" 這個 rules 文件 可以在我的 dotfiles 裏面找到 。 然後規則調用的 usbipall.sh 我這麼寫的， 文件同樣在我的 dotfiles 裏面 ： #!/bin/sh ( allusb = $( usbip list -p -l ) for usb in $allusb do busid = $( echo \" $usb \" | sed \"s|#.*||g;s|busid=||g\" ) if [ \" $busid \" = \"1-1.1\" ] then # ignoring usb ethernet continue fi echo \" $( date -Iseconds ) : Exporting $busid \" usbip bind --busid = \" $busid \" done ) >>/var/log/usbipall.log 2 > & 1 這個腳本做了這樣幾件事。 調用 usbip list --local 列出本地所有 usb 設備。 針對每個設備 取出它的 busid 判斷是不是樹莓派的 USB 以太網卡，不是的話繼續 通過 usbip bind --busid= 命令把這個 usb 設備導出到網上 最後把所有輸出記錄到 /var/log/usbipall.log 日誌裏面 樹莓派這邊設置就完成了。從此之後插入的 usb 設備就會統統導出出去。 這裏需要注意一下，啓用了 udev 規則之後，就沒法插鍵盤鼠標到樹莓派上控制它了……我都是從另一端 ssh 上樹莓派操作的。如果有什麼地方設置錯誤，可能需要把樹莓派的 SD 卡拔下來插到電腦上，刪除掉 rules 文件…… 仔細檢查設置正確了之後，重新載入 udev 規則，或者重啓樹莓派： # systemctl restart systemd-udevd 這樣樹莓派這邊就設置好了。 設置 Arch Linux 的 PC 端 同樣假設 PC 這邊也已經聯網。接下來同樣安裝 usbip 工具： $ sudo pacman -Syu usbip 然後我寫了個小腳本去鏈接樹莓派端， 這個文件 usbiprpi3.sh 也在我的 dotfiles ： #!/bin/sh rpi3 = \"192.168.0.117\" modprobe vhci-hcd allusb = $( usbip list -p -r $rpi3 | cut -d \":\" -f1 -s | sed 's|&#94;[ \\t]*||;/&#94;$/d' ) for busid in $allusb do if [ \" $busid \" = \"1-1.1\" ] then # ignoring usb ethernet continue fi echo \"Attaching $busid \" usbip attach --remote = $rpi3 --busid = \" $busid \" done 其中腳本第一行填入上面記錄下來的樹莓派的 IP 地址，接下來腳本做了這麼幾件事： 用 modprobe 確認加載 vhci-hcd 通用虛擬鍵鼠驅動 用 usbip list --remote= 列出遠程設備上已經導出了的 USB 設備，取出他們的 busid 對每個設備用 usbip attach 接上該設備 然後就已經準備妥當，接下來是見證奇蹟的時刻： $ sleep 10 ; sudo ./usbiprpi3.sh Attaching 1-1.4.3 Attaching 1-1.4.1 因爲只有一套鍵盤鼠標，所以先 sleep 個 10 秒，在此期間快速把鍵鼠拔下來插到樹莓派的 USB 口上去。 如果對自己手速沒自信也可以把時間設長一點。然後用 root 權限執行 usbiprpi3.sh 。 一切正常的話，先能觀測插上樹莓派的鍵盤鼠標被樹莓派初始化了一下，比如鍵盤燈會亮， 然後這些設備會被導出出去，從而鍵盤燈滅掉，然後 10 秒等待結束後他們被遠程接到了 PC 端， 又會被初始化一下，同時 PC 端這邊會有上述 Attaching 的輸出。然後鍵盤鼠標就能像平常一樣用啦。 使用體驗 因爲就是通過 IP 轉發 USB 嘛，所以就和普通地接 USB 的體驗差不多，當然前提是網絡環境足夠穩定。 在我家間隔 5 米到無線路由器的環境下，基本感覺不到網絡延遲的影響。 通過這種方式聊天上網應該和直接接 USB 設備完全一樣。本文就是在通過樹莓派轉發的前提下用鍵盤打字寫的。 不過如果網絡負載本身就很大的話，可能會一些延遲，比如我開着 OBS 直播打東方的時候，原本就手殘 的我感覺更加手殘了…… 試過拿着樹莓派在房間到處走，走到無線信號覆蓋不到的地方， usbip 會斷掉，PC 上的現象就像是 USB 設備被拔下來了……所以如果無線網絡不穩的話，可能需要對上面腳本做個循環？不過那樣可能會用起來很彆扭吧。 以及，上述操作 usbip 是走 TCP 3240 端口，數據包大概完全沒有加密，所以考慮安全性的話， 最好還是在內網環境使用。不過轉念一想，萬一有別人接上了我導出出去的 USB ，也就是截獲我的鍵盤， PC 這邊沒法 attach 設備了，應該馬上會發現吧。我敲打 sudo 之類命令的時候 shell 裏面沒有回顯， 就不會再繼續敲密碼了。而且似乎對攻擊者也沒有什麼好處？要是他 usb attach 到了我的設備上， 我就能控制他的鍵盤了耶~","tags":"tech","url":"//farseerfc.me/usbip-forward-raspberrypi.html"},{"title":"【聽譯】君さえいなけりゃよかった","text":"君さえいなけりゃよかった 如果你從未出現過該多好 降り出した雨の中で 君に出会った時から 下起雨的那一刻 從遇到你那時起 君がいないということが 当たり前じゃなくなった 身邊沒有你的情況 就已經不再是平常 ああ こんなはずじゃない 啊 不應該是這樣的 ずっと自分勝手にさ 過ごせたはずなのに 明明一直是散漫地過着自己的日子 まるで僕じゃないような僕が さらけ出されてくよ 就像是帶出了不是我的另一面的我 君さえいなけりゃよかった こんな気持ちは知らないから 如果你從未出現過該多好 就不會知道這種心情 やらなくちゃいけないことが 手つかずのまま積もってく 一堆不得不做的事情 堆在手頭越積越多 僕じゃなくてもいいのなら こっちを見て笑わないでよ 如果不是我也可以的話 就別看着我這邊笑啊 大袈裟じゃなくてそれだけで 忘れられなくなるの 甚至那些不重要的事情 都變得難以忘記了 君の適当な話も 全部心に刺さります 你無意間隨口說的話 全都刺在心頭 気にしなけりゃいいのにな 残らずかき集めちゃうの 雖說只要不在意就可以了 卻一句不剩全收集了起來 ああ こんなはずじゃない こんなはずじゃない 啊 不應該是這樣的 不應該是這樣的 君に出会わなきゃよかった こんなに寂しくなるのなら 如果沒遇到過你該多好 就不會變得如此寂寞 君じゃなくてもいいことが もう見つからないの 已經找不到 和你無關也可以的情況了 忘れられないから 君じゃなかったら 無法忘記了 要不是你的話 いっそ見損なってしまうような そんなひとだったらなあ 乾脆變成根本看不起的人 如果是那種人的話 でもそれでも どうせ無理そう 嫌いになれないや 但是即使如此 大概反正也不可能 無法變得討厭 僕がいなくてもいいなら いっそ不幸になってしまえ 如果不是我也可以的話 乾脆變得不幸吧 最後にまた僕の元に 泣きついてくればいい 最後還是會回到我身邊 哭着湊過來的話就可以 君さえいなけりゃよかった こんな気持ちは知らないから 如果沒有你該多好 就不會知道這種心情 やらなくちゃいけないことが 手つかずのまま積もってく 一堆不得不做的事情 堆在手頭越積越多 僕じゃなくてもいいのなら こっちを見て笑わないでよ 如果不是我也可以的話 就別看着我這邊笑啊 大袈裟じゃなくてそれだけで 甚至那些不重要的事情 君のこと 間違いなく 對你 毫無疑問 苦しいほど 好きになっちゃうよ 刻骨銘心地 變得喜歡上了啊 忘れられないから 君じゃなかったら 因爲無法忘記 如果不是你的話 君に出会わなきゃ 僕じゃなかったら 要是沒遇到過你 如果不是我的話 君さえいなけりゃよかった 如果你從未出現過該多好","tags":"life","url":"//farseerfc.me/kimisaeinakerya.html"},{"title":"【譯】使用 GNU stow 管理你的點文件","text":"譯註 這篇是翻譯自 Brandon Invergo 的博客的英文文章 Using GNU Stow to manage your dotfiles 。 Brandon Invergo 的博客採用 CC-BY-SA 3.0 授權，因此本文也同樣採用 CC-BY-SA 3.0 ，不同於其它我寫的文章是 CC-BY-NC-SA 4.0 授權。 我自己已經使用此文中介紹的方案管理 我自己的 dotfiles 快 3 年了。最早想採用這樣的管理方案是爲了方便在多臺 Arch Linux 系統之間同步配置， 後來逐漸主力系統也更新換代了一次，又同步到了自己的 vps 上去，目前管理多個 Arch Linux 上都多少都有這套配置。甚至裝好 Arch Linux 添加好用戶最初做的事情就是安裝 stow git 然後 clone 了我自己的 dotfiles repo 下來，然後按需取想要的配置，快捷方便有效。 廢話不多說，下面是原文和翻譯。與之前的翻譯一樣，正文部分給出原文引用以便對照參考。 使用 GNU stow 管理你的點文件 我昨天偶然間發現一些我覺得值得分享的經驗，就是那種「爲毛我沒有早點知道這個？」那一類的。 我將在這篇文章中介紹如何使用 GNU Stow 管理你的 GNU/Linux 系統中位於用戶家目錄裏的各種配置文件 （通常又叫「點文件(dotfiles)」比如 .bashrc）。 I accidentally stumbled upon something yesterday that I felt like sharing, which fell squarely into the \"why the hell didn't I know about this before?\" category. In this post, I'll describe how to manage the various configuration files in your GNU/Linux home directory (aka \"dotfiles\" like .bashrc) using GNU Stow. 這件事的困難之處在於，如果能用版本管理系統(VCS, Version Control System)比如 Git, Mercurial(hg), Bazaar(bzr) 管理點文件的話會非常方便，但是這些點文件大部分都位於家目錄的頂級目錄下， 在這個位置不太適合初始化一個版本管理倉庫。這些年下來我試過很多程序，設計目的在於解決這個問題， 幫你把這些配置文件安置在某個下級目錄中，然後安裝或者鏈接這些文件到它們應該在的位置。 嘗試下來這些程序沒有一個真正能打動我。它們要麼有很多依賴（比如 Ruby 和一大坨庫）， 要麼需要我記住如何用它，考慮到同步配置這種不算經常使用的場合，要記住用法真的挺難。 The difficulty is that it would be helpful to manage one's configuration files with a version control system like Git, Mercurial or Bazaar, but many/most dotfiles reside at the top-level of your home directory, where it wouldn't be a good idea to initialize a VCS repository. Over time I've come across various programs which aim to manage this for you by keeping all the files in a subdirectory and then installing or linking them into their appropriate places. None of those programs ever really appealed to me. They would require a ton of dependencies (like Ruby and a ton of libraries for it) or they would require me to remember how to use them, which is difficult when really for such a task you rarely use the program. 最近我在用 GNU Stow 來管理我從源代碼在本地編譯安裝到 /​usr/​local/​ 中的一些程序。 基本上說，在這種常見用法下，是你把這些本地編譯的包配置安裝到 /​usr/​local/​stow/​${PKGNAME}-{PKGVERSION} 這樣的位置，然後在 /​usr/​local/​stow/​ 目錄中執行 # stow ${PKGNAME}-${PKGVERSION} ，然後它就會爲程序所有的文件創建符號鏈接放在 /​usr/​local 中合適的地方。然後當你想用 Stow 卸載這個程序的時候，就不必再考慮會留下什麼垃圾文件， 或者找不到安裝時用的 Makefile 了。這種安裝方式下也可以非常容易地切換一個程序的不同版本 （比如我想嘗試不同配置選項下的 dwm 或者 st 的時候）。 Lately I've been using GNU Stow to manage programs I install from source to /usr/local/. Basically, in this typical usage, you install locally built packages to /usr/local/stow/${PKGNAME}-{PKGVERSION} and then from /usr/local/stow/ you run # stow ${PKGNAME}-${PKGVERSION} and the program generates symbolic links to all the programs' files into the appropriate places under /usr/local/. Then, when you uninstall a program via Stow, you don't have to worry about any stray files that you or a provide Makefile may have missed. It also makes handling alternate versions of a program quite easy (i.e. when I'm experimenting with different configurations of dwm or st). 前段時間在我掃郵件列表的時候，看到某個帖子中某人在說使用 Stow 管理安裝他的點文件。 當時我沒特別在意這個帖子，但是大概我大腦潛意識把它歸檔保存爲今後閱讀了。 昨天我想起來試試這種用法，試過後我不得不說，這比那些專門設計用來做這任務的點文件管理器要方便太多了， 雖然表面上看起來這種用法沒那麼顯而易見。 Some time ago I happened across a mailing list posting where someone described using Stow to manage the installation of their dotfiles. I didn't pay much attention to it but my brain must have filed it away for later. Yesterday I decided to give it a try and I have to say that it is so much more convenient than those other dedicated dotfile-management programs, even if it wasn't an immediately obvious option. 方法很簡單。我建了個 ${HOME}/​dotfiles 文件夾，然後在裏面爲我想管理的每個程序配置都 創建一個子文件夾。然後我把這些程序的配置從原本的家目錄移動到這每一個對應的子文件夾中， 並保持它們在家目錄中的文件夾結構。比如，如果某個文件原本應該位於家目錄的頂層文件夾裏， 那它現在應該放在這個程序名子目錄的頂層文件夾。如果某個配置文件通常應該位於默認的 ${XDG_CONFIG_HOME}/​${PKGNAME} 位置 ( ${HOME}/​.config/​${PKGNAME} )， 那麼現在它應該放在 ${HOME}/​dotfiles/​${PKGNAME}/​.config/​${PKGNAME} ，如此類推。然後在那個 dotfiles 文件夾裏面，直接運行 $ stow $PKGNAME 命令， Stow 就會爲你自動創建這些配置文件的符號鏈接到合適的位置。接下來就很容易爲這個 dotfiles 目錄初始化版本管理倉庫，從而記錄你對這些配置文件做的修改（並且這也可以極度簡化在不同電腦之間 共享配置，這也是我想要這麼做的主要原因）。 The procedure is simple. I created the ${HOME}/dotfiles directory and then inside it I made subdirectories for all the programs whose cofigurations I wanted to manage. Inside each of those directories, I moved in all the appropriate files, maintaining the directory structure of my home directory. So, if a file normally resides at the top level of your home directory, it would go into the top level of the program's subdirectory. If a file normally goes in the default ${XDG_CONFIG_HOME}/${PKGNAME} location (${HOME}/.config/${PKGNAME}), then it would instead go in ${HOME}/dotfiles/${PKGNAME}/.config/${PKGNAME} and so on. Finally, from the dotfiles directory, you just run $ stow $PKGNAME and Stow will symlink all the package's configuration files to the appropriate locations. It's then easy to make the dotfiles a VCS repository so you can keep track of changes you make (plus it makes it so much easier to share configurations between different computers, which was my main reason to do it). 舉個例子，比如說你想管理 Bash, VIM, Uzbl 這三個程序的配置文件。Bash 會在家目錄的頂層文件夾 放幾個文件； VIM 通常會有在頂層文件夾的 .vimrc 文件和 .vim 目錄；然後 Uzbl 的配置位於 ${XDG_CONFIG_HOME}/​uzbl 以及 ${XDG_DATA_HOME}/​uzbl 。於是在遷移配置前，你的家目錄的文件夾結構應該看起來像這樣： For example, let's say you want to manage the configuration for Bash, VIM and Uzbl. Bash has a couple files in the top-level directory; VIM typically has your .vimrc file on the top-level and a .vim directory; and Uzbl has files in ${XDG_CONFIG_HOME}/uzbl and ${XDG_DATA_HOME}/uzbl. So, your home directory looks like this: home/ brandon/ .config/ uzbl/ [...some files] .local/ share/ uzbl/ [...some files] .vim/ [...some files] .bashrc .bash_profile .bash_logout .vimrc 然後遷移配置的方式是，應該建一個 dotfiles 子目錄，然後像這樣移動所有配置文件： You would then create a dotfiles subdirectory and move all the files there: home/ /brandon/ .config/ .local/ .share/ dotfiles/ bash/ .bashrc .bash_profile .bash_logout uzbl/ .config/ uzbl/ [...some files] .local/ share/ uzbl/ [...some files] vim/ .vim/ [...some files] .vimrc 然後執行以下命令： Then, perform the following commands: $ cd ~/dotfiles $ stow bash $ stow uzbl $ stow vim 然後，瞬間，所有你的配置文件（的符號鏈接）就安安穩穩地放入了它們該在的地方，無論原本這些目錄結構 有多麼錯綜複雜，這樣安排之後的 dotfiles 文件夾內的目錄結構立刻整理得有條有理， 並且可以很容易地轉換成版本控制倉庫。非常有用的一點是，如果你有多臺電腦，可能這些電腦並沒有 安裝完全一樣的軟件集，那麼你可以手選一些你需要的軟件配置來安裝。在你的 dotfiles 文件夾中總是 可以找到所有的配置文件，但是如果你不需要某個程序的某份配置，那你就不對它執行 stow 命令，它就不會擾亂你的家目錄。 And, voila, all your config files (well, symbolic links to them) are all in the correct place, however disorganized that might be, while the actual files are all neatly organized in your dotfiles directory, which is easily turned into a VCS repo. One handy thing is that if you use multiple computers, which may not have the same software installed on them, you can pick and choose which configurations to install when you need them. All of your dotfiles are always available in your dotfiles directory, but if you don't need the configuration for one program, you simply don't Stow it and thus it does not clutter your home directory. 嗯，以上就是整個用法介紹。希望能有別人覺得這個用法有用！我知道對我來說這個非常有幫助。 Well, that's all there is to it. Hopefully someone else out there finds this useful! I know I've found it to be a huge help.","tags":"tech","url":"//farseerfc.me/using-gnu-stow-to-manage-your-dotfiles.html"},{"title":"爲什麼 Linus Torvalds 不願意將 Linux 變成 GPLv3 授權？","text":"從 知乎 轉載 和上篇文章一樣，這篇也是來自一個知乎上我回答的問題。 原問題：为什么 Linus Torvalds 不愿意将 Linux 变成 GPLv3 授权？ DebConf 14: Q&A with Linus Torvalds Youtube Youku 我的回答： 這裏有段 Linus Torvalds 在 DebConf 14 上的 Q&A: https://youtu.be/1Mg5_gxNXTo?t=47m20s 其中關於 GPLv3 和協議的那一段在47:20開始到57:00左右。 裏面 Linus 對自己的觀點澄清得很清楚了。 看u2b或者聽英語有困難的請留評論，我抽空可以試着翻譯一下。 然後接下來就是我承諾的翻譯了 問：你是否同意說你貶低了 GPLv3 ? 以及…… Q: Do you agree that you undermine GPLv3? and ... L: 是的 L: Yes 問：我們如何纔能讓你別這麼做？ Q: How can we get you to stop? L: 什麼？ L: What? 問：我們如何纔能讓你別這麼做？ Q: How can we get you to stop? L: 哦我討厭 GPLv3 ，我是在故意貶低它。實際上我覺得 GPLv3 的擴展非常可怕。 我能理解爲什麼人們想要做這個，但是我覺得它本應是一個全新的協議。 L: Oh I hate GPLv3. I undermined it on purpose. I actually thought the GPLv3 extensions were horrible. I understand why people would want to do them but I think it should have been a completely new license. 嗯我喜歡版本 2 的那些理由，並且我仍然覺得版本 2 是一個非常棒的協議， 理由是：「我給你源代碼，你給我你對它的修改，我們就扯平了」 對吧？這是我用 GPL 版本 2 的理由，就是這麼簡單。 Emm my argument for liking version 2, and I still think version 2 is a great license, was that, \"I give you source code, you give me your changes back, we are even.\" Right? That's my take on GPL version 2, right, it's that simple. 然後版本 3 的擴展在某些方面讓我個人覺得非常不舒服，也就是說「我給你源代碼， 這意味着你必須服從我的一些規則，否則你不能把它用在你的設備上。」 對我來說，這是違反了版本 2 協議所追求的所有目的。然而我理解爲什麼 FSF 要這麼做， 因爲我知道 FSF 想要達成什麼，但是對我來說這完全是不同的協議了。 And version 3 extended that in ways that I personally am really uncomfortable with, namely \"I give you source code, that means that if you use that source code, you can't use it on your device unless you follow my rules.\" And to me that's, that's a violation of everything version 2 stood for. And I understand why the FSF did it because I know what the FSF wants. But to me it's not the same license at all. 所以我當時非常不安，並且表明了自己的觀點，並且這是在版本 3 發佈的數月之前。 在那很久之前曾經有過一場討論……在版本 3 之前有一個早期的版本， 事實上幾年之前，那時我就說過：「不，這不可能工作」。 並且在那個早期的討論階段我已經在內核裏寫好了「嘿，我可沒有寫過版本 2 或者更高版本」。所以之後也沒有過（爭議）……隨後版本 3 出來的時候我非常開心， 因爲我早在大概 5 年前做了預防，之後也就再也沒有過關於內核的協議究竟是哪個 版本的討論。 So I was very upset and made it very clear, and this was months before version 3 was actually published. There was a discussion about this long before... There was an earlier version of version 3, years before actually, where I said \"No, this is not gonna fly.\" And during that earlier discussion I had already added to the kernel that, \"Hey, I don't have the version 2 or later\". And there was no... And I was really happy then when version 3 came out, that I have done that something like 5 years before, because there was ever never any question about what the license for the kernel was. 不過事實上我覺得版本 3 是……呃不……我事實上覺得版本 3 是個 不錯 的協議， 對吧。我堅定地相信「如果是你寫的代碼，那麼你有權利決定它應該用什麼協議」。 並且版本 3 是個不錯的選擇。版本 3 不好的地方在……「我們給你了版本 2 ，然後我們試圖偷偷混入這些新的規則，並且想逼着所有人都跟着升級」這是我不喜歡版本 3 的地方。並且 FSF 在其中做了很多見不得人的事情，我覺得做得很不道德。 But I actually thought that version 3 is ... Uh, no ... I actually think version 3 is a FINE license, right. I'm a firm believer in, \"If you write your code, it is your choice to pick a license.\" And version 3 is a fine license. Version 3 was not a good ... \"Here we give you version 2, and then we tried to sneak in these new rules, and tried to force everybody to upgrade.\" That was the part I disliked. And the FSF did some really sneaky stuff, downright immoral in my opinion. 問：所以你在說 Tivoization 的事情麼？ Q: So you are talking about Tivoization ? 譯註： 關於 Tivoization Tivoization 是 FSF 發明的一個詞，表示 TiVo 的做法。 TiVo 是一個生產類似電視機頂盒之類的設備的廠商，他們在他們的設備中用到了 Linux 內核和很多別的開源組件，並且他們根據 GPLv2 協議開放了他們使用的組件的源代碼。 然而他們在他們出售的設備中增加了數字簽名，驗證正在執行的系統和軟件是他們自己 編制的軟件，從而限制了用戶修改運行軟件的自由。這種做法在 FSF 看來是鑽了 GPLv2 的法律上的空子，所以 FSF 提出了 GPLv3 封堵這種做法。 L: 沒錯，Tivoization 的事情一直是我反對版本 3 的主要根據。並且，FSF 在這件事上表現得極不誠實。「嘿，其實我們允許你無效化 Tivoization 條款」，這樣他們試圖， 應該說他們是在明白着欺騙別人，並且說「嘿，這意味着你可以使用除去 Tivoization 部分的 GPLv3」。 這很……在場的諸位中有誰從 FSF 那兒聽過這個說法？（請舉手） L: Ehmm, yeah the Tivoization is always my main, eh dislike of version 3. And, the FSF was being very dishonest thing. \"Hey, we actually allow you to invalidate the Tivoization clause\" and they tried to, they literally lied to people, and say \"Hey, so that means that you can use GPLv3 without the Tivoization part\", right. This is ... How many people heard this particular statement from the FSF? (Please raise your hands) 好吧，或許他們只試過對我用這套說辭，但是他們真的試過。我的反應是「我可不傻」，對吧。是的， 的確你可以…… GPLv3 允許你說「好， Tivoization 的事情對我們來說不是問題」， 但是它同時又允許別人接過這個項目，並且說「嘿，我覺得……去掉了 Tivoization 的 GPLv3 是兼容完整的 GPLv3 的，所以我可以 fork 這個項目，然後我將在自己的 fork 上用完整的 GPLv3 寫驅動。」然後我就囧了。我的困境在於說「嘿，我給了你我的源代碼，現在我卻不能拿回你對它 的修改了」。這是徹底違背了我用這個協議最初的目的了。 Ok, maybe they only tried to convince me with that one. But they did try. And it was like, \"I'm not stupid\", right. Yes, you can ... The GPLv3 allows you to say \"Ok, Tivoization is not an issue for us\". But it allows somebody else to take the project, and say \"Hey, I ... The GPLv3 without Tivoization is compatible with the full GPLv3, so I will now make my own fork of this, and I will start doing drivers that use the full version of version 3\" And where am I stuck then? I am stuck saying \"Hey I give you the source code, and now I can't take it back your changes\". That's completely against the whole point of the license in the first place. 所以 FSF 是，我是說那時他們暗地裏做的那些事情，讓我當下決定永遠不再和 FSF 有任何瓜葛。 所以如果你想捐錢給一個行善的組織，那就捐給 EFF 吧。FSF 充滿了瘋狂難處的人。這只是我的觀點。 呃其實我……嗯……我說得有點過分了。FSF 裏有很多不錯的人，不過其中有些人有點過激。 So the FSF was, I mean the kind of stuff that was going on behind the scenes, ah, made me once and for all to decide to never had any thing to do with the FSF again. So if you wanted to give money to an organization that does good? Give it to the EFF. The FSF is full of crazy bittered people. That's just mine opinion. Uh, actually I have ... Ah ... I overstated that a bit, right. The FSF has a lot of nice people in it, but some of them are bit too extreme. 問: 嗯我也希望 EFF 能更多的關注於軟件的自由方面。但是你能……你覺得 Tivoization 這種行爲也能在某種方式上讓我作爲用戶獲益麼？ Q: Well I wish the EFF care more about software freedom. But, uh, can you ... Do you think that Tivoization benefits me as a user somehow? L: 不，我不覺得。我的意思是……這從來都不是我的論據，這不是我選擇了 GPLv2 的理由。 並不是說我覺得 Tivoization 是某種值得你去爭取的權利，而是說在我的世界觀中，這是你的決定。 如果你生產硬件去鎖住了其中的軟件，這是你作爲一個硬件提供者的決定。 這完全不影響我作爲一個軟件提供者給你軟件的決定。你能看出我的立場在哪兒了麼？ 我不喜歡上鎖的硬件，但是同時這也從來不是我想要給 Linux 加上的的社會契約。 L: No, no I don't. I mean that ... But that was never my argument. That was not why I selected the GPLv2. This is my whole point. It's not that I think Tivoization is necessarily something that you should strive for. But it is something that in my world view, it's your decision. If you make hardware that locks down the software, that's your decision as a hardware maker. That has no impact on my decision as a software maker to give you the software. Do you see where I am coming from? I don't like the locked down hardware, but at the same time that was never the social contract I intended with Linux. 對我來說，呃我想說，大家可能知道或者不知道， GPLv2 並不是 Linux 的最初的協議。 對我來說重要的部分一直是「我給你軟件，你可以用它做任何你想要做的事情。如果你做了任何改進， 你需要把它交還給我。」這是協議最初的樣子。最早的協議還有一條完全錯誤的條款，寫得完全不合理， 那時我很傻。嘿我也傻過。我最初的協議說你不能用它賺錢。這是失策，這明顯是不對的不好的， 因爲它和我真正想要做的事情沒有任何關係。但是那時我很傻很天真， 我沒意識到錢的事情在其中完全不重要。然後我發現了其中的問題，我看到了 GPLv2 然後說「嘿， 這是個完美的協議」。然後我看到了 GPLv3 我說「不，這做得過分了，這不是我想要的」 所以我讓 Linux 成爲了僅限 GPLv2 ，對吧。 To me, umm, I mean, people may or may not realize GPLv2 wasn't even the first license for Linux. To me the important part was always \"I give you software, you can do whatever you want with it. If you making improvements, you have to give them back.\" That was the first version of the license. It also had a completely broken clause which was completely insane and I was stupid. Hey it happened. My origin license says that you can't make money change hands. And that was a mistake. That was clearly just wrong and bad because it really didn't have anything to do with what I wanted. But I was young, I was poor, I didn't realize that the whole money thing wasn't the important part. And I have saw the errors in my ways, I saw the GPLv2 and said \"Hey, that's the perfect license\". And I saw the GPLv3 and I said \"No, that's overreaching a lot, that's not what I wanted\". And so I made Linux GPLv2 only, right. 問: 所以你是否認爲，即使你不能修改跑着這個軟件的設備，拿回對軟件的修改也還是同樣重要的？ Q: So do you think getting the patches back is as useful even if you can't modify the device that it is used on? L: 是的，當然。我想說 TiVo 它自己實際上就是一個例子。他們的修改有點複雜，但是我想說他們基本 是，一開始基本是運行在一套相當標準的 MIPS 設備上。然後他們的修改是想繞開他們用到的芯片上的 一些問題，並且這些是合格的修改。之後的事情是他們覺得他們需要鎖住他們的硬件，我不喜歡這個。 但是就像我已經說的，我覺得這是他們的決定。 L: Yeah, absolutely. And I mean TiVo itself is actually an example of this. Their patches were kind of crafty but I mean they were basically running on a, originally a fairly standard MIPS thing. And their patches were working around bugs in the chipsets they used. And they were valid patches. The fact that they then felt that their hardware had to be locked down someway. I didn't like it. But as I have mentioned, I felt that that was their decision. 並且他們有真正的理由去這麼做。這是有時人們忽視的地方。有時是真的有理由去做 TiVo 他們做的事情。有時強加給你這種限制的是，無線運營商。有時強加給你的是迪士尼。 有時強加給你限制的甚至是法律。 GPLv3 在醫療設備之類的場合其實允許最後一種情況，我記得。 我的觀點是，整個 Tivoization 的事情有時是有理由去這麼做的。如果你生產…… 我是說我不是硬件設計者，我覺得 FPGA 之類的東西很酷，但是我……我的意思是我真的不想把我對世界的 看法強加給別人。你不是非得要用 Linux ，如果你想要用 Linux ，那麼我唯一要求你做的事情是把源代碼（變更）還給我。然後在 GPLv2 中還有很多繁文縟節規定了詳細的細節，這些都不重要。這是我一直以來的觀點。 And they had real reasons for that. That's something people sometimes missed. There are sometimes reasons to do what TiVo did. Sometimes it's imposed on you by, wireless carriers. Sometimes it's imposed on you by Disney. Uh sometimes it's imposed on you by laws. The GPLv3 actually accepts the last one when it comes to things like medical equipment I think. But the point is that the whole Tivoization thing is, sometimes it's, there is a reason for it. And if you make ... I mean I am not a hardware designer. I think FPGA and stuff like that is really cool. But I always ... I mean I really don't want to impose my world view on anybody else. You don't have to use Linux. If you do use Linux, the only thing I asked for is source code back. And there is all these other verbiages in the GPLv2 about exact details, those aren't important. And that was always my standpoint. 問: 好吧那我就不浪費時間了。 Q: Ok, well I will stop my non-point of making noise now. 譯註： 關於 ISC 協議 ISC 協議是一個開源軟件協議，和兩句的 BSD 協議功能相同。OpenBSD 項目選擇儘量用 ISC 協議公開他們新寫的代碼。 L: 我的意思是別誤解……我也喜歡別的協議。我用過……到底是哪個 BSD 協議是可以接受的？ 有一個 BSD 協議實際上非常不錯。它實際上是……什麼？ L: I mean don't get me ... I mean I like other licenses too. I have used like the four, emmm... Which BSD license is the acceptable one? One of the BSD license is actually really nice. And it's actually the... What? 觀衆： ISC A: ISC L: ISC？並且事實上我在鼓勵那些不在意拿回修改但是在意「嘿，我做了一個很酷的東西，請用它」。 我鼓勵這些人去用 BSD 協議做這些事情。我想說 BSD 協議在這種場合是完美的。 只是碰巧我覺得對於我的項目，拿回修改也同樣重要，所以對我而言 BSD 不好。但是重點是 對我而言 。 GPLv3 可能對你們想要做的事情而言是完美的協議，這很好，並且這時你就應該去用 GPLv3 。只是當代碼是別人寫的時候，你沒有這個選擇權。 L: ISC? And I actually encourage people who don't care about the giving code back but care about the \"Hey, I did something cool, please use it\". I encourage people to use the BSD license for that. And I mean the BSD license is wonderful for that. It so happens that I thought that for my project the giving back is equally important so I, for me BSD is bad. But the point is for me . The GPLv3 maybe the perfect license for what you guys want to do. And that's fine. And then it's the license you should use. It's just that when somebody else wrote the code you don't get that choice.","tags":"import","url":"//farseerfc.me/why-linus-torvalds-undermine-gplv3.html"},{"title":"C语言中\".\"与\"->\"有什么区别？","text":"從 知乎 轉載 轉載幾篇知乎上我自己的回答，因爲不喜歡知乎的排版，所以在博客裏重新排版一遍。 原問題：C语言中\".\"与\"->\"有什么区别？ 除了表达形式有些不同，功能可以说完全一样阿。那为何又要构造两个功能一样的运算符？ 效率有差异？可是现在编译器优化都那么强了，如果真是这样岂不是有些多此一举 刚刚翻了下书，说早期的C实现无法用结构直接当作参数在函数间传递，只能用指向结构的指针在函数间进行传递！我想这应该也是最直观的原因吧。 我的回答 首先 a->b 的含義是 (*a).b ，所以他們是不同的，不過的確 -> 可以用 * 和 . 實現，不需要單獨一個運算符。 嗯，我這是說現代的標準化的 C 語義上來說， -> 可以用 * 和 . 的組合實現。 早期的 C 有一段時間的語義和現代的 C 的語義不太一樣。 稍微有點彙編的基礎的同學可能知道，在機器碼和彙編的角度來看，不存在變量，不存在 struct 這種東西，只存在寄存器和一個叫做內存的大數組。 所以變量，是 C 對內存地址的一個抽象，它代表了一個位置。舉個例子，C 裏面我們寫： a = b 其實在彙編的角度來看更像是 * A = * B 其中 A 和 B 各是兩個內存地址，是指針。 好，以上是基本背景。 基於這個背景我們討論一下 struct 是什麼，以及 struct 的成員是什麼。 假設我們有 struct Point { int x ; int y ; }; struct Point p ; struct Point * pp = & p ; 從現代語義上講 p 就是一個結構體對象， x 和 y 各是其成員，嗯。 從彙編的語義上講， p 是一個不完整的地址，或者說，半個地址，再或者說，一個指向的東西是虛構出來的地址。而 x 和 y 各是在 Point 結構中的地址偏移量。也就是說，必須有 p 和 x 或者 p 和 y 同時出現，才形成一個完整的地址，單獨的一個 p 沒有意義。 早期的 C 就是在這樣的模型上建立的。所以對早期的 C 而言， *pp 沒有意義，你取得了一個 struct ，而這個 struct 不能塞在任何一個寄存器裏，編譯器和 CPU 都無法表達這個東西。 這時候只有 p.x 和 p.y 有意義，它們有真實的地址。 早期的 C 就是這樣一個看起來怪異的語義，而它更貼近機器的表達。 所以對早期的 C 而言，以下的代碼是對的： p . x = 1 ; int * a ; a = & ( p . x ); 而以下代碼是錯的： ( * pp ). x = 1 ; 因爲作爲這個賦值的目標地址表達式的一部分， *pp ，這個中間結果沒法直譯到機器碼。 所以對早期的 C 而言，對 pp 解引用的操作，必須和取成員的偏移的操作，這兩者緊密結合起來變成一個單獨的操作，其結果纔有意義。 所以早期的 C 就發明了 -> ，表示這兩個操作緊密結合的操作。於是纔能寫： pp -> x = 1 ; 嗯，這就是它存在的歷史原因。 而這個歷史原因現在已經不重要了，現代的符合標準的 C 編譯器都知道 (*pp).x 和 pp->x 是等價的了。 說句題外話， C++ 裏面還發明了 .* 和 ->* 這兩個運算符（注意 ->* 不是單獨的 -> 和 * 並排放的意思），關於爲什麼要發明這兩個運算符，而不能直接說 a ->* b 的意思就是 a ->(*b) ，這個就作爲課堂作業吧。","tags":"import","url":"//farseerfc.me/dot-and-arrow-in-c.html"},{"title":"啓用 GitHub Issue 作爲博客留言系統","text":"從今天起本博客將啓用 GitHub Issue 作爲留言系統。 原本使用的 Disqus 將繼續保留一段時間，目前沒有關閉的計劃。 換用 GitHub Issue 是計劃了好久的事情了，最初重做這個主題的時候就有考慮過。 這個想法的契機是看到了這篇 GitHub hosted comments for GitHub hosted blogs ，然後立馬覺得這個想法很符合寄宿在 GitHub Pages 上的博客。 一個限制是要求評論者必須有 GitHub 賬戶，考慮到我的博客的受衆這個要求估計不算太過分。 使用 GitHub Issue 的好處麼，比如自帶的 GFMD 富文本格式，郵件通知，還有訂閱和取消訂閱通知，郵件回復， 這些方面都不比第三方留言系統遜色。 換用 GitHub Issue 另一方面原因是最近聽說 Disqus 被部分牆了，想必以後牆也會越來越高。之前曾經試過在這個博客換上多說， 然而效果我並不喜歡，多說喜歡侵入頁面加很多奇怪的東西，比如用戶的頭像通常是 http 的……也試過結合新浪微博的評論，而新浪微博越來越封閉，API 也越來越不靠譜。 使用 GitHub Issue 作爲評論的方式比較簡單，上面那篇博客裏面提到了，代碼量不比 加載 Disqus 多多少，而且沒有了 iframe 的困擾，唯一麻煩的地方就是要稍微設計一下佈局方式讓它融入 現有的頁面佈局。 我參考上面的實現在這裏 。 這個加載代碼使用兩個變量加載 Issue Comments ，一個是在 pelicanconf.py 裏的 GITHUB_REPO ，可以指向任何 Repo ，我指向 farseerfc/farseerfc.github.io 的這個 GitHub Page repo ，另一個變量是每篇文章裏需要加上 issueid 的元數據，關連文章到每個 Issue 上。 還有一個稍微麻煩的事情是現在每寫一篇文章之後都要新建一個 issue 了。 手動操作有點累人，於是我 寫了個腳本 自動搜索 pelican 的 content 文件夾裏面文章的 slug 並且對沒有 issueid 關連的 文章創建 issue 。 好啦新的留言系統的外觀樣式還在測試中，希望大家多留言幫我測試一下！ 2016年8月7日19:30更新 新增了對 GitHub Issue comments 裏面 reactions 的支持，套用 font-awesome 的圖標（似乎沒 GitHub 上的圖標好看）。這個還屬於 GitHub API 的實驗性功能，要加入 Accept: application/​vnd.github.squirrel-girl-preview HTTP 頭纔能拿到。 2016年8月7日23:16更新 感謝 @iovxw 的測試讓我發現 github 的高亮回復和郵件回復是需要特殊處理的。 高亮回復用上了 這裏的 CSS 郵件引言的展開事件直接用 jQuery 做了： $ ( \".email-hidden-toggle > a\" ). on ( \"click\" , function ( e ){ e . preventDefault (); $ ( \".email-hidden-reply\" , this . parent ). toggle (); }); 還得注意郵件的回復需要 CSS 裏面 white-space: pre-wrap 。","tags":"tech","url":"//farseerfc.me/github-issues-as-comments.html"},{"title":"PacVis: 可視化 pacman 本地數據庫","text":"PacVis 我爲什麼要做 PacVis 我喜歡 Arch Linux ，大概是因爲唯有 Arch Linux 能給我對整個系統「瞭如指掌」的感覺。 在 Arch Linux 裏我能清楚地知道我安裝的每一個包，能知道系統裏任何一個文件是來自哪個包， 以及我爲什麼要裝它。或許對 Debian/Fedora/openSUSE 足夠熟悉了之後也能做到這兩點， 不過他們的細緻打包的結果通常是包的數量比 Arch 要多個 3 到 10 倍，並且打包的細節也比 Arch Linux 簡單的 PKGBUILD 要複雜一個數量級。 每一個裝過 Arch Linux 的人大概都知道，裝了 Arch Linux 之後得到的系統非常樸素，按照 ArchWiki 上的流程一路走下來的話，最關鍵的一條命令就是 pacstrap /​mnt base ， 它在 /​mnt 裏作爲根調用 pacman -S base 裝上了整個 base 組， 然後就沒有然後了。這個系統一開始空無一物，你需要的任何東西都是後來一點點用 pacman 手動裝出來的，沒有累贅，按你所需。 然而時間長了，系統中難免會有一些包，是你裝過用過然後忘記了， 然後這些包就堆在系統的角落裏，就像家裏陳年的老傢俱，佔着地，落着灰。雖然 pacman -Qtd 能方便地幫你找出所有 曾經作爲依賴被裝進來，而現在不被任何包依賴 的包，但是對於那些你手動指定的包， 它就無能爲力了。 於是我就一直在找一個工具能幫我梳理系統中包的關係，方便我： 找出那些曾經用過而現在不需要的包 找出那些體積大而且佔地方的包 釐清系統中安裝了的包之間的關係 Android 系統架構 關於最後一點「釐清包的關係」，我曾經看到過 macOS 系統架構圖 和 Android 的系統架構圖，對其中的層次化架構印象深刻，之後就一直在想，是否能畫出現代 Linux 桌面系統上類似的架構圖呢？又或者 Linux 桌面系統是否會展現完全不同的樣貌？ 從維基百科或者別的渠道能找到 Linux 內核、或者 Linux 圖形棧， 或者某個桌面環境的架構，但是沒有找到覆蓋一整個發行版的樣貌的。 於是我便想，能不能從包的依賴關係中自動生成這樣一張圖呢。 PacVis的老前輩們 在開始寫 PacVis 之前，我試過一些類似的工具，他們都或多或少能解決一部分我的需要， 又在某些方面有所不足。這些工具成爲了 PacVis 的雛形，啓發了 PacVis 應該做成什麼樣子。 pactree pactree 曾經是一個 獨立的項目 ，現在則是 pacman 的一部分 了。 從手冊頁可以看出， pactree 的輸出是由某個包開始的依賴樹。 加上 --graph 參數之後 pactree 還能輸出 dot 格式的矢量圖描述，然後可以用 dot 畫出依賴圖： pactree pacvis-git -d3 --graph | dot -Tpng >pacvis-pactree.png $ pactree pacvis-git -d3 pacvis-git ├─python-tornado │ └─python │ ├─expat │ ├─bzip2 │ ├─gdbm │ ├─openssl │ ├─libffi │ └─zlib ├─pyalpm │ ├─python │ └─pacman │ ├─bash │ ├─glibc │ ├─libarchive │ ├─curl │ ├─gpgme │ ├─pacman-mirrorlist │ └─archlinux-keyring └─python-setuptools └─python-packaging ├─python-pyparsing └─python-six $ pactree pacvis-git -d3 --graph | dot -Tpng >pacvis-pactree.png 從畫出的圖可以看出，因爲有共用的依賴，所以從一個包開始的依賴關係已經不再是一棵 圖論意義上的樹(Tree) 了。最初嘗試做 PacVis 的早期實現的時候，就是試圖用 bash/python 腳本解析 pactree 和 pacman 的輸出，在 pactree 的基礎上把整個系統中所有安裝的包全都包含到一張圖裏。 當然後來畫出的結果並不那麼理想，首先由於圖非常巨大，導致 dot 的自動佈局要耗費數小時，最後畫出的圖也過於巨大基本上沒法看。 然而不得不說沒有 pactree 就不會有 PacVis ，甚至 pacman 被分離出 alpm 庫也和 pactree 用 C 重寫的過程有很大關係，而 PacVis 用來查詢 pacman 數據庫的庫 pyalpm 正是 alpm 的 Python 綁定。因爲 pactree 的需要而增加出的 alpm 庫奠定了 PacVis 實現的基石。 pacgraph pacgraph 的輸出 pacgraph 是一位 Arch Linux 的 Trusted User keenerd 寫的程序，和 PacVis 一樣也是用 Python 實現的。 比起 pactree ， pacgraph 明顯更接近我的需求，它默認繪製整個系統的所有安裝包， 並且用聰明的佈局算法解決了 dot 佈局的性能問題。 pacgraph 的輸出是一個富有藝術感的依賴圖，圖中用不同的字體大小表示出了每個包佔用 的磁盤空間。通過觀察 pacgraph 的輸出，我們可以清楚地把握系統全局的樣貌， 比如一眼看出這是個桌面系統還是個服務器系統，並且可以很容易地發現那些佔用磁盤空間 巨大的包，考慮清理這些包以節約空間。 更棒的是 pacgraph 還提供了一個交互性的 GUI 叫做 pacgraph-tk ，顯然通過 tk 實現。 用這個 GUI 可以縮放觀察整幅圖的細節，或者選中某個包觀察它和別的包的依賴關係。 pacgraph 還支持通過參數指定只繪製個別包的依賴關係，就像 pactree 那樣。 不過 pacgraph 也不是完全滿足我的需要。如我前面說過，我希望繪製出的圖能反應 這個發行版的架構面貌 ，而 pacgraph 似乎並不區別「該包依賴的包」和「依賴該包的包」 這兩種截然相反的依賴關係。換句話說 pacgraph 畫出的是一張無向圖， 而我更想要一張有向圖，或者說是 有層次結構的依賴關係圖 。 於是就有了 PacVis PacVis 剛打開的樣子 總結了老前輩們的優勢與不足，我便開始利用空餘時間做我心目中的 PacVis 。 前後斷斷續續寫了兩個月，又分爲兩個階段，第一階段做了基本的功能和雛形， 第二階段套用上 https://getmdl.io/ 的模板，總算有了能拿得出手給別人看的樣子。 於是乎前兩天在 AUR 上給 pacvis 打了個 pacvis-git 包，現在想在本地跑 pacvis 應該很方便了，用任何你熟悉的 aurhelper 就可以安裝，也可以直接從 aur 下載 PKGBUILD 打包： ~$ git clone aur@aur.archlinux.org:pacvis-git.git ~$ cd pacvis-git ~/pacvis-git$ makepkg -si ~/pacvis-git$ pacvis Start PacVis at http://localhost:8888/ 按照提示說的，接下來打開瀏覽器訪問 http://localhost:8888/ 就能看到 PacVis 的樣子了。僅僅作爲嘗試也可以直接打開跑在我的服務器上的 demo: https://pacvis.farseerfc.me/ ，這個作爲最小安裝的服務器載入速度大概比普通的桌面系統快一點。 在 Windows msys2 跑 PacVis 另外補充一下，因爲 PacVis 只依賴 pyalpm 和 tornado ，所以在別的基於 pacman 的系統上跑它應該也沒有任何問題，包括 Windows 上的 msys2 裏（儘管在 msys2 上編譯 tornado 的包可能要花些功夫）。 PacVis 的圖例和用法 操作上 PacVis 仿照地圖程序比如 Google Maps 的用法，可以用滾輪或者觸摸屏的手勢 縮放、拖拽，右上角有個側邊欄，不需要的話可以點叉隱藏掉，右下角有縮放的按鈕和 回到全局視圖的按鈕，用起來應該還算直觀。 pacvis-git 包的依賴 先解釋圖形本身，整張圖由很多小圓圈的節點，以及節點之間的箭頭組成。 一個圓圈就代表一個軟件包，而一條箭頭代表一個依賴關係。縮放到細節的話， 能看到每個小圓圈的下方標註了這個軟件包的名字，鼠標懸浮在圓圈上也會顯示響應信息。 還可以點開軟件包，在右側的邊欄裏會有更詳細的信息。 比如圖例中顯示了 pacvis-git 自己的依賴，它依賴 pyalpm, python-tornado 和 python-setuptools ，其中 pyalpm 又依賴 pacman 。圖中用 紫色 表示手動安裝的包， 橙色 表示被作爲依賴安裝的包， 箭頭的顏色也隨着包的顏色改變。 值得注意的是圖中大多數箭頭都是由下往上指的，這是因爲 PacVis 按照包的依賴關係做 了拓撲排序，並且給每個包賦予了一個拓撲層級。比如 pacvis-git 位於 39 層，那麼它依賴的 pyalpm 就位於 38 層，而 pyalpm 依賴的 pacman 就位於 37 層。根據層級關係排列包是 PacVis 於 pacgraph 之間最大的不同之處。 除了手動縮放， PacVis 還提供了搜索框，根據包名快速定位你感興趣的包。 以及在右側邊欄中的 Dep 和 Req-By 等頁中，包的依賴關係也是做成了按鈕的形式， 可以由此探索包和包之間的關聯。 最後稍微解釋一下兩個和實現相關的參數： Max Level 這是限制 PacVis 載入的最大拓撲層。系統包非常多的時候 PacVis 的佈局算法會顯得很慢，限制層數有助於加快載入，特別是在調試 PacVis 的時候比較有用。 Max Required-By 這是限制 PacVis 繪製的最大被依賴關係。稍微把玩一下 PacVis 就會發現系統內絕大多數 的包都直接依賴了 glibc 或者 gcc-libs 等個別的幾個包，而要繪製這些依賴的話會導致 渲染出的圖中有大量長直的依賴線，不便觀察。於是可以通過限制這個值，使得 PacVis 不繪製被依賴太多的包的依賴關係，有助於讓渲染出的圖更易觀察。 從 PacVis 能瞭解到的一些事實 一個 KDE 桌面的 PacVis 結果全圖， 放大（17M） 稍微玩一下 PacVis 就能發現不少有趣現象，上述「絕大多數包依賴 glibc 」就是一例。 除此之外還有不少值得玩味的地方。 依賴層次 系統中安裝的包被明顯地分成了這樣幾個層次： glibc 等 C 庫 Bash/Perl/Python 等腳本語言 coreutils/gcc/binutils 等核心工具 pacman / systemd 等較大的系統工具 gtk{2,3}/qt{4,5} 等 GUI toolkit chromium 等 GUI 應用 Plasma/Gnome 等桌面環境 大體上符合直觀的感受，不過細節上有很多有意思的地方，比如 zsh 因爲 gdbm 間接依賴了 bash，這也說明我們不可能在系統中用 zsh 完全替代掉 bash。 再比如 python （在 Arch Linux 中是 python3）和 python2 和 pypy 幾乎在同一個拓撲層級。 zsh 因爲 gdbm 間接依賴了 bash 不過偶爾顯示的依賴層級不太符合直觀，比如 qt5-base < qt4 < gtk2 < gtk3 。 qt5 因爲被拆成了數個包所以比 qt4 更低級這可以理解，而 gtk 系比 qt 系更高級這一點是很多人（包括我）沒有預料到的吧。 循環依賴 有些包的依賴關係形成了循環依賴，一個例子是 freetype2 和 harfbuzz，freetype2 是繪製字體的庫，harfbuzz 是解析 OpenType 字形的庫，兩者對對方互相依賴。 另一個例子是 KDE 的 kio 和 kinit，前者提供類似 FUSE 的資源訪問抽象層， 後者初始化 KDE 桌面環境。 freetype2 和 harfbuzz 之間的循環依賴 因爲這些循環依賴的存在，使得 PacVis 在實現時不能直接拓撲排序，我採用環探測 算法找出有向圖中所有的環，並且打破這些環，然後再使用拓撲排序。 因此我在圖中用紅色的箭頭表示這些會導致環的依賴關係。 有些包沒有依賴關係 man-pages 和 licenses 沒有依賴關係 有些包既不被別的包依賴，也不依賴別的包，而是孤立在整張圖中，比如 man-pages 和 licenses 。這些包在圖中位於最頂端，拓撲層級是 0 ，我用 藍色 正方形特別繪製它們。 只看依賴關係的話 Linux 內核完全不重要 所有用戶空間的程序都依賴着 glibc ，而 glibc 則從定義良好的 syscall 調用內核。 因此理所當然地，如果只看用戶空間的話， glibc 和別的 GNU 組件是整個 GNU/Linux 發行版的中心，而 Linux 則是位於依賴層次中很深的位置，甚至在我的 demo 服務器上 Linux 位於整個圖中的最底端，因爲它的安裝腳本依賴 mkinitcpio 而後者依賴了系統中的衆多組件。 pacman -Qtd 不能找到帶有循環依賴的孤兒包 msys2 中帶有循環依賴的孤兒包 這是我在 msys2 上測試 PacVis 的時候發現的，我看到在渲染的圖中有一片羣島， 沒有連上任何手動安裝的包。這種情況很不正常，因爲我一直在我的所有系統中跑 pacman -Qtd 找出孤兒包並刪掉他們。放大之後我發現這些包中有一條循環依賴， 這說明 pacman -Qtd 不能像語言的垃圾回收機制那樣找出有循環依賴的孤兒包。 PacVis 的未來 目前的 PacVis 基本上是我最初開始做的時候設想的樣子，隨着開發逐漸又增加了不少功能。 一些是迫於佈局算法的性能而增加的（比如限制層數）。 今後準備再加入以下這些特性： 更合理的 optdeps 處理。目前只是把 optdeps 關係在圖上畫出來了。 更合理的 依賴關係抉擇 。有時候包的依賴關係並不是直接根據包名，而是 provides 由一個包提供另一個包的依賴。目前 PacVis 用 alpm 提供的方式抉擇這種依賴，於是這種關係並沒有記錄在圖上。 目前的層級關係沒有考慮包所在的倉庫 (core/extra/community/...) 或者包所屬的組。 加入這些關係能更清晰地表達依賴層次。 目前沒有辦法只顯示一部分包的關係。以後準備加入像 pactree/pacgraph 一樣顯示部分包。 如果你希望 PacVis 出現某些有趣的用法和功能，也 請給我提 issue 。","tags":"tech","url":"//farseerfc.me/pacvis.html"},{"title":"X 中的混成器與 Composite 擴展","text":"在上篇文章 「桌面系統的混成器簡史」 中我介紹了其它桌面系統中的混成器的發展史和工作原理， 話題回到我們的正題 Linux 系統上，來說說目前 X 中混成器是如何工作的。 這篇文章將比上一篇深入更多技術細節，不想看太多細節的可以直接跳過看 結論 。 原始的 X 的繪圖模型 首先，沒有混成器的時候 X 是這樣畫圖的： X 的應用程序沒有統一的繪圖 API 。GTK+ 在 3.0 之後統一用 Cairo 繪圖， 而 Cairo 則是基於 PDF 1.4 的繪圖模型構建的， GTK 的 2.0 和之前的版本中也有很大一部分的繪圖是用 Cairo 進行， 其餘則通過 xlib 或者 xcb 調用 X 核心協議提供的繪圖原語繪圖。 QT 的情況也是類似，基本上用 QPaint 子系統繪製成位圖然後交給 X 的顯示服務器。 顯示服務器拿到這些繪製請求之後，再在屏幕上的相應位置繪製整個屏幕。 當然還有很多老舊的不用 GTK 或者 QT 的程序，他們則直接調用 X 核心協議提供的繪圖原語。 值得注意一點是 X 上除了沒有統一的繪圖模型，也沒有統一的矢量圖格式。 X 核心協議的繪圖原語提供的是像素單位的繪圖操作，沒有類似 GDI+ 或者 Quartz 提供的 設備無關 ( Device Independence ) 的「點」的抽象。所以只用 X 的繪圖原語的話，我們可以把 (1,1) 這個像素點塗黑，但是不能把 (0.5, 0.5) 這個點塗黑，這一設計缺陷在 Unix Hater's Handbook 中已經被吐槽過了。因爲這個缺陷，所以直接用 X 繪圖原語繪製的圖像不能像 矢量圖那樣進行無損縮放。同樣的缺陷導致 X 繪圖原語繪製的字符不能做到 子像素級 ( subpixel-level ) 抗鋸齒 ( anti-aliasing ) （這解釋了默認配置下的 xterm 和 urxvt 中的字體渲染爲什麼難看 ）。相比之下 GDI 有對應的 WMF 矢量圖格式， Quartz 有對應的 PDF 矢量圖格式， 而 X 中沒有這樣的格式對應。因爲沒有統一的矢量圖格式，所以無論是 Cairo 、QPaint 還是沒有用這些繪圖庫但是同樣在意字體和曲線渲染效果的程序（比如 Firefox 和 Chromium）都需要首先渲染到內部的 XPixMap 位圖格式，做好子像素渲染和矢量縮放，然後再把渲染好的位圖轉交給 X 圖形服務器。 通過 Composite 擴展重定向窗口輸出 2004年發佈的 X11R6.8 版本的 Xorg 引入了 Composite 擴展 。這個擴展背後的動機以及前因後果在一篇文章 The (Re)Architecture of the X Window System 中有詳細的表述。Composite 擴展允許某個 X 程序做這幾件事情： 通過 RedirectSubwindows 調用將一個窗口樹中的所有窗口渲染重定向到 內部存儲 ( off-screen storage ) 。重定向的時候可以指定讓 X 自動更新窗口的內容到屏幕上或者由混成器手動更新。 通過 NameWindowPixmap 取得某個窗口的內部存儲。 通過 GetOverlayWindow 獲得一個特殊的用於繪圖的窗口， 在這個窗口上繪製的圖像將覆蓋在屏幕的最上面。 通過 CreateRegionFromBorderClip 取得某個窗口的邊界剪裁區域（不一定是矩形）。 有了 Composite 擴展，一個 X 程序就可以調用這些 API 實現混成器。 這裏有篇 教學解釋如何使用 Composite 擴展 。開啓了混成的 X 是這樣繪圖的： 整個 X 的混成器模型與 Mac OS X 的混成器模型相比，有如下幾點顯著的區別： 混成的部分是交由外部的程序完成的，對混成的繪製方式和繪製普通窗口一樣。 出於效率考慮，絕大多數 X 上的混成器額外使用了 XRender 擴展或者 OpenGL/EGL 來加速繪製貼圖。不過即使如此，還是不能避免同樣的位圖（內容不一定完全一致， 比如 X 可以在窗口交給它的位圖上加上邊框然後再返還給混成器） 在不同的三個程序之間來回傳遞 。 RedirectSubwindows 調用針對的是一個窗口樹，換句話說是一個窗口 及其全部子窗口，不同於 Mac OS X 中混成器會拿到全部窗口的輸出。 這個特點其實並不算是限制，因爲 X 中每個虛擬桌面都有一個根窗口，只要指定這個根窗口 就可以拿到整個虛擬桌面上的全部可見窗口輸出了。 反而這個設計提供了一定的自由度，比如我們可以用這個調用實現一個截圖程序， 拿到某個特定窗口的輸出，而不用在意別的窗口。 爲了讓窗口有輸出，窗口必須顯示在當前桌面上，不能處於最小化 狀態或者顯示在別的虛擬桌面，用 X 的術語說就是窗口必須處於 被映射 ( mapped ) 的狀態。因此直接用上述方法 不能得到沒有顯示的窗口的輸出 ，比如不能對最小化的窗口 直接實現 Windows 7 中的 Aero Peak 之類的效果。這個限制可以想辦法繞開， 比如在需要窗口輸出的時候臨時把窗口映射到桌面上，拿到輸出之後再隱藏起來， 不過要實現這一點需要混成器和窗口管理器相互配合。 不像 Mac OS X 的基於 OpenGL Surface 的繪圖模型是 設備無關 ( device independent ) 的，這裏 X 的繪圖模型是 設備相關 ( device dependent ) 的。 這既是優點也是缺點。從缺點方面而言，顯示到 X 的位圖輸出因爲設備相關性， 所以嚴格對應顯示器的點陣，並不適合作爲文檔格式打印出來。當然無論是 Cairo 還是 QPaint 都提供了到 PostScript 或者 PDF 後端的輸出，所以實用層面這個並不構成問題。 設備相關這一點的優點在於，繪製到 XPM 位圖的時候，程序和繪圖庫是能拿到輸出設備（顯示器） 的特殊屬性的，從而繪圖庫能考慮不同的色彩、分辨率、 DPI 或者 子像素佈局 ( subpixel layout ) 這些屬性以提供最好的渲染效果。 Mac OS X 10.4 在設計的時候也曾考慮過提供無極縮放的支持，而這種支持到了 Mac OS X 10.5 中就縮水變成了 Retina 的固定 2 倍縮放。這種局面在 X 上沒有發生正是因爲 X 的繪圖模型的這種設備相關性，而 Mac OS X 的混成器採用的 OpenGL Surface 則無視了這些設備相關的屬性。 輸入事件的重定向，這可能做到麼？ 通過上述 Composite 擴展提供的 API ，混成器可以把窗口的 輸出 重定向到自己的窗口上。 但是僅僅重定向輸出，整個 X 還不處於可用狀態，因爲 沒有重定向輸入 。 考慮一下用戶試圖用鼠標點擊某個按鈕或者文本框，這時鼠標處於的位置是在 OverlayWindow 上繪製的位置，這個鼠標事件會交給 OverlayWindow ，而用戶期待這個事件被發送給他看到的按鈕上。 需要重定向的事件主要有鍵盤和鼠標事件兩大類（暫時先不考慮觸摸屏之類的額外輸入）。 由於 Composite 擴展並沒有直接提供這方面的重定向 API ，這使得輸入事件處理起來都比較麻煩， 假設要重定向鍵盤事件，混成器需要效仿輸入法框架（fcitx, ibus, scim） 那樣處理一部分按鍵事件並把其餘事件轉給具有輸入焦點的程序。 看看現有的輸入法框架和諸多程序間的問題，我們就能知道這裏的坑有多深。 於是 大部分 X 的混成器都不處理鍵盤事件重定向 。再來看重定向鼠標事件，這邊的坑比重定向鍵盤事件的坑更多， 因爲不像重定向窗口輸出那樣只需要考慮 頂層 ( top-level ) 窗口， 重定向鼠標輸入的時候要考慮所有子窗口（它們有獨立的事件隊列）， 以及要準確記錄輸入事件事件發生時的鍵盤組合鍵狀態，還要正確實現 ICCCM/EWMH 中描述的轉交窗口焦點的複雜規則，所有這些都已經在 X 中實現過的事情需要重新實現一遍。 由於坑太多難以實現，所以所有 X 下的混成器的實現方式都是直接忽略這個繁重的任務， 不重定向輸入事件 而把它交給 X 處理。具體的實現方式就是通過 XFixes 擴展提供的 SetWindowShapeRegion API 將 OverlayWindow 的 輸入區域 ShapeInput 設爲空區域，從而忽略對這個 OverlayWindow 的一切鼠標鍵盤事件。 這樣一來對 OverlayWindow 的點擊會透過 OverlayWindow 直接作用到底下的窗口上。 因爲選擇了不重定向輸入事件， X 下的混成器通常會處於以下兩種狀態： 選擇狀態下可以縮放窗口的大小，扭曲窗口的形狀，並且可以把窗口繪製在任意想要繪製的位置上 （並不是移動窗口的位置）， 但是不能讓用戶與窗口的內容交互 。 正常狀態下可以讓用戶與窗口的內容交互，但是 繪製的窗口位置、大小和形狀必須嚴格地和 X 記錄的窗口的位置、大小和形狀保持一致 。持續時間短暫的動畫效果可以允許位置和形狀稍有偏差，但是在動畫的過程中如果用戶點擊了 變形縮放過的窗口，那麼鼠標事件將發往錯誤的（ X 記錄中的而非顯示出的）窗口元素上。 可以發現這兩種狀態就直接對應了 Gnome 3 的普通狀態和縮略圖狀態（點擊 活動 ( Activity ) 或者戳畫面左上角之後顯示的狀態），這也解釋了爲什麼儘管 Gnome 3 的窗口有碩大的關閉按鈕，但是在縮略圖狀態下 Gnome 3 仍然需要給窗口加上額外的關閉按鈕： 因爲處於縮略狀態下的窗口只是一張畫而不能點 。 Composite 擴展的這些限制使得 X 下的混成器目前只能實現 Mac OS X 那樣的 Exposé 效果，而不能實現 LG3D 那樣直接在 3D 空間中操縱窗口內容。 解決重定向問題曾經的一縷曙光是 昇陽公司 ( Sun Microsystems ) 在開發 LG3D 的過程中同時提議過另一個 X 擴展叫做 Event Interception 或者簡稱 XEvIE ，這個擴展的設計目的就是提供 API 讓某個程序接收並操縱全部的鍵盤和鼠標事件。可惜這個擴展隨着昇陽公司本身的隕落而 處於無人維護的狀態，這一點也在它的官方網頁上說明了： It has been suggested that this extension should not be used because it is broken and maintainerless. Composite 擴展的不足 通過上面的介紹，我們就已經可以看到 Composite 擴展的不足之處了。 總結起來說，主要有兩大不足： 繪圖效率低。因爲同樣的位圖從應用程序傳到 Xorg ，再從 Xorg 傳到混成器， 最後從混成器再繪製到屏幕上，繞了一個大彎。這就是爲什麼 Wayland 的開發者在他的slide the real story behind Wayland and X 裏這麼說： and what's the X server? really bad IPC 那麼 X 服務器到底做了什麼呢？ 非常糟糕的進程間通訊 沒有重定向輸入事件。如果我們要在 X 的混成器裏做這個事情， 基本上我們要全部重寫一遍 X 已經寫好的窗口事件分發邏輯。 既然同樣要重寫，爲什麼不直接重寫一遍 X 呢，扔掉那些歷史負擔，扔掉那些無用的 API ，重新設計可擴展的 API ，做好快速安全的 IPC —— 嗯，重寫 X 就是 Wayland 的目的。 不過這麼重寫了的 Wayland 還是我們熟悉可愛的 X 麼？它有哪些地方變樣了？ 這將是我下一篇文章的內容。 附錄：擴展閱讀 我自己沒有寫過窗口管理器，沒有寫過混成器，沒有寫過 Wayland 程序，以上說的都是我從互聯網上看到的整理出來的內容。寫下本文的過程中我參考了這些文章： The (Re)Architecture of the X Window System 這篇2004年寫的文章描述了 Composite 擴展出現的動機和歷史，介紹了繪圖庫的實現情況，涉及了上面所說的那些 X 擴展被用到的情況和可能。 同時這篇文章還展望了很多現在的 X 已然實現了的功能，比如 OpenGL 和 X 的結合方面我們有了 GLX 和 AIGLX ，比如內核的顯卡支持方面我們有了 DRI 和 KMS 。總之這是一篇描述 Linux 桌面未來的發展軌跡的非常有閱讀價值的歷史文獻。 so you want to build a compositor 這是一篇 2008 年寫的博文，介紹如何用 Clutter 實現一個最簡單的混成器。 Composite tutorial 這是另一篇介紹如何實現一個簡單的混成器的博文，用 Qt 實現，但是同樣很底層。 unagi 這是一個可用的（但是已經長期沒有開發的）類似 xcompmgr 的混成器。這個項目貌似 是一位研究生的碩士畢業設計，同時他公開了碩士學位的畢業論文 Master thesis: Writing an X compositing manager 其中也對實現一個簡單的混成器做了詳盡描述，包括介紹了相關的 X 擴展和調用。","tags":"tech","url":"//farseerfc.me/compositor-in-X-and-compositext.html"},{"title":"桌面系統的混成器簡史","text":"（原本是想寫篇關於 Wayland 的文章，後來越寫越長感覺能形成一個系列， 於是就先把這篇背景介紹性質的部分發出來了。） Linux 系統上要迎來 Wayland 了，或許大家能從各種渠道打聽到 Wayland 是一個混成器，替代 X 作爲顯示服務器。 那麼 混成器 是個什麼東西，桌面系統爲什麼需要它呢？ 要理解爲什麼桌面系統需要 混成器 （或者它的另一個叫法， 混成窗口管理器 ( Compositing Window Manager ) ），在這篇文章中我想回顧一下歷史， 瞭解一下混成器出現的前因後果。 首先介紹一下混成器出現前主要的一類窗口管理器，也就是 棧式窗口管理器 ( Stacking Window Manager ) 的實現方式。 本文中所有桌面截圖來自維基百科，不具有著作權保護。 早期的棧式窗口管理器 棧式窗口管理器的例子，Windows 3.11 的桌面 我們知道最初圖形界面的應用程序是全屏的，獨佔整個顯示器（現在很多遊戲機和手持設備的實現仍舊如此）。 所有程序都全屏並且任何時刻只能看到一個程序的輸出，這個限制顯然不能滿足人們使用計算機的需求， 於是就有了 窗口 的概念，有了 桌面隱喻 。 在 桌面隱喻 ( Desktop Metaphor ) 中每個窗口只佔用顯示面積的一小部分， 有其顯示的位置和大小，可以互相遮蓋。於是棧式窗口管理器就是在圖形界面中實現桌面隱喻的核心功能， 其實現方式大體就是：給每個窗口一個相對的\"高度\"或者說\"遠近\"，比較高的窗口顯得距離用戶比較近， 會覆蓋其下比較低的窗口。繪圖的時候窗口管理器會從把窗口按高低排序，按照從低到高的順序使用 畫家算法 繪製整個屏幕。 這裏還要補充一點說明，在當時圖形界面的概念剛剛普及的時候，繪圖操作是非常\"昂貴\"的。 可以想象一下 800x600 像素的顯示器輸出下，每幀 真彩色 位圖就要佔掉 \\(800 \\times 600 \\times 3 \\approx 1.4 \\text{MiB}\\) 的內存大小，30Hz 的刷新率（也就是30FPS）下每秒從 CPU 傳往繪圖設備的數據單單位圖就需要 \\(1.4 \\times 30 = 41 \\text{MiB}\\) 的帶寬。對比一下當時的 VESA 接口 總的數據傳輸能力也就是 \\(25 \\text{MHz} \\times 32 \\text{bits} = 100 \\text{MiB/s}\\) 左右， 而 Windows 3.1 的最低內存需求是 1MB，對當時的硬件而言無論是顯示設備、內存或是CPU， 這無疑都是一個龐大的負擔。 於是在當時的硬件條件下採用棧式窗口管理器有一個巨大 優勢 ：如果正確地採用畫家算法， 並且合理地控制重繪時 只繪製沒有被別的窗口覆蓋的部分 ，那麼無論有多少窗口互相 遮蓋，都可以保證每次繪製屏幕的最大面積不會超過整個顯示器的面積。 同樣因爲實現方式棧式窗口管理器也有一些難以迴避的 限制 ： 窗口必須是矩形的，不能支持不規則形狀的窗口。 不支持透明或者半透明的顏色。 爲了優化效率，在縮放窗口和移動窗口的過程中，窗口的內容不會得到重繪請求， 必須等到縮放或者移動命令結束之後窗口纔會重繪。 以上這些限制在早期的 X11 窗口管理器比如 twm 以及 XP 之前經典主題的 Windows 或者經典的 Mac OS 上都能看到。 在這些早期的窗口環境中，如果你拖動或者縮放一個窗口，那麼將顯示變化後的窗口邊界， 這些用來預覽的邊界用快速的位圖反轉方式繪製。當你放開鼠標的時候纔會觸發窗口的 重繪事件。 雖然有很多方法或者說技巧能繞過這些限制，比如 Windows XP 上就支持了實時的 重繪事件和不規則形狀的窗口剪裁，不過這些技巧都是一連串的 hack ，難以擴展。 NeXTSTEP 與 Mac OS X 中混成器的發展 NeXTSTEP 桌面 轉眼進入了千禧年， Windows 稱霸了 PC 產業，蘋果爲重振 Macintosh 請回了 Jobs 基於 NeXTSTEP 開發 Mac OSX 。 NeXTSTEP 在當時提供的 GUI 界面技術相比較於同年代的 X 和 Windows 有一個很特別的地方： 拖動滾動條或者移動窗口的時候，窗口的內容是 實時更新 的，這比只顯示一個縮放大小的框框來說被認爲更直觀。 而實現這個特性的基礎是在 NeXTSTEP 中運用了 Display PostScript (DPS) 技術，簡單地說，就是每個窗口並非直接輸出到顯示設備，而是把內容輸出到 (Display) PostScript 格式交給窗口管理器，然後窗口管理器再在需要的時候把 PostScript 用軟件解釋器解釋成位圖顯示在屏幕上。 比起讓窗口直接繪製，這種方案在滾動和移動窗口的時候不需要重新渲染保存好的 DPS ， 所以能實現實時渲染。到了實現 Mac OS X 的時候，爲了同時兼容老的 Mac 程序 API (carbon) 以及更快的渲染速度，以及考慮到 Adobe 對蘋果收取的高昂的 Display PostScript 授權費， Mac OS X 的 Quartz 技術在矢量圖的 PDF 描述模型和最終渲染之間又插入了一層抽象： Mission Control 也就是說在 Mac OS X 中無論窗口用何種方式繪圖，都會繪製輸出成一副內存中的位圖交給混成器， 而後者再在需要的時候將位圖混成在屏幕上。這種設計使得 2001年3月發佈的 Mac OS X v10.0 成爲了第一個廣泛使用的具有軟件混成器的操作系統。 到了 Mac OS X v10.2 的時候，蘋果又引入了 Quartz Extreme 讓最後的混成渲染這一步發生在 顯卡上。然後在 2003年1月公開亮相的 Mac OS X v10.3 中，他們公佈了 Exposé (後來改名爲 Mission Control) 功能，把窗口的縮略圖（而不是事先繪製的圖標）並排顯示在桌面上， 方便用戶挑選打開的窗口。 由於有了混成器的這種實現方式，使得可能把窗口渲染的圖像做進一步加工，添加陰影、三維和動畫效果。 這使得 Mac OS X 有了美輪美奐的動畫效果和 Exposé 這樣的方便易用的功能。 或許對於喬布斯而言，更重要的是因爲有了混成器，窗口的形狀終於能顯示爲他 夢寐以求 的 圓角矩形 了！ 插曲：曇花一現的 Project Looking Glass 3D 在蘋果那邊剛剛開始使用混成器渲染窗口的 2003 年，昔日的 昇陽公司 ( Sun Microsystems ) 則在 Linux 和 Solaris 上用 Java3D 作出了另一個炫酷到沒有朋友的東西，被他們命名爲 Project Looking Glass 3D （縮寫LG3D，別和 Google 的 Project Glass 混淆呀）。這個項目的炫酷實在難以用言語描述， 好在還能找到兩段視頻展示它的效果。 Youtube Youku Youtube Youku LG3D 如視頻中展示的那樣， LG3D 完全突破了傳統的棧式窗口管理方式， 在三維空間中操縱二維的窗口平面，不僅像傳統的窗口管理器那樣可以縮放和移動窗口， 還能夠旋轉角度甚至翻轉到背面去。從視頻中難以體會到的一點是， LG3D 在實現方式上與 Mac OS X 中的混成器有一個本質上的不同，那就是處於（靜止或動畫中）縮放或旋轉狀態 下的窗口是 可以接受輸入事件 的。這一重要區別在後面 Wayland 的說明中還會提到。 LG3D 項目展示了窗口管理器將如何突破傳統的棧式管理的框架，可以說代表了窗口管理器的未來發展趨勢。 LG3D 雖然以 GPL 放出了實現的源代碼，不過整個項目已經停滯開發許久了。 官方曾經放出過一個 預覽版的 LiveCD 。可惜時隔久遠（12年前了）在我的 VirtualBox 上已經不能跑起來這個 LiveCD 了…… 更爲可惜的是，就在這個項目剛剛公開展示出來的時候，喬布斯就致電昇陽， 說如果繼續商業化這個產品，昇陽公司將涉嫌侵犯蘋果的知識產權 （時間順序上來看，蘋果最初展示 Exposé 是在 2003年6月23日的 Apple Worldwide Developers Conference ，而昇陽最初展示 LG3D 是在 2003年8月5日的 LinuxWorld Expo）。 雖然和喬布斯的指控無關，昇陽公司本身的業務也着重於服務器端的業務， 後來隨着昇陽的財政困難，這個項目也就停止開發並不了了之了。 Windows 中的混成器 Longhorn 中的 Wobbly 效果 Youtube Youku 上面說到， Windows 系列中到 XP 爲止都還沒有使用混成器繪製窗口。 看着 Mac OS X 上有了美輪美奐的動畫效果， Windows 這邊自然不甘示弱。 於是同樣在 2003 年展示的 Project Longhorn 中就演示了 wobbly 效果的窗口， 並且跳票推遲多年之後的 Windows Vista 中實現了完整的混成器 Desktop Window Manager (DWM) 。整個 DWM 的架構和 Mac OS X 上看到的很像： 和 Mac OS X 的情況類似， Windows Vista 之後的應用程序有兩套主要的繪圖庫，一套是從早期 Win32API 就沿用至今的 GDI（以及GDI+），另一套是隨着 Longhorn 計劃開發出的 WPF 。 WPF 的所有用戶界面控件都繪製在 DirectX 貼圖上，所以使用了 WPF 的程序也可以看作是 DirectX 程序。而對老舊的 GDI 程序而言，它們並不是直接繪製到 DirectX 貼圖的。首先每一個 GDI 的繪圖操作都對應一條 Windows Metafile (WMF) 記錄，所以 WMF 就可以看作是 Mac OS X 的 Quartz 內部用的 PDF 或者 NeXTSTEP 內部用的 DPS，它們都是矢量圖描述。隨後，這些 WMF 繪圖操作被通過一個 Canonical Display Driver (cdd.dll) 的內部組建轉換到 DirectX 平面，並且保存起來交給 DWM。最後， DWM 拿到來自 CDD 或者 DirectX 的平面，把它們混合起來繪製在屏幕上。 值得注意的細節是，WPF 底層的繪圖庫幾乎肯定有 C/C++ 綁定對應， Windows 自帶的不少應用程序 和 Office 2007 用了 Ribbon 之後的版本都採用這套繪圖引擎，不過微軟沒有公開這套繪圖庫的 C/C++ 實現的底層細節，而只能通過 .Net 框架的 WPF 訪問它。這一點和 OS X 上只能通過 Objective-C 下的 Cocoa API 調用 Quartz 的情況類似。 另外需要注意的細節是 DirectX 的單窗口限制在 Windows Vista 之後被放開了，或者嚴格的說是 基於 WDDM 規範下的顯卡驅動支持了多個 DirectX 繪圖平面。 在早期的 Windows 包括 XP 上，整個桌面上同一時刻只能有一個程序的窗口處於 DirectX 的 直接繪製 模式，而別的窗口如果想用 DirectX 的話，要麼必須改用軟件渲染要麼就不能工作。 這種現象可以通過打開多個播放器或者窗口化的遊戲界面觀察到。 而在 WDDM 規範的 Vista 中，所有窗口最終都繪製到 DirectX 平面上，換句話說每個窗口都是 DirectX 窗口。又或者我們可以認爲，整個界面上只有一個真正的窗口也就是 DWM 繪製的全屏窗口， 只有 DWM 處於 DirectX 的直接渲染模式下，而別的窗口都輸出到 DirectX 平面裏（可能通過了硬件加速）。 由 DWM 的這種實現方式，可以解釋爲什麼 窗口模式下的遊戲總是顯得比較慢 ，原因是整個桌面有很多不同的窗口都需要 DWM 最後混成，而如果在全屏模式下，只有遊戲 處於 DirectX 的直接渲染方式，從而不會浪費對遊戲而言寶貴的 GPU 資源。 由於 DWM 實現了混成器，使得 Vista 和隨後的 Windows 7 有了 Aero Glass 的界面風格， 有了 Flip 3D 、Aero Peek 等等的這些輔助功能和動畫效果。 這套渲染方式延續到 Windows 8 之後，雖然 Windows 8 還提出了 Modern UI 不過傳統桌面上的渲染仍舊是依靠混成器來做的。 這就結束了？ Linux 桌面呢？ 別急，我寫這些文章的目的是想聊聊 Linux 中的混成器，尤其是 X 下現有的混成器和 Wayland ，這篇文章只是個背景介紹。關於 X 中混成器的實現方式和限制，且聽我下回分解。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"//farseerfc.me/brief-history-of-compositors-in-desktop-os.html"},{"title":"避免在博文中寫「簡單地」","text":"我的 RSS 訂閱着一個博客叫 The Old New Thing ，作者是Windows開發者之一的 Raymond Chen ，記錄 Windows 中的很多有趣的技術細節。 這個博客中的一些精彩內容還被他寫成了一本書，中文名叫《Windows編程啓示錄》 (ISBN: 978-7-111-21919-4 ) 而英文書名就叫 The Old New Thing — Practical Development Throughout the Evolution of Windows (ISBN: 978-0-321-44030-3 )。 今天看到這個博客的一篇文章說 你用「簡單地」次數越多我越懷疑你不懂這個詞的意思 ， 描述他看到某個博客上指導讀者打開命令行、執行某條魔法命令、從命令輸出抽取參數、 改寫配置文件、用魔法命令重啓服務，並把這些工作描述爲「簡單地」。 的確正如 Raymond 指出，一個人覺得簡單的事情對別人並不一定是簡單的。 搜了一下我自己寫的東西，的確很多地方寫了「簡單」二字，這的確對讀者不友好。 從今往後避免用「簡單」來描述。","tags":"life","url":"//farseerfc.me/stop-write-simply.html"},{"title":"用 Travis-CI 生成 Github Pages 博客","text":"2015年2月21日更新 上次介紹過 這個博客改換了主題 ， 本以爲這個話題可以告一段落了，沒想到還能繼續寫呢。 寄宿在 Github Pages 上的靜態博客通常有兩種方案，其一是使用 Jekyll 方式撰寫，這可以利用 Github Pages 原本就有的 Jekyll支持 生成靜態網站。另一種是在 本地 也就是自己的電腦上生成好，然後把生成的 HTML 網站 push 到 Github Pages ，這種情況下 Github Pages 就完全只是一個靜態頁面宿主環境。 我用 Pelican 生成博客，當然就只能選擇後一種方式了。這帶來一些不便，比如本地配置 pelican 還是有一點點複雜的，所以不能隨便找臺電腦就開始寫博客。有的時候只是想修正一兩個錯別字， 這時候必須打開某臺特定的電腦纔能編輯博客就顯得不太方便了。再比如 pelican 本身雖然是 python 寫的所以跨平臺，但是具體到博客的配置方面， Windows 環境和 Linux/OSX/Unix-like 環境下還是有 些許出入 的。還有就是沒有像 wordpress 那樣的基於 web 的編輯環境，在手機上就不能隨便寫一篇博客發表出來（不知道有沒有勇士嘗試過在 Android 的 SL4A 環境下的 python 中跑 pelican ，還要配合一個 Android 上的 git 客戶端 ）。 當然並不是因此就束手無策了，感謝 Travis-CI 提供了免費的 持续整合 ( Continuous integration ) 虛擬機環境， 通過它全自動生成靜態博客成爲了可能。 關於 Travis-CI 持续整合 原本是 敏捷開發 ( Agile Development ) 或者 極限編程 ( Extreme Programming ) 中提到的概念，大意就是說在開發的過程中， 一旦有微小的變更，就全自動地 持續 合併到主線中， 整合 變更的內容到發佈版本裏。 這裏的 整合 實際上可以理解爲 全自動測試 加上 生成最終產品 。 可以看到 持續整合 實際強調 全自動 ，於是需要有一個服務器不斷地監聽主線開發的變更內容， 一旦有任何變更（可以理解爲 git commit ）就自動調用測試和部署腳本。 於是要用持續整合就需要一個整合服務器，幸而 Travis-CI 對 github 上的公開 repo 提供了免費的整合服務器虛擬機服務，和 github 的整合非常自然。所以我們就可以用它提供的虛擬機 爲博客生成靜態網站。 啓用 Travis-CI 自動編譯 這一步很簡單，訪問 https://travis-ci.org/ 並用你的 Github 賬戶登錄， 授權它訪問你的賬戶信息就可以了。然後在 https://travis-ci.org/repositories 裏開啓 需要編譯的 repo ，這樣 Travis-CI 就會監視對這個 repo 的所有 push 操作，並且對 每個 push 調用測試了。 在 Travis-CI 中開啓對 Github Repo 的持續整合 然後在 repo 的根目錄放一個 .travis.yml 文件描述編譯的步驟。 暫時 測試的目的下我寫的 .travis.yml 大概是下面這樣。 language : python python : - \"2.7\" before_install : - sudo apt-add-repository ppa:chris-lea/node.js -y - sudo apt-get update - sudo apt-get install nodejs ditaa doxygen parallel install : - sudo pip install pelican - sudo pip install jinja2 - sudo pip install babel - sudo pip install beautifulsoup4 - sudo pip install markdown - sudo npm install -g less - wget \"http://downloads.sourceforge.net/project/plantuml/plantuml.jar?r=&ts=1424308684&use_mirror=jaist\" -O plantuml.jar - sudo mkdir -p /opt/plantuml - sudo cp plantuml.jar /opt/plantuml - echo \"#! /bin/sh\" > plantuml - echo 'exec java -jar /opt/plantuml/plantuml.jar \"$@\"' >> plantuml - sudo install -m 755 -D plantuml /usr/bin/plantuml - wget https://bintray.com/artifact/download/byvoid/opencc/opencc-1.0.2.tar.gz - tar xf opencc-1.0.2.tar.gz - cd opencc-1.0.2 && make && sudo make install && cd .. - sudo locale-gen zh_CN.UTF-8 - sudo locale-gen zh_HK.UTF-8 - sudo locale-gen en_US.UTF-8 - sudo locale-gen ja_JP.UTF-8 script : - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - mkdir output - env SITEURL=\"farseerfc.me\" make publish Travis-CI 提供的虛擬機是比較標準的 Ubuntu 12.04 LTS ，打上了最新的補丁，並且根據你指定的 語言選項會把相應的解釋器和編譯器升級到最新版（或者指定的版本）。這裏用 python 語言的配置， 所以 python 是 2.7 的最新版並且有 pip 可以直接用。 配置中的 before_install 和 install 的區別其實不大，其中任何一個失敗的話算作 build errored 而不是 build fail ，而如果在 script 裏失敗的話算作 build fail 。 爲了編譯我的模板，還需要比較新的 less.js ，所以添加了 ppa 裝了個最新的 nodejs 並用它裝上了 less 。 還從源碼編譯安裝上了最新版的 opencc 1.0.2 ，因爲 Ubuntu 源裏的 opencc 的版本比較老(0.4)， 然後 doxygen 作爲 opencc 的編譯依賴也裝上了。 其它安裝的東西麼，除了 pelican 之外都是插件們需要的。以及我還需要生成 4 個語言的 locale 所以調用了 4 次 locale-gen 。由於是比較標準的 Ubuntu 環境，所以基本上編譯的步驟和在本地 Linux 環境中是一樣的，同樣的這套配置應該可以直接用於本地 Ubuntu 下編譯我的博客。 寫好 .travis.yml 之後把它 push 到 github ，然後 travis 這邊就會自動 clone 下來開始編譯。 travis 上能看到編譯的完整過程和輸出，一切正常的話編譯結束之後 build 的狀態就會變成 passing ，比如 我的這次的build 。 從 Travis-CI 推往 Github 上面的測試編譯通過了之後，下一步就是讓 travis-ci 編譯的結果自動推到 Github Pages 並發佈出來。要推往 Github 自然需要設置 Github 用戶的身份，在本地設置的時候是把 ssh key 添加到 github 賬戶就可以了，在編譯細節都通過 github repo 公開了的 travis 上 當然不能放推送用的私有 key ，所以我們需要另外一種方案傳遞密碼。 Github 上創建 Personal Access Token 好在 Github 支持通過 Personal Access Token 的方式驗證，這個和 App Token 一樣可以隨時吊銷，同時完全是個人創建的。另一方面 Travis-CI 支持加密一些私密數據，通過環境變量的方式傳遞給編譯腳本，避免公開密碼這樣的關鍵數據。 首先創建一個 Personal Access Token ，這裏需要勾選一些給這個 Token 的權限，我只給予了最小的 public_repo 權限，如側邊裏的圖。 生成之後會得到一長串 Token 的散列碼。 如果你不能使用 travis 命令 2015年2月21日更新 使用 travis encrypt 命令來加密重要數據最方便，不過如果有任何原因， 比如 ruby 版本太低或者安裝不方便之類的，那麼不用擔心，我們直接通過 travis api 也能加密數據。 第一步用這個命令得到你的repo的 pubkey ： curl -H \"Accept: application/vnd.travis-ci.2+json\" https://api.travis-ci.org/repos/<github-id/repo>/key | python2 -m json.tool | grep key | sed 's/.*\"key\": \"\\(.*\\)\"/\\1/' | xargs -0 echo -en | sed 's/ RSA//' > travis.pem 其中的 <github-id/repo> 替換成 github 上的 用戶名/repo名， 比如我的是 farseerfc/farseer 。travis api 獲得的結果是一個 json ，所以還用 python 的 json 模塊處理了一下，然後把其中包含 key 的行用 grep 提取出來，用 sed 匹配出 key 的字符串本身，然後 xargs -0 echo -en 解釋掉轉義字符，然後刪掉其中的 \"<空格>RSA\" 幾個字（否則 openssl 不能讀）， 最後保存在名爲 travis.pem 的文件裏。 有了 pubkey 之後用 openssl 加密我們需要加密的東西並用 base64 編碼： echo -n 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' | openssl rsautl -encrypt -pubin -inkey travis.pem | base64 -w0 替換了相應的身份信息和token之後，這行得到的結果就是 secure 裏要寫的加密過的內容。 然後我們需要 travis 命令來加密這個 token ， archlinux 用戶可以安裝 aur/​ruby-travis ，其它用戶可以用 gems 安裝： $ gem install travis 裝好之後，在設定了 Travis-CI 的 repo 的目錄中執行一下 travis status ， 命令會指導你登錄 Travis-CI 並驗證 repo 。正常的話會顯示最新的 build 狀態。 然後同樣在這個 repo 目錄下執行： $ travis encrypt 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' 當然上面一行裏的相應信息替換爲個人的信息，作爲這個命令的執行結果會得到另一長串散列碼， 把這串散列寫入剛纔的 .travis.yml 文件： env : - secure : \"long secure base64 string\" 有了這段聲明之後， Travis-CI 就會在每次編譯之前，設置上面加密的環境變量。 然後在編譯腳本中利用這些環境變量來生成博客： script : - git config --global user.email \"$GIT_EMAIL\" - git config --global user.name \"$GIT_NAME\" - git config --global push.default simple - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - git clone --depth 1 https://$GH_TOKEN@github.com/farseerfc/farseerfc.github.io output - env SITEURL=\"farseerfc.me\" make publish after_success : - cd output - git add -A . - git commit -m \"update from travis\" - git push --quiet 這裏要注意最後 git push 的時候一定要加上 --quiet ，因爲默認不加的時候會把 代入了 $GH_TOKEN 的 URL 顯示出來，從而上面的加密工作就前功盡棄了…… 根據 travis 的文檔 ， after_success 裏寫的步驟只有在 script 裏的全都完全無錯執行完之後纔會執行，這正是我們 push 的條件。目前 after_success 的成功與否不會影響到 build 的狀態。 具體我用的配置見 這裏的最新版 。 在我的 make github 中 調用了 git push 命令，從而執行了 make github 之後就會自動部署到 github 上。 用 Web 編輯並發佈靜態博客 經過以上設置之後，一切正常的話，每次對主 repo 推送更新的同時， Travis-CI 就會自動 拉來更新然後編譯並發佈了。可以放置這樣的圖標 在項目的 Readme.md 中顯示編譯狀態。 這樣設置之後的另一個好處就在於可以利用 Github 的 Web 界面編輯文章內容。在 Github 裏 編輯和保存之後會自動作爲一個 commit 提交，所以也會觸發 Travis-CI 的自動編譯。 在 Github 的 Web 界面中直接編輯文章內容 以及雖然目前還沒有好用的 Github 的手機客戶端，不過直接用 Android/iPhone 的瀏覽器登錄 github 並編輯文章的可用性也還不錯，所以同樣的方式也可以直接在手機上發佈博文了。 That is all, happy blogging ~","tags":"tech","url":"//farseerfc.me/travis-push-to-github-pages-blog.html"},{"title":"從天氣預報談談日本的學術氛圍","text":"最近 mazk 說我 life 分類裏的文章太少 ，所以想了想寫了這篇。 很多人問過我爲什麼要來日本留學，嘛原因之一是我英語太差了，相對而言日語比較好。 另一方面，我比較喜歡日本的學術氛圍。這個當然是主觀體會，而不是客觀的評價，只是我 覺得相對於 歐美喜歡研究基礎架構技術 ， 日本則偏向實用層面 。 說個具體一點例子，最近看到這篇新聞說 卢布贬值影响中央气象台预报准确率？ ，其中提到： 因为卢布贬值，天气预报的准确率会有所降低 也說道： 不过经我多年的观察，中国中央气象台的预报准确率实在是不怎么样，具体到我生活的地区， 实际天气状况和中国中央气象台预报的出入较大…… 相信不少人也有類似的體會。 天氣預報是事關人們生活的重要信息，其準確度對生產生活當然有很大影響。 說到增加天氣預報的準確度，人們自然會想到高性能的超級計算機比如 天河二號 ，想到環繞在地球高空的 氣象衛星 ，想到遍佈世界各地的氣象站觀測臺。想想這麼多耗資不菲的高尖端項目被國家投入， 用來改善天氣預報的準確程度，看起來這的確是一個困難的科研課題。 話說回來，準確預測氣溫、氣壓、溼度、降水概率等等這些事情對於生產生活固然重要， 不過對一般民衆而言，天氣預報最重要的作用就只是回答 明天我該穿多厚的衣服，出門是否需要打傘 這種問題。一年四季換衣服的時機其實並不那麼頻繁，氣溫提升五度或者降低兩度這種程度下人們估計也 不能感覺得到，大體上只要根據「昨天穿什麼衣服，昨天覺得冷不冷」就能作出判斷。另一方面， 出門是否需要打傘 這樣的問題的確只能依靠天氣預報來回答。 那麼解決 出門是否需要打傘 這個問題需要那麼高尖端的技術麼？ 我所在的大阪大學情報科學研究科有個已經畢業的學長 今城 健太郎 ( いまじょう けんたろう ) 就對此作出了解答。他的專業不是氣象預測，而是圖像分析處理，純粹的計算機科學學科。 而他的本科畢業設計就着眼於「僅僅分析氣象雲圖，能否高精度預測降水概率」， 其研究成果，就是一個叫 ないんたん 的降水概率預測系統 。 這個系統有數個會賣萌的Twitter機器人 @ninetan ，每時每刻對 其預測地區的降水情況做播報，同時也有詳細的降水概率曲線圖對 大阪 ( @ninetan_osaka )， 京都 ( @ninetan_kyoto )， 東京 ( @ninetan_tokyo )， 兵庫 ( @ninetan_hyogo )， 和歌山 ( @ninetan_wakayam ) 的各個大學所在校區 兩個半小時內做精確的降水概率預測。比如今天晚上大阪大學三個校區的降水概率圖如下： 今天晚上大阪大學三個校區的降水概率圖 從上面的圖可以看出這個系統的預測精度是以 分爲單位 的，可以看到 兩個半小時內各地的降水量的大小。比如我可以根據這張圖看出，我所在的吹田校區 將在 21時35分 開始有微弱的概率下起 0.1mm/h~1mm/h 的毛毛雨，到 22時05分 左右這個降水概率 爬升到最高大約45%，從而作出判斷： 我最好在晚上九點左右離開學校回家，避免淋雨。 自從研究室的前輩給我介紹這個天氣預報系統開始，我用了它兩三年了，直觀感覺是 這個系統的預測精度驚人得準確，基本上能接近 《魔法的禁書目錄》中的「樹形圖設計者」 能做的天氣預報的程度， 它說何時會下雨就一定下雨，它說何時雨停就一定雨停。同學們出門和回家的時候一般都會 看一眼這個天氣預報然後決定是否出門。「啊今天晚上9點開始下雨所以早點回家」 或者「啊還有30分鐘雨就停了，再在研究室裏留一會兒」。 這只是一個本科生的畢業設計，所以覆蓋面小（只有5所大學的十幾個校區，只能預測 未來兩個多小時的降水概率），不過僅此而已能做到如此的精度以至於實用，實在讓我 驚訝。系統的測試之初就有人說： 最近ないんたん予報あたりすぎてないんたんが雨降らせてるんじゃないかという疑惑 — すみのネコ歩き (@sumi_eee) 2011 7月 6日 最近ないんたん預告實在太準了，甚至讓人懷疑是不是ないんたん把雨招來的。 不過最近身邊的日本人似乎已經把這個系統的準確當作習以爲常了，就像日本的電車 掐着秒錶準點到站一樣，理所當然。 把天氣預報這種高尖端的技術做到如此實用的地步，這基本上可以代表我對 日本學術界研究方式和研究目的的總體印象了。 嗯今天就寫這麼多，9點到了，我要按照天氣預報的預測，準時回家了。 ——寫於2015羊年除夕夜，9點。","tags":"life","url":"//farseerfc.me/weather-forcast-academic-in-japan.html"},{"title":"archlinux 上用 chrome 實現 透明計算 遠程登錄","text":"透明計算 具體是什麼，因爲他們沒有公開技術細節所以我並不知道，只是看 公開出來的演示視頻 ，感覺似乎只要能從手機上遠程登錄系統桌面，就能算是透明計算了。 如果透明計算真是這個意思，那麼我似乎已經用着這個技術很多年了嘛。 Xorg 上常用的遠程桌面工具有很多，基於 VNC 協議的、基於NX的和基於 RDP 協議的都能找到， 直接 ssh X forwarding 效果也不錯。只是這些方案的一個 不太易用 的地方在於，需要 通過 ip 訪問到遠程的電腦，所以在跨越 NAT 之類的情況下不太容易使用。 於是今天介紹一個使用方便設置也簡單的方法： 通過 chrome-remote-desktop 在 archlinux 上使用遠程桌面。這個方案的優勢在於，藉助 Google 的雲端服務器（內部貌似是XMPP協議下的握手） 方便地實現了 NAT 穿透，無論什麼網絡環境基本都能使用。當然，要支持遠程登錄， 位於遠端的登錄的計算機必須一直開着 Chrome Remote Desktop 的後臺服務。 Chrome Remote Desktop 插件 Chrome Remote Desktop 的客戶端 雖然可能有很多人不知道，不過 Chrome 內包括遠程桌面的功能很久了。只是這個功能的界面默認 沒有提供界面，要使用它需要安裝 Google 官方出品的 remote-desktop 插件 。 裝好之後遠程桌面的客戶端就準備好，可以用來遠程訪問別的計算機桌面了（無論是 Windows/OS X 還是 Linux 都支持）。並且不光可以自己遠程訪問自己賬戶的桌面，還可以遠程協助朋友的桌面。 Archlinux 上設置遠程登錄的服務器 有了客戶端之後還要設置一下纔能讓桌面作爲遠程登錄的服務器。Windows 和 OS X 上 Chrome 會自動下載需要的安裝包，無腦下一步就能裝好了。Linux上由於發行版衆多，桌面配置各異， 所以需要一點手動配置。官方的設置步驟記載在 這裏 其中給出了 debian 用的二進制包和 Ubuntu 12.10 上的設置方式，以下設置是參考官方步驟。 首先要安裝 chrome-remote-desktop 這個包，這個包實際上對應了 Windows/OS X 上用安裝程序 安裝的 Remote Desktop Host Controller。 archlinux 上開啓了 [archlinuxcn] 倉庫的話，可以直接安裝打好的包。或者可以從 AUR 裝。 $ pacman -Ss chrome-remote-desktop archlinuxcn/ chrome-remote-desktop 40.0.2214.44-1 Allows you to securely access your computer over the Internet through Chrome. 裝好之後從會說這麼一段話： groupadd：无效的组 ID \"chrome-remote-desktop\" Please create ~/.config/chrome-remote-desktop folder manually, if it doesn't exist, or else you can't use CRD. The needed files are created by the Chrome app, inside the chrome-remote-desktop folder, after Enabling Remote Connections. To {enable,start} the service use systemctl --user {enable,start} chrome-remote-desktop You may need to create a ~/.chrome-remote-desktop-session file with commands to start your session Go to https://support.google.com/chrome/answer/1649523 for more information. 那句報錯是 AUR 裏打的包還沒跟上上游 Google 的更改導致的錯誤， 首先我們需要把遠程登錄的用戶添加入 chrome-remote-desktop 這個用戶組裏。 新版本的 chrome remote desktop 提供了一個命令做這個事情，所以執行以下命令就可以了： $ /opt/google/chrome-remote-desktop/chrome-remote-desktop --add-user 然後我們需要手動創建 ~/​.config/​chrome-remote-desktop 這個文件夾，內容是空的 就好了，隨後 chrome 會往這裏面放 host#.json 文件用於身份驗證。 $ mkdir ~/.config/chrome-remote-desktop 然後我們要創建一個 shell 腳本 ~/​.chrome-remote-desktop-session ，這是遠程 登錄時的 .xinitrc ，內容麼就是啓動你想在遠程登錄時用的桌面環境。 這裏可以指定一個和你正在登錄的 WM/DE 不同的桌面，比如我啓動 xfce4： $ cat ~/.chrome-remote-desktop-session # !/bin/bash startxfce4 $ chmod 755 .chrome-remote-desktop-session 接下來需要從 Chrome 的插件裏啓用遠程桌面。打開 Chrome 的 Remote Desktop 插件，這時 應該可以看到一個「啓用遠程鏈接」的按鈕。 Chrome Remote Desktop 插件中「啓用遠程鏈接」的按鈕 在撰寫本文的時候， Archlinux 官方源裏的 chromium 的版本和 aur/google-chrome 的版本尚且還是 40.0.2214.111 ，而 Chrome Web Store 中提供的 Chrome Remote Desktop 的插件的版本是 41.0.2272.41 。雖然通常並不要求兩者版本一致，不過貌似最近 Chrome 內部的 Remoting 功能更改了 API 導致可能出問題。如果你找不到 「啓用遠程鏈接」的按鈕，請嘗試一下新版本的 Chrome 比如 google-chrome-dev 。 在這一步啓用之後，老版本的 chrome 應該也就能使用遠程桌面了。 在32位的 Linux 版本上，最近更新的 Chrome Remote Desktop 插件可能無法正確識別 Host 的版本，具體 參考這個 bug 。 點擊「啓用遠程鏈接」，設定一個 PIN 密碼（不需要很複雜，這裏首先有 Google 帳號驗證保證只有 你纔能訪問），然後就能看到這套電腦的 hostname 出現在「我的電腦」列表裏。 啓用遠程鏈接之後的樣子 同時，啓用了遠程鏈接之後，可以在剛剛創建的 ~/.config/chrome-remote-desktop 文件夾中找到記錄了驗證信息的文件。 $ ls .config/chrome-remote-desktop chrome-profile host#8cfe7ecfd6bb17955c1ea22f77d0d800.json pulseaudio#8cfe7ecfd6 然後就可以啓動對應的 systemd 用戶服務了，如果想自動啓動服務要記得 systemctl --user enable ： $ systemctl --user start chrome-remote-desktop.service 如果上面的設置一切正常，就可以看到 chrome-remote-desktop 啓動了另外一個 Xorg 執行你 剛剛指定的桌面環境： htop 中看到的 chrome-remote-desktop 啓動的另外一個 Xorg 然後就可以試着通過 Remote Desktop 插件登錄到這個新開的 Xorg 了： 「遠程」登錄到新的 XFCE4 Linux 版本的 Chrome遠程桌面 和 Windows/ OS X 上的區別 通過上面的設置步驟也可以看出，Linux版本的遠程桌面會在後臺開一個獨立的 X 會話，而不能 復用現在已有的 X 會話。對遠程登錄的用法而言這還能接受，對遠程協助的功能而言有點問題， 因爲正在使用的人不能觀察協助者做了什麼，協助者也不能繼續請求協助的人的操作。 當然目前 Chrome 遠程桌面的 Linux Host Controller 還只是 beta 版本，官方只測試支持 Ubuntu 12.04 和 12.10 （14.04之後似乎有 Bug ），所以不能要求太多。希望以後能改善吧。 Bonus： 手機遠程登錄 手機上的 Chrome 遠程桌面 App 通過上面的設置就可以從任何一個 Chrome 遠程桌面客戶端登錄剛剛設置的這臺電腦了。 因爲 Chrome 在三大桌面系統 Windows / OS X / Linux 上都有，所以應該能覆蓋大多數桌面 系統了。 除了桌面的 Chrome 之外還有一個客戶端是 Android 上的 Chrome 遠程桌面 App 經過上面的設置之後，從這個 App 也能看到並登錄： 手機遠程登錄 好啦，開始享受國家自然科學一等獎的透明計算技術吧！","tags":"tech","url":"//farseerfc.me/arch-chrome-remote-desktop.html"},{"title":"換到 farseerfc.me 域名","text":"上個月就在 狗爹 ( godaddy ) 上買了個自己的域名 farseerfc.me 準備用在這個 博客上，當時試着轉到過這個域名，發現 自定義域名 ( custom domain ) 只支持 http 不支持 https ，想着還要買自己的證書，於是就扔在了一旁。不用自定義域名的話， 放在 github.io 上是可以用 HTTPS 的。 今天在 #archlinux-cn 上受大牛 quininer 和 lilydjwg 點播， 發現 cloudflare 有提供 免費的支持 SSL 的 CDN 服務 趕快去申請了一個，感覺非常讚，於是就換過來了。 設置的方法按照 這篇博文 說的一步步做下來，如它所述，用 CloudFlare 的優點如下： CDN 加速 SSL (HTTPS) 加密 支持 SPDY 協議 支持 IPv6 2015年12月29日更新 現在不光支持 SPDY 而且支持 HTTP/2 了。 然後 免費賬戶 的一些缺點有： CloudFlare 和 github.io 之間的數據不是加密的，因爲 github 自定義域名 ( custom domain ) 還不支持使用自己的證書。這也是一開始我沒用 自定義域名的原因嘛，這沒有辦法…… CloudFlare 給免費賬戶簽名的 SSL 證書比較新，不支持一些老的設備和瀏覽器，比如不支持 老的 XP 系統的 IE 或者 2.x 的 Android。這種情況下沒辦法只能用沒有加密的 HTTP 了。 不支持 HSTS 頭 ，所以不能從服務器這邊強制瀏覽器用 HTTPS。當然可以放個 javascript 跳轉， 也可以用 HTTPSEverywhere 這種方案。 2015年12月29日更新 如評論中 提到的 現在支持 HSTS 了。 設置步驟 基本按照默認的選項下一步就可以了。 和那個博主一樣我把 安全級別 ( Security profile ) 降到了 Low ，即使是可疑流量也 不會要求輸入 CAPTCHA 。 把 SSL 方式開在 Flexible SSL，訪客到 CloudFlare 是加密的，而 CloudFlare 到 github.io 是不加密的。 把 CDN 開到了 CDT+Full Optimization ，可以對訪問加速。由於是完全靜態的博客，沒有 動態變化的內容，所以應該比較安全。 服務器設置的一步需要將 域名解析服務器 ( DNS nameservers ) 從狗爹的服務器改到 CloudFlare 的，如下圖： 更改狗爹的域名服務器 申請好之後就由 CloudFlare 接管域名解析了，接下來在 CloudFlare 的 DNS 設置添加一條 A 類規則指向 github pages 的 IP 。 更改CloudFlare的DNS規則 等一切都反映到 DNS 服務器上就設置完成了，接下來給 farseerfc.github.io push 一個 CNAME 文件 寫上我的域名就可以了。我用 Makefile 配合我的 pelican 配置做這個： publish : rmdrafts cc clean theme [ ! -d $( OUTPUTDIR ) ] || find $( OUTPUTDIR ) -mindepth 1 -not -wholename \"*/.git*\" -delete rm -rf cache echo $( SITEURL ) > content/static/CNAME $( PELICAN ) $( INPUTDIR ) -o $( OUTPUTDIR ) -s $( PUBLISHCONF ) $( PELICANOPTS ) $( MAKE ) rsthtml github : ( cd $( OUTPUTDIR ) && git checkout master ) env SITEURL = \"farseerfc.me\" $( MAKE ) publish ( cd $( OUTPUTDIR ) && git add . && git commit -m \"update\" && git push ) SITEURL = '//' + getenv ( \"SITEURL\" , default = 'localhost:8000' ) STATIC_PATHS = [ 'static' , 'images' , 'uml' , 'images/favicon.ico' , 'static/CNAME' ] EXTRA_PATH_METADATA = { 'images/favicon.ico' : { 'path' : 'favicon.ico' }, 'static/CNAME' : { 'path' : 'CNAME' } } 然後把生成的靜態網站 push 到 github 之後可以從項目設置裏看到域名的變化： Github 配置好自定義域名之後的變化 最後把Disqus的評論也遷移到新的域名，disqus有方便的遷移嚮導，一直下一步就可以了。 這樣就一切都設置妥當了。 致謝 最後要感謝提供消息的 quininer 和 lilydjwg ，感謝撰寫設置步驟的 Jonathan J Hunt ， 感謝 CloudFlare 提供免費 SSL CDN 服務，感謝 Github 提供 方便免費的 Pages 託管。","tags":"tech","url":"//farseerfc.me/switch-to-farseerfc-dot-me-domain.html"},{"title":"重新設計了 Pelican 的主題與插件","text":"2015年2月14日更新 前言: 新天新地，將一切都更新了 [1] 不知不覺間放任這邊長草很久了，從上次 折騰主題 到現在都快三年了， 而從上次 寫了篇告白信 到現在也有快兩年了。 這期間曾經把主題配色從 Bootstrap 2 默認的 白底黑字改成了讓眼睛更舒適的黑底白字，也不過是用 drop-in 的配色方案而已，沒有本質上的改進。 洞中一日世上千載，兩年裏 Bootstrap 已經升上 v3.3 , 而 Pelican 則已經升到 3.5 了。 早就眼饞 Bootstrap 和 Pelican 中的諸多新功能新設計，不過無奈於時間有限只能飽飽眼福。 近日想寫的東西越積越多，終於下定決心花了前前後後 兩個月 的時間重新設計了一遍 Pelican 的主題，配合一些我覺得有用的插件。於是本博客就變成你們現在看到的樣子了。 （以及本篇博文也用了兩個月的時間寫完，其間還發了幾篇別的短文，算是恢復寫博客的嘗試吧。） 在邁阿密參加 ICSR 2015 的時候 拍到的街邊一家叫 Pelican 的旅館 Bootstrap 3 的新設計 全新的 優先移動設備 ( mobile-first ) 響應式 ( responsive ) 設計。 原本Bootstrap 2雖然有響應式設計， 不過諸多細節不能符合我的需求，最終還是得手工 hack @media 查詢去微調。 現在的 優先移動設備 ( mobile-first ) 響應式 ( responsive ) 柵格系統 ( grid system ) 則相對顯得科學很多了，也終於能在手持 設備上看起來舒服一些。諸位可以嘗試改變窗口寬度，或者在不同的手持設備上打開這個 blog ，體驗一下這個頁面在不同顯示器大小中的效果。如果仍有問題歡迎 發 Issue 給我 。 科學的 導航欄 ( Navbar ) 。 比 Bootstrap 2 那個科學很多了。無論是 保持 ( sticky ) 在上端還是跟着浮動， 或者像這邊這樣 自動隱藏 都很簡單。 更多細節參考 Bootstrap 3 主頁 。 Pelican 3.5 的新功能 Python 2 和 Python 3 統一代碼： 再沒有惱人的 unicode 相關的問題了。這對 blog 系統來說相當重要啊。 而且還能方便切換 pypy 等不同的解釋器。 全新的插件系統：非常多功能強大的 插件 等着你。 增強了導入系統：嗯總算可以導入我的中文的 wordpress 博客了。（雖然那邊長草更久了……） 站內鏈接 ：不用 硬編碼 ( hard code ) 目標頁面的鏈接了，可以直接寫源文件的位置然後讓 pelican 處理，這樣能簡化各種 插件 ( plugin ) 和 主題 ( theme ) 的實現。 更多細節參考 Pelican 文檔 。 新的文件夾佈局 Pelican 的新文件夾佈局 . ├── cache 生成頁面的 pickle 緩存 ├── content 讀取的全部內容 │ ├── <categories> 按分類存放的文章 │ ├── pages 像 About 這樣的固定頁面 │ └── static 文章內用到的靜態內容 ├── drafts 文章的草稿箱 ├── Makefile 生成用的 makefile ├── pelicanconf.py 測試時用的快速 Pelican 配置 ├── publishconf.py 部署時用的耗時 Pelican 配置 ├── output -> ../farseerfc.github.io ├── plugins -> ../pelican-plugins └── theme -> ../pelican-bootstrap3 之前的博客 仍然留在 github 上，其中的內容完全搬過來了。開始寫老博客的時候 Pelican 版本較早，沒有形成好的 文件夾佈局，導致生成的文章、使用的模板和撰寫的內容全都混在一起，非常難以管理， 於是趁改版之際用了新的文件夾佈局方式，並分爲 4 個 git repo 分別管理歷史。 首先是存放 總的博客內容的 repo ， 其佈局是如圖那樣的。這樣將生成的靜態網站和生成網站用的配置啦內容啦分開之後，頓時清晰了很多。 然後這個內容 repo 中的三個符號鏈接分別指向三個子 repo（沒用 git submodule 管理純粹是因爲偷懶）。 theme 指向 pelican-bootstrap3 ，是我修改過的 pelican 主題。 plugins 指向 pelican-plugins ，由於 plugins 的質量有些參差不齊，其中不少 plugin 都按我的需要做了些許修改，一些是功能改進，另一些則是修bug（比如不少plugin只支持 python 2）。 最後 output 指向 farseerfc.github.io 也就是發佈的靜態網站啦。 接下來從 主題 和 插件 兩個方面介紹一下改版的細節。 主題： Material Design 風格的 Bootstrap 3 上篇 博文 就總結了我爲了這個博客尋找了一堆 CSS 框架，並且最終決定用 bootstrap-material-design , DandyDev/pelican-bootstrap3 和 Bootstrap 3 這三個項目結合的方式實現這個模板的主題。 這三個項目都或多或少經過了我的修改，修改後的項目以 pelican-bootstrap3 爲基礎放在 這裏 ，包括 Bootstrap3 樣式 和 Material 樣式 。 對 Bootstrap 3 的定製 由於架構完善，修改 Bootstrap 3 感覺非常簡單。另一方面我在 Web 前端技術上的技能點也不多， 所以修改的地方非常有限，只能按我自己的需求定製而已。 響應式設備的大小 修改了 Bootstrap 3 響應式設備的大小 @ screen-xs : 320px ; @ screen-sm : 598px ; /* 768px; */ @ screen-md : 952px ; /* 992px; */ @ screen-lg : 1350px ; /* 1200px; */ @ screen-xl : 2030px ; @ container-sm : 582px ; /* 750px; */ @ container-md : 930px ; /* 970px; */ @ container-lg : 1320px ; /* 1170px; */ @ container-xl : 1990px ; 首先把 Bootstrap 3 默認適配的幾個 響應式設備的大小 改成了我需要的大小。 xs 和 sm 的大小分別按照我的手機屏幕 豎屏 和 橫屏 時候的瀏覽器頁面寬度來算， md 是想兼容 Nexus 7 橫屏 960 的寬度以及 一個常見上網本 1024 的寬度。 lg 的大小則按照常見的筆記本 1366 寬的屏幕來適配。 這裏 Bootstrap 3 支持的設備大小的一個問題是，它最多考慮到 1200 像素寬的顯示器，而更寬的 比如 1600、 2048 甚至 2560 像素寬的顯示器現在也並不少見，其結果就是頁面中左右兩側 有很大的空間被浪費掉了。作爲深受這一問題困擾的用戶之一，我用 這裏介紹的方法 給 bootstrap 增加了一類「 比大更大 ( bigger than bigger ) 」的 xl 響應式設備尺寸，寬度設爲支持 2048 像素寬的顯示器，具體的修改反映在 variables.less 文件裏。 根據寬度自動分欄和瀑布式佈局 接下來目標是讓主頁的文章列表像 Google+ 主頁那樣根據顯示器寬度自動調整分欄，使得寬度不同的 顯示器上每個分欄的寬度接近。想要達到的效果是，根據上面定義的屏幕寬度尺寸： xs 用單欄 流動 ( fluid ) 佈局 sm 用上方單欄文章列表、下方雙欄 側邊欄 ( sidebar ) 固定佈局 md 用單欄文章列表、單欄 側邊欄 固定佈局 導航欄 ( Navbar ) 文章 側邊欄 底欄 導航欄 文章 側邊欄 1 側邊欄 2 底欄 ( footer ) 導航欄 文章 1 側邊欄 1 文章 2 側邊欄 2 底欄 ( footer ) lg 用雙欄文章列表、單欄 側邊欄 固定佈局 xl 用三欄文章列表、雙欄 側邊欄 固定佈局 導航欄 文章 1 文章 3 側邊欄 1 文章 2 文章 4 側邊欄 2 底欄 ( footer ) 導航欄 文章 1 文章 3 文章 5 側邊欄 1 文章 2 文章 4 文章 6 側邊欄 2 底欄 ( footer ) 一開始純粹用 Bootstrap3 的響應式柵格實現這個分欄佈局，結果發現效果不太理想， 因爲文章列表和側邊欄的高度是變化的，會導致柵格間留下大片空白。後來改用 這裏示範的純CSS瀑布式佈局 實現文章和側邊欄的佈局，具體的實現代碼在 waterfall.less ，總算達到了想要的佈局了。 正文的樣式 最最重要的是文章正文的樣式。這裏我想要達到的效果是，在大屏幕上用更大的字號，讓讀者 看起來更舒適，同時在小屏幕上用比較小的字號，最終保證基本上「一行」的文字數接近。這個修改 主要針對 .jumbotron ， 用了 不太科學的方式 代碼太長就不貼全了。 一些細微的定製 把主題配色改成了現在這樣的淡紫色 @brand-primary: darken(#6B5594, 6.5%); ，配合我的頭像風格， 這個修改只需要一行。 接着刪掉了 .btn 的 white-space: nowrap; 讓按鈕的文字可以換行， 這也只是一行修改。 2015年1月29日更新 另外我也不太喜歡 Bootstrap 3 默認在手機上的 摺疊導航欄 ( collapsed navbar ) ， 摺疊之後的操作不夠直觀方便而且依賴 javascript 所以有 bug …… 於是我把它關掉了， 具體方式是在 variables.less 把 @grid-float-breakpoint 和 @grid-float-breakpoint-max 都設爲0就可以了。 對 bootstrap-material-design 的定製 這裏定製的地方不多。原樣式中一個不太科學的做法是所有 .btn 都強制加上了陰影 效果，這在已經有陰影的環境裏用的話非常礙眼，像是 Win9x 風格的厚重睫毛膏。既然可以單獨 給每個樣式加陰影，於是就把 .btn 強制的陰影去掉了，只保留鼠標懸停之後強調的陰影。 其它定製的細節麼就是統一配色風格，修補漏洞錯誤，微調響應式效果而已，這裏不細說。 將以上兩者整合在 pelican-bootstrap3 裏 Pelican 實現顯示源代碼按鈕 顯示源代碼按鈕借用了 Pelican 配置中自帶的 OUTPUT_SOURCES 選項將源文件複製到輸出文件夾： OUTPUT_SOURCES = True OUTPUT_SOURCES_EXTENSION = '.rst' 然後在 Makefile 裏用 pygmentize 把所有源代碼文件着色： find -iname \"*.rst\" | parallel -I@ pygmentize -f html -o @.html @ 最後在按鈕按下的時候用 jQuery 載入源代碼： < a onclick = \"$.get('{{SITEURL}}/{{article.slug}}.rst.html', function(data){$('#source-code').html(data)});$('#article-content').toggle();$('#source-content').toggle();\" > 雖然難看的 hack 比較多，但是能用！ 雖說 pelican-bootstrap3 是我 fork 出來的，不過由於我修改的地方實在太多，代碼看來基本上 接近重寫了一份。好在之前有給 pelican 寫 bootstrap 2 主題的經驗，這次修改算得上駕輕就熟。 可以對比一下 上游作者的博客 和這裏的樣子體會一下感覺。 具體修改過的地方包括： 套用 bootstrap-material-design 的各個元素樣式。 在文章列表模板應用上面提到的 Bootstrap 3 的柵格佈局和瀑布式佈局。 翻譯到多個語言，這裏在後面的 i18n-subsite 插件裏詳述。 套用後面會介紹到的各種插件。 統一側邊欄的樣式到一個模板裏。 添加 Atom 訂閱按鈕和 breadcrumb 條。 對正文中出現的插圖，添加點擊放大的功能，通過 Bootstrap 的 modal 實現。 上面提到的用 這個bootstrap插件 讓導航欄自動隱藏。 顯示源代碼按鈕 ，也就是每篇文章信息欄中的 按鈕。 插件: 發揮 Pelican 和 reStructuredText 的優勢 先列舉一下我目前用到的所有插件： PLUGINS = [ \"i18n_subsites\" , \"plantuml\" , \"youku\" , \"youtube\" , 'tipue_search' , 'neighbors' , 'series' , 'bootstrapify' , 'twitter_bootstrap_rst_directives' , \"render_math\" , 'extract_toc' , 'summary' ] 嗯其實不算多。接下來逐一介紹一下這些各具特色的插件。 i18n-subsites 這個插件的目的是創建 國際化 ( internationalization ) 子站 ( subsite ) 。 之前介紹 Pelican 配置的時候就提到過， 原本的 Pelican 就支持一篇文章用多種語言書寫，有 lang 屬性註明這篇文章使用的 語言，以及 slug 屬性註明多語言的翻譯之間的關聯，換句話說同一篇文章的多個語言 版本應該有相同的 slug 和不同的 lang 。然後原本 Pelican 裏對多語言的 實現方式是，首先有一個 主語言 是模板和大部分文章採用的語言，文章列表中會優先列出 用 主語言 撰寫的文章，然後從 主語言 的文章鏈接到別的翻譯版本。 很多博客系統和CMS對多語言的支持都是這樣的，這種處理方式的缺點也顯而易見：作爲 主語言 的語言必須足夠通用，纔能讓進來的人找到合適的翻譯版本，所以通常 主語言 都是英語。 而這個插件做的事情描述起來很簡單：將文章按語言屬性分到多個子站，每個子站獨立放在各自的文件夾。 比如主站是 https://farseerfc.github.io/ 的話，那麼英語的子站就可以是 https://farseerfc.github.io/en/ 。 然後分別對多個子站生成靜態頁面。具體的實現方式是對 pelican 的頁面生成步驟做了拆分： pelican 按正常情況讀入文章，生成元信息。 i18n-subsites 針對每個語言，覆蓋掉 pelican 的一些選項設置比如路徑和 URL ， 分別調用 pelican 的頁面生成器按模板生成文章。 對共用的靜態內容比如模板的 js 和 css 文件，只在主站中生成，子站中的相應鏈接全部鏈回主站。 雖然描述起來簡單，但是這個插件可以說最大化利用了 Pelican 的插件系統，實現細節相對比較 複雜，大概是我用的這些插件裏面最複雜的了。不誇張的說 Pelican 3.4 支持的新插件 API 和 站內鏈接功能基本上就是爲了配合這個插件的。至於具體它會覆蓋哪些 Pelican 的配置，請參閱它的 README.md文件 。 按內容拆分多語言子站的做法只解決了問題的一半，還留下另一半的問題，也即對模板的翻譯。 對這個問題， i18n-subsites 提供了兩套方案供選擇： 用覆蓋配置路徑的方式讓每個子站套用不同的模板。這配置起來簡單，但是對模板維護起來有點困難。 用 jinja2 的 i18n 插件，配合 Python 的 gettext 庫實現內容翻譯。這個方案 配置起來比較複雜 ，但是配置好之後用起來就很方便了。 只是要記得每次修改了模板都要更新翻譯，處理 *.po 和 *.mo 文件等等瑣碎事宜。 這裏我用 jinja2 的 i18n 插件的方式實現了模板的翻譯， 各個語言的翻譯在這裏 ， 然後用 這裏的 SCons 腳本 根據內容是否變化自動更新 po 和 mo 文件。 配置好這一套方案之後，還要注意在模板和文章中處理好鏈接。用 Pelican 3.4 之後推薦的 新的文章間鏈接的寫法以及將 SITEURL 設置爲實際 URL 並且關閉 RELATIVE_URLS 之後，應該就不會出沒什麼問題了（可能還要考慮使用的模板和插件的兼容性，大部分都是寫死了 URL 的問題）。 plantuml 嵌入 PlantUML 的示例 PlantUML 是一個Java實現的， 用接近文字描述的語言繪製 UML 圖或者 GUI 界面圖的工具，非常適合嵌入在 Markdown、 reStructuredText、 AsciiDoc 等這種輕量級標記語言裏。 然後麼這個 plantuml 插件就是定義了一個新的 reStructuredText 指示符 ( directive ) .. uml:: ，把嵌入的內容提取出來調用 plantuml 命令處理 成圖像然後再插入到文章中。 比如示例裏的這個 UML 圖就是用這樣一段簡單的文字描述生成的： .. uml :: Object <|-- ArrayList Object : equals() ArrayList : Object[] elementData ArrayList : size() 實際用起來這個插件實現上稍微有點小問題：首先它只支持 python2，所以我把它改寫成了 python 2 和 3 都通用的語法；其次它原本輸出的文件夾似乎會被 pelican 刪掉，所以把它改了個位置； 然後它輸出的 URL 也和 i18n-subsites 插件間有不兼容的問題，也順帶修掉了。 修改之後的代碼在這裏 。 2015年1月30日更新 嵌入 Ditaa 的示例 plantuml 是繪製UML的，除此之外還有一個類似的工具是繪製一般的 流程圖 ( diagram ) 的，叫 ditaa ，和 plantuml 非常像，也比較像 reStructuredText 的表格。 於是我也照貓畫虎實現了一個 ditaa 的 指示符 ( directive ) ，用起來類似這樣： .. ditaa :: +-------------+ | ditaa |-------+ | Diagram | | +-------------+ | PNG out &#94; | | ditaa in | | v +--------+ +--------+----+ /----------------\\ | | --+ Pelican +--> | | | Text | +-------------+ | Beautiful Blog | |Document| | !magic! | | | | {d}| | | | | +---+----+ +-------------+ \\----------------/ : &#94; | Lots of work | +-----------------------------------+ render-math 嵌入公式的示例 示範行內公式 \\(A_\\text{c} = (\\pi/4) d&#94;2\\) . 整行公式 \\begin{equation*} \\alpha{}_t(i) = P(O_1, O_2, \\ldots O_t, q_t = S_i \\lambda{}) \\end{equation*} 這個插件提供在 reStructuredText 中用 LaTeX 語法插入數學公式的能力，定義了 :math: 行內角色 ( role ) 和 .. math:: 指示符 ( directive ) 。 實際工作的渲染庫當然是大名鼎鼎的 MathJax ，這個插件 會用 MathJax 的 CDN 載入，所以也沒有額外的依賴文件。（只是不知道是否會被國內牆掉， 如果公式顯示不正常請 務必 告訴我。） youtube 和 youku 顧名思義，這兩個插件分別實現嵌入 youtube 和 youku 視頻。其中 youtube 是原本就有的插件， youku 是我照貓畫虎抄的。 之前寫了一篇 KDE5 Plasma 之跳動賣萌的活動按鈕 用到了這兩個插件。 tipue_search Tipue search 是一個非常有意思也很強大的搜索工具， 通過 jQuery 實現靜態博客的站內搜索功能。實現方式是，它需要你寫一個 json 文件，包含 整個網站的 全部 文章的標題和文字內容，然後在搜索的時候讀入這個 json 做搜索（是不是有點耍賴）。 雖然聽起來會有性能問題，但是應用在小型的靜態博客上效果意外很不錯，比如本站的所有文章內容 放在一起的 json 也只有 300KiB 左右。 這個插件就是自動在 pelican 輸出完全部靜態網頁之後，調用 beautifulsoup4 從所有網頁中抽取出 純文本，產生這個 json 給 Tipue 用。 neighbors 和 series 這兩個插件比較類似也都比較簡單， neighbors 提供一篇文章的前後文章信息， 在主題模板裏可以用來製作 上一篇 和 下一篇 按鈕。 series 提供將多篇文章歸類爲一個 系列 的支持，當然也需要在 主題模板中定義顯示「文章系列」的列表。這兩個插件的效果都能在本文末尾，評論區上方的部分看到。 bootstrapify 和 twitter_bootstrap_rst_directives 這兩個插件讓文章的 正文 套用上 Bootstrap 的樣式。 bootstrapify 這個插件實現得比較簡單，用 beautifulsoup4 在靜態網頁的結果裏面過濾元素， 對 table , img , embed , iframe , video , object 這幾個標籤套用上 響應式嵌入對象的類 讓他們更美觀。 twitter_bootstrap_rst_directives 這個插件則是增加了幾個 reStructuredText 的 行內角色 ( role ) 和 指示符 ( directive ) 。 它實現的 行內角色 ( role ) 包括： 用 :kbd: 實現如 Ctrl+C 這樣的鍵盤快捷鍵， 用 :code: 嵌入代碼片段，用 :glyph: 嵌入字符圖標。 它實現的 指示符 ( directive ) 包括： labels 行內標籤 ， alerts 提示段落 ， panels 嵌入面板 ， 以及還有一個 media 混排圖標 。 對其中的 panel 我改寫了它在文章正文中的樣式，在 lg 或者 xl 的屏幕寬度下，分別用 \\(\\frac{1}{2}\\) 和 \\(\\frac{1}{3}\\) 大小的嵌入面板， 簡單實現和正文文字的圖文混排。 除此以外我還在 twitter_bootstrap_rst_directives 這個插件裏套用它的框架實現了兩個額外 的 行內角色 ( role ) ， 分別是 :ruby: ：通過 html5 的 <ruby> 標籤實現文字上方的注音（firefox下 不支持 ，會使用文字後的括號顯示）， 以及 :html: ：在 行內插入 裸 ( raw ) html 標籤（這屬於 Markdown 的基本功能，在 reStructuredText 這邊由於要考慮多種輸出格式於是就比較麻煩了）。這兩個 行內角色 ( role ) 的 實現代碼在這裏 。 2015年2月3日更新 今天又在 twitter_bootstrap_rst_directives 裏增加了兩個 行內角色 ( role ) 。 一個是 :twi: 用來寫 twitter 用戶的鏈接，比如 @farseerfc ，另一個是 :irc: 用來指向 freenode 的 channel ，比如 #yssyd3 。 2015年2月14日更新 今天增加了 .. friend:: 用來寫好友鏈接，以及 fref 用來引用好友， 比如 LQYMGT 這樣。 extract_toc 和 summary 最後是這兩個有點「名不副實」的插件。 reStructuredText 原本就有自動生成 目錄 ( toc ) 的功能，用起來也非常簡單，只需要在想要插入目錄的地方寫一行 .. contents:: ，剩下的都由 docutils 自動生成了。 只是當然這樣生成的目錄肯定會插入在文章的正文裏，而 extract_toc 這個插件的作用就是簡單地 把這個目錄抽取出來，讓模板能在別的地方放置這個目錄。比如我這裏就把目錄放在了一個 panel 裏。 然後 Pelican 也原本就有從文章中抽取 總結 ( summary ) 顯示在文章列表的功能。 Pelican 原始的實現似乎是按照文字數抽取前半段，不總是適合作爲總結。 於是這個 summary 插件的作用其實是允許在正文中以特殊的註釋的方式標註哪些部分應該被抽出來作爲總結。 summary 這個插件原本的實現只允許抽取一段文字，我又對它的實現做了少許擴充，允許標註多段 文字合併起來作爲總結。 2015年1月29日更新 今天在 extract_toc 插件的幫助下，在側邊欄裏放了一個 Bootstrap affix 的目錄， 它保持在頁面的右側位置不變，方便導航到文章的各個地方。具體實現方法除了 Bootstrap 3 的 Affix 文檔 ，還參考了 這篇更詳細的說明 。 結語 這個博客的配置都可以在 github 上找到 ，包括用來 自動生成整個博客的 Makefile ，由於比較長，這裏就不再貼了。 折騰這個主題前後歷時兩個月，期間學會了不少東西，也算是不錯的收穫吧。 現在既然基礎打好了，接下來就要開始多寫博客了。（希望拖延症不會再犯……） 最近發現除了我的博客之外還有一個網站 Kansas Linux Fest fork 了我的主題，不過他們用了我修改的早期版本，還是原本的 Bootstrap 3 和 bootstrap-material-design 樣式。自己草草修改的東西被別人用到果然還是有點小激動呢， 以及接下來不能馬馬虎虎地寫 commit 消息了。 [1] 賽65:17「看哪！我造新天新地」啟21:5「我將一切都更新了。」 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"//farseerfc.me/redesign-pelican-theme.html"},{"title":"總結一下 Material Design 的 CSS 框架","text":"現在這裏的界面風格要從 Google 在 I/O 2014 大會 上公佈Android L 也即 後來的 Lollipop 說起。 他們在談論界面設計的時候公佈了他們的 設計準則： Material Design ( 中文非官方翻譯 )。 當然這只是一些準則，總結並描述了之前在 Web 設計和移動端 App 界面設計方面的一些規範， 並且用材料的類比來形象化的比喻這個準則。關於 Material Design 的更多中文資料可 參考這裏 。 看到 Material Design 之後就覺得這個設計風格非常符合直覺，於是想在這邊也用上 Material Design。 但是我在 Web 前端科技樹上沒點多少技能點，所以想找找別人實現好的模板 或者框架直接套用上。在網絡上搜索數日找到了這幾個： Polymer Paper Elements Polymer Polymer logo Google 官方提供的參考實現應該是 Polymer 中的 Paper Elements 。 由於是 官方參考實現 ，這個框架的確非常忠實地實現了 Material Design 的設計，但是同時 由於它基於 HTML5 Web Components 構建，相關技術我還 不太懂，瀏覽器兼容性和其餘 HTML 技術的兼容性也還不太完善的樣子…… 並且對於我這個 Web 開發的半吊子來說，Polymer 只是提供了一組設計組建，沒有完善的 響應式 (responsive) 佈局支持，也沒有 Navbar 這種常見的框架組建，真的要用起來的話還 需要手工實現不少東西。於是口水了半天之後只好放棄……以後可能真的會換用這個，只是目前需要學 的東西太多了。 Angular Material Design AngularJS AngularJS 是 Google 對 Web Components 技術的另一個 嘗試。而這額 Angular Material Design 項目 就是基於 AngularJS 構建的Material Design 庫啦，同樣是 Google 出品所以應該算得上半個 官方實現吧。 相比於 Polymer, AngularJS 算是實用了很多，提供了基於 CSS Flexbox 的佈局。有人對這兩者的評價是， 如果說 Polymer 代表了 未來趨勢 ，那麼 AngularJS 就是 眼下可用 的 Web Components 實現了。 只不過同樣是因爲它是 Components 的框架，對 WebApp 的支持很豐富，大量採用 Ajax 等 JavaScript 技術， 對於我這個靜態博客來說仍然稍顯高級了……非常擔心還不支持 HTML5 的瀏覽器 比如 w3m 甚至 cURL 對它的支持程度。 於是最終也沒有使用它。 Materialize Materialize Materialize 這是一批(自稱?)熟悉 Android 上 Material Design 的設計師們新近出爐的框架，試圖提供一個接近 Bootstrap 的方案。 最早是在 Reddit 上看到對它的討論的，立刻覺得這個想法不錯。 體驗一下官網的設計就可以看出，他們的動畫效果非常接近 Polymer 的感覺，響應式設計的佈局 也還不錯。 只是同樣體驗一下他們現在的官網就可以看出，他們目前的 bug 還比較多 ，甚至一些 bug 在他們自己的主頁上也有顯現。 雖然不想給這個新出爐的項目潑涼水，不過看來要達到他們聲稱的接近 Bootstrap 的易用度還任重而道遠…… bootstrap-material-design + bootstrap3 這是我最終選擇的方案。這個方案將三個項目組合在了一起，分別是 bootstrap-material-design , pelican-bootstrap3 和 Bootstrap 3 。 Bootstrap 3 想必不用再介紹了，很多網站都在使用這套框架，定製性很高。 bootstrap-material-design 是在 Bootstrap 3 的基礎上套用 Material Design 風格 製作的一套 CSS 庫，當然也不是很完善並且在不斷改進中，一些細節其實並不是很符合我的要求。 最後 pelican-bootstrap3 是用 Bootstrap 3 做的 pelican 模板。 這三個項目或多或少都有點不合我的口味，於是嘛就把 pelican-bootstrap3 fork了一套放在 這裏 ，其中還包括我自己改 過的 Bootstrap3 樣式 和 Material 樣式 ，需要的可以自取。 至於細節上我定製了哪些地方，敬請聽下回分解……","tags":"tech","url":"//farseerfc.me/summarize-material-design-css-framework.html"},{"title":"從非緩衝輸入流到 Linux 控制檯的歷史","text":"這篇也是源自於水源C板上板友的一個問題，涉及Linux上的控制檯的實現方式和歷史原因。因爲內容比較長，所以在這裏再排版一下發出來。 原帖在這裏 。 可以設置不帶緩衝的標準輸入流嗎？ WaterElement(UnChanged) 於 2014年12月09日23:29:51 星期二 問到： 請問對於標準輸入流可以設置不帶緩衝嗎？比如以下程序 #include <stdio.h> #include <unistd.h> int main ( int argc , char * argv []) { FILE * fp = fdopen ( STDIN_FILENO , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 似乎還是需要在命令行輸入後按回車纔會讓 fgets 返回，不帶緩衝究竟體現在哪裏？ 這和緩存無關，是控制檯的實現方式的問題。 再講細節一點，這裏有很多個程序和設備。以下按 linux 的情況講： 終端模擬器窗口（比如xterm）收到鍵盤事件 終端模擬器(xterm)把鍵盤事件發給虛擬終端 pty1 pty1 檢查目前的輸入狀態，把鍵盤事件轉換成 stdin 的輸入，發給你的程序 你的程序的 c 庫從 stdin 讀入一個輸入，處理 標準庫說的輸入緩存是在 4 的這一步進行的。而行輸入是在 3 的這一步被緩存起來的。 終端pty有多種狀態，一般控制檯程序所在的狀態叫「回顯行緩存」狀態，這個狀態的意思是: 所有普通字符的按鍵，會回顯到屏幕上，同時記錄在行緩存區裏。 處理退格( BackSpace )，刪除( Delete )按鍵爲刪掉字符，左右按鍵移動光標。 收到回車的時候把整個一行的內容發給stdin。 參考： http://en.wikipedia.org/wiki/Cooked_mode 同時在Linux/Unix下可以發特殊控制符號給pty讓它進入「raw」狀態，這種狀態下按鍵 不會被回顯，顯示什麼內容都靠你程序自己控制。 如果你想得到每一個按鍵事件需要用raw狀態，這需要自己控制回顯自己處理緩衝， 簡單點的方法是用 readline 這樣的庫（基本就是「回顯行緩存」的高級擴展，支持了 Home/End，支持歷史）或者 ncurses 這樣的庫（在raw狀態下實現了一個簡單的窗口/ 事件處理框架）。 參考： http://en.wikipedia.org/wiki/POSIX_terminal_interface#History 除此之外， Ctrl-C 轉換到 SIGINT ， Ctrl-D 轉換到 EOF 這種也是在 3 這一步做的。 以及，有些終端模擬器提供的 Ctrl-Shift-C 表示複製這種是在 2 這一步做的。 以上是 Linux/unix 的方式。 Windows的情況大體類似，只是細節上有很多地方不一樣： 窗口事件的接收者是創建 cmd 窗口的 Win32 子系統。 Win32子系統接收到事件之後，傳遞給位於 命令行子系統 的 cmd 程序 cmd 程序再傳遞給你的程序。 Windows上同樣有類似行緩存模式和raw模式的區別，只不過實現細節不太一樣。 strace查看了下 WaterElement(UnChanged) 於 2014年12月10日21:53:54 星期三 回復： 感謝FC的詳盡解答。 用strace查看了下，設置標準輸入沒有緩存的話讀每個字符都會調用一次 read 系統調用， 比如輸入abc： read(0, abc \"a\", 1) = 1 read(0, \"b\", 1) = 1 read(0, \"c\", 1) = 1 read(0, \"\\n\", 1) = 1 如果有緩存的話就只調用一次了 read 系統調用了： read(0, abc \"abc\\n\", 1024) = 4 如果想感受一下 raw mode 沒錯，這個是你的進程內C庫做的緩存，tty屬於字符設備所以是一個一個字符塞給你的 程序的。 如果想感受一下 raw mode 可以試試下面這段程序（沒有檢測錯誤返回值） #include <stdio.h> #include <unistd.h> #include <termios.h> static int ttyfd = STDIN_FILENO ; static struct termios orig_termios ; /* reset tty - useful also for restoring the terminal when this process wishes to temporarily relinquish the tty */ int tty_reset ( void ){ /* flush and reset */ if ( tcsetattr ( ttyfd , TCSAFLUSH , & orig_termios ) < 0 ) return - 1 ; return 0 ; } /* put terminal in raw mode - see termio(7I) for modes */ void tty_raw ( void ) { struct termios raw ; raw = orig_termios ; /* copy original and then modify below */ /* input modes - clear indicated ones giving: no break, no CR to NL, no parity check, no strip char, no start/stop output (sic) control */ raw . c_iflag &= ~ ( BRKINT | ICRNL | INPCK | ISTRIP | IXON ); /* output modes - clear giving: no post processing such as NL to CR+NL */ raw . c_oflag &= ~ ( OPOST ); /* control modes - set 8 bit chars */ raw . c_cflag |= ( CS8 ); /* local modes - clear giving: echoing off, canonical off (no erase with backspace, &#94;U,...), no extended functions, no signal chars (&#94;Z,&#94;C) */ raw . c_lflag &= ~ ( ECHO | ICANON | IEXTEN | ISIG ); /* control chars - set return condition: min number of bytes and timer */ raw . c_cc [ VMIN ] = 5 ; raw . c_cc [ VTIME ] = 8 ; /* after 5 bytes or .8 seconds after first byte seen */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 0 ; /* immediate - anything */ raw . c_cc [ VMIN ] = 2 ; raw . c_cc [ VTIME ] = 0 ; /* after two bytes, no timer */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 8 ; /* after a byte or .8 seconds */ /* put terminal in raw mode after flushing */ tcsetattr ( ttyfd , TCSAFLUSH , & raw ); } int main ( int argc , char * argv []) { atexit ( tty_reset ); tty_raw (); FILE * fp = fdopen ( ttyfd , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 終端上的字符編程 vander(大青蛙) 於 2014年12月12日08:52:20 星期五 問到： 學習了！ 進一步想請教一下fc大神。如果我在Linux上做終端上的字符編程，是否除了用ncurses庫 之外，也可以不用該庫而直接與終端打交道，就是你所說的直接在raw模式？ 另外，終端類型vt100和linux的差別在哪裏？爲什麼Kevin Boone的KBox配置手冊裏面說必 須把終端類型設成linux，而且要加上terminfo文件，才能讓終端上的vim正常工作？term info文件又是幹什麼的？ Linux控制檯的歷史 嗯理論上可以不用 ncurses 庫直接在 raw 模式操縱終端。 這裏稍微聊一下terminfo/termcap的歷史，詳細的歷史和吐槽參考 Unix hater's Handbook 第6章 Terminal Insanity。 首先一個真正意義上的終端就是一個輸入設備（通常是鍵盤）加上一個輸出設備（打印 機或者顯示器）。很顯然不同的終端的能力不同，比如如果輸出設備是打印機的話，顯 示出來的字符就不能刪掉了（但是能覆蓋），而且輸出了一行之後就不能回到那一行了 。再比如顯示器終端有的支持粗體和下劃線，有的支持顏色，而有的什麼都不支持。 早期Unix工作在電傳打字機（TeleTYpe）終端上，後來Unix被port到越來越多的機器上 ，然後越來越多類型的終端會被連到Unix上，很可能同一臺Unix主機連了多個不同類型 的終端。由於是不同廠商提供的不同的終端，能力各有不同，自然控制他們工作的方式 也是不一樣的。所有終端都支持回顯行編輯模式，所以一般的面向行的程序還比較好寫 ，但是那時候要撰寫支持所有終端的「全屏」程序就非常痛苦，這種情況就像現在瀏覽 器沒有統一標準下寫HTML要測試各種瀏覽器兼容性一樣。 通常的做法是 使用最小功能子集 假設終端是某個特殊設備，不管別的設備。 水源的代碼源頭 Firebird2000 就是那樣的一個程序，只支持固定大小的vt102終端。 這時有一個劃時代意義的程序出現了，就是 vi，試圖要做到「全屏可視化編輯」。這在 現在看起來很簡單，但是在當時基本是天方夜譚。 vi 的做法是提出一層抽象，記錄它所需要的所有終端操作，然後有一個終端類型數據庫 ，把那些操作映射到終端類型的具體指令上。當然並不是所有操作在所有終端類型上都 支持，所以會有一堆 fallback，比如要「強調」某段文字，在彩色終端上可能 fallback 到紅色，在黑白終端上可能 fallback 到粗體。 vi 一出現大家都覺得好頂讚，然後想要寫更多類似 vi 這樣的全屏程序。然後 vi 的作 者就把終端抽象的這部分數據庫放出來形成一個單獨的項目，叫 termcap （Terminal Capibility），對應的描述終端的數據庫就是 termcap 格式。然後 termcap 只是一個 數據庫（所以無狀態）還不夠方便易用，所以後來又有人用 termcap 實現了 curses 。 再後來大家用 curses/termcap 的時候漸漸發現這個數據庫有一點不足：它是爲 vi 設 計的，所以只實現了 vi 需要的那部分終端能力。然後對它改進的努力就形成了新的 terminfo 數據庫和 pcurses 和後來的 ncurses 。 然後 VIM 出現了自然也用 terminfo 實現這部分終端操作。 然後麼就是 X 出現了， xterm 出現了，大家都用顯示器了，然後 xterm 爲了兼容各種 老程序加入了各種老終端的模擬模式。不過因爲最普及的終端是 vt100 所以 xterm 默 認是工作在兼容 vt100 的模式下。然後接下來各種新程序（偷懶不用*curses的那些） 都以 xterm/vt100 的方式寫。 嗯到此爲止是 Unix 世界的黑歷史。 知道這段歷史的話就可以明白爲什麼需要 TERM 變量配合 terminfo 數據庫纔能用一些 Unix 下的全屏程序了。類比一下的話這就是現代瀏覽器的 user-agent。 然後話題回到 Linux 。 大家知道 Linux 早期代碼不是一個 OS， 而是 Linus 大神想 在他的嶄新蹭亮的 386-PC 上遠程登錄他學校的 Unix 主機，接收郵件和逛水源（咳咳 ）。於是 Linux 最早的那部分代碼並不是一個通用 OS 而只是一個 bootloader 加一個 終端模擬器。所以現在 Linux 內核裏還留有他當年實現的終端模擬器的部分代碼，而這 個終端模擬器的終端類型就是 linux 啦。然後他當時是爲了逛水源嘛所以 linux 終端 基本上是 vt102 的一個接近完整子集。 說到這裏脈絡大概應該清晰了， xterm終端類型基本模擬 vt100，linux終端類型基本模 擬 vt102。這兩個的區別其實很細微，都是同一個廠商的兩代產品嘛。有差別的地方差 不多就是 Home / End / PageUp / PageDown / Delete 這些不在 ASCII 控制字符表裏的按鍵的映射關係不同。 嗯這也就解釋了爲什麼在linux環境的圖形界面的終端裏 telnet 上水源的話，上面這些 按鍵會錯亂…… 如果設置終端類型是 linux/vt102 的話就不會亂了。在 linux 的 TTY 裏 telnet 也不會亂的樣子。 寫到這裏纔發現貌似有點長…… 總之可以參考 Unix hater's Handbook 裏的相關歷史評論和吐槽，那一段非常有意思。","tags":"tech","url":"//farseerfc.me/from-unbuffered-stdin-to-history-of-linux-tty.html"},{"title":"KDE5 Plasma 之跳動賣萌的活動按鈕","text":"今天嘗試 KDE5 Plasma 的活動的時候無意間發現這個現象。 只要把活動按鈕拖出桌面，它就會在桌面邊緣來回跳動。 視頻如下： Youtube Youku 當然你可以把它再拖回來，所以這個問題還無傷大雅，只是賣萌。 比比之前 Gnome3 那個跳動的界面真是好太多了： Youtube Youku 順便，今天還看到一個賣萌的 KDE5 Plasma 靜音圖標的翻譯： KDE5のミュート画面の中国語翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","url":"//farseerfc.me/jumping-kde5-plasma-activities-button.html"},{"title":"嫁給我好麼","text":"渲染的樣子 可以玩的是下面這個： * 用 WASD←→ 移動，需要 WebGL 支持","tags":"life","url":"//farseerfc.me/marry-me.html"},{"title":"ICSE 2012","text":"June 6 Keynote 1 沒怎麼聽懂，只記得講到了finance is not money但是沒聽懂這個和軟件有什麼關係。 Cost Estimation for Distributed Software Project 講到他們試圖改善現有的模型去更精確地評估軟件開發的開銷。 他們會給PM建議之前的項目的歷史數據，然後對於新項目，他們建議歷史上已有 的項目的數據，從而幫助PM得到更精確的評估。他們試圖儘量減少項目評估對PM 的經驗的需求，從而幫助即使經驗很少的PM也能準確評估項目的開銷。 他們的觀點： Context-specfic solutions needed! 我們需要更上下文相關的解決方案！ Early user paticipation is key! 早期用戶的參與是關鍵 Characterizing Logging Practices in Open-Source Software Common mistakes in logging messages 在日誌記錄中容易犯的錯誤 他們學習了歷史上的log記錄，然後試圖找到重複修改的輸出log的語句，確定log 中存在的問題。他們首先確定修改是事後修改。 通常的修改的比例（9027個修改） 45% 靜態文本 27% 打印出的變量 26% 調試等級verbosity 2% 日誌輸出的位置 他們發現有調試等級的變化，是因爲安全漏洞之類的原因，或者在開銷和數據 之間的權衡。 大多數對log的變量的修改都是爲了增加一個參數。他們之前的LogEnhancer是爲了 解決這個問題而提出的，通過靜態檢查，提醒程序員是否忘記了某個參數 對text的修改是因爲要改掉過時的代碼信息，避免誤導用戶。 他們的實驗是採用了基於code clone 的技術，找到所有log語句，然後找不一致 的clone，然後自動提出建議。 Combine Functional and Imperative Pgrm for Multicore Sw: Scala & Java 趨勢：到處都是多核，但是併發程序呢？ 他們研究的對象是Scala和Java，因爲可以編譯後確認JVM字節碼的語義。 Java: 共享內存 顯示創建的線程 手動同步 Wait/Notify機制 Scala: 高階函數 Actors, 消息傳遞 lists, filters, iterators while 共享狀態, OO import java.* 能從java導入任何庫 auto type inferance 自動類型推導 實驗的參與者都經過4周的訓練，實驗項目是工業等級的開發項目 結果： scala 的項目平均比java多花38%的時間，主要都是花在Test和debug上的時間。 程序員的經驗和總體時間相關，但是對test和debug沒有顯著影響。 scala的爲了讓編程更有效率的設計，導致debug更困難。比如類型推導，debug 的時候需要手動推導，來理解正在發生什麼。 scala的程序比java小，中位數2.6%，平均15.2% 性能比較： 單核：scala的線性程序的性能比java好 4核： scala 7s @ 4 threads java 4si @ 8 threads median 83s scala 98s java 32core: best scala 34s @ 64 threads 結論 java有更好的scalability scala類型推導 45%說對攜帶碼有幫助 85%說導致程序錯誤 調試 23%認爲scala簡單 77%認爲java簡單 multi-paradigram are better Sound Empirical Evidence in Software Testing Test data generation 測試數據自動生成 Large Empirical Studies - not always possible For open source software - big enough Identifing Linux Bug Fixing Patch current practice: manual Current research: keywords in commits link bug reports in bugzilla Try to solve classification problem issue pre-identified post-identified data from commit log feature extraction text pre-process stemmed non-stop words model learning research questions Active Refinement of Clone Anomaly Reports motivating code clones, clone groups clone used to detect bugs anomaly : inconsistent clone group many anomaly clone are note bug, high false positive approach reorder by sorted bug reports June7 Keynotes 2: Sustainability with Software - An Industrial Perspective Sustainability Classic View: Idenpendent view with overlap Social Environment Economic Nested viw Environment Social Economic Triple bottom line economic -global business, networks , global econ env natural res, climate change, population grow social awareness, connectivity, accountability Green IT reduce IT energy more than 50% cooling - doing nothing mini e-waste: not properly recycled 80% in EU 75% in US foster dematerialization In-Memory Technology: Expected Sustainable Benefits What can we do? consider all software lifecycle phases in your design avoid energy expensive behavior in your codes design lean architectures Green by IT 2% green IT 98% green IT On How Often code is cloned across repositories Line based hashing code clone detection never do anything harder than sorting hashing a window of 5 lines of normalized (tokenized) code, dropping 3/4 of the hashing 把ccfinder一個月的工作縮短到了3, 4天。沒有比較presion和recall。 14% type1 16% type2 17% type3 (not really type2) Graph-based analysis and prediction for sw evolution graph are everywhere internet topology social net chemistry biology in sw - func call graph - module dependency graph developer interaction graph - commit logs - bug reports experiment 11 oss, 27~171 release, > 9 years predictors NodeRank similar to pagerank of google measure relative importance of each node func call graph with noderank compare rank with severity scale on bugzilla correlation between noderank and BugSeverity func level 0.48 ~ 0.86 varies among projects. model level > func level ModularityRatio cohesion/coupling ratio: IntraDep(M)/InterDep(M) forecast mantencance effort use for identify modules that need redesign or refactoring EditDistance bug-based developer collaboration graphs ED(G1,G2)=|V1|+|V2|-2|V1交V2|+|E1|+|E2|-2|E1交E2| use for release planning resource allocation graph metrics graph diameter average node degree indicates reuse clustering coefficient assortativity num of cycles Conclusion \"Actionable intelligence\" from graph evolution studie 11 large long-live projs predictors identify pivotal moments in evolution What make long term contributors: willingness and opportunity in OSS OSS don't work without contributors form community mozilla (2000-2008) 10&#94;2.2 LTC <- 2 order -> 10&#94;4.2 new contributors <- 3.5 order -> 10&#94;7.7 users gnome (1999-2007) 10&#94;2.5 LTC <- 1.5 order -> 10&#94;4.0 new contributors <- 3.5 order -> 10&#94;6.5 users approach read issues of 20 LTC and 20 non-LTC suvery 56 (36 non-LTC and 20 LTC) extract practices published on project web sites summeray Ability/Willingness distinguishes LTCs Environment macro-climate popularity micro-climate attention bumber of peers performance of peers regression model newcomers to LTC conversion drops actions in first month predicts LTCs 24% recall 37% precision develop of auxiliary functions: should you be agile? a empirial assessment of pair programming and test-first programming can agile help auxiliary functions? experiment pair vs solo test-first vs test-last students vs professors research questions r1: can pair help obtain more correct impl r2: can test-first r3: dst test1 encourage the impl or more test cases? r4: does test1 course more coverage result test-first higher coverage non change with correctness pair improve on correctness longer total programming time Static Detection of Resource Contention Problems in Server-side script Addressed the race condition of accessing database or filesystem of PHP Amplifying Tests to Validate Exception Handling Code 異常處理的代碼不但難寫，而且難以驗證。各種組合情況難以估計，尤其是手機 系統上。 A tactic-centric approach automating traceability of quality concerns tactic traceability information models","tags":"life","url":"//farseerfc.me/icse2012.html"},{"title":"MSR 2012 @ ICSE","text":"Mining Software Repository 2012 @ ICSE 參加了今年的MSR，會場在University of Zurich。一大早來到大學，註冊有點 小插曲，顯然瑞士人搞不清楚中國人的名字，3個楊（Yang）姓的中國人的名牌 被搞錯了。然後堀田學長的所屬被寫作了\"Japan, Japan\"，成爲了全日本的代表。 MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) 首先是來自微軟亞洲研究院（MicroSoft Research @ Asia, MSR Asia）的Keynots， 於是就變成了MSR在MSR的演講。MSR的張冬梅（Dongmei Zhang）女士的演講 分爲關於Software Analysis和XIAO的兩部分。XIAO是MSRA開發的Code Clone Detector，似乎我要給井上研做的就是這個。想更多瞭解Xiao的細節，不過張女士 演講結束的時候的鼓掌導致了話筒的小故障。 Towards Improving BTS with Game Mechanisms 感覺這篇的內容基本上就是關於 http://www.joelonsoftware.com/items/2008/09/15.html 這裏寫到的東西，然後說同樣的理論是否可以用於Issue Tracking之類的事情上。 個人感覺這個意義不大，stackoverflow之所以成功是因爲它把開源社區本身就 具有的名譽體系具現化了，本着大家都喜歡被別人奉爲大牛的心態，就如同 wikipedia一樣。同樣的理論如果用於公司內部的Issue Tracking系統上，會得到 完全不同的東西吧。就像MSDN的組織方式雖然和wikipedia是一樣的，但是在MSDN 裏找信息的感覺和在wikipedia完全不一樣。個人不太看好這個方向。 GHTorrent 這篇的slide在這裏可以看到： http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Github的主要數據，代碼，已經可以通過git接口 獲得了，wiki是git的形式保存的。所以這個項目的目的就是暴露別的數據，主要 是issue tracking，code comments，這種。代碼訪問github api，然後用分佈式 實現以克服api的限制，然後提供torrents形式的history下載。github api獲得 的json數據以bson的形式保存在MongoDB裏，解析過的有了Schema之後的數據保存 在MySQL裏並可以導出SQL。 個人的想法，覺得數據如果能夠更統一，全部存在Git裏或許更好，像Wiki一樣。 同樣是要暴露全部歷史記錄的目的，用Torrent自己實現的歷史遠不如用Git的 接口實現的歷史記錄方便吧，git blame之類的也更方便追蹤code comment之類的 作者信息。當然對git的raw date直接讀寫，需要對git的內部原理有足夠的理解， 或許只有github的人有這種能力了。 Topic Mining 用得兩個參數， DE 和 AIC，完全不能理解，過後研究。實驗針對了Firefox, Mylyn, Eclipse三個軟件。試圖從Repo中分析源代碼的identifier和comments， 找到topic和bug之間的關係，比如怎樣的topic更容易導致bug。得出的結論似乎 也很曖昧，只是說核心功能被報告的bug更多，但是不知道原因。這只能表示核心 功能受到更多關注和更多測試吧，並不能說明核心功能就容易產生bug。 不過這個的Slide做得很漂亮，很容易理解。 SeCold A linked data platform for mining software repositories 沒聽懂這個項目的目的。 The evolution of software 第二天的Keynotes，關於將Social Media和Software Development相結合的想法。 或許就是Github賴以成功的基礎。講到代碼中的comment, Tags, uBlog, blog之類 的social的特性和IDE的融合的趨勢。 Do Faster Releases Imporve Software Quality? 使用Firefox作爲例子。 結論是快速發佈導致bug更多，更容易crash，但是bug更快得到修復，並且用戶 更快轉向新的發佈。 Security vs Performance Bugs in Firefox Performance bugs are regression, blocks release. 一些感想 基於自然語義分析的commit分割 經常工具（比如git）的使用者並沒有按照工具設計者的意圖使用工具，這給MSR 帶來很多困難。舉個例子，git有非常完美的branch系統，通常期望git的使用者 能夠在一次commit裏commit一個功能，比如一個bug的修復，或者一個feature的 添加，但是事實上經常有很多邏輯上的commit被合併在一個裏面了。 或許這不是使用者的錯，而是工具仍然不夠人性的表現。或許我們可以自動把 一次的commit按照語義分割成多個。 分割之後，可以更容易地把issue和commit關聯，也更容易組織更多的研究。 關於這次發表中大家用的slides系統 題目爲``Incorporating Version Histories in Information Retrieval Based Bug Localization''的人用的slide是beamer的。公式很多，overlay很多，列表 很多，圖片很少，典型的beamer做出的slide。思維導圖用得很不錯。今天一天 有至少3個slide是用beamer做的。 題目爲``Towards Improving Bug Tracking Systems with Game Mechanisms'' 的人用了prezi，圖片很多，過度很多。但是比如沒有頁號沒有頁眉頁腳，正式 會議的場合不太方便。 至少有六個以上用了Apple Keynotes，Keynotes做出來的東西真的和Powerpoint 做出來的很難區別，其中兩個人用了初始的主題所以才看出來。 剩下的自然是PPT。MSRA的張女士做的雖然是PPT，倒是有很多beamer的感覺， 比如頁眉頁腳和overlay的用法。這些如果都是PPT做出來的，會多很多額外的 人力吧。 值得一提的是有一個題目爲``Green Mining: A Methodology of Relating Software Change to Power Consumption''的人的slide全是``劣質''的手繪漫畫， 效果意外地好，很低碳很環保很綠色很可愛。具體效果可以參考下面的動畫，雖然 現場看到的不是一個版本： http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv 微軟是個腹黑娘！ 嘛雖然這也不是什麼新聞了。MSR2012的Mining Challenge的贊助商是微軟，管理 組織者來自微軟研究院，獎品是Xbox和Kinect。然後今年的題目是： Mining Android Bug 我看到了微軟滿滿的怨氣……","tags":"life","url":"//farseerfc.me/msr2012.html"},{"title":"Pyssy 項目","text":"簡介 Pyssy 是用於 上海交通大學 飲水思源站 的一系列 Python 腳本和工具。 Pyssy 被有意設計爲既可以託管寄宿在 SAE [1] 上，也可以在單機上獨立使用。 項目地址： http://pyssy.sinaapp.com/ Github上的源代碼地址： https://github.com/yssy-d3/pyssy [1] Sina App Engine ，新浪雲平臺，類似 Google App Engine 的東西。 依賴關係 Pyssy 使用 Flask 作爲網頁服務器， 並且使用 Memcached 或者 Redis 作爲抓取 水源Web 的緩存。 SAE Python 環境下請開啓 Memcached 支持。 本地環境下請安裝 Redis-py 並運行 redis-server 服務器程序。","tags":"tech","url":"//farseerfc.me/pyssy.html"},{"title":"PyRuby","text":"今天在GitHub上閒逛的時候看到一個叫做 PyRuby 的項目。項目的Readme說得很好： PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } 甚至 PyPI 上還有這個項目的包。 一開始我還以爲這又是一個野心勃勃的基於PyPy的Ruby實現，或者某種trick在Python裏面直接調用Ruby解釋器。 然後我想看看這個的源代碼 只有一個ruby.py文件，內容是： # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) 是的……的確……這種嘗試把Python和Ruby放在一起的想法絕對是瘋了……","tags":"tech","url":"//farseerfc.me/mix-ruby.html"},{"title":"關於C++模板的類型轉換的討論","text":"這兩天在飲水思源的C板，關於C++模板的類型轉換的一個討論，後面是我的解答。 討論地址 http://bbs.sjtu.edu.cn/bbstcon,board,C,reid,1330078933,file,M.1330078933.A.html 原問題 今天在書上看到模板演繹的時候可以允許cast-down，於是我寫了個東西： template < bool _Test , class _Type = void > struct enable_if { }; template < class _Type > struct enable_if < true , _Type > { typedef _Type type ; }; class A { }; class B : A { }; template < typename T > struct traits { static int const value = false ; }; template <> struct traits < A > { static int const value = true ; }; template < typename T > void f ( T , typename enable_if < traits < T >:: value >:: type * = 0 ) { } template <> void f < A > ( A , enable_if < traits < A >:: value >:: type * ) { } template < typename T > class BB {}; template < typename T > class DD : public BB < T > {}; template < typename T > void ff ( BB < T > ) {}; int main ( int argc , char * argv []) { A a ; B b ; DD < long > dd ; //f(b); ff ( dd ); } 奇怪的是重載決議的時候， f 的情況下它就不讓我特化的 f<A> 進來。 但是在 ff 的情況下， ff<BB<long>> 卻進來了。 在VC10和GCC3.4下測試 我的解答 我們來設身處地地作爲編譯器，看一遍到底發生了什麼。 約定符號 # : A#B 是把 B 帶入 A<T> 的參數 T 之後實例化得到的結果。 首先看ff的情況。 DD < long > dd ; 處理到這句的時候，編譯器看到了 DD<long> 的實例化，於是去實例化 DD#long ，繼而實例 化了 BB#long 。 ff ( dd ); 這句，首先計算重載函數集合。 第一步，需要從參數 DD#long -> BB<T> 推斷 ff<T> 的 T 。根據函數模板參數推斷規則： :code:`class_template_name<T>` 類型的參數，可以用於推斷 :code:`T` 。 於是編譯器推斷 T 爲 long 。這裏就算不是 BB 而是完全無關的 CC 都可以推斷成功，只要 CC 也 是一個 CC<T> 形式的模板。 第二步，模板特化匹配。因爲只有一個模板，所以匹配了最泛化的 ff<T> 。 第三步，模板實例化。 推斷了 long -> T 之後，編譯器實例化 ff#long 。 重載函數集合： {ff#long} 然後重載抉擇找到唯一的可匹配的實例 ff#long ，檢查實際參數 DD#long 可以隱式轉換到 形式參數 BB#long ，從而生成了這次函數調用。 再來看f的情況。 f ( b ); 計算候選重載函數集合。 第一步，對所有 f 模板推斷實參。根據函數模板參數推斷規則： 帶有 :code:`T` 類型的參數，可以用於推斷 :code:`T` 。 於是 B -> T 被推斷出來了。 第二步，模板特化匹配。 這裏 B 不是 A ，所以不能用 f<A> 特化，只能用 f<T> 模板。 第三步，模板實例化。 B 帶入 f<T> 實例化成 f#B 的過程中，實例化 traits#B 。 由於沒有針對 B 的特化，所以用 traits<T> 模板， traits#B::value=false ，進而 enable_if#false 沒有 type ，出錯。 唯一的模板匹配出錯，重載函數集合爲空，SFINAE原則不能找到合適的匹配，於是報錯。","tags":"tech","url":"//farseerfc.me/discuss-cpp-template-downcast.html"},{"title":"嘗試一下 Pelican","text":"似乎一夜之間所有的 極客們 都 有了 自己 的 Github主頁 和 Octopress 博客。就像所有人在他們的博客中指出的，靜態博客的確比傳統的WordPress方式具有更多優勢。 自從看到這些 我就一直在想着自己搭一個 Octopress 。 但是似乎 Octopress 不適合我 一上手就被 Octopress的搭建步驟 煩到了。 RVM 是什麼？ rbenv 又是什麼？ 看來 Ruby 社區的快節奏發展已經超過了我的想象，他們似乎需要一套發行版管理器來調和不同版本之間的 Ruby 的兼容性問題。 雖然同樣的兼容性問題在 Python 社區也有 [1] ，不過總覺得 Python 至少還沒到需要一個發行版管理器的程度 [2] 。 真正的問題是我手上還沒有一個可以讓我隨便玩的 Linux 環境（真的想要……）。 而無論是 RVM 還是 rbenv 似乎都只支持 Unix/Linux/MacOSX 。 身爲極客就註定不能用 Windows 麼？（或許是的……）。 剩下的問題就是 Ruby 和 Python 兩大陣營的對立問題了。我不熟悉 Markdown ， 相對來說比較喜歡 ReST 。 似乎無論哪邊都要 依賴 Pygments 作爲代碼着色器，那麼其實 Rubyist 也至少需要安裝 Python 。 我傾向於不依賴任何 Ruby 組件，最好沒有 C 擴展 的純 Python 實現。 於是我開始在 Github 上找 Python 的靜態博客引擎。 Flask 的作者 mitsuhiko 寫的 rstblog 看起來不錯，不過似乎沒有多少人在用。 Hyde 似乎很完善，不過默認的標記語言是 MarkDown ， 又依賴於幾個 Ruby 組建，而且官方網站的設計實在太前衛。 最終我看到了 Pelican 。 [1] 比如 Python 2.x 與 3.x 之間看似難以跨越的鴻溝，以及 PyPy 、 CPython 、 Stackless 、 Cython 等各個實現之間的微妙差別。 [2] 是的，我們有 easy_install ，我們有 pip ， 不過這些都是包管理器，都是裝好特定的Python實現之後的事情。 Python實現本身還不需要包管理器來管理。 Python 的版本問題基本上也只需要 2to3.py 和 3to2.py 這樣的輕量級轉換器就可以了，你不需要爲了安裝多個軟件而在硬盤裏留下多個不同版本的 Python 。 如果爲了引用的穩定性，你可以用 virtualenv ，不過這又是另一回事情了。 那麼就 Pelican 吧 對我而言， Pelican 相比於 Octopress 有幾個好處： 純 Python 實現。 這意味着我可以換用任何 Python 解釋器而不必擔心兼容性問題。比如我就換成了 PyPy 。 多語言支持。因爲 Pelican 的作者似乎是個法國人。不過這個似乎大部分人不需要…… 我是想儘量把一篇博客寫成三種語言作爲鍛鍊吧。 ReST 。這樣我就可以用 Leo 的 @auto-rst 直接寫 ReST了。簡單方便快捷有效。 不過似乎 Pelican 的關注度不如 Octopress 那麼高，現在一些部分還有細微的問題： pelican-import 從 WordPress 導入的時候對中文、日文的支持似乎很成問題。 日期格式、時區、字符集、和多語言功能的結合度還不夠。 我在嘗試改善它。 模板還不夠豐富。 插件也不夠多…… 希望這麼優秀的工具能夠受到更多關注，以上這些問題都是增加關注度之後很快就能解決的問題。 我的設置 settings.py 安裝 Pelican 很容易，一句話就夠了： $ pip install pelican 然後把文章寫成ReST的格式，放在`pages`文件夾裏面。(重新)生成只要： $ pelican -s settings.py 上傳到 Github: $ git commit -am \"Commit message\" $ git push 就這麼簡單。附上我的配置文件： # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , ' %a , %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a ' ), 'jp' :( 'jpn' , '%Y/%m/ %d ( %a )' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","url":"//farseerfc.me/try-pelican.html"},{"title":"關於我的Blogs","text":"從 farseerfc.wordpress.com 導入 很久沒有寫過blog或者之類的東西了。這邊一直荒廢着。 由於國內被牆的原因，另一個wordpress： http://fchome.sinaapp.com/ 應該會同步更新這裏的內容。 抽空寫點什麼吧。","tags":"import","url":"//farseerfc.me/about-my-blogs.html"},{"title":"\"…if we do this work … \" --Bill Gates","text":"導入自 renren From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf 如果這就是我至今在Xen4.0上得不到ACPI 3.0的完善支持的原因，那麼我詛咒Bill Gates！","tags":"import","url":"//farseerfc.me/if-we-do-this-work.html"},{"title":"[zz]\"西廂計劃\"原理小解","text":"從 farseerfc.wordpress.com 導入 好神奇的想法，先存着，以後慢慢研究 原文： http://blog.youxu.info/2010/03/14/west- chamber/ 待月西廂下，迎風戶半開。隔牆花影動，疑是玉人來。 最近推上最流行的一個關鍵詞是\"西廂計劃\", 這個計劃名字取得很浪漫，客戶端叫做張生，對，就是西廂記裏面那個翻牆去見崔鶯鶯小姐的張生；顯然，服務器端必然叫做崔鶯鶯。客戶端的張生是最重要的部件，可以不依賴於服務端工作。因爲西廂計劃的作者只是簡要的介紹了一下原理，其他報道又語焉不詳，我當時就覺得很好奇，花了昨天一個晚上詳細讀了一下源代碼，終於知道怎麼回事了，覺得原理非常漂亮，所以寫篇文章介紹總結一下。 先說大方向。大家都知道，連接被重置的本質，是因爲收到了破壞連接的一個 TCP Reset 包。以前劍橋大學有人實驗過，客戶端和服務器都忽略 Reset, 則通信可以不受影響。但是這個方法其實只有理論價值，因爲絕大多數服務器都不可能忽略 Reset 的 (比如 Linux, 需要 root 權限配置iptables, 而且這本身也把正常的 Reset 給忽略了)。只要服務器不忽略 Reset, 客戶端再怎麼弄都沒用，因爲服務器會停止發送數據，Reset 這條連接。所以，很多報道說西廂計劃是忽略 Reset, 我從源代碼來看應該不是這樣。在我看來，西廂計劃是利用了牆的一個可能的弱點–牆只在連接發起的時候把一個 TCP 連接加入監聽序列，如果牆認爲這個連接終止了，就會從監聽序列中去掉這條記錄，這樣，這條連接上後續的包就不會被監聽。西廂計劃就是讓牆\"認爲\"這個連接終止的一個絕妙的方法。只要牆認爲這個連接兩端都是死老虎，牆就不會觸發關鍵詞檢測，其後所有的數據，都不存在連接被重置的問題了。 如何讓一個連接置之死地而後生，就是西廂計劃那幫黑客神奇的地方了。這也不是一日之功。 首先，這幫牛人發現，牆的是一個入侵檢測系統，把含有關鍵字的包當成一種\"入侵\"來對待。採取這種設計有很多好處，但缺點是入侵檢測系統可能具有的問題，牆都可能有。西廂計劃主頁上那篇著名的論文就是講這些七七八八的漏洞的。可以說處理這些七七八八的漏洞是非常困難的，迫使牆的設計者\"拆東牆，補西牆\"。這樣補來補去，外表看起來好像很牛逼的牆，其實有很多本質上無法簡單修補的漏洞，其中有一個致命的，就是 TCP 連接狀態的判定問題。 出於入侵檢測系統這種設計的侷限，牆沒有，也沒辦法準確判定一條 TCP 連接的狀態，而只是根據兩邊收到的數據來\"推測\"連接的狀態。而所有的關鍵詞檢測功能，都是基於\"連接還活着\"的這個推測的結果的。因爲牆的規則是在連接發起的時候開始對這條連接的檢測，在連接終止的時候停止對這條連接的檢測，所以，一旦對連接的狀態推測錯誤，把還活着的連接當成已經關閉的連接，牆就會放棄對這條連接上隨後所有的包的檢測，他們都會都透明的穿過牆的入侵檢測。 上面只是想法，具體到 TCP 協議實現這一層，就要只迷惑牆，還不能觸及我要通信的服務器。最理想的情況下，在任何有效通信之前，就能讓牆出現錯誤判斷，這些，就需要對 TCP 協議有深刻理解了。西廂計劃的那幫黑客，居然真的去讀 TCP 幾百頁的 RFC，還居然就發現了方法（這裏我假設讀者都知道 TCP 的三次握手過程和序列號每次加一的規則）。 我們都知道，三次握手的時候，在收到服務器的 SYN/ACK 的時候，客戶端如果發送 ACK 並且序列號+1 就算建立連接了，但是客戶端如果發送一個序列號沒 +1 的 FIN （表示連接終止，但是服務器知道，這時候連接還沒建立呢， FIN 這個包狀態是錯的，加上序列號也是錯的，服務器自己一判斷，就知道這個包是壞包，按照標準協議，服務器隨手丟棄了這個包）, 但這個包，過牆的時候，在牆看來，是表示連接終止的(牆是 ma de in china, 是比較山寨的，不維護連接狀態，並且，牆並沒有記下剛纔服務器出去的 SYN/ACK 的序列號，所以牆不知道序列號錯了）。所以，牆很高興的理解爲連接終止，舒了一口氣去重置其他連接了， 而這個連接，就成了殭屍，牆不管你客戶端了，而這時候，好戲纔剛剛開始。 事實上，牆是雙向檢測的（或者說對每個包都檢測的），因此，對服務器和客戶端實現相同的對待方法，所以，牆不管客戶端還不行，假如服務端有關鍵詞傳給客戶端，牆還是有可能要發飆的（這裏說有可能，因爲我也不知道）。所以，最好的辦法就是，讓服務端也給牆一個終止連接的標誌就好了。可是這個說起來簡單，做起來難，怎麼能讓不受自己控制的服務器發一個自己想要的包呢？ 西廂計劃的那幫黑客，再次去讀幾百頁的 RFC, 令人驚訝的發現，他們居然在 RFC 上發現了一個可以用的特性。我們上面說了，三次握手的時候，在收到 SYN/ACK 後，客戶端要給服務器發送一個序列號+1 的ACK，可是，假如我不+1呢，直接發 ACK 包給服務器。 牆已經認爲你客戶端是死老虎了，不理你了，不知道你搞什麼飛機，讓這個 ACK 過了。可是服務器一看，不對啊，你給我的不是我期待的那個序列號， RFC 上說了，TCP 包如果序列號錯了的話，就回復一個 Reset. 所以，服務器就回復了一個 Reset。這個 Reset 過牆的時候，牆一看樂了，服務器也終止連接了，好吧，兩邊都是死老虎了，我就不監聽這條連接了。而至於客戶端，這個服務器過來的 Reset 非常好識別，忽略就是。隨後，客戶端開始正確的發送 ACK, 至此，三次握手成功，真正的好戲開始，而牆則認爲客戶端和服務器都是死老虎，直接放過。所以，張生就這樣透明的過了牆。 至於過牆以後所有的事情，《西廂記》裏面都有記載，各位讀者自行買書學習。 現在的西廂計劃客戶端，即\"張生\"模塊的防連接重置的原理就是這樣，服務器端，即鶯鶯模塊的實現也是類似的。防DNS那個，不懂 DNS 協議，所以看不懂。我猜想，因爲開發人員都是黑客，所以自然喜歡用最經得起折騰和高度定製的 Linux 開發。 現在看西廂計劃的實現，因爲依賴於 Linux 內核模塊 netfilter, 在 Linux 上如魚得水，但往其他平臺的移植可能是個亟待解決的問題。 我覺得，在其他平臺上，可以通過 libpcap 和 libnet ，在用戶態實現相同的功能，就是有點麻煩而已，有興趣的懂網絡的可以照西廂計劃原理，在家自行做出此功能；當然，全中國人民都用 Linux 最好 :) PS 1: 據說是西廂計劃一個作者畫的原理圖： http://img.ly/DIi PS 2: 我對 TCP 的理解僅限於課本，如果上面的對技術的理解有錯，請大家指出。 PS 3: 有些漏洞，可能是設計上本質缺陷，不是那麼容易修復的。 PS 4: 除了最後一個圖，本文沒有其他相關鏈接，如需相關資料，自行Google。","tags":"import","url":"//farseerfc.me/zz-introducing-scholarzhang.html"},{"title":"寫程序讓CPU佔用率保持正弦函數","text":"導入自 renren 據說是一道微軟的面試題。如題，寫程序，讓Windows的任務管理器中的性能監視器呈現正弦曲線。 潛心鑽研良久，得代碼：（java） public class sincpu { private static final int cycle = 1024 , tick = 256 ; public static void main ( String [] args ) throws InterruptedException { for ( int i = 0 ;; i ++ ){ work ( calcNextSleep ( i % cycle )); sleep ( tick - calcNextSleep ( i % cycle )); } } private static long calcNextSleep ( long i ){ return ( int )( Math . sin (( double ) i * 2 * Math . PI / cycle ) * tick + tick ) / 2 ; } private static void sleep ( long sleepTime ) throws InterruptedException { if ( sleepTime < 2 ) Thread . yield (); else Thread . sleep ( sleepTime ); } private static void work ( long period ) { long start = System . currentTimeMillis (); for (;;){ Math . sin ( 1 ); if ( System . currentTimeMillis () - start >= period ) break ; } } } 多核CPU上測試時要注意關掉一個CPU：","tags":"import","url":"//farseerfc.me/sine-cpu.html"},{"title":"關於神創論的一些見解","text":"導入自 renren 看到陳驫同學很有感想的一篇神創論與命運日誌，覺得近日很久沒有看到這樣的評論了。想說幾句自己的觀點。 首先我認爲，神創論與宿命論沒有多少關聯，甚至進化論者相較於神創論者更容易接受宿命論的觀點。因爲神創論主張意志的存在，人所具有的個體意志與神的意志，因此在神創論者的眼中事件的結果是可以通過意志來改變的，亦即如果我從物理樓11樓跳下，那麼我就可以改變自己死亡時間的宿命。上帝的意志同樣可以左右事件的結果，也就是所謂的宿命不復存在。而進化論者不承認意志獨立於物質世界的存在，你我的思考、行爲，都受到物理學法則諸如量子力學的約束，這就引出了北大物理系教授的那句\"宇宙中的一切都是可以計算的\"，亦即宿命論。如我我選擇現在從物理樓上跳下，我這一行爲並不是處於個人的獨立意志，乃是想證明這一點，亦即我跳樓這一舉動是有其背後的動機與原因的，就如同計算機的輸入必然導致了輸出，宿命的必然終結於此。 其次，關於事件的複雜度所導致的隨機化，在大量混沌隨機中也存在着如統計學和隨機分形學這樣的規律，並不是否認宿命的充分理由。 關於神創論的合理性問題。我認爲是否相信神的存在只是一個boolean二值問題，它爲true爲false本身並不重要，重要的是確定它的取值之後得到的推論與結果。如果否認神的存在，如現代數學這樣的完美又何以存在，進化論者的解釋是事物最終會向着更好更高級的方向發展，產生現代數學乃至現代科學是發展的必然。而這種論調顯然有悖於物理中以熱力學第二定律爲首的，預言事物會隨時間推演愈發混亂的論斷。更進一步，甚至整個人類、整個生物系統的存在都是有悖於熱力學推論的現象，是某種理論只能以\"小概率事件\"解釋的現象。 神創論的核心觀點之一，是神的唯一存在性，按照鄒恆明的比喻，這就如同數學中集閤中元素的的唯一性一般至關重要。數學乃至近代科學的發展，其起源在於這種對神性的探求，而不僅僅是好奇心就可以解釋的。反觀東方文化中數學的發展，開始時領先於西方科學千餘每年，但是始終作爲一種craft-oriented的實用主義學科。可以說沒有了神的唯一性支持，人們就不能確信自己能找到這樣一種完美高效的學科，只能在實用的基礎上發展其基礎算數。可以想象，沒有神的完美與唯一性，數學必將發展成現代化學或者微軟軟件這樣，龐大而充滿特例，到處都是修補與查表，怎麼會像現在的完美、簡潔與和諧。 神創論者並不是將難題推與\"神\"然後放任不管，他們相信神是最爲理智的存在，創人時人同樣得到了神的智慧和理智，也就是神可以用人的理智來理解。 引用牛頓《自然哲學的數學原理》中終章的話\"太陽、恆星、行星的這個極精緻的結構不可能存在，除非通過一個有理智的和有權能的存在的設計和主宰……他不是作爲宇宙的靈魂，而是作爲一切的主宰而統治所有……\" 以上…… (發現最近的哲理思維果然慢了不少，寫作思緒也一片混亂&#94;_&#94;)","tags":"import","url":"//farseerfc.me/some-thought-on-creationism.html"},{"title":"由記憶棒誤差故障引發的關於面向對象設計的九點思考","text":"從 farseerfc.wordpress.com 導入 故障描述: MMC Memory Stick Duo記憶棒未經Adapter適配器，直接插入SD Reader，致使MMC卡入SD Reader中。 棧展開： 某日下午，無課。 忙於數分作業，想查詢用手機拍攝的板書照片。 取出手機中的MMC。 未經裝配Adapter，直接插入SD Reader。 (A runtime exception was thrown.) 嘗試翻轉筆記本機身，倒出MMC，未果。(rethrow) 嘗試用手指甲取出，未果。(rethrow) 考慮到有\"推入反彈\"機制，嘗試將MMC推入更深，反彈機制由於類型不匹配而失效，未果。(rethrow) (The exception spread across the border of the model.) 電腦維修技師接手(catch) 技師未能發現問題所在，由我解說原委。 (Because the exception lose the information, RTTI was asked to recall the information) 技師發現問題，嘗試用鑷子鑷出MMC，未果。 技師開解機箱(expose the data structure) 技師製作鉤子，勾出MMC(hooker link to the structure) 取出MMC，故障解除 故障總結 1.接收到沒有完全瞭解、或沒有適當工具解決的exception時，不要嘗試用不成熟的技術解決，應儘快尋求能解決它的代碼。否則，被反覆rethrow的exception，尤其是通過模塊邊界的exception，有可能由subclass退化爲superclass，並因此而喪失一些信息。儘量不要讓exception丟失信息，必要時，通過RTTI機制尋回信息。 2.超負荷運轉，多線程執行，這種種複雜性都有可能導致錯誤，應避免。無論你有多麼信任你的代碼或能力。 3.在設計class的interface時，相匹配的interface應該滿足is-a的關係。因此，任何能插入SD Reader的object，即任何實現了SD interface的object，都應該is-a SD card。這次故障中，interface接受了MMC，但MMC不是SD。即使這種情況下throw an exception，都不能使事態緩和。能提供compile-time error時，儘量讓錯誤以compile-time error的形式展現，並在事先解決。類型匹配問題是應該能在事先解決的問題。 4.Design patterns中的Adapter pattern應該只是迫不得已情況之下的解決方案。只有當你無權改變現狀時，才能使用Adapter。如果能改變現狀，應該改變設計以符合interface。 5.因爲上條，所有相似功能的對象應具有相同的interface，不同的interface是本次故障的根源所在。 6.特殊情況下，破壞封裝機制並expose the data structure是必要的，應該有方法支持這種做法。C的指針和C#的Reflection技術都以不同的方式支持這種做法。其他的一些語言機制，比如serializing(序列化)或streaming(流化)，也可以以某種方式間接支持這一做法。當然，機制還應避免這種做法被濫用。 7.相反功能具有相同操作的設計，容易造成使用的混亂，應適當避免。比如SD Reader的推入反彈設計，即插入和彈出使用同一個向裏推的操作的設計。同樣的設計還包括，C++中的setNewHandle使用同一個函數，同時設置和返回handle。以及有些書中提倡的，使用同名函數重載的方式，實現setter/getter的設計。 8.特殊工具(hooker)對於解決特定問題，通常比手工解決有效。不要嫌麻煩而不願意構造特殊工具。 9.棧語義，即FILO順序，總在不知不覺中影響我們。違反了FILO順序的操作極易造成混亂。本故障發生時正確的處理順序爲： 裝配Adapter 插入SD Reader 讀取數據 停用設備 拔出SD Reader 拆解Adapter 本次故障的原因就是違反了FILO順序，違反了棧語義。","tags":"import","url":"//farseerfc.me/9-thoughts-about-oop-from-wrongly-insert-memory-stick.html"},{"title":"Program Development in Java Preface","text":"從 farseerfc.wordpress.com 導入 程序開發原理 ——抽象、規格與面向對象設計 Barbara Liskov 、John Guttag 著 楊嘉晨 等譯 關於翻譯風格： 多年來閱讀計算機類的著作及譯作，感覺總體的困難在於一大堆沒有標準譯名的技術術語。由於通行於工業界和學術界的還是英文原名和術語，我決定保留大量的英文術語。這樣的翻譯風格借鑑於臺灣著名的譯者和作者侯捷先生。對於譯與不譯的權衡，主要考慮閱讀的流暢，以及讀者的理解能力，或許難免帶有一些主觀色彩。 前言 Preface 構建產品級質量的程序——可以在很長一段時間內使用的程序——衆所周知是極其困難的。本書的目標就是改善程序員解決這項任務的效率。我希望讀者在閱讀本書之後成爲一名好程序員。我相信本書的成功在於改善編程技巧，因爲我的學生告訴我這已經發生在他們身上。 怎麼纔算是一名好程序員？是產生整個程序產品的效率。關鍵是要在每一階段減少浪費掉的努力。解決的方法包括：在開始編寫代碼之前就仔細考慮你的實現方案，通過未雨綢繆的方法來編寫代碼，使用嚴格的測試在早期發現錯誤，以及仔細注意模塊化編程，這樣當錯誤出現時，只需要改動極少數代碼就可以修正整個程序。本書涉及所有這些領域的技術。 模塊化編程(Modularity)是編寫好程序的關鍵。把程序分解成許多小模塊，每一個模塊通過良好定義的狹窄接口和別的模塊交互作用(interact)。有了模塊化，可以修正一部分程序中的錯誤而不考慮程序的其他部分，而且可以僅僅理解一部分程序而不必理解整個程序。沒有模塊化，程序是一大堆有着錯綜複雜的相互關係的部分的拼湊。很難去領悟和修改這樣一個程序，同樣也很難讓它正常工作。 因此本書的重點在於創建模塊化的程序：怎樣把程序組織成一系列精心挑選的模塊。本書認爲模塊化就是抽象(abstraction)。每一個模塊意味着一個抽象，比如說指引一系列文檔中的關鍵字的目錄，或者在文檔中使用目錄來查找匹配某個問題的文檔的過程。着重強調面向對象編程思想——在程序中使用數據抽象和對象的思想。 這本書使用Java作爲它的編程示例的語言。我們沒有假定讀者已經熟悉Java。儘管可能沒什麼價值，但是本書中的思想是語言無關的，並且可以在任何語言的編程中使用。 怎樣使用這本書？ How Can the Book Be Used 本書《程序開發原理》有兩種使用方法。其一是作爲課本教材，講述如何用面向對象的方法來設計和實現複雜系統；其二是編程專家使用，幫助他們改善編程技能，增進他們的關於模塊化和Object-Oriented(面向對象)設計的知識。 作爲教材使用時，本書一般作爲第二或第三門程序設計課程。我們已經在MIT使用本書很多年，給大一大二的本科生教授第二門編程課。在這一階段，學生們已經知道怎樣編寫小程序。課程在兩方面利用這一點：讓學生更仔細地思考小程序，以及教他們如何利用小程序作爲組件構建大型程序。這本書也可以在專業（如軟件工程）後期教學中使用。 建立在本書基礎上的課程適合於所有計算機科學專業。儘管許多學生可能永遠不會成爲真正的大型程序的設計師，他們可以在開發部門工作，在那兒他們負責設計和實現能與整個結構耦合的子系統。模塊化設計的子系統是這種任務中心，這對那些從事大型程序設計任務的人來說也同樣重要。 這本書講什麼？What Is This Book About 通觀全篇三分之二的書致力於討論在構建獨立的程序模塊時產生的問題，剩下的部分討論怎樣運用這些模塊構建大型程序。 程序模塊Program Modules 這一部分的書集中討論抽象機制(abstraction mechanism)。它討論procedure(子程序)和exception(異常)，數據抽象，遍歷(iteration)抽象，數據抽象系列(family)以及多態(polymorphic)抽象。 在對抽象的討論中，三個步驟是重要的。首先是決定被抽象的東西到底是什麼：它提供給它的用戶哪些行爲。創造抽象是設計的關鍵，因此本書討論如何在衆多選擇中挑選，以及怎樣才能創造出好的抽象。 第二步是通過爲一個抽象制定一個規格(specification)來獲取它的意義。如果沒有一些描述，一個抽象就會含糊不清，而變得沒有使用價值。specification則提供了需要的描述。本書定義了一種specification的格式，討論了一份好的specification應有的屬性，並且提供了許多示例。 第三步是實現抽象。本書討論怎樣設計一份實現，以及在簡潔性和執行性能之間怎樣權衡利弊。書中強調封裝(encapsulation)的重要性以及在一份實現中履行規格中定義的行爲的重要性。書中同樣提供一些技術——尤其是不變式斷言(representation invariant)和抽象函數(abstraction function)——來幫助讀者理解代碼和它的原因。不變式斷言和抽象函數都實現到儘可能的程度，這對於除錯和調試很有用。 關於類型層次(type hierarchy)的材料注重討論使用它作爲抽象的技術——一種把相關聯的一組數據抽象歸入同一系列的技術。這裏很重要的一點是，是否應當將一個類型作爲另一個類型的子類。本書定義了替換原則——通過比較子類和父類的specification，來決定是否建立子類關係的方法 [1] 。 本書同樣涉及除錯和調試。書中討論怎樣得到足夠數量的測試情況，來準備通過黑箱和白箱測試，它同樣強調了複查(regression)測試的重要性。 編寫大型程序 Programming in the Large 本書的其後部分講解怎樣用模塊化的方法設計和實現大型程序。它建立在前文有關abstraction和specification的材料的基礎之上。 編寫大型程序涵蓋四個主要議題。首先講解需求分析——怎樣才能領悟程序中需要什麼。本書討論怎樣實施需求分析，也討論書寫產生的需求規格的方式，通過使用一種描述程序的抽象階段的數據模型。使用這種模型將產生一份更爲正式的specification，同時它也使需求檢查更加嚴格，這樣可以更好的領悟需求。 編寫大型程序的第二項議題是程序設計，這通常是一個循序漸進的過程。設計過程圍繞構建有用的抽象來組織，這些抽象作爲整個程序之中理想的構建組建。這些抽象在設計時被仔細的編寫規格，這樣當程序實現時，那些實現抽象的模塊可以獨立地開發。這種設計使用設計筆記編寫文檔，包括描述整個程序結構的模塊間依賴性的圖示。 第三項議題是實現和測試。本書討論了前置設計分析對於實現的必要性，以及怎樣進行設計複審。它同樣討論了設計和實現的順序。這一部分比較了自頂而下與自底而上的組織方式，討論如何使用驅動程序和佔位程序 [2] (stub)，並且強調了制定一個事先的順序策略的必要性，以滿足開發組織和客戶的需求。 本書以一章設計模式(design pattern)結束。一些模式在前面的章節介紹過，比如遍歷抽象是算法的主要組建。最後的章節討論前文中沒有涉及到的模式。希望它作爲這一教材的介紹。有興趣的讀者可以繼續閱讀其它書中更完善的討論 [3] 。 [1] 譯註：如果子類的specification包括了所有父類的specification，就是說父類的要求也是子類的要求，或者子類的要求更爲嚴格，那麼可以建立父子關係。而替換原則的說法是，對於具有父子關係的類，任何需要一個父類對象的地方，都可以替換爲一個子類對象。 [2] 譯註：在測試某一組建時，由於其餘組建還未實現，這一組建與其餘組建的接口銜接部分無法工作。此時可以針對這一組建編寫其餘組建的佔位程序(stub)，預留出接口的銜接代碼。佔位代碼通常不做任何有價值的事情，只報告組建的銜接部位工作正常。 [3] 譯註：作者指的是設計模式的開山之作——《Design Patterns—Elements of Reusable Object-Oriented Software》,作者爲設計模式界著名的\"四人幫\"GoF(Gang of Four)。此書詳盡討論了三大類共23個廣泛使用的設計模式的適用範圍、依存關係、實現細節以及已有的應用領域等問題。書中以C++和Smalltalk爲示例語言，不過書中所涉及的模式適用於所有面向對象的語言。","tags":"import","url":"//farseerfc.me/program-development-in-java-preface.html"},{"title":"C++ Tricks 3.2 標號、goto，以及switch的實現","text":"從 farseerfc.wordpress.com 導入 3.2 標號、goto，以及switch的實現 goto語句及標號(label)是最古老的C語言特性，也是最早被人們拋棄的語言特性之一。像彙編語言中的jmp指令一樣，goto語句可以跳轉到同一函數體中任何標號位置： void f() {int i=0; Loop: //A label ++i; if(i<10)goto Loop; //Jump to the label } 在原始而和諧的早期Fortran和Basic時代，我們沒有if then else，沒有for和while，甚至沒有函數的概念，一切控制結構都靠goto(帶條件的或無條件的)構件。軟件工程師將這樣的代碼稱作\"意大利麪條\"代碼。實踐證明這樣的代碼極容易造成混亂。 自從證明了結構化的程序可以做意大利麪條做到的任何事情，人們就開始不遺餘力地推廣結構化設計思想，將goto像猛獸一般囚禁在牢籠，標號也因此消失。 標號唯一散發餘熱的地方，是在switch中控制分支流程。 很多人不甚瞭解switch存在的意義，認爲它只是大型嵌套if then else結構的縮略形式，並且比if語句多了很多\"不合理\"的限制。如果你瞭解到switch在編譯器內部的實現機制，就不難理解強加在switch之上的諸多限制，比如case後只能跟一個編譯期整型常量，比如用break結束每一個case。首先看一個switch實例： switch (shape.getAngle()) { case 3: cout<<\"Triangle\";break; case 4: cout<<\"Square\";break; case 0:case1: cout<<\"Not a sharp!\";break; default: cout<<\"Polygon\"; } 任何程序員都可以寫出與之對應的if結構： int i= getAngle(shape); if (i==3) cout<<\"Triangle\"; else if(i==4) cout<<\"Square\"; else if(i==0||i==1) cout<<\"Not a sharp!\"; else cout<<\"Polygon\"; 看起來這兩段代碼在語義上是完全一樣的，不是麼？ 不！或許代碼的執行結果完全一樣，但是就執行效率而言，switch版本的更快！ 要了解爲什麼switch的更快，我們需要知道編譯器是怎樣生成switch的實現代碼的： 首先，保留switch之後由{}括起來的語具體，僅將其中case、default和break替換爲真正的標號： switch (getAngle(shape)) { _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 隨後，對於所有出現在case之後的常量，列出一張只有goto的跳轉表，其順序按case後的常量排列： goto _case_0; goto _case_1; goto _case_3; goto _case_4; 然後，計算case之後的常量與跳轉表地址之間的關係，如有需要，在跳轉表中插入空缺的項目： 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; //因爲沒有case 2，所以插入此項以條轉到default 100120: goto _case_3; 100125: goto _case_4; 假設一個goto語句佔用5個字節，那麼在本例中，goto的地址=case後的常量*5+100105 之後，生成跳轉代碼，在其餘條件下跳轉至default，在已知範圍內按照公式跳轉，全部的實現如下： { int i= getAngle(shape); if (i<0||i>=5)goto _default; i=i*5+100105; //按照得出的公式算出跳轉地址 goto i; //僞代碼，C中不允許跳轉到整數，但是彙編允許 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; 100120: goto _case_3; 100125: goto _case_4; _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 經過這樣處理整個switch結構，使得無論switch後的變量爲何值，都可以通過最多兩次跳轉到達目標代碼。相比之下if版本的代碼則採用線性的比較和跳轉，在case語句很多的情況下效率極低。 由此,我們也可以知道,爲什麼case後跟的一定是編譯期整型常數，因爲編譯器需要根據這個值製作跳轉表。我們可以明白爲什麼case與case之間應該用break分隔，因爲編譯器不改變switch語句體的結構，case其本身只是一個具有語義的標號而已，要想跳出switch，就必須用break語句。","tags":"import","url":"//farseerfc.me/c-tricks-3-2-label-goto-and-implementation-of-switch.html"},{"title":"C++ Tricks 3.1 左值右值與常量性(lvalue，rvalue & constant)","text":"從 farseerfc.wordpress.com 導入 3.1 左值右值與常量性(lvalue，rvalue & constant) 首先要搞清楚的是，什麼是左值，什麼是右值。這裏給出左值右值的定義： 1、左值是可以出現在等號(=)左邊的值，右值是隻能出現在等號右邊的值。 2、左值是可讀可寫的值，右值是隻讀的值。 3、左值有地址，右值沒有地址。 根據左值右值的第二定義，值的左右性就是值的常量性——常量是右值，非常量是左值。比如： 1=1;//Error 這個複製操作在C++中是語法錯誤，MSVC給出的錯誤提示爲\"error C2106: '=' : left operand must be l-value\"，就是說'='的左操作數必須是一個左值，而字面常數1是一個右值。可見，嚴格的區分左值右值可以從語法分析的角度找出程序的邏輯錯誤。 根據第二定義，一個左值也是一個右值，因爲左值也可讀，而一個右值不是一個左值，因爲右值不可寫。 通常情況下，聲明的變量是一個左值，除非你指定const將它變成一個右值： int lv=1; const int rv=lv; 由於右值的值在程序執行期間不能改變，所以必須用另一個右值初始化它。 一個普通變量只能用右值初始化，如果你想傳遞左值，必須聲明一個引用或一個指針： int & ref=lv;//用引用傳遞左值 int * plv=&lv;//傳遞指針以間接傳遞左值 必須用左值初始化引用，然而，可以用右值初始化常量引用： int & r1=1; //Error! const int & r2=1; //OK 這實際上相當於： int _r2=1; const int & r2=_r2; 這樣的寫法在函數體內沒什麼作用，但是在傳遞函數參數時，它可以避免潛在的(傳遞左值時的)複製操作，同時又可以接受右值。 通常情況下，函數的參數和返回值都只傳回右值，除非你明確的通過引用傳遞左值。 明確了左值與右值的區別，有助於我們寫函數時確定什麼時候應該有const，什麼時候不該有。比如，我們寫了一個代表數學中複數的類Complex： class Complex; 然後，我們寫針對Complex的運算符重載：operator+和operator=。問題在於，參數和返回值應該是什麼類型，可選類型有四種： Complex、const Complex、Complex&、const Complex&。 對於operator+，我們不會改變參數的值，所以可以通過const Complex&傳遞參數。至於返回值類型，由於int類型的加法返回右值，所以根據Do as the ints do的原則，返回值類型爲const Complex： const Complex operator+(const Complex&,const Complex&); 對於operator=，同樣要思考這些問題。我們寫入第一個參數，所以第一個參數爲Complex&，我們只讀取第二個參數，所以第二個參數爲const Complex&。至於返回值，還是Do as the ints do。int的賦值返回左值，不信你可以試一試： int i; (i=1)=2; 雖然比較傻，先將i賦爲1，再將其改爲2，但是這是被C++語法支持的做法，我們就理應遵守。所以返回第一個參數的左值： Complex& operator=(Complex&,const Complex&); const是C++引入的語言特性，也被ANSI C99借鑑，在經典版本的C語言中是沒有的。關於const的歷史，有幾點值得玩味。最初Bjarne Stroustrup引入const時，可寫性是和可讀性分開的。那時使用關鍵字readonly和writeonly。這個特點被首先提交到C的ANSI標準化委員會(當時還沒有C++標準化的計劃)，但是ANSI C標準只接受了readonly的概念，並將其命名爲const。隨後，有人發現在多線程同步的環境下，有些變量的值會在編譯器的預料之外改變，爲了防止過度優化破壞這些變量，C++又引入關鍵字violate。從語義特點來看，violate是const的反義詞，因爲const表示不會變的量，而violate表示會不按照預期自行變化的量。從語法特點而言，violate與const是極爲相似的，適用於const的一切語法規則同樣適用於violate。 值的常量性可以被劃分爲兩種：編譯期常量和運行期常量。C++語法並沒有嚴格區分這兩種常量，導致了少許混亂： const int i=5;const int * pi=&i; const_cast<int&>i=1;//對於運行期常量，在需要時可以去除它的常量性 int a[i];//對於編譯期常量，可以用它來指定數組大小 cout<<i<<sizeof(a)/sizeof(a[0])<<*pi; 這種將編譯期與運行期常量的特性混用的方法，勢必導致語義的混亂。數組a的大小最終是5，因爲採用了i的編譯期值，而不管i在運行期是否被改變了值。最後一句代碼將（有可能）輸出551，第一個i的值作爲一種優化在編譯期綁定，第二個值標明瞭a的大小，第三個值通過指針顯示地輸出i的運行期真實值。 在C++的近親C#的語法中，這兩種常量被嚴格地區分開：編譯期常量由const指定，只能是內建類型變量；運行期常量由readonly指定，可以是任何類型。永遠不會改變的常量，如圓周率pi的值，應該用const聲明；而其它有可能改變的常量，皆由readonly聲明。 C++中的const的特點更傾向於C#中的readonly，雖然語法上允許使用const的編譯期常量性，但正如上文所展示的，這容易造成混亂。爲了得到C#中const的語義，在C++中，我們不必迴歸惡魔#define的懷抱，可以使用所謂\"匿名enum技巧\"。當匿名聲明一個enum類型時，其中的枚舉值就是一個int類型的編譯期常量，比如： enum{Size=5;}; int a[Size]; 這種使用匿名enum來聲明編譯期常量的做法，被廣泛應用於STL、boost等模板庫的實現代碼中。","tags":"import","url":"//farseerfc.me/c-tricks-3-1-lvalue-rvalue-constant.html"},{"title":"C++ Tricks 2.2 I386平臺的內存佈局","text":"從 farseerfc.wordpress.com 導入 2.2 I386平臺的內存佈局 衆所周知，I386是32位體系結構。因此對於絕大多數I386平臺的C++編譯器而言，sizeof(int)=sizeof(long)=sizeof(void*)=4。當然C++標準對此沒有任何保證，我們也不應該試圖編寫依賴於此的代碼。 32位指針的可尋址空間爲4GB。爲充分利用這麼大的尋址空間，也是爲了支持其它更先進的技術比如多任務技術或者動態鏈接庫技術，WinNT使用虛擬內存技術，給與每個應用程序全部4GB的內存空間。4GB的地址被一分爲二，前2GB供應用程序自己使用，後2GB由系統內核分配和管理。這2GB的內存地址，通常被劃分成3種內存區使用： 1 代碼及靜態數據區 由代碼加載器從動態鏈接庫鏡像(通常是exe或dll文件)加載，通常定位到鏡像文件中指定的基址開始的內存區。如果基址所在內存已被佔用，動態連接器會將代碼或數據重定向到其它可用地址。 在C++中，靜態數據包括：名字空間(namespace)和全局(global)對象、函數的static對象、類的static數據成員。這些靜態數據由編譯器分配地址(但可能被重定向)，由靜態連接器寫入代碼文件(通常是exe或dll)的靜態數據區段。所以標準說，這些靜態數據在編譯期就已經具有地址。 2 棧(Stack) 棧是最常用的動態數據存儲區，所有函數的non-static對象和函數參數都在程序運行期在棧上分配內存。在數據結構中，術語\"棧(Stack)\"意指先進後出(FILO，First In Last Out)，與\"隊列(Queue)\"所指的FIFO相對。相對於基於堆的對象分配技術，默認使用棧的對象分配有兩點優勢： 一、棧的FILO與人的思維方式相同 現實生活中有許多事例都使用FILO的方式，比如人們必須先提起話筒再撥打號碼，而後掛斷電話之後再放下話筒。使用FILO的棧，可以保證事物的銷燬順序以其誕生順序相反的順序進行，不會產生在掛斷電話之前就放下話筒的尷尬。 二、棧的分配管理僅需要兩個額外指針：棧頂(esp)和棧底(ebp)指針 從實現的技術層面而言，棧的管理比其它動態分配技術要簡單很多。I386平臺上的動態棧管理，僅需要棧頂和棧底兩個指針。這兩個指針的存儲顯然不能放置於棧中，置於靜態數據區又有損效率。I386平臺爲管理動態棧專門預留了兩個通用寄存器變量esp與ebp，分別代表棧頂(esp,Extended Stack Pointer)與棧底(Extended Bottom Pointer)指針。其中的extended代表它們是32位指針，以區分16位的sp和bp寄存器。 棧是動態存儲區的特點，表明它的內存佔用將隨着程序的運行而變化。I386平臺上WinNT將應用程序的棧置於程序空間，向下增長。程序初始化時，由操作系統將esp指向系統分配的棧空間的頂部。當程序需要在棧上分配變量時，就將esp減去變量所需字節數，這被稱作\"壓棧(Push)\"；隨後又要銷燬變量時，就將esp加上變量所需字節數，這被稱作\"彈出(Pop)\"。esp與ebp兩者之間所夾的空間，就是當前函數正在使用的棧空間。由於棧向下增長，esp(棧頂)的值總是小於ebp(棧底)的值，新分配的變量地址總是小於舊變量的地址。 3 堆(Heap)和自由存儲區 棧中的變量對於分配與釋放的順序有特定要求，這在一定程度上限制了棧的適用範圍。面向對象(OO，Object Oriented)的程序設計思想也要求能自由地控制變量的分配與銷燬。由此，現代操作系統都提供了被稱作\"堆(Heap)\"的自由存儲區，以允許由程序員控制的對象創建和銷燬過程。C標準庫函數malloc和free則是對操作系統提供的堆操作的封裝。C++提供的自由存儲區運算符new和delete則通常是malloc和free的又一層封裝。 操作系統經由malloc和free控制對堆的訪問。堆的存儲管理技術各不相同，簡單的使用雙鏈表管理，複雜的可以比擬一個完整的文件系統。 由於額外的管理需求，使用系統提供的通用分配器在堆上分配和銷燬變量的代價，無論從空間角度還是效率角度而言，都比在棧上分配對象要高昂很多。對於sizeof上百的大型對象，這樣的高昂代價還是可以接受的，但是對於sizeof只有個位數的小對象，這樣的代價通常是一個數量級的差距。正因爲這個原因，STL不使用new和delete，轉而使用分配子(alllocor)分配對象。","tags":"import","url":"//farseerfc.me/c-tricks-2-2-i386-memory-layout.html"},{"title":"C++ Tricks","text":"從 farseerfc.wordpress.com 導入 C++ Tricks By FarseerFc 從今天起，我再將在 Live Space 和 QQZone 同時發表一系列文章，暫定名爲\"C++Tricks\"。 本文旨在記錄和闡述一些本人學習C++時所得的心得、技巧。總體來看，本文涉及的內容是每一個C++程序員都應該知道的，但是很少見諸C++教材。希望對各位同仁學習C++有所幫助。 也可以通過QQ或MSN向我索要此文的DOC版或PDF版，會比網頁上的更新的快一點。 1 詞法問題(Lexical Problems) 1.1 條件運算符(?:) 1.2 逗號運算符(,)、邏輯運算符(&&,||)與運算符重載的陷阱 2 X86體系結構 2.1 X86概述 2.2 I386平臺的內存佈局 2.3 I386平臺C函數內部的棧分配 2.4 I386平臺C函數調用邊界的棧分配 2.5 I386平臺的邊界對齊(Align) 2.6 I386平臺C函數的可變參數表(Variable Arguments) 2.7 I386平臺的其它函數調用模型 3 過程式編程 3.1 左值右值與常量性(lvalue，rvalue & constant) 3.2 標號、goto，以及switch的實現","tags":"import","url":"//farseerfc.me/c-tricks.html"},{"title":"C++ Tricks 2.3 I386平臺C函數內部的棧分配","text":"從 farseerfc.wordpress.com 導入 2.3 I386平臺C函數內部的棧分配 函數使用棧來保存局部變量，傳遞函數參數。進入函數時，函數在棧上爲函數中的變量統一預留棧空間，將esp減去相應字節數。當函數執行流程途徑變量聲明語句時，如有需要就調用相應構造函數將變量初始化。當執行流程即將離開聲明所在代碼塊時，以初始化的順序的相反順序逐一調用析構函數。當執行流程離開函數體時，將esp加上相應字節數，歸還棧空間。 爲了訪問函數變量，必須有方法定位每一個變量。變量相對於棧頂esp的位置在進入函數體時就已確定，但是由於esp會在函數執行期變動，所以將esp的值保存在ebp中，並事先將ebp的值壓棧。隨後，在函數體中通過ebp減去偏移量來訪問變量。以一個最簡單的函數爲例： void f() { int a=0; //a的地址被分配爲ebp-4 char c=1; //c的地址被分配爲ebp-8 } 產生的彙編代碼爲： push ebp ;將ebp壓棧 mov ebp,esp ;ebp=esp 用棧底備份棧頂指針 sub esp,8 ;esp-=8，爲a和c預留空間，包括邊界對齊 mov dword ptr[ebp-4],0 ;a=0 mov byte ptr[ebp-8],1 ;c=1 add esp,8 ;esp+=8，歸還a和c的空間 mov esp,ebp ;esp=ebp 從棧底恢復棧頂指針 pop ebp ;恢復ebp ret ;返回 相應的內存佈局是這樣： 09992:c=1 <-esp 09996:a=0 10000:舊ebp <-ebp 10004:…… 注:彙編中的pop、push、call、ret語句是棧操作指令，其功能可以用普通指令替換 push ebp相當於: add esp,4 mov dword ptr[esp],ebp pop ebp相當於： mov ebp,dword ptr[esp] sub esp,4 call fun_address相當於： push eip jmp fun_address ret相當於 add esp,4 jmp dword ptr[esp-4] 帶參數的ret ret 8相當於 add esp,12 jmp dword ptr[esp-4] 所有局部變量都在棧中由函數統一分配，形成了類似逆序數組的結構，可以通過指針逐一訪問。這一特點具有很多有趣性質，比如，考慮如下函數，找出其中的錯誤及其造成的結果： void f() { int i,a[10]; for(i=0;i<=10;++i)a[i]=0;/An error occurs here! } 這個函數中包含的錯誤，即使是C++新手也很容易發現，這是老生常談的越界訪問問題。但是這個錯誤造成的結果，是很多人沒有想到的。這次的越界訪問，並不會像很多新手預料的那樣造成一個\"非法操作\"消息，也不會像很多老手估計的那樣會默不作聲，而是導致一個，呃，死循環！ 錯誤的本質顯而易見，我們訪問了a[10]，但是a[10]並不存在。C++標準對於越界訪問只是說\"未定義操作\"。我們知道，a[10]是數組a所在位置之後的一個位置，但問題是，是誰在這個位置上。是i! 根據前面的討論，i在數組a之前被聲明，所以在a之前分配在棧上。但是，I386上棧是向下增長的，所以，a的地址低於i的地址。其結果是在循環的最後，a[i]引用到了i自己！接下來的事情就不難預見了，a[i]，也就是i，被重置爲0，然後繼續循環的條件仍然成立……這個循環會一直繼續下去，直到在你的帳單上產生高額電費，直到耗光地球電能，直到太陽停止燃燒……呵呵，或者直到聰明的你把程序Kill了……","tags":"import","url":"//farseerfc.me/c-tricks-2-3-i386-stack-allocation-in-c-functions.html"},{"title":"C++ Tricks 2.4 I386平臺C函數調用邊界的棧分配","text":"從 farseerfc.wordpress.com 導入 2.4 I386平臺C函數調用邊界的棧分配 當調用一個函數時，主調函數將參數以聲明中相反的順序壓棧，然後將當前的代碼執行指針(eip)壓棧，然後跳轉到被調函數的入口點。在被調函數中，通過將ebp加上一個偏移量來訪問函數參數，以聲明中的順序(即壓棧的相反順序)來確定參數偏移量。被調函數返回時，彈出主調函數壓在棧中的代碼執行指針，跳回主調函數。再由主調函數恢復到調用前的棧。 函數的返回值不同於函數參數，通過寄存器傳遞。如果返回值類型可以放入32位變量，比如int、short、char、指針等類型，通過eax寄存器傳遞。如果返回值類型是64位變量，如_int64，同過edx+eax傳遞，edx存儲高32位，eax存儲低32位。如果返回值是浮點類型，如float和double，通過專用的浮點數寄存器棧的棧頂返回。如果返回值類型是用戶自定義結構，或C++類類型，通過修改函數簽名，以引用型參數的形式傳回。 同樣以最簡單的函數爲例： void f(){ int i=g(1,2); } int g(int a,int b){ int c=a+b； return c; } 產生的彙編代碼如下： f: push ebp ;備份ebp mov ebp,esp ;建立棧底 sub esp,4 ;爲i分配空間 mov eax,2 ;準備參數b的值2 push eax ;將b壓棧 mov eax,1 ;準備參數a的值1 push eax ;將a壓棧 call g ;調用g add esp,8 ;將a和b一起彈出，恢復調用前的棧 mov dword ptr[ebp-4],eax ;將返回值保存進變量i mov esp,ebp ;恢復棧頂 pop ebp ;恢復棧底 g: push ebp ;備份ebp mov ebp,esp ;建立棧底 sub esp,4 ;爲局部變量c在棧中分配內存 mov eax,dword ptr[ebp+8] ;通過ebp間接讀取參數a的值 mov ebx,dword ptr[ebp+12] ;通過ebp間接讀取參數b的值 add eax,ebx ;將a和b的值相加，之和存在eax中 mov dword ptr[ebp-4],eax ;將和存入變量c mov eax,dword ptr[ebp-4] ;將c作爲返回值，代碼優化後會刪除此句 add esp,4 ;銷燬c的內存 mov esp,ebp ;恢復棧頂 pop ebp ;恢復棧底 ret ;返回函數f 棧的內存佈局如下： 100076:c <- g的esp 100080:f的ebp=100100 <- g的ebp 100084:f的eip 100088:a=1 100092:b=2 100096:i 100100:舊ebp <-f的ebp 100104:…… 注意在函數g的彙編代碼中，訪問函數的局部變量和訪問函數參數的區別。局部變量總是通過將ebp減去偏移量來訪問，函數參數總是通過將ebp加上偏移量來訪問。對於32位變量而言，第一個局部變量位於ebp-4，第二個位於ebp-8，以此類推，32位局部變量在棧中形成一個逆序數組；第一個函數參數位於ebp+8，第二個位於ebp+12，以此類推，32位函數參數在棧中形成一個正序數組。 由於函數返回值通過寄存器返回，不需要空間分配等操作，所以返回值的代價很低。基於這個原因，舊的C語法約定，不寫明返回值類型的函數，返回值類型爲int。這一規則與現行的C++語法相違背，因爲C++中，不寫明返回值類型的函數返回值類型爲void，表示不返回值。這種語法不兼容性是爲了加強C++的類型安全，但同時也帶來了一些問題。","tags":"import","url":"//farseerfc.me/c-tricks-2-4-i386-stack-allocation-accross-function-invocation.html"},{"title":"C++ Tricks 2.5 I386平臺的邊界對齊(Align)","text":"從 farseerfc.wordpress.com 導入 2.5 I386平臺的邊界對齊(Align) 首先提問，既然I386上sizeof(int)==4、sizeof(char)==1，那麼如下結構(struct)A的sizeof是多少？ struct A{int i;char c;}; 答案是sizeof(A)==8……1+5=8？ 呵呵，這就是I386上的邊界對齊問題。我們知道，I386上有整整4GB的地址空間，不過並不是每一個字節上都可以放置任何東西的。由於內存總線帶寬等等的技術原因，很多體系結構都要求內存中的變量被放置於某一個邊界的地址上。如果違反這個要求，重則導致停機出錯，輕則減慢運行速度。對於I386平臺而言，類型爲T的變量必須放置在sizeof(T)的整數倍的地址上，char可以隨便放置，short必須放在2的整數倍的地址上，int必須放在4的整數倍的地址上，double必須放在8的整數倍的地址上。如果違反邊界對齊要求，從內存中讀取數據必須進行兩次，然後將獨到的兩半數據拼接起來，這會嚴重影響效率。 由於邊界對齊問題的要求，在計算struct的sizeof的時候，編譯器必須算入額外的字節填充，以保證每一個變量都能自然對齊。比如如下聲明的struct: struct WASTE { char c1; int i; char c2; } 實際上相當於聲明瞭這樣一個結構： struct WASTE { char c1; char _filling1 [3];//三個字節填充，保證下一個int的對齊 int i; char c2； char _filling2 [3];//又三個字節填充 } 值得注意的是尾部的3個字節填充，這是爲了可以在一個數組中聲明WASTE變量，並且每一個都自然對齊。因爲有了這些填充，所以sizeof(WASTE)==12。這是一種浪費，因爲只要我們重新安排變量的聲明，就可以減少sizeof： struct WASTE { int i; char c1,c2; } 像這樣的安排，sizeof就減少到8，只有2個字節的額外填充。爲了與彙編代碼相兼容，C語言語法規定，編譯器無權擅自安排結構體內變量的佈局順序，必須從左向右逐一排列。所以，妥當安排成員順序以避免內存空間的浪費，就成了我們程序員的責任之一。一般的，總是將結構體的成員按照其sizeof從大到小排列，double在最前，char在最後，這樣總可以將結構的字節填充降至最小。 C++繼承了C語言關於結構體佈局的規定，所以以上的佈局準則也適用於C++的class的成員變量。C++進一步擴展了佈局規定，同一訪問區段(private、public、protected)中的變量，編譯器無權重新排列，不過編譯器有權排列訪問區段的前後順序。基於這個規則，C++中有的程序員建議給每一個成員變量放在單獨區段，在每一個成員聲明之前都加上private:、public:、protected:標誌，這可以最大限度的利用編譯器的決策優勢。 在棧中按順序分配的變量，其邊界也受到對齊要求的限制。與在結構中不同的是，棧中的變量還必須保證其後續變量無論是何種類型都可以自由對齊，所以在棧中的變量通常都有平臺相關的對齊最小值。在MSVC編譯器上，這個最小值可以由宏_INTSIZEOF(T)查詢： #define _INTSIZEOF(T) ( (sizeof(T) + sizeof(int) - 1) & ~(sizeof(int) - 1) ) _INTSIZEOF(T)會將sizeof(T)進位到sizeof(int)的整數倍。 由於在棧中分配變量使用_INTSIZEOF而不是sizeof，在棧上連續分配多個小變量(sizeof小於int的變量)會造成內存浪費，不如使用結構(struct)或數組。也就是說： char c1,c2,c3,c4;//使用16字節 char c[4];//使用4字節 當然，使用數組的方法在訪問數組變量(比如c[1])時有一次額外的指針運算和提領(dereference)操作，這會有執行效率的損失。這又是一種空間(內存佔用)vs時間(執行效率)的折中，需要程序員自己根據情況權衡利弊。 sizeof的大小可能比我們預期的大，也可能比我們預期的小。對於空類： class Empty {}; 在通常情況下，sizeof(Empty)至少爲1。這是因爲C++語法規定，對於任何實體類型的兩個變量，都必須具有不同的地址。爲了符合語法要求，編譯器會給Empty加入1字節的填充。所以sizeof()的值不可能出現0的情況。可是對於以下的類聲明： class A:public Empty{vitual ~A(){}}; sizeof(A)有可能是6，也有可能是5，也有可能是4！必不可少的四個字節是一個指向虛函數表的指針。一個可能有的字節是Empty的大小，這是是因爲編譯器在特定情況下會將Empty視作一個\"空基類\"，從而實施\"空基類優化\"，省掉那毫無作用的一字節填充。另一個字節是A的一字節填充，因爲從語法上講，A沒有成員聲明，理應有1字節填充，而從語義上講，編譯器給A的聲明加入了一個指向虛函數表的指針，從而A就不再是一個\"空類\"，是否實施這個優化，要看編譯器作者對語法措詞的理解。也就是說，sizeof也會出現4+1+1=4的情況。具體要看編譯器有沒有實施\"空基類優化\"和\"含虛函數表的空類優化\"。 結構和類的空間中可能有填充的字節，這意味着填充字節中可能有數值，雖然這數值並不影響結構的邏輯狀態，但是它也可能不知不覺中影響到你。比如說，你手頭正好有一組依賴於底層硬件(比如多處理器)的函數，他們在操縱連續字節時比手動編碼要快很多，而你想充分利用這種硬件優勢： bool BitCompare(void* begin,void* end,void* another); 這個函數將區間[begin,end)之間的字節與another開始的字節相比較，如果有一位不同就返回false，否則返回true。 比如你想將這個函數用於你自己的類的operator==中，這樣可以利用硬件加快速度。不過你在動手前要充分考慮，你的class是否真的要比較每一位。如果在類的成員中存在編譯器填充的字節數，那麼應用以上的函數就是不正確的，因爲填充的字節中可以有不同的值。爲了保證你可以用Bitwise Compare，你必須確保填充的字節中的值也是相同的。這不僅要求你在類的構造函數中初始化類的每一bit而不是每一個成員，也要求你在複製初始化和複製賦值函數中也同時保證bitwise copy語義，而不是編譯器默認產生的memberwise語義。當然，你可能通過與BitCompare一同提供的BitCopy來完成這個艱鉅的任務。","tags":"import","url":"//farseerfc.me/c-tricks-2-5-address-alignment.html"},{"title":"C++ Tricks 2.6 I386平臺C函數的可變參數表(Variable Arguments)","text":"從 farseerfc.wordpress.com 導入 2.6 I386平臺C函數的可變參數表(Variable Arguments) 基於前文(2.4節)分析，我們可以不通過函數簽名，直接通過指針運算，來得到函數的參數。由於參數的壓棧和彈出操作都由主調函數進行，所以被調函數對於參數的真實數量不需要知曉。因此，函數簽名中的變量聲明不是必需的。爲了支持這種參數使用形式，C語言提供可變參數表。可變參數表的語法形式是在參數表末尾添加三個句點形成的省略號\"...\"： void g(int a,char* c,...); 省略號之前的逗號是可選的，並不影響詞法語法分析。上面的函數g可以接受2個或2個以上的參數，前兩個參數的類型固定，其後的參數類型未知，參數的個數也未知。爲了知道參數個數，我們必須通過其他方法，比如通過第一個參數傳遞： g(3,\"Hello\",2,4,5);//調用g並傳遞5個參數，其中後3個爲可變參數。 在函數的實現代碼中，可以通過2.4節敘述的，參數在棧中的排列順序，來訪問位於可變參數表的參數。比如: void g(int a,char* c...){ void *pc=&c;int* pi=static_cast<int*>(pc)+1;//將pi指向首個可變參數 for(int i=0;i<a;i++)std::cout<<pi[i]<<\" \"； std::cout<<c<<std::endl; } 我們甚至可以讓一個函數的所有參數都是可變參數，只要有辦法獲知參數的數量即可。比如，我們約定，在傳遞給addAll的參數都是int，並且最後一個以0結束： int addAll(...); int a=f(1,4,2,5,7,0); 那麼addAll可以這樣實現： int addAll(...){ int sum=0;int *p=&sum; //p指向第一個局部變量 p+=3; //跳過sum，ebp，eip，現在p指向第一個參數 for(;*p;++p) //如果p不指向0就繼續循環 sum+=*p; return sum; } 可變參數表的最廣泛應用是C的標準庫函數中的格式化輸入輸出：printf和scanf。 void printf(char *c,...); void scanf(char *c,...); 兩者都通過它的首個參數指出後續參數表中的參數類型和參數數量。 如果可變參數表中的參數類型不一樣，那麼操縱可變參數表就需要複雜的指針運算，並且還要時刻注意邊界對齊(align)問題，非常令人頭痛。好在C標準庫提供了用於操縱可變參數表的宏(macro)和結構(struct)，他們被定義在庫文件stdarg.h中: typedef struct {char *p;int offset;} va_list; #define va_start(valist,arg) #define va_arg(valist,type) #define va_end(valist) 其中結構va_list用於指示參數在棧中的位置，宏va_start接受一個va_list和函數的可變參數表之前的參數，通過第一個參數初始化va_list中的相應數據，因此要使用stdarg.h中的宏，你的可變參數表的函數必須至少有一個具名參數。va_arg返回下一個類型爲type的參數，va_end結束可變參數表的使用。還是以上文的addAll爲例，這次寫出它的使用標準宏的版本： int addAll(int i,...) { va_list vl; //定義一個va_list結構 va_start(vl,i); //用省略號之前的參數初始化vl if(i=0)return 0; //如果第一個參數就是0，返回 int sum=i; //將第一個參數加入sum for(;;){ i=va_arg(vl,int); //取得下一個參數，類型是sum if(i==0)break; //如果參數是0，跳出循環 sum+=i; } va_end(vl); return sum; } 可以看出，如果參數類型一致，使用標準庫要多些幾行代碼。不過如果參數類型不一致或者未知(printf的情況)，使用標準庫就要方便很多，因爲我們很難猜出編譯器處置邊界對齊(align)等彙編代碼的細節。使用標準庫的代碼是可以移植的，而使用上文所述的其它方法操縱可變參數表都是不可移植的，僅限於在I386平臺上使用。 縱使可變參數表有使用上的便利性，它的缺陷也有很多，不可移植性和平臺依賴性只是其一，最大的問題在於它的類型不安全性。使用可變參數表就意味着編譯器不對參數作任何類型檢查，這在C中算是一言難盡的歷史遺留問題，在C++中就意味着惡魔reinterpret_cast被你喚醒。C的可變參數表是C++代碼錯誤頻發的根源之一，以至於C++標準將可變參數表列爲即將被廢除的C語言遺留特性。C++語法中的許多新特性，比如重載函數、默認參數值、模板，都可以一定程度上替代可變參數表，並且比可變參數表更加安全。 可變參數表在C++中惟一值得嘉獎的貢獻，是在模板元編程(TMP)的SFINAE技術中利用可變參數表製作最差匹配重載。根據C++標準中有關函數重載決議的規則，具有可變參數表的函數總是最差匹配，編譯器在被逼無奈走頭無路時纔會選擇可變參數表。利用這一點，我們可以精心製作重載函數來提取類型信息。比如，要判斷一個通過模板傳遞來的類型是不是int： long isIntImp(int); char isIntImp(...); template<typename T> struct isInt { enum{value=sizeof(isIntImp(T()))==sizeof(long);} } 然後，在一個具有模板參數T的函數中，我們就可以寫 if(isInt<T>::value)//... 在這個(不怎麼精緻的)例子中，如果T是int，那麼isIntImp的第一個重載版本就會被選中，返回值類型就是long，這樣value就爲1。否則，編譯器只能選中第二個具有可變參數表的重載版本，返回值類型成爲char，這樣value就爲0。把它說得再明白一些，上文的代碼所表達的意思是：如果類型T是int，那它就是int，否則它就不是int，呵呵簡單吧。這種通過重載決議規則來提取類型信息的技術，在模板元編程中被稱作SFINAE，它和其它模板元編程技術被廣泛運用於STL、Boost等模板庫的開發實現之中。 值得注意的是，在上文SFINAE的運用中，isIntImp並沒有出現定義而只提供了聲明，因爲我們並沒有實際調用isIntImp函數，而只是讓它參與重載決議並用sizeof判斷其返回值類型。這是C++的一個設計準則的完美體現：不需要的東西可以不出現。由於這一準則，我們避免了在C++中調用具有可變參數表的函數這一危險舉動，而僅僅利用了可變參數表在語法分析過程中的特殊地位，這種對於危險語言特性的巧妙利用是善意而無害的。","tags":"import","url":"//farseerfc.me/c-tricks-2-6-i386-variable-arguments.html"},{"title":"C++ Tricks 2.7 I386平臺的其它函數調用模型","text":"從 farseerfc.wordpress.com 導入 2.7 I386平臺的其它函數調用模型 上文介紹的只是I386平臺上C函數調用的標準模型，被稱作__cdecl。事實上，Microsoft Visual C++編譯器還支持其它一些函數調用模型，所有調用模型名稱皆以雙下劃線開頭，下面列出所有函數調用模型的異同： 1 __cdecl 參數壓棧順序：逆序(從右至左) 參數堆棧恢復者：主調函數(caller) __cdecl明確地指出函數使用C函數調用模型，這是默認的調用模型。 2 __stdcall 參數壓棧順序：逆序(從右至左) 參數堆棧恢復者：被調函數(callee) __stdcall是微軟所謂的標準調用模型。可惜的是它與__cdecl不兼容。幾乎所有的Win32API函數使用這種函數調用模型，希望在DLL之間，或者在程序和WinNT操作系統之間傳遞函數指針的函數也應該使用這種模型。與__cdecl模型的不同之處在於，__stdcall模型下由被調函數恢復堆棧。主調函數在call語句之後，不需要再加上add語句。而被調函數的ret語句則被添加一個參數，代表函數參數堆棧的長度。因此，被調函數需要明確的知曉函數參數的數量和類型，所以在__stdcall模型下不支持可變參數表，所有參數必須寫明。 3 __thiscall 參數壓棧順序：逆序(從右至左)，this用ecx傳遞。 參數堆棧恢復者：被調函數(callee) __thiscall是VC編譯器中類的非靜態成員函數(non-static member functon)的默認調用模型。但是如果此成員函數有可變參數表，VC編譯器會使用__cdecl。和__stdcall一樣，__thiscall由被調函數恢復堆棧。比較獨特的是__thiscall會通過ecx寄存器傳遞成員函數的this指針，而__cdecl下this指針是通過在參數表最前面增加一個函數參數來傳遞的。__thiscall是VC編譯器對this指針的使用的一種優化，大大提高了面向對象程序的效率。在VC2003及之前的編譯器上__thiscall不是一個關鍵字，不能被顯式指定。但可以給成員函數顯式指定__cdecl來避免使用__thiscall。 4 __fastcall 參數壓棧順序：逆序(從右至左)，前兩個32位函數參數放入ecx和edx中 參數堆棧恢復者：被調函數(callee) 快速函數調用模型，將前兩個32位函數參數放入ecx和edx中，其餘參數再逆序壓棧。使用的是和__thiscall類似的優化技術，加快函數調用，適合運用在小型inline函數上。同樣使用__stdcall形式的被調函數恢復堆棧，所以不支持可變參數表。 5 __pascal 參數壓棧順序：正序(從左至右) 參數堆棧恢復者：被調函數(callee) 過程式編程語言Pascal所使用的函數調用模型，由此得名。也是16位版本的Windows使用的API模型，過時的模型，現在已經廢棄且禁止使用。你會看到有些書本仍會不時提到它，所以需要注意。__pascal是正序壓棧，這與大部分I386函數模型都不相同。與__stdcall一樣，由被調者恢復堆棧，不支持可變參數表。歷史上曾有過的別名PASCAL、pascal、_pascal(單下劃線)，現在都改成了__stdcall的別名，與__pascal(雙下劃線)不同。 6 其它函數調用模型，以及模型別名。 __syscall：操作系統內部使用的函數調用模型，由用戶模式向核心模式跳轉時使用的模型。由於用戶模式和核心模式使用不同的棧，所以沒辦法使用棧來傳遞參數，所有參數通過寄存器傳遞，這限制了參數的數量。用戶模式編程中不允許使用。 __fortran：數學運算語言fortran使用的函數模型，由此得名。在C中調用由fortran編譯的函數時使用。 __clrcall：微軟.Net框架使用的函數模型，託管(Managed)C++默認使用，也可以從非託管代碼調用託管函數時使用。參數在託管棧上正序(從左至右)壓棧，不使用普通棧。 CALLBACK、PASCAL、WINAPI、APIENTRY、APIPRIVATE：I386平臺上是__stdcall的別名 WINAPIV：I386平臺上是__cdecl的別名 7 函數調用模型的指定 函數調用模型的指定方式和inline關鍵字的指定方式相同，事實上，inline可以被看作是C++語言內建的一種函數調用模型。唯一不同的是，聲明函數指針時，也要指明函數調用模型，而inline的指針是不能指明的，根本不存在指向inline函數的指針。比如： int CALLBACK GetVersion(); int (CALLBACK * pf)()=GetVersion;","tags":"import","url":"//farseerfc.me/c-tricks-2-7-i386-calling-conventions.html"},{"title":"C++ Tricks 2.1 X86概述","text":"從 farseerfc.wordpress.com 導入 2.1 X86概述 所謂X86體系結構，是指以Intel 8086芯片爲首的芯片所沿襲的CPU結構，一些文檔中又被稱作IA32體系結構。包括的芯片有但不限於:Intel 8086至 80486，奔騰(Pentium)系列處理器1至4，賽揚系列處理器，酷睿系列處理器，以及AMD的相應型號產品。X86體系結構在早期屬於16位處理器，自80386之後擴展爲32位處理器，所以一些文檔中又把80386之後的32位處理器體系稱作I386。自Pentium4後期，AMD的Athlon64開始，I386被進一步擴充爲64位處理器，含有64位尋址能力的X86體系結構被稱作X86-64或IA32-64。總之，市售的個人電腦用CPU，除蘋果的Macintosh之外，全部採用X86體系結構芯片。 在X86早期，16位的尋址能力只支持64KB(2&#94;16=64K)內存，這顯然是不夠的。Intel採用分段尋址的方法，用4位段位+16位偏移量，提供了總共1MB(2&#94;20=1M)的尋址能力。所以在X86的16位編程中，有兩種指針類型：長指針(lp,long pointer)和短指針(sp,short pointer)，長指針(20位)提供整個內存空間尋址能力，短指針(16位)僅支持同一段中的尋址。在\"古代\"DOS及Win3.x編程過程中，兩種類型的指針，以及總共1MB的內存大小，常常把程序員們折騰得焦頭爛額。 自I386之後，CPU纔開始提供32位的尋址能力。有了整整4GB(2&#94;32=4G)的尋址空間，所有指針統一爲長指針(32位)。時至今日，我們仍可以看到微軟文檔中指針變量的lp前綴。由於內存管理的需要，分段機制被保留下來，但這一次不是因爲地址空間太小，而是因爲地址空間遠大於實際內存容量，從而採用了虛擬內存機制。 在從16位結構向32位結構轉變的過程中，由於向下兼容的歷史原因，曾一度長時間出現硬件32位(I386)、軟件16位(Win3.x)的情況。同樣也是爲了兼容16位軟件，Win9x操作系統(Win95、Win98、WinME)保留了16位代碼和32位代碼。混合代碼的設計使得Win9x及其混亂和不穩定。直到完全32位內核的操作系統WinNT(以及構建於其上的Win2000，WinXP，Win2003)的出現，X86平臺上內存佈局混亂的局面才得以改善。有了從16位至32位移植的經驗和準備，現今的從32位到64位的操作系統移植顯得平穩順利很多。WinXP和WinVista系統都同時發佈了32位版本和64位版本，並且其x86-64系統都實現了對32位軟件的無縫銜接支持。","tags":"import","url":"//farseerfc.me/c-tricks-2-1-x86-architecture.html"},{"title":"C++ Tricks 1.2 逗號運算符(,)、邏輯運算符(&&,||)與運算符重載的陷阱","text":"從 farseerfc.wordpress.com 導入 1.2 逗號運算符(,)、邏輯運算符(&&,||)與運算符重載的陷阱 很多人甚至不知道逗號(,)也是個C++運算符。與語法上要求出現的逗號(比如分隔函數參數的逗號)不同的是，出現在表達式中的逗號運算符在語義上表示多個表達式操作的連續執行，類似於分隔多語句的分號。比如： for ( int i=0,j=9;i<10;++i , --j)std::cout<<i<<\"+\"<<j<<\"=9\\n\"; 在這句語句中，出現了兩個逗號，其中前者是語法上用來分隔聲明的變量的，並非逗號運算符，而後者則是一個逗號運算符。根據C++標準，逗號運算符的執行順序爲從左到右依次執行，返回最後一個子表達式的結果。由於只有最後一個表達式返回結果，所以對於一個語義正常的逗號表達式而言，前幾個子表達式必須具有副作用。同時，從語言的定義中也可以看出，逗號表達式對求值的順序有嚴格要求。 對求值順序有要求的，除了逗號表達式和條件表達式(參見1.1)，在C++中還有邏輯運算符(&&和||)。邏輯運算相較於數學運算和位運算而言，有個顯著的不同點：邏輯運算在計算到一半時，就有可能已經得到結果，這樣繼續運算另一半就不是必需的。對於A&&B，如果A=false，那麼無論B爲何值，整個的結果都是false；同樣的A||B，如果A=true，那麼不考慮B，結果一定是true。 C++標準規定，如果邏輯運算到一半(算出A)時，就已經可以確定運算的結果，那麼就不運算剩下的另一半(B)。這種執行語義被稱作\"短路\"。在其它一些編程語言中，短路語義是可以選擇的：在Ada裏非短路的邏輯運算符爲and和or，短路的邏輯運算符爲and_then和or_else。但是在C++中，邏輯運算符的短路語義是語法上強制的，我們沒有非短路版本的運算符。如果確實需要非短路語義，我們總是可以通過增加一個bool中間變量加以解決。有時，短路對於保證正確執行是必須的，比如： char *p=getString(); if (p && *p)std::cout<<p; 這段代碼在得到了一個字符串後，在字符串不爲空時輸出它。在C++中判斷一個字符串不爲空需要兩個步驟：判斷指針是否爲0，以及指針不爲0時判斷指針指向的內容是否爲''。就像條件表達式中討論到的(參見1.1)，在p爲空時提領p是個極其危險的操作。邏輯運算符的短路語義則避免了這種危險。 以上對逗號運算符與邏輯運算符的討論，僅限於C++標準所定義的運算符語義。爲什麼這樣說呢？這是因爲在C++中，運算符的語義是可以由程序員自行定義的，這種機制叫做運算符重載(operator overload)。運算符重載可以將人們熟悉的運算符表達式轉換成函數調用，使編程靈活而直觀，是個方便的語言特性。不過有時運算符重載也會使人困擾，那就是當運算符重載遇到求值順序問題時。 C++中，並不是所有合法運算符都可以被合法地重載。條件運算符雖然對求值順序有要求，但它並不在可重載運算符之列，所以運算符重載機制對它沒有影響。問題在於，逗號運算符和邏輯運算符都可以被合法地重載： class BadThing{/* Some Bad and Stupid Thing*/}; BadThing& operator ,(BadThing&, BadThing&);//重載了逗號運算符 bool operator &&(BadThing&, BadThing&);//重載了&& BadThing b1,b2; if (b1&&b2)b1,b2;//被替換成如下形式： if ( operator &&(b1,b2)) operator ,(b1,b2); 可以看到，重載了運算符之後，對運算符的使用被替換爲相應的函數調用形式。因此，舊有的運算符的執行順序不再適用，取而代之的是函數參數的壓棧順序。 根據C++標準規定，任何參數必須在進入函數之前壓棧，所以在進入 operator &&之前，b1、b2就會被求值，這裏不再有短路規則，任何依賴於短路語義的不知不覺間操作BadThing的代碼(可能通過模板)都會混亂。 短路語義只是一個方面，更重要的在於壓棧順序。鑑於執行效率和舊代碼兼容性等細節問題，C++標準在壓棧順序上給編譯器的開發者留有很大自主性。標準的說辭是，編譯器可能以任何它覺得方便的順序將參數壓棧，從左到右，從右到左，甚至從中間到兩邊，在這一點上我們不能安全地做任何假設。在上面的例子中，編譯器生成的代碼可能先計算b1再計算b2，也可能是相反的順序。再看看編譯器的實際情況，在我試過的所有基於X86體系結構的編譯器中，參數都是以逆向壓棧，即從右到左，有悖於大多數人的閱讀習慣和直覺(別說你是來自伊斯蘭的……)。 在C時代使用函數調用時，壓棧順序並不是什麼大問題，畢竟大多數人會在函數調用的邊界稍稍小心一些。但是到了C++中，事情變得有些複雜，因爲簡單如a+b的使用，就有可能被運算符重載機制替換爲函數調用。更何況有模板參與之後，我們寫代碼時不能確定對象的真實類型，也就無法預知一個運算符是否真的被重載過，唯一穩妥的方法是，假定任何有可能被重載的運算符的使用都是函數調用。 <p style=\"margin:0;\"> 回到上文的示例中，由於,和&&都被替換爲函數調用，程序的執行順序將成爲壓棧順序，在X86上很有可能是從右到左，與標準定義的運算符的順序正好相反。逗號運算符原本就含有\"先…後…\"的語義，這種顛倒的執行順序勢必造成程序和程序員的混亂。以我的經驗而言，含有 operator ,的類，完全沒有辦法和STL或者iostream相互協作，反而會導致巨量的錯誤報告(什麼叫巨量的錯誤報告有概念麼？如果沒有，那說明你還沒玩過範式編程(GP, Generic Programming)。去玩玩GP吧，看看你的編譯器對巨量的定義。在我手頭，針對3.5KB的代碼文件傾瀉出3.8 MB 的錯誤信息的編譯器不在少數……)。有鑑於此，我的結論是，除非你有充足的依據支持你這麼做(比如你的粗暴上司的鍵盤上只剩下逗號能用)，並且你清楚的瞭解這麼做的後果的嚴重性(比如至少要看過此文)，否則我奉勸你，永遠不要碰 operator ,、 operator &&以及 operator ||！","tags":"import","url":"//farseerfc.me/c-tricks-1-2-trap-in-comma-logical-operator.html"},{"title":"C++ Tricks 1.1  條件運算符(?:)","text":"從 farseerfc.wordpress.com 導入 1.1 條件運算符(?:) 條件運算符(?:)是C++中唯一的三目運算符(trinary operator)，用於在表達式中作條件判斷，通常可以替換if語句，與Visual Basic中的iif函數、Excel中的if函數有同樣的作用。語法形式如下： condition ? true_value : false_value 其中 condition *條件是任何可以轉換爲bool類型的表達式，包括但不僅限於**bool* 、 int 、指針。與 if 和 while 的條件部分稍顯不同的是，這裏不能定義變量，否則會導致語法錯誤。 另外，條件語句會切實地控制執行流程，而不僅僅是控制返回值。也就是說，兩個返回值表達式中永遠只有一個會被求值，在表達式的執行順序很重要時，這點尤爲值得注意。比如： int *pi=getInt(); int i=pi ? *pi : 0; 這裏，只有當pi的值不爲0時，它纔會被提領(dereference)。這種語義保證了程序的正確性，因爲提領一個空指針將導致致命的運行期錯誤(通常是非法操作的警告)。同時，正因爲條件運算符控制運算流程的特點，使得它不能用類似iif的普通函數來模擬： int iif( int con, int t, int f){ if (c) return t; return f;}//試圖模擬?: …//in some function int *pi=getInt(); int i=iif(pi,*pi,0);//Error! 這段代碼會導致上文提到的致命運行期錯誤。C/C++標準規定，參數在被傳遞給函數之前求值，因此無論pi爲何值，都會被提領。又因爲函數傳回一個空指針的情況比較少見，所以這樣的錯誤在調試時很難被發現，一旦發生又勢必造成重大災難。這樣的代碼在實踐中應儘量避免。 有時，條件運算符控制流程的特點會不知不覺影響我們的代碼。在C時代，最大值MAX通常用宏實現： #define MAX(a,b) ((a)>(b) ? (a) : (b)) 需要用額外的括號將宏參數和宏本體保護起來，以免運算符優先級擾亂邏輯，這是宏醜陋的特點之一，這裏暫且不提。矛盾在於，用具有副作用的表達式調用宏時，會出現問題： int i=5,j=6;//… int a=MAX(++i,++j); 代碼的作者原意顯然是想先將i,j分別遞增，再將其中較大的一個賦給a。執行這段代碼，當i=5,j=6時，a=8，知道爲什麼嗎？通過宏展開，賦值語句成這樣： int a=(++i)>(++j) ? (++i) : (++j);//刪除了多餘括號 在判斷之前，i、j被分別自增一次，然後捨棄:之前的部分，j又被自增一次。執行之後，i=6,j=8。 MAX的更正確更安全的實現，是利用模板將類型參數化。STL標準算法中就有一個這樣的工具級模版函數std::max。 條件運算符是表達式而不是語句，這使得它可以出現在任何需要表達式的地方，這擴大了它的適用範圍。在那些語法上只能出現表達式而不能出現語句的地方（比如變量初始化），條件運算符有着不可替代的作用。 條件運算符優於 if 語句的另一個場合是\"模板元編程\"(TMP, Template MetaProgramming)。在TMP這個古怪奇異的編譯期運算編程技術中，一切舊有的技術和法則被全線擊破，我們所能仰仗的工具，只有模板特化(Specialization)、 typedef s、函數聲明(無法調用它們)、以及編譯期常量運算。已經有人很深入地論證過，僅有以上這些，就已經形成了一個\"圖靈完善\"的計算機語言。我們可以用模板特化技術，來模擬條件分支，循環迭代等一系列複雜的語言結構。由於可以參與編譯期常量運算，條件運算符在TMP世界中很自然地扮演起重要角色。 比如，給與類型T的一個變量t，我們想聲明一個緩衝區存放t和一個int，緩衝區的大小不小於sizeof(T)也不小於sizeif(int)，我們可以這樣寫： char buffer[sizeof(T)>sizeof(int)? sizeof(T): sizeof(int)]; 我們不能用一個if語句替換這個運算： int i; if(sizeof(T)>sizeof(int))i=sizeof(T); else i=sizeof(int); char buffer[i];//語法錯誤! 原因在於數組聲明中的下標必須是一個編譯期常量，而不是一個運行期的值，條件表達式的運算可以在編譯期進行，if語句就只能在執行期執行。","tags":"import","url":"//farseerfc.me/c-tricks-1-1-conditional-operator.html"},{"title":"填補信仰、喚醒良知","text":"從 farseerfc.wordpress.com 導入 填補信仰、喚醒良知 我們聽盡了呼籲與號召，對於良知，我不必譴責喪失它的國人，不必盛讚良知的美好。我只想討論，喪失了良知的原因——空缺的信仰。 一、空缺信仰喪失良知 現代的國人缺少信仰，以至於喪失良知。曾幾何時，中華民族由良好的信仰凝聚而成。三皇五帝時，族民們以炎黃爲信仰；春秋戰國時，士大夫之族以周制禮樂爲信仰；漢代以後，百姓延習孔孟之說、老聃之道，以儒家學說爲信仰；自大唐起，以佛教爲首的現代宗教紛紛傳入中原，人民開始以它們作爲信仰。 直至鴉片戰爭、五四運動，西方文化入侵中華，國人開始拋棄國學，轉而去研究科學；文化大革命，十年文化浩劫，人們批判舊的信仰，卻沒有合適的新的信仰前來填補。從此，國人的信仰出現空缺，國人的良知也被一塊塊蠶食殆盡。 二、信仰、科學、迷信 在許多國人的心目中，信仰就等於迷信。從小到大的教育告訴我們，信奉宗教是愚昧而又無知的表現，科學與信仰是矛盾的。是麼？ 我們無法保證社會上的每一個人都接受過良好的教育，我們無法確信最前沿的科學素養能在民衆中普及。在科普與教育力不從心的社會死角，在科學技術尚不能及的文化盲區，我們依舊需要信仰的規範與限制，我們的良知需要信仰！ 信仰不等於迷信。信仰本身無所謂謎與不迷，迷信是持有信仰的人誤解了信仰，盲目遵從的結果。以爲燒過香就可以免遭禍患，以爲捐了錢就可以升入天堂，以爲引火自焚就可以功德圓滿，這便是迷信了。希特勒曾經的人類完善計劃，依照遺傳學的原理，將科學家與運動員強行結爲夫婦孕育生命，希望得到最優秀的人類種族，這便是對科學這種信仰的迷信！ 由此可見，科學與信仰並不是矛盾的硬幣的兩面，從某種意義而言科學本身也是信仰的一種。雖然歷史上宗教往往作爲科學發展的阻礙，可信奉真理的信念一直是推動科學發展的動力。牛頓就曾說過，對自然規律的探詢是爲了更接近上帝。由此可見，信仰與真理，與良知毫無矛盾。 三、信仰喚醒良知 很少有人仔細思考過，良知的缺失是由信仰的缺失造成的。信仰是人思想的寄託與依靠，是人行動處世的準則。沒有了信仰的人，思想行爲就缺少了約束的標準，人就更容易因爲一時不成熟的衝動，背叛良知、鑄成錯誤。 泰國人以佛教爲信仰，泰國的寺廟每天都會有成千上萬人頂禮膜拜。寺廟有一個人盡皆知的不成文規定：不得穿鞋進入。於是在寺廟之外，遊客們可以看到千百雙各式的鞋子有序的擺放在門口。國人每每看到此景，總會詫異地問：沒有人會偷鞋麼？得到的答案極爲簡單：廟前偷鞋會遭報應。由於擁有信仰，泰國人作了壞事會受到良知的譴責，泰國商人售出假貨會徹夜難眠。二戰期間，無數猶太難民被天主教會收留藏匿從而僥倖逃生，這同樣是出於，天主教徒們被自己信奉的教義\"衆生生來平等\"，所喚醒的良知。 天下無賊的世界，不能僅靠科普說教來營造。如果脫離了信仰，縱使是教育也無法培養良知。我問過許多修化學的同學，學習化學的意義，結論竟是爲了考試。如果沒有對科學的信仰，我們可以牢記公式定理，卻質疑它們是真理；如果沒有對社會公德的信仰，我們可以熟背交通規則，卻正大光明地闖紅燈；如果沒有對醫療道德的信仰，醫生可以放任傷口發炎，從而留住病人繼續治療…… 國人需要信仰的約束，需要填補信仰的空白，從而喚醒那深埋於每個國人內心深處的良知！","tags":"import","url":"//farseerfc.me/filling-believings-calling-conscience.html"},{"title":"SSD 就是大U盘？聊聊闪存类存储的转换层","text":"上篇 「柱面-磁头-扇区寻址的一些旧事」 整理了一下我对磁盘类存储设备（包括软盘、硬盘，不包括光盘、磁带）的一些理解， 算是为以后讨论文件系统作铺垫；这篇整理一下我对闪存类存储设备的理解。 这里想要讨论的闪存类存储是指 SSD 、SD卡、U盘、手机内置闪存等基于 NAND 又有闪存转换层的存储设备（下文简称闪存盘），但不包括裸 NAND 设备、3D Xpoint （Intel Optane）等相近物理结构但是没有类似的闪存转换层的存储设备。 闪存类存储设备这几年发展迅猛，SD卡和U盘早就替代软盘成为数据交换的主流， SSD 大有替代硬盘的趋势。 因为发展迅速，所以其底层技术变革很快，不同于磁盘类存储技术有很多公开资料可以获取， 闪存类存储的技术细节通常是厂商们的秘密，互联网上能找到很多外围资料， 但是关于其如何运作的细节却很少提到。所以我想先整理一篇笔记，记下我搜集到的资料，加上我自己的理解。 本文大部分信息来源是 Optimizing Linux with cheap flash drives 和 A Summary on SSD & FTL ，加上我的理解，文中一些配图也来自这两篇文章。 1 NAND Flash 原理 比 NAND Flash 更早的 EEPROM 等存储技术 曾经用过 NOR Flash cell ，用于存储主板配置信息等少量数据已经存在 PC 中很久了。后来 NAND Flash 的微型化使得 NAND Flash 可以用于存储大量数据，急剧降低了存储成本，所以以 NAND Flash 为基础的存储技术能得以替代硬盘等存储设备。 Tutorial: Why NAND Flash Breaks Down 这里不想涉及太多 NAND Flash 硬件细节，有个演讲 Tutorial: Why NAND Flash Breaks Down 和 YouTube 视频 介绍了其原理，感兴趣的可以参考一下。只罗列一下视频中提到的一些 NAND Flash 的特点： NAND Flash 使用 floating gate 中束缚电子来保存二进制数据，对这些 Cell 有读取（Read）、 写入（Programming）、擦除（Erase）的操作。擦写次数叫 P/E cycle。 电子的量导致的电势差可以区别 1 和 0 ，这是 Single Level Cell (SLC) 的存储方式。 或者可以用不同的电势差区分更多状态保存更多二进制位，从而有 Multi-Level Cell (MLC)， TLC， QLC 等技术。可以对 MLC 的 Flash Cell 使用类似 SLC 的写入模式，物理区别只是参考电压， 只是 SLC 模式写入下容量减半。 高密度设计下，一组 NAND Flash Cell 可以同时并发读写。所以有了读写页 2KiB/4KiB 这样的容量。 页面越大，存储密度越高，为了降低成本厂商都希望提高读写页的大小。 为了避免添加额外导线，NAND Flash Cell 是使用基板上加负电压的方式擦除 floating gate 中的二进制位的，所以擦除操作没法通过地址线选择特定 Cell 或者读写页，于是整块擦除有块大小。 写入操作对 SLC 单个 Cell 而言，就是把 1 置 0 ，而擦除操作则是把整块置 1 。SLC 可以通过地址线单独选择要写入的 Cell ，MLC 则把不同页的二进制放入一个 Cell ，放入时有顺序要求， 先写处于高位的页，再写低位的。所以 MLC 中不同页面地址的页面是交错在同一组 Cell 中的。 SLC 其实并没有特别要求擦除块中的写入顺序，只是要求仅写一次（从 1 到 0）。 MLC 则有先写高位页再写低位页的要求。厂商规格中的要求更严格，擦除块中必须满足按页面编号顺序写入。 写入和擦除操作是通过量子隧道效应把电子困在 floating gate 中的，所以是个概率事件。通过多次脉冲 可以缩小发生非预期概率事件的可能性，但是没法完全避免，所以需要 ECC 校验纠错。 根据 ECC 强度通常有三种 ECC 算法，强度越强需要越多算力： 汉民码 可根据 n bit 探测 \\(2&#94;n - n -1\\) 中的 2 bit 错误，修正 1 bit 错误。 BCH码 可根据 \\(n*m\\) bit 纠错 \\(2&#94;n\\) bit 中的 m bit 错误。 LDPC 原理上类似扩展的汉民码，能做到使用更少校验位纠错更多错误。 因为 ECC 的存在，所以读写必须至少以 ECC 整块为单位，比如 256 字节或者整个页面。 也因为 ECC 的存在， \\(ECC(\\texttt{0xFF}) \\ne \\texttt{0xFF}\\) ，空页（擦除后全1的页面）必须特殊处理。所以需要区分写了数据全 1 的页和空页。 ECC校验多次失败的页面可以被标记为坏页，出厂时就可能有一些坏页，这些由转换层隐藏起来。 断电后，也有小概率下束缚的电子逃逸出 floating gate ，时间越长越可能发生可以探测到的位反转。 所以基于 NAND Flash 的存储设备应该避免作为存档设备离线保存。 电子逃逸的概率也和温度有关，温度越高越容易逃逸，所以高温使用下会有更高的校验错误率。 读取时，因为用相对较高的电压屏蔽没有读取的地址线，有一定概率影响到没被读取的页面中存储的数据。 控制器可能考虑周期性地刷新这些写入后多次读取的页面，这可能和后文的静态擦写均衡一起做。 正在写入或者擦除中突然断电的话下，写入中的一整页数据可能并不稳定，比如短期内能正常读取但是难以持续很长时间。 MLC 擦写次数与错误率 上篇讲硬盘的笔记中提到过，硬盘物理存储也有越来越强的校验机制，不过相比之下 NAND Flash 出现临时性校验失败的可能性要高很多，需要控制器对校验出错误的情况有更强的容忍能力。 厂商们制作存储设备的时候，有一个需要达到的错误率目标（比如每 \\(10&#94;{-14}\\) bit 出现一次位反转），针对这个目标和实际物理错误率，相应地设计纠错强度。校验太强会浪费存储密度和算力， 从而提升成本，这里会根据市场细分找折衷点。 2 封装结构 从外部来看，一个闪存盘可能有这样的结构： ssd-enclosure.svg 从上往下，我们买到的一个闪存盘可能一层层分级： 整个闪存盘有个控制器，其中含有一部分 RAM 。然后是一组 NAND Flash 封装芯片（chip）。 每个封装芯片可能还分多个 Device ，每个 Device 分多个 Die ，这中间有很多术语我无法跟上，大概和本文想讨论的事情关系不大。 每个 Die 分多个平面（Plane），平面之间可以并行控制，每个平面相互独立。从而比如在一个平面内 做某个块的擦除操作的时候，别的平面可以继续读写而不受影响。 每个平面分成多个段（Segment)，段是擦除操作的基本单位，一次擦除一整个段。 每个段分成多个页面（Page），页面是读写操作的基本单位，一次可以读写一整页。 页面内存有多个单元格（Cell），单元格是存储二进制位的基本单元，对应 SLC/MLC/TLC/QLC 这些， 每个单元格可以存储一个或多个二进制位。 以上这些名字可能不同厂商不同文档的称法都各有不同，比如可能有的文档把擦除块叫 page 或者叫 eraseblock 。随着容量不断增大，厂商们又新造出很多抽象层次，比如 chip device die 这些， 不过这些可能和本文关系不大。如果看别的文档注意区别术语所指概念，本文中我想统一成以上术语。 重要的是有并行访问单元的平面（Plane）、擦除单元的段（Segment）、读写单元的页（Page）这些概念。 抽象地列举概念可能没有实感，顺便说一下这些概念的数量级： 每个 SSD 可以有数个封装芯片。 每个芯片有多个 Die 。 每个 Die 有多个平面。 每个平面有几千个段。比如 2048 个。 每个段有数百个页到几千页，比如 128~4096 页，可能外加一些段内元数据。 每个页面是 2KiB~8KiB 这样的容量，外加几百字节的元数据比如 ECC 校验码。 和硬盘相比，一个闪存页面大概对应一个到数个物理扇区大小，现代硬盘也逐渐普及 4KiB 物理扇区， 文件系统也基本普及 4KiB 或者更大的逻辑块（block）或者簇（cluster）大小，可以对应到一个闪存页面。 每次读写都可以通过地址映射直接对应到某个闪存页面，这方面没有硬盘那样的寻址开销。 闪存盘的一个页面通常配有比硬盘扇区更强的 ECC 校验码，因为 NAND 单元格丧失数据的可能性比磁介质高了很多。 闪存有写入方式的限制，每次写入只能写在「空」的页面上，不能覆盖写入已有数据的页面。 要重复利用已经写过的页面，需要对页面所在段整个做擦除操作，每个段是大概 128KiB 到 8MiB 这样的数量级。每个擦除段需要统计校验失败率或者跟踪擦除次数，以进行擦写均衡（Wear Leveling）。 3 擦写均衡（Wear Leveling）和映射层（Flash Translation Layer） Animation: wear leveling on SSD drives 擦除段的容量大小是个折衷，更小的擦除段比如 128KiB 更适合随机读写， 因为每随机修改一部分数据时需要垃圾回收的粒度更小；而使用更大的擦除段可以减少元数据和地址映射的开销。 从擦除段的大小这里，已经开始有高端闪存和低端闪存的差异，比如商用 SSD 可能比 U 盘和 SD 卡使用更小的擦除段大小。 闪存盘中维护一个逻辑段地址到物理段地址的映射层，叫闪存映射层（Flash Translation Layer ）。每次写一个段的时候都新分配一个空段， 写完后在映射表中记录其物理地址。映射表用来在读取时做地址转换，所以映射表需要保存在闪存盘控制器的 RAM 中，同时也需要记录在闪存内。具体记录方式要看闪存盘控制器的实现，可能是类似日志的方式记录的。 「段地址映射表」的大小可以由段大小和存储设备容量推算出来。比如对一个 64GiB 的 SD 卡，如果使用 4MiB 的段大小，那么需要至少 16K 个表项。假设映射表中只记录 2B 的物理段地址， 那么需要 32KiB 的 RAM 存储段地址映射表。对一个 512GiB 的 SSD ，如果使用 128KiB 的段大小， 那么至少需要 4M 个表项。记录 4B 的物理段地址的话，需要 16MiB 的 RAM 存储地址映射， 或者需要动态加载的方案只缓存一部分到 RAM 里。控制器中的 RAM 比 NAND 要昂贵很多，这里可以看出成本差异。 除了地址映射表，每个物理段还要根据擦除次数或者校验错误率之类的统计数据，做擦写均衡。有两种擦写均衡： 动态擦写均衡（Dynamic Wear Leveling）：每次写入新段时选择擦除次数少的物理段。 静态擦写均衡（Static Wear Leveling）：空闲时，偶尔将那些许久没有变化的逻辑段搬运到 多次擦除的物理段上。 低端闪存比如 SD 卡和 U 盘可能只有动态擦写均衡，更高端的 SSD 可能会做静态擦写均衡。 静态擦写均衡想要解决的问题是：盘中写入的数据可以根据写入频率分为冷热， 总有一些冷数据写入盘上就不怎么变化了，它们占用着的物理段有比较低的擦除计数。 只做动态擦写均衡的话，只有热数据的物理段被频繁擦写，加速磨损， 通过静态擦写均衡能将冷数据所在物理段释放出来，让整体擦写更平均。 但是静态擦写均衡搬运数据本身也会磨损有限的擦写次数，这需要优秀的算法来折衷。 除了擦写均衡用的统计数据外， FTL 也要做坏块管理。闪存盘出厂时就有一定故障率，可能有一部分坏块。 随着消耗擦写周期、闲置时间、环境温度等因素影响，也会遇到一些无法再保证写入正确率的坏块。 NAND Flash 上因为量子隧道效应，偶尔会有临时的校验不一致，遇到这种情况，除了根据 ECC 校验恢复数据， FTL 也负责尝试对同一个物理段多次擦除和读写，考察它的可用性。排除了临时故障后， 如果校验不一致的情况仍然持续，那么需要标注它为坏块，避免今后再写入它。 出厂时，闪存盘配有的物理段数量就高于标称的容量，除了出厂时的坏块之外，剩余的可用物理段可以用于 擦写均衡，这种行为称作 Over Provisioning 。除了盘内预留的这些空间，用户也可以主动通过分区的方式或者文件系统 TRIM 的方式预留出更多可用空间， 允许 FTL 更灵活地均衡擦写。 4 段内写入顺序与垃圾回收策略 段是闪存盘的擦写单元，考虑到段是 128KiB ~ 8MiB 这样的数量级，现实中要求每次连续写入一整段的话， 这样的块设备接口不像硬盘的接口，不方便普通文件系统使用。所以在段的抽象之下有了更小粒度的页面抽象， 页面对应到文件系统用的逻辑块大小，是 2KiB~8KiB 这样的数量级，每次以页面为单位读写。 写入页面时有段内连续写入的限制，于是需要段内映射和垃圾回收算法，提供对外的随机写入接口。 写入操作时， FTL 控制器内部先「打开（open）」一个段，等写入完成，再执行垃圾回收「关闭(close)」一个段。 写入过程中处于打开状态的段需要一些额外资源（RAM等）跟踪段内的写入状况，所以闪存盘同时能「打开」 的段数量有限。并且根据不同的垃圾回收算法，需要的额外资源也不尽相同，在 Optimizing Linux with cheap flash drives 一文中介绍几种可能的垃圾回收算法： 4.1 线性写入优化 Animations: linear-access optimized 假设写入请求大部分都是连续写入，很少有地址跳转，那么可以使用线性优化算法。 Open：当第一次打开一个段，写入其中一页时，分配一个新段。如果要写入的页不在段的开头位置，那么搬运写入页面地址之前的所有页面到新段中。 Write: 在 RAM 中跟踪记录当前写入位置，然后按顺序写下新的页面。 Close: 最后搬运同段中随后地址上的页面，并关闭整段，调整段映射表。 如果在段内写入了几页之后，又跳转到之前的位置，那需要在跳转时关闭当前段写入（并完整搬运剩下的页面）， 然后重新打开这一段，搬运调转地址之前的页面，从跳转的页面位置开始写入。 线性优化算法的好处在于：没有复杂的页面地址映射，段内的逻辑页面地址就是物理页面地址。 读一页的时候根据页面偏移和当前写入位置就能判断读新物理段还是老物理段。遇到突然断电之类的情况， 即使丢失最近写入的新物理段，老物理段的数据仍然还在，所以没必要保存 RAM 中的地址映射到闪存元数据中。 线性优化算法的坏处是:每遇到一次乱序的写入，都要整段执行一次搬运，造成 写入放大（Write Amplification） 。 一些文档中，将这种地址映射垃圾回收方式叫做「段映射（Segment Mapping）」，因为从 FTL 全局来看只维护了擦写段的地址映射关系。 4.2 段内地址映射 Animations: block remapping 对需要随机乱序写入的数据，可以使用段内地址映射。方式是额外在段外的别的闪存区域维护一张段内地址映射表， 像段地址一样，通过查表间接访问页面地址。 Open: 分配一块新的段，同时分配一个新的段内映射表。 Write: 每写入一页，在段内映射表记录页面的在新段中的物理地址。 Close: 复制老段中没有被覆盖写入的页到新段，并记录在段内映射表中，然后释放老段和老的段内映射表。 也就是说同时维护两块不同大小的闪存空间，一块是记录段数据的，一块是记录段内地址映射表的， 两块闪存空间有不同的写入粒度。可以在每个物理段内额外留出一些空间记录段内地址映射表，也可以在 FTL 全局维护一定数量的段内地址映射表。 每次读取段内的数据时，根据映射表的内容，做地址翻译。新段中页面的排列顺序将是写入的顺序， 而不是地址顺序。 根据实现细节，段内地址映射可以允许覆盖写入老段中的页面，但是可能不允许覆盖写入新段（正在写入的段） 中已经写入的页面，遇到一次连续的写请求中有重复写入某一页面的时候，就需要关闭这一段的写入，然后重新打开。 段内地址映射的优点是：支持随机写入，并且只要段处于打开状态，随机写入不会造成写入放大（Write Amplification）。 缺点是：首先地址映射这层抽象有性能损失。其次遇到突然断电之类的情况， 下次上电后需要扫描所有正打开的段并完成段的关闭操作。 和「段映射」术语一样，在一些文档中，将这种段内地址映射的方式叫做「页面映射（Page Mapping）」，因为从 FTL 全局来看跳过了擦写段这一层，直接映射了页面的地址映射。 4.3 日志式写入 Animations: data logging 除了大量随机写入和大量连续写入这两种极端情况，大部分文件系统的写入方式可能会是对某个地址空间 进行一段时间的随机写入，然后就长时间不再修改，这时适合日志式的写入方式。 日志式的写入方式中写入一段采用三个物理段：老物理段，用于日志记录的新物理段，和垃圾回收后的段。 Open: 分配一块新的段。可能额外分配一个用于记录日志的段，或者将日志信息记录在数据段内。 Write：每写入一页，同时记录页面地址到日志。 Close：再分配一个新段执行垃圾回收。按日志中记录的地址顺序将数据段中（新写入）的页面或者老段中 没有被覆盖的页面复制到垃圾回收结束的新段中。 日志式写入在写入过程中像段内地址映射的方式一样，通过日志记录维护页面地址映射关系， 在写入结束执行垃圾回收之后，则像线性写入的方式一样不再需要维护页面映射。 可以说日志式写入某种程度上综合了前面两种写入方式的优点。 日志式写入的优点：允许随机顺序写入，并且在执行垃圾回收之后，不再有间接访问的地址转换开销。 日志式写入的缺点：触发垃圾回收的话，可能比段地址映射有更大的写入放大（Write Amplification）。 在一些文档中，将这种日志式写入方式称作「混合映射（Hybrid Mapping）」，因为在段开启写入期间行为像页面映射， 在段关闭写入后行为像段映射。 5 针对特定写入模式的优化 上述三种地址映射和垃圾回收方式，各有不同的优缺点，根据数据块的写入模式可能需要挑选相应的策略。 并且「全局段地址映射表」、「段内页面地址映射表」、「写入页面地址日志」之类的元数据因为频繁修改， FTL 也可能需要用不同的策略来记录这些元数据。这里面向不同使用场景的闪存设备可能有不同的 FTL 策略，并且 FTL 可能根据逻辑地址来选择哪种策略。 5.1 混合垃圾回收策略 Performance measurements on a class 10 SDHC card 用来记录照片、视频等的 SD 卡、microSD、U盘等设备可能根据数据的逻辑地址，为特定文件系统布局优化， 这里特定文件系统主要是指 FAT32 和 exFAT 这两个 FAT 系文件系统。 FAT 系文件系统的特点在于， 地址前端有一块空间被用来放置 文件分配表(File Allocation Table) ，可以根据文件系统簇大小和设备存储容量推算出 FAT 表占用大小，这块表内空间需要频繁随机读写。 对 FTL 自身的元数据，和 FAT 表的逻辑地址空间，需要使用「段内地址映射」来保证高效的随机读写， 而对随后的数据空间可使用「线性写入优化」的策略。 右侧上图有张性能曲线，测量了一个 class 10 SDHC 卡上，不同读写块大小时，顺序读取、顺序写入、随机写入、 对 FAT 区域的写入之类的性能差异。下图是测量的读取延迟。可以看出 FAT 区域的随机写入和其余逻辑地址上有明显不同的性能表现。 为容纳普通操作系统设计的 eMMC 和 SSD 难以预测文件系统的读写模式，可能需要使用更复杂的地址映射和垃圾回收策略。 比如一开始假定写入会是顺序写入，采用「线性优化」方式；当发生乱序写入时，转变成类似「日志式写入」 的方式记录写入地址并做地址映射；关闭段时，再根据积累的统计数据判断，可能将记录的日志与乱序的数据 合并（merge）成顺序的数据块，也可能保持页面映射转变成类似「段内地址映射」的策略。 5.2 利用 NAND Flash 物理特性的优化 再考虑 NAND Flash 的物理特性，因为 MLC 要不断调整参考电压做写入， MLC 的写入比 SLC 慢一些，但是可以对 MLC Flash 使用 SLC 式的写入， FTL 控制器也可能利用这一点，让所有新的写入处于 SLC 模式，直到关闭整段做垃圾回收时把积攒的 SLC 日志段回收成 MLC 段用于长期保存。 一些网页将这种写入现象称作「SLC 缓存」甚至称之为作弊，需要理解这里并不是用单独的 SLC Flash 芯片做 writeback 缓存，更不是用大 RAM 做缓存，处于 SLC 模式的写入段也是持久存储的。 5.3 同时打开段数 上述地址映射和垃圾回收策略都有分别的打开（open）、写入（write）、关闭（close）时的操作， 闪存盘通常允许同时打开多个段，所以这三种操作不是顺序进行的，某一时刻可能同时有多个段处在打开的状态， 能接受写入。不过一个平面（Plane）通常只能进行一种操作（读、写、擦除），所以打开写入段时， FTL 会尽量让写入分部在不同的平面上。还可能有更高层次的抽象比如 Device、 Chip 、 Die 等等，可能对应闪存盘内部的 RAID 层级。 闪存盘能同时打开的段不光受平面之类的存储结构限制，还受控制器可用内存（RAM）限制之类的。 为 FAT 和顺序写入优化的 FTL ，可能除了 FAT 区域之外，只允许少量（2~8）个并发写入段， 超过了段数之后就会对已经打开的段触发关闭操作（close），执行垃圾回收调整地址映射，进而接受新的写入。 更高端的 SSD 的 FTL 如果采用日志式记录地址的话，同时打开的段数可能不再局限于可用内存限制， 连续的随机写入下按需动态加载段内地址映射到内存中，在空闲时或者剩余空间压力下才触发垃圾回收。 5.4 预格式化 FTL 可能为某种文件系统的写入模式做优化，同时如果文件系统能得知 FTL 的一些具体参数（比如擦除段大小、 读写页大小、随机写入优化区域），那么可能更好地安排数据结构，和 FTL 相互配合。 F2FS 和 exFAT 这些文件系统都在最开头的文件系统描述中包含了一些区域，记录这些闪存介质的物理参数。 闪存盘出厂时，可能预先根据优化的文件系统做好格式化，并写入这些特定参数。 5.5 TRIM 和 discard 另一种文件系统和 FTL 相互配合的机制是 TRIM 指令。TRIM 由文件系统发出，告诉底层闪存盘（ 或者别的类型的 thin provisioning 块设备）哪些空间已经不再使用， FTL 接受 TRIM 指令之后可以避免一些数据搬运时的写入放大。关于 TRIM 指令在 Linux 内核中的实现，有篇 The best way to throw blocks away 介绍可以参考。 考虑到 FTL 的上述地址映射原理， TRIM 一块连续空间对 FTL 而言并不总是有帮助的。 如果被 TRIM 的地址位于正在以「段内地址映射」或「日志式映射」方式打开的写入段中，那么 TRIM 掉一些页面可能减少垃圾回收时搬运的页面数量。但是如果 TRIM 的地址发生在已经垃圾回收结束的段中， 此时如果 FTL 选择立刻对被 TRIM 的段执行垃圾回收，可能造成更多写入放大， 如果选择不回收只记录地址信息，记录这些地址信息也需要耗费一定的 Flash 写入。 所以 FTL 的具体实现中，可能只接受 TRIM 请求中，整段擦除段的 TRIM ，而忽略细小的写入页的 TRIM 。 可见 FTL 对 TRIM 的实现是个黑盒操作，并且 TRIM 操作的耗时也非常难以预测，可能立刻返回， 也可能需要等待垃圾回收执行结束。 对操作系统和文件系统实现而言，有两种方式利用 TRIM ： 通过 discard 挂载选项，每当释放一些数据块时就执行 TRIM 告知底层块设备。 通过 fstrim 等外部工具，收集连续的空块并定期发送 TRIM 给底层设备。 直觉来看可能 discard 能让底层设备更早得知 TRIM 区域的信息并更好利用，但是从实现角度来说， discard 不光影响文件系统写入性能，还可能发送大量被设备忽略掉的小块 TRIM 区域。可能 fstrim 方式对连续大块的区间执行 TRIM 指令更有效。 6 TL;DR 低端 vs 高端 标题中的疑问「SSD就是大U盘？」相信看到这里已经有一些解答了。 即使 SSD 和U盘中可以采用类似的 NAND Flash 存储芯片，由于他们很可能采用不同的 FTL 策略，导致在读写性能和可靠性方面都有不同的表现。（何况他们可能采用不同品质的 Flash ）。 如果不想细看全文，这里整理一张表，列出「高端」闪存盘和「低端」闪存盘可能采取的不同策略。 实际上大家买到的盘可能处于这些极端策略中的一些中间点，市场细分下并不是这么高低端分明。 比如有些标明着「为视频优化」之类宣传标语的「外置SSD」，对消费者来说可能会觉得为视频优化的话一定性能好， 但是理解了 FTL 的差异后就可以看出这种「优化」只针对线性写入，不一定适合放系统文件根目录的文件系统。 参数 低端 高端 段大小 8MiB 128KiB 段地址映射 静态段映射 日志式映射 随机写入范围 FTL元数据与FAT表区域 全盘 同时打开段数 4~8 全盘 物理段统计信息 无（随机挑选空闲段） 擦除次数、校验错误率等 擦写均衡 动态均衡（仅写入时分配新段考虑） 静态均衡（空闲时考虑搬运） 写入单元模式 TLC 长期存储 MLC， 模拟 SLC 日志 介绍完闪存类存储，下篇来讲讲文件系统的具体磁盘布局，考察一下常见文件系统如何使用 HDD/SSD 这些不同读写特性的设备。","tags":"tech","url":"//farseerfc.me/zhs/flash-storage-ftl-layer.html"},{"title":"柱面-磁头-扇区寻址的一些旧事","text":"在 SSD 这种新兴存储设备普及之前，很长一段时间硬盘是个人计算机的主要存储设备。 更往前的磁带机不常见于个人计算机，软盘的地位很快被硬盘取代，到 SSD 出现为止像 MiniDisc 、 DVD-RAM 等存储设备也从未能挑战过硬盘的地位。硬盘作为主要存储设备，自然也影响了文件系统的设计。 这篇笔记稍微聊一聊硬盘这种存储设备的寻址方式对早期文件系统设计的一些影响，特别是 柱面-磁头-扇区寻址（Cylinder-head-sector addressing, 简称CHS寻址）的起源和发展。 大部分内容来自维基百科 Cylinder-head-sector 词条 这里只是记录笔记。现今的硬盘已经不再采用 CHS 寻址，其影响却还能在一些文件系统设计中看到影子。 柱面、磁头、扇区以及相关术语 磁盘示意图（来自维基百科 Cylinder-head-sector 词条 ） chs-illustrate-trans.svg 如右图所示，一块硬盘(Hard Disk Drive, HDD)是一个圆柱体转轴上套着一些磁碟片(platter)， 然后有一条磁头臂(actuator arm)插入磁碟片间的位置，加上一组控制芯片（controller）。 每个磁碟片有上下两面涂有磁性材质，磁头臂上有一组磁头（head），每个磁头对应磁盘的一个面， 所以比如一个 3 碟的硬盘会有 6 个磁头。 每个磁碟片上定义了很多同心圆的磁头轨道，叫做磁道（track），磁道位于盘面上不同半径的位置， 通过旋转磁碟臂能让磁头移动到特定的半径上，从而让读写磁头在不同的磁道间跳转。 不同磁头上同磁道的同心圆共同组成一个柱面（cylinder），或者说移动磁碟臂能选定磁盘中的一个柱面。 磁道上按等角度切分成多个小段，叫做扇区（sector），每个扇区是读写数据时采用的最小单元。 早期在 IBM 大型机之类上使用的硬盘的扇区大小比较小，到 IBM PC 开始个人计算机用的硬盘扇区基本被统一到 512 字节。现代硬盘内部可能采用 Advanced Format 使用 4K 字节扇区。 在早期软盘和硬盘的寻址方式被称作「柱面-磁头-扇区寻址」，简称 CHS 寻址， 是因为这三个参数是软件交给硬件定位到某个具体扇区单元时使用的参数。 首先柱面参数让磁头臂移动到某个半径上，寻址到某个柱面，然后激活某个磁头，然后随着盘面旋转， 磁头定位到某个扇区上。 「柱面-磁头-扇区」这个寻址方式，听起来可能不太符合直觉，尤其是柱面的概念。直觉上， 可能更合理的寻址方式是「盘片-盘面-磁道-扇区」，而柱面在这里是同磁道不同盘片盘面构成的一个集合。 不过理解了磁盘的机械结构的话，柱面的概念就比较合理了，寻址时先驱动磁头臂旋转， 磁头臂上多个磁头一起飞到某个磁道上，从而运动磁头臂的动作定义了一个柱面。 柱面和磁头（CH）组合起来能定位到某个特定的磁道，画张图大概如下图所示： tikz diagram 上图中值得注意的是磁道的编号方式，我用相同的颜色画出了相同的磁道。因为按照 CHS 的顺序寻址，所以先定位柱面，然后选定磁头。磁盘上按半径从外向内定义柱面的编号，最外圈的磁道位于 0号柱面，由0号磁头开始。随着柱面编号增加，逐步从外圈定位到内圈。 物理 CHS 寻址 以上术语中，柱面号和磁头号直接对应了硬盘上的物理组成部分，所以在物理 CHS 寻址方式下，通过扇区地址的写法能对应到扇区的具体物理位置。之所以这样描述扇区， 是因为早期的软盘和硬盘驱动器没有内置的控制芯片，可以完全由宿主系统执行驱动程序驱动。 在 IBM PC 上，驱动软盘和硬盘的是 CPU 执行位于主板 BIOS (Basic Input/Output System) 中的程序，具体来说操作系统（比如DOS）和应用程序调用 INT 13H 中断，通过 AH=02H/03H 选择读/写操作，BIOS 在中断表中注册的 13H 中断处理程序执行在 CPU 上完成读写请求。调用 INT 13H 读写扇区的时候，CPU 先通过 INT 13H AH=0CH 控制硬盘的磁头臂旋转到特定柱面上，然后选定具体磁头，让磁头保持在磁道上读数据， 通过忙轮训的方式等待要读写的扇区旋转到磁头下方，从而读到所需扇区的数据。在 DOS 之后的操作系统， 比如早期的 Windows 和 Linux 和 BSD 能以覆盖中断程序入口表的方式提供升级版本的这些操作替代 BIOS 的程序。 以上过程中可以看出两点观察： CHS 寻址下，跨磁道的寻址（不同 CH 值），和磁道内的寻址（同 CH 不同 S ），是本质上不同的操作。跨磁道的寻址有移动磁头臂的动作，会比磁道内寻址花费更多时间。 通过扇区号的磁道内寻址是个忙轮训操作，需要占用完整 CPU 周期。这也隐含扇区号在一个磁道内的物理排列不必是连续的。 实际上扇区号的物理排列的确不是连续的，每个物理扇区中除了用512字节记录扇区本身的数据， 还有扇区的开始记录和结束记录，写有扇区编号和扇区校验码。每读到一个扇区， CPU 可能需要做一些额外操作（比如计算比对校验、写入内存缓冲区、调整内存段页映射） 后才能继续读下一个扇区，如果物理排列上连续编号扇区，可能等 CPU 做完这些事情后磁头已经旋转到之后几个扇区上了。所以出厂时做磁盘低级格式化的时候， 会跳跃着给扇区编号，给 CPU 留足处理时间。比如下图： tikz diagram 上图中假设有3个柱面，每个柱面6个磁头，每个磁道内11个扇区，并且画出了三种不同的扇区编号跳转情况， 分别是磁道内的扇区跳转（+3），柱面内的磁头跳转（+5），以及柱面间跳转（+10）。 实际磁盘上的柱面数、扇区数要多很多，寻址时需要跳转的距离也可能更长，这里只是举例说明。 图中和实际情况相同的是，柱面号和磁头号从 0 开始编号，而扇区号从 1 开始编号， 所以做逻辑地址换算的时候要考虑编号差异。 早期 IBM PC 的 BIOS 使用 24bit 的 CHS 地址，其中 10bit 柱面(C)、 8bit 磁头(H)、 6bit 扇区(S)。从而用物理 CHS 寻址方式的软盘和硬盘驱动器最多可以寻址 1024 个柱面，256 个磁头， 63 个扇区，其中扇区数因为从 1 开始编号所以少了 1 个可寻址范围。比如 3.5 吋高密度（HD）软盘有双面， 出厂时每面 80 磁道，每磁道 18 扇区，从而能算出 1,474,560 字节的容量。 如此跳跃编号扇区之后，不是总能给磁道中所有扇区编号，可能在磁道的末尾位置留几个没有使用的扇区空间， 这些是磁道内的保留扇区，可以在发现坏扇区后使用这些隐藏扇区作为替代扇区。当然读写替代扇区的时候 因为扇区寻址不连续可能会有一定性能损失。 因为物理 CHS 寻址下，磁盘由 CPU 执行驱动程序来驱动，所以以上扇区跳跃的长短实际是由 CPU 的速度等因素决定的，理论上 CPU 越快，跳跃间隔可以越短，从而磁盘读写速度也能加快。磁盘出厂时， 厂商并不知道使用磁盘的计算机会是怎样的性能，所以只能保守地根据最慢的 CPU 比如 IBM 初代 PC 搭配的 8086 的速度来决定跳跃间隔。所以在当年早期玩家们流传着这样一个操作：买到新硬盘， 或者升级了电脑配置之后，对硬盘做一次 低级格式化(Low level formating) ，聪明的低级格式化程序能智能安排扇区编号，提升硬盘读写速度，也能跳过已知坏道位置继续编号， 甚至可能将更多保留扇区暴露成可用扇区。这对现代有硬盘控制器的硬盘而言已经没有意义了。 逻辑 CHS 寻址 随着硬盘容量不断增加， BIOS 中用来 CHS 寻址的地址空间逐渐不够用了。早期 24bit 地址按 C H S 的顺序分为 10 8 6 的位数，用 8bit 来寻址磁头最多可以有 256 个磁头，而只有 10bit 来寻址柱面，就只能有 1024 个柱面。最初 IBM 这么划分是因为早期用于 IBM 大型机之类的硬盘可以有 厚厚一叠的盘片组，同样的寻址方式就直接用于了 IBM PC 。而 PC 用的硬盘迫于硬盘仓空间大小， 有厚度限制，硬盘中物理盘面可能只有四五个盘片，硬盘容量增加主要是增加盘片表面的数据密度而非增加盘片数量。 于是逐渐地，硬盘厂商开始对 CHS 寻址的地址空间做一些手脚。比如最初的简单想法是重新定义 CH ，将一些磁头数挪用做柱面数。从而有了逻辑 CHS 寻址，其中 CH 是固定一组，通过简单换算从 CH 值找到物理的柱面和磁头数。结合 CH 而不映射 S 的优势在于，从操作系统和文件系统来看依然能根据逻辑 CHS 地址估算出地址跳转所需大概的时间，只是原本一次切换磁头的动作可能变成一次短距离的切换柱面。 此时的操作系统和文件系统已经开始出现针对 CHS 寻址特点的优化方式， 尽量减少跨磁道的寻址能一定程度提升读写速度，跨磁道时的磁道间距离也会影响寻道时间， 文件系统可能会根据CHS地址来安排数据结构，优化这些寻址时间。 即便使用没有针对 CHS 寻址方式优化过的操作系统和文件系统，比如局限在早期 Windows 和 FAT 系文件系统上，早期这些桌面系统用户们仍然能自己优化磁盘读写性能：通过分区。 分区是硬盘上连续的一段空间，早期由于 BIOS 和 bootloader 的一些技术限制， 每个分区必须对齐到柱面大小上。早期 PC 玩家们通过把一个大硬盘切分成多个小分区， 使用时尽量保持近期读写针对同一个分区，就可以减少寻址时的额外开销，改善读写速度。 于是隐含地，CHS 寻址导致底层硬盘和上层操作系统之间有一层性能约定： 连续读写保证最快的读写速度 。硬盘实现 CHS 寻址时，调整扇区编号方式让连续的 CHS 地址有最快读写速度，文件系统也根据这个约定， 按照 CHS 地址的跳跃来估算读写速度耗时并针对性优化。 区位记录（Zone bit recoding, ZBR） 以上物理 CHS 寻址，其实依赖一个假设： 每个磁道上有同样数量的扇区 。早期硬盘上也的确遵循这个假设， 所以我们上面的图示里才能把一个盘面上的扇区展开成一张长方形的表格，因为每个磁道的扇区数是一样的。 实际上当时的硬盘都是恒定角速度（constant angular velocity, CAV）的方式读写，无论磁头在哪儿， 盘片都旋转保持恒定的转速，所以对磁头来说在单位时间内转过的角度影响读写二进制位的数量， 而磁头扫过的面积在这里没有影响。 区位记录（来自维基百科 Zone bit recording 词条 ） DiskStructure.svg 不过随着硬盘容量增加，盘面的数据密度也随之增加，单位面积中理论能容纳的二进制位数量有限。 理论上，如果保持相同密度的话，盘片外圈能比内圈容纳更多数据。因此硬盘厂商们开始在盘面上将磁道划分出 区块（zone），外圈区块中的磁道可以比内圈区块中的磁道多放入一些扇区。这种方式下生产出的硬盘叫 区位记录硬盘（Zone bit recoding, ZBR），相对的传统固定磁道中扇区数的硬盘就被叫做恒定角速度（CAV） 硬盘。 如右图所示，区位记录在硬盘上将多个柱面组合成一个区块，区块内的磁道有相同数量的扇区， 而不同区块的磁道可以有不同数量的扇区，外圈区块比内圈区块有更多扇区。 显然要支持 ZBR ，物理 CHS 寻址方式不再有效，于是 ZBR 硬盘将原本简单的地址换算电路升级为更复杂的磁盘控制器芯片，替代 CPU 来驱动硬盘，把来自文件系统的逻辑 CHS 地址通过换算转换到物理 CHS 地址，并且驱动磁头做跳转和寻址。 从而有了独立的控制芯片之后，硬盘读写扇区的速度不再受 CPU 速度影响。有了完整的逻辑-物理地址转换后， 逻辑扇区编号不再对应物理扇区编号，上述编号跳转和坏扇区处理之类的事情都由磁盘控制芯片代为完成。 从而 CHS 地址已经丧失了物理意义，只留下 连续读写保证最快的读写速度 这样的性能约定。 有了 ZBR 之后，硬盘读写速度也不再恒定，虽然仍然保持恒定转速，但是读写外圈磁道时单位时间扫过的扇区 多于读写内圈磁道时扫过的扇区。所以 ZBR 硬盘的低端地址比高端地址有更快的读写速度， 通过硬盘测速软件能观察到阶梯状的「掉速」现象。 逻辑地址转换也会造成逻辑 CHS 寻址能访问到的扇区数少于物理 CHS 寻址的现象， 磁盘中扇区被重新编号后可能有一些扇区剩余，于是 ZBR 硬盘的出厂低级格式化可能会均分这些访问不到的扇区 给每个磁道作为保留扇区，留作坏扇区后备。 另外有了独立磁盘控制器芯片之后，扇区内的校验算法也不再受制于 BIOS INT 13H 接口。 原本 BIOS 的 INT 13H 接口定义了每个扇区 512 字节，额外配有 4 字节校验， 32bit 的校验码对 4096bit 的数据来说，只能允许一些简单的校验算法，比如 32bit CRC ，或者比如 汉明码 对 4096bit 的数据需要 13bit 的校验。突破了校验算法限制后硬盘可以在物理扇区中放更多校验位，使用更复杂的 ECC 算法，提供更强的容错性。 IDE/SATA 接口的硬盘由内部控制器负责计算和比对校验，而 SAS 接口的硬盘（主要用于服务器）可以读取 520/528 字节长度的扇区，包含额外校验位。 通过 ZBR ，逻辑 CHS 寻址不再局限在具体每磁道扇区数等物理限制上，但是仍然局限在 CHS 总位数。 24bit 的 CHS 地址能寻址 \\(1024*256*63 = 16515072\\) 个扇区，也就是 8064MiB 的空间。 于是早期很多操作系统有 7.8G 硬盘大小的限制。后来 ATA/IDE 标准提升了 CHS 寻址数量，从 24bit 到 28bit 到 32bit ，不过在系统引导早期仍然依赖 BIOS 最基本的 24bit CHS 寻址能力，于是那时候安装系统时要求引导程序装在前 8G 范围内也是这个原因。 从 CHS 到 LBA 随着硬盘大小不断提升，无论是操作系统软件层，还是硬盘厂商硬件层，都逐渐意识到逻辑 CHS 寻址是两边相互欺骗对方的骗局：文件系统根据假的 CHS 地址的提示苦苦优化，而硬盘控制器又要把物理 CHS 模拟到假的 CHS 地址上以兼容 BIOS 和操作系统。和 CS 领域太多别的事情一样， CHS 寻址过早地暴露出太多底层抽象细节，而上层软件又转而依赖于这些暴露出的细节进行优化， 底层细节的变动使得上层优化不再是有意义的优化。 于是 ATA 标准 引入了 逻辑块寻址（Logical Block Addressing, LBA） 来替代 CHS 寻址，解决其中的混乱。LBA 的思路其实就是逻辑 CHS 寻址的简单换算，因为 CHS 寻址下 S 从 1 开始计算，而 LBA 使用连续扇区编号，从 0 开始编号，所以换算公式如下： \\begin{equation*} LBA 地址 = ( C \\times 磁头数 + H ) \\times 扇区数 + ( S - 1 ) \\end{equation*} 使用 LBA 寻址，操作系统和文件系统直接寻址一个连续地址空间中的扇区号， 不应该关心柱面和磁头之类的物理参数，将这些物理细节交由磁盘控制器。 对操作系统和文件系统这些上层软件而言，LBA寻址的抽象仍然保证了 连续读写提供最快的读写速度 ，文件系统仍然会尝试根据 LBA 地址优化，尽量连续读写从而减少寻道时间。 从 CHS 寻址切换到 LBA 寻址，需要硬盘和操作系统两方面的努力，所以很长一段时间， 硬盘同时支持两种寻址方式，在控制器内部做转换。最后需要放弃支持的是深植了 CHS 寻址的 BIOS ，使用 BIOS 引导的 MBR 引导程序还在用 CHS 寻址方式读取数据加载操作系统，直到大家都切换到 UEFI 。 并且随着硬盘使用 LBA 寻址，导致上层软件很难预测底层硬件实际切换柱面切换磁头之类的时机， 潜在地导致一些性能不确定性。于是硬盘控制器在除了负责实际驱动物理磁盘之外， 还开始负责维护一块盘内缓冲区，实现盘内的 IO 队列。缓冲区的存在允许磁盘控制器同时接收更多来自上层软件 的读写请求，转换成实际物理布局参数，并根据磁盘物理布局来调整读写顺序，增加总体吞吐率。 比如 ATA TCQ 和 SATANCQ 就是这样的盘内队列协议。 当然有缓冲区和盘内队列的存在也使得突然断电之类的情况下更难保证数据一致性，于是 SCSI/SATA 标准开始约定特殊的请求，从操作系统能发送命令让底层设备清空自己的读写队列。 叠瓦磁记录（Shingled Magnetic Recording, SMR） 逐渐从历史讲到了现在，随着硬盘记录密度的不断增加，硬盘厂商们也在不断发明新技术尝试突破磁盘记录的物理极限。 因为有了在硬盘上独立的控制器，并且切换到了逻辑块地址（LBA）的寻址方式， 操作系统大部分时候不用再关心底层硬盘的物理技术革新，比如垂直写入技术（perpendicular magnetic recording, PMR）将磁头记录方式从水平转换成垂直记录，增加了记录密度，但不影响寻址方式。 叠瓦磁记录（来自 The Feasibility of Magnetic Recording at 10 Terabits Per Square Inch on Conventional Media ） 不过技术革新中也有影响寻址方式的技术，比如 叠瓦磁记录技术（Shingled Magnetic Recording, SMR） 。 SMR 技术基于一个技术事实：物理上磁头的写入头（write head）需要比读取头(read head )占用更大面积，如果按照写入头的物理极限放置磁记录，那么对于读取头会有很多空间浪费。从而 SMR 试图让相邻磁道的写入有部分重叠，从而增加记录密度。即便重叠了相邻磁道，读取磁道还是能随机定位， 而写入磁道会覆盖它后面叠加上的磁道，所以写入磁道必须严格按地址顺序写入。为了满足随机顺序写入的需要， SMR 硬盘把连续的几个磁道组织成区块（zone），在一个区块内必须按顺序写入。 这里的区块可以和区位记录（ZBR）是同样的区块，也可以独立于 ZBR 做不同大小的区块分割。 这种区块内连续写入的要求，很像是 SSD 这种基于闪存介质的记录方式， SMR 硬盘也同样像 SSD 一样在磁盘控制器内引入 日志结构式的记录方式，采用类似的 GC 算法 ，收到随机写入请求的时候，在区块间执行 GC 搬运数据块，对操作系统提供可以任意写入的抽象接口。 当然这种类似闪存介质的 FTL 的抽象有对读写性能的直接影响。SMR 硬盘可以将这些细节完全隐藏起来（ Device Managed），或者完全暴露给宿主系统（Host Managed ），或者在读写时隐藏细节的同时在宿主想查询的时候提供接口查询（Host Aware）。和 SSD 一样，消费级的 SMR 硬盘通常选择隐藏细节只在被询问时暴露，完全暴露细节的设备通常只在企业服务器级别 的产品中看到。 可以期待，随着 SMR 硬盘的逐渐普及，文件系统设计中也将更多考虑 SMR 的特性加以优化。这些优化可能参考 对 SSD 的优化（比如尽量连续写入），但是又不能完全照搬（比如 SSD 需要考虑写平衡而 SMR 硬盘不需要，比如 SSD 不用担心随机寻道时间而 SMR 硬盘需要）。这些对现在和未来文件系统的设计提供了更多挑战。 4KiB 扇区大小 不局限于硬盘，存储设备发展中另一个方向是增加扇区大小。如前所述，在应用于 PC 之前的硬盘设计也曾有过比 512 字节更小的扇区大小，而自从 PC 普及之后 512 字节扇区逐渐成为主流， 甚至到了挥之不去的地步。随着硬盘容量提升，直接寻址 512 字节的扇区显得不再那么高效， 文件系统内部也早已把多个扇区合并成一个逻辑簇（cluster）或者块（block），按簇或块的粒度管理。 在底层硬件同样也是按照 512 字节大小划分扇区，每个扇区都要独立计算校验，如果能增大扇区大小到比如 4KiB，将能更经济地安排扇区校验码，从而得到更多可用容量。可见 512 字节扇区大小这一设计，和 CHS 寻址一样，逐渐成为了操作系统和硬盘厂商彼此间互相努力维护的谎言。 硬盘物理扇区提升为 4KiB 大小的设计，叫做「 先进格式化（Advanced Format） 」，这样的硬盘叫做先进格式化硬盘（AFD）。在此基础上，硬盘控制器可以提供模拟 512 字节扇区的模拟层， 叫做 512e ，也可以直接提供 4K 大小的扇区给操作系统，叫做 4K native (4Kn)。 操作系统和文件系统要尽量避免依赖 512e 以提供最优性能，支持 4Kn 扇区寻址也是现在和未来 文件系统设计中一个重要挑战。 双磁头臂（Dual Actuator） 双磁头臂（来自 Seagate Storage Update - LOC Designing Storage Architecture for Digital Collections ） 除了提升容量，硬盘发展的另一个方向是提升读写速度。通过上述 CHS 寻址方式可见， 传统方式下提升硬盘读写速度有两种方式： 提升磁记录密度 提升（磁头臂和盘片）转速 第一种方式提升记录密度，在增加容量的同时也能提升硬盘读写速度，所以是长久以来硬盘厂商的主要方式。 第二种方式提升转速则很快就遇到了物理瓶颈，硬盘以前是 5400rpm 现在最高能到 15000rpm 附近，高速旋转的盘片就像一个螺旋桨一样，外圈线速度已经到了接近声速，很难再往上提升。 以及盘片转速影响连续读写速度，而磁头臂转速影响寻道速度，高速寻道对磁头臂旋转有极高精度要求。 所以长久以来，衡量硬盘速度有两项指标：连续读写速度和每秒操作数(IOPS)，随着容量提升， 也在提升连续读写速度，但是很难提升 IOPS ，相对而言随机寻道所需的开销越来越昂贵。 目前硬盘厂商们在尝试一种新的方式提升硬盘 IOPS ：增加一条磁头臂。一个硬盘驱动器内封入两组甚至多组 磁头臂，每个磁头臂能独立旋转，从而能独立寻址定位。这样的硬盘叫双/多磁头臂（Dual/Multi Actuator）硬盘。 从操作系统角度来看，双磁头臂硬盘更像是一根连接线上接有等容量的两个独立驱动器， 可以在盘内控制器上组 RAID0 ，或者把两个磁头臂都暴露给操作系统，由操作系统组 RAID0 或更智能地使用独立寻址的能力。 结论（TL;DR）和预告 软件层面的优化与硬件层面的革新一直是一组矛盾。长久以来文件系统和硬盘设备在关于寻址方式的磨合中， 逐渐演化出一条真理，也是我文中一直在强调的： 连续读写提供最快的读写速度 。文件系统总是能根据底层设备暴露出的一些抽象泄漏，比如物理 CHS 布局，比如 512 字节扇区大小， ，针对性做更多优化，但是随着底层设备的技术革新这些优化也随之成为泡影。 从 SMR 技术中也能看出， 硬盘的读写接口也在逐渐向 SSD 的接口靠拢，从而文件系统的「优化」也在逐渐 向这种「倾向顺序写入」的方向优化。关于这些发展趋势待我有空再谈。","tags":"tech","url":"//farseerfc.me/zhs/history-of-chs-addressing.html"},{"title":"Btrfs vs ZFS 实现 snapshot 的差异","text":"zfs 这个东西倒是名不符实。叫 z storage stack 明显更符合。 叫 fs 但不做 fs 自然确实会和 btrfs 有很大出入。 我反而以前还好奇为什么 btrfs 不弄 zvol ， 直到我意识到这东西真是一个 fs ，名符奇实。 —— 某不愿透露姓名的 Ext2FSD 开发者 Btrfs 和 ZFS 都是开源的写时拷贝（Copy on Write, CoW）文件系统，都提供了相似的子卷管理和 快照(snapshot）的功能。网上有不少文章都评价 ZFS 实现 CoW FS 的创新之处，进而想说「 Btrfs 只是 Linux/GPL 阵营对 ZFS 的拙劣抄袭」。或许（在存储领域人尽皆知而在领域外）鲜有人知，在 ZFS 之前就有 NetApp 的商业产品 WAFL (Write Anywhere File Layout) 实现了 CoW 语义的文件系统，并且集成了快照和卷管理之类的功能。描述 btrfs 原型设计的 论文 和 发表幻灯片 也明显提到 WAFL 比提到 ZFS 更多一些，应该说 WAFL 这样的企业级存储方案才是 ZFS 和 btrfs 共同的灵感来源，而无论是 ZFS 还是 btrfs 在其设计中都汲取了很多来自 WAFL 的经验教训。 我一开始也带着「 Btrfs 和 ZFS 都提供了类似的功能，因此两者必然有类似的设计」这样的先入观念，尝试去使用这两个文件系统， 却经常撞上两者细节上的差异，导致使用时需要不尽相同的工作流， 或者看似相似的用法有不太一样的性能表现，又或者一边有的功能，比如 ZFS 的在线去重（in-band dedup） ， Btrfs 的 reflink ，在另一边没有的情况，进而需要不同细粒度的子卷划分方案。后来看到了 LWN 的这篇 《A short history of btrfs》 让我意识到 btrfs 和 ZFS 虽然表面功能上看起来类似，但是实现细节上完全不一样， 所以需要不一样的用法，适用于不一样的使用场景。 为了更好地理解这些差异，我四处搜罗这两个文件系统的实现细节，于是有了这篇笔记， 记录一下我查到的种种发现和自己的理解。 （或许会写成一个系列？还是先别乱挖坑不填。） 只是自己的笔记，所有参阅的资料文档都是二手资料，没有深挖过源码，还参杂了自己的理解， 于是难免有和事实相违的地方，如有写错，还请留言纠正。 1 Btrfs 的子卷和快照 关于写时拷贝（CoW）文件系统的优势，我们为什么要用 btrfs/zfs 这样的写时拷贝文件系统， 而不是传统的文件系统设计，或者写时拷贝文件系统在使用时有什么区别之类的，网上同样也能找到很多介绍 ，这里不想再讨论。这里假设你用过 btrfs/zfs 至少一个的快照功能，知道它该怎么用， 并且想知道更多细节，判断怎么用那些功能才合理。 先从两个文件系统中（表面上看起来）比较简单的 btrfs 的子卷（subvolume）和快照（snapshot）说起。 关于子卷和快照的常规用法、推荐布局之类的话题就不细说了，网上能找到很多不错的资料，比如 btrfs wiki 的 SysadminGuide 页 和 Arch wiki 上 Btrfs#Subvolumes 页都有不错的参考价值。 1.1 子卷和快照的术语 在 btrfs 中，存在于存储媒介中的只有「子卷」的概念，「快照」只是个创建「子卷」的方式， 换句话说在 btrfs 的术语里，子卷（subvolume）是个名词，而快照（snapshot）是个动词。 如果脱离了 btrfs 术语的上下文，或者不精确地称呼的时候，也经常有文档把 btrfs 的快照命令创建出的子卷叫做一个快照，所以当提到快照的时候，根据上下文判断这里是个动词还是名词， 把名词的快照当作用快照命令创建出的子卷就可以了。或者我们可以理解为， 互相共享一部分元数据（metadata）的子卷互为彼此的快照（名词） ， 那么按照这个定义的话，在 btrfs 中创建快照（名词）的方式其实有两种： 用 btrfs subvolume snapshot 命令创建快照 用 btrfs send 命令并使用 -p 参数发送快照，并在管道另一端接收 btrfs send 命令的 -p 与 -c 这里也顺便提一下 btrfs send 命令的 -p 参数和 -c 参数的差异。 只看 btrfs-send(8) 的描述的话： -p <parent> send an incremental stream from parent to subvol -c <clone-src> use this snapshot as a clone source for an incremental send (multiple allowed) 看起来这两个都可以用来生成两个快照之间的差分，只不过 -p 只能指定一个「parent」， 而 -c 能指定多个「clone source」。在 unix stackexchange 上有人写明了这两个的异同 。使用 -p 的时候，产生的差分首先让接收端用 subvolume snapshot 命令对 parent 子卷创建一个快照， 然后发送指令将这个快照修改成目标子卷的样子，而使用 -c 的时候，首先在接收端用 subvolume create 创建一个空的子卷，随后发送指令在这个子卷中填充内容，其数据块尽量共享 clone source 已有的数据。 所以 btrfs send -p 在接收端产生是有共享元数据的快照，而 btrfs send -c 在接收端产生的是仅仅共享数据而不共享元数据的子卷。 定义中「互相共享一部分 元数据 」比较重要，因为除了快照的方式之外， btrfs 的子卷间也可以通过 reflink 的形式共享数据块。我们可以对一整个子卷（甚至目录）执行 cp -r --reflink=always ，创建出一个副本，副本的文件内容通过 reflink 共享原本的数据，但不共享元数据，这样创建出的就不是快照。 说了这么多，其实关键的只是 btrfs 在传统 Unix 文件系统的「目录/文件/inode」 这些东西之外只增加了一个「子卷」的新概念，而子卷间可以共享元数据或者数据， 用快照命令创建出的子卷就是共享一部分元数据。 1.2 于是子卷在存储介质中是如何记录的呢？ 首先要说明， btrfs 中大部分长度可变的数据结构都是 CoW B-tree ，一种经过修改适合写时拷贝的B树结构，所以在 on-disk format 中提到了很多个树。这里的树不是指文件系统中目录结构树，而是写时拷贝B树（CoW B-tree，下文简称B树） ，如果不关心B树细节的话可以把 btrfs 所说的一棵树理解为关系数据库中的一个表， 和数据库的表一样 btrfs 的树的长度可变，然后表项内容根据一个 key 排序。 B树结构由索引 key 、中间节点和叶子节点构成。每个 key 是一个 (uint64_t object_id, uint8_t item_type, uint64_t item_extra) 这样的三元组，三元组每一项的具体含义由 item_type 定义。 key 三元组构成了对象的概念，每个对象（object）在树中用一个或多个表项（item）描述，同 object_id 的表项共同描述一个对象。B树中的 key 只用来比较大小而不必连续，从而 object_id 也不必连续，只是按大小排序。有一些预留的 object_id 不能用作别的用途，他们的编号范围是 -255ULL 到 255ULL，也就是表中前 255 和最后 255 个编号预留。 B树中间节点和叶子节点结构大概像是这个样子： btree_nodes btree_node header TREE_NODE key0: address key1: address key2: address ... free space btree_leaf1 header LEAF_NODE key0: offset size key1: offset size key2: offset size ... keyN offset size free space dataN ... data2 data1 data0 btree_node:key0->btree_leaf1:label btree_leaf1:e->btree_leaf1:e btree_leaf1:w->btree_leaf1:w btree_leaf1:e->btree_leaf1:e 由此，每个中间节点保存一系列 key 到叶子节点的指针，而叶子节点内保存一系列 item ，每个 item 固定大小，并指向节点内某个可变大小位置的 data 。从而逻辑上一棵B树可以包含任何类型的 item ，每个 item 都可以有可变大小的附加数据。通过这样的B树结构，可以紧凑而灵活地表达很多数据类型。 有这样的背景之后，比如在 SysadminGuide 这页的 Flat 布局 有个子卷布局的例子。 toplevel (volume root directory, not to be mounted by default) +-- root (subvolume root directory, to be mounted at /) +-- home (subvolume root directory, to be mounted at /home) +-- var (directory) | \\-- www (subvolume root directory, to be mounted at /var/www) \\-- postgres (subvolume root directory, to be mounted at /var/lib/postgresql) 用圆柱体表示子卷的话画成图大概是这个样子： Flat_layout toplevel toplevel root root toplevel->root home home toplevel->home var var toplevel->var postgres postgres toplevel->postgres www www var->www 上图例子中的 Flat 布局在 btrfs 中大概是这样的数据结构， 其中实线箭头是B树一系列中间节点和叶子节点，逻辑上指向一棵B树，虚线箭头是根据 inode 号之类的编号的引用： Flat_layout_on_disk superblock SUPERBLOCK ... root_tree ... roottree ROOT_TREE 2: extent_tree 3: chunk_tree 4: dev_tree 5: fs_tree 6: root_dir \"default\" -> ROOT_ITEM 256 10: free_space_tree 256: fs_tree \"root\" 257: fs_tree \"home\" 258: fs_tree \"www\" 259: fs_tree \"postgres\" -7: tree_log_tree -5: orphan_root superblock:sn_root->roottree:label roottree:e->roottree:e toplevel FS_TREE \"toplevel\" 256: inode_item DIR 256: dir_item: \"root\" -> ROOT_ITEM 256 256: dir_item: \"home\" -> ROOT_ITEM 257 256: dir_item: \"var\" -> INODE_ITEM 257 256: dir_item: \"postgres\" -> ROOT_ITEM 259 257: inode_item DIR 257: dir_item: \"www\" -> ROOT_ITEM 258 roottree:root_fs->toplevel:label root FS_TREE \"root\" 256: inode_item DIR roottree:root_sub_root->root:label home FS_TREE \"home\" 256: inode_item DIR roottree:root_sub_home->home:label www FS_TREE \"www\" 256: inode_item DIR roottree:root_sub_www->www:label postgres FS_TREE \"postgres\" 256: inode_item DIR roottree:root_sub_postgres->postgres:label toplevel:toplevel_dir_root->roottree:root_sub_root toplevel:toplevel_dir_home->roottree:root_sub_home toplevel:toplevel_dir_postgres->roottree:root_sub_postgres toplevel:toplevel_dir_www->roottree:root_sub_www toplevel:e->toplevel:e 上图中已经隐去了很多和本文无关的具体细节，所有这些细节都可以通过 btrfs inspect-internal 的 dump-super 和 dump-tree 查看到。 ROOT_TREE 中记录了到所有别的B树的指针，在一些文档中叫做 tree of tree roots 。「所有别的B树」 举例来说比如 2 号 extent_tree ，3 号 chunk_tree ， 4 号 dev_tree ，10 号 free_space_tree ，这些B树都是描述 btrfs 文件系统结构非常重要的组成部分，但是在本文关系不大， 今后有机会再讨论它们。在 ROOT_TREE 的 5 号对象有一个 fs_tree ，它描述了整个 btrfs pool 的顶级子卷，也就是图中叫 toplevel 的那个子卷（有些文档用定冠词称 the FS_TREE 的时候就是在说这个 5 号树，而不是别的子卷的 FS_TREE ）。除了顶级子卷之外，别的所有子卷的 object_id 在 256ULL 到 -256ULL 的范围之间，对子卷而言 ROOT_TREE 中的这些 object_id 也同时是它们的 子卷 id ，在内核挂载文件系统的时候可以用 subvolid 找到它们，别的一些对子卷的操作也可以直接用 subvolid 表示一个子卷。 ROOT_TREE 的 6 号对象描述的不是一棵树，而是一个名叫 default 的特殊目录，它指向 btrfs pool 的默认挂载子卷。最初 mkfs 的时候，这个目录指向 ROOT_ITEM 5 ，也就是那个顶级子卷，之后可以通过命令 btrfs subvolume set-default 修改它指向别的子卷，这里它被改为指向 ROOT_ITEM 256 亦即那个名叫 \"root\" 的子卷。 每一个子卷都有一棵自己的 FS_TREE （有的文档中叫 file tree），一个 FS_TREE 相当于传统 Unix 文件系统中的一整个 inode table ，只不过它除了包含 inode 信息之外还包含所有文件夹内容。在 FS_TREE 中， object_id 同时也是它所描述对象的 inode 号，所以 btrfs 的 子卷有互相独立的 inode 编号 ，不同子卷中的文件或目录可以拥有相同的 inode 。 或许有人不太清楚子卷间 inode 编号独立意味着什么，简单地说，这意味着你不能跨子卷创建 hard link ，不能跨子卷 mv 移动文件而不产生复制操作。不过因为 reflink 和 inode 无关， 可以跨子卷创建 reflink ，也可以用 reflink + rm 的方式快速「移动」文件（这里移动加引号是因为 inode 变了，传统上不算移动）。 FS_TREE 中一个目录用一个 inode_item 和多个 dir_item 描述， inode_item 是目录自己的 inode ，那些 dir_item 是目录的内容。 dir_item 可以指向别的 inode_item 来描述普通文件和子目录， 也可以指向 root_item 来描述这个目录指向一个子卷。有人或许疑惑，子卷就没有自己的 inode 么？其实如果看 数据结构定义 的话 struct btrfs_root_item 结构在最开头的地方包含了一个 struct btrfs_inode_item 所以 root_item 也同时作为子卷的 inode ，不过用户通常看不到这个子卷的 inode ，因为子卷在被（手动或自动地）挂载到目录上之后， 用户会看到的是子卷的根目录的 inode 。 比如上图 FS_TREE toplevel 中，有两个对象，第一个 256 是（子卷的）根目录，第二个 257 是 \"var\" 目录，256 有4个子目录，其中 \"root\" \"home\" \"postgres\" 这三个指向了 ROOT_TREE 中的对应子卷，而 \"var\" 指向了 inode 257 。然后 257 有一个子目录叫 \"www\" 它指向了 ROOT_TREE 中 object_id 为 258 的子卷。 1.3 那么快照又是如何记录的呢？ 以上是子卷、目录、 inode 在 btrfs 中的记录方式，你可能想知道，如何记录一个快照呢？ 特别是，如果对一个包含子卷的子卷创建了快照，会得到什么结果呢？如果我们在上面的布局基础上执行： btrfs subvolume snapshot toplevel toplevel/toplevel@s1 那么产生的数据结构大概如下所示： Flat_layout_on_disk superblock SUPERBLOCK ... root_tree ... roottree ROOT_TREE 2: extent_tree 3: chunk_tree 4: dev_tree 5: fs_tree 6: root_dir \"default\" -> ROOT_ITEM 256 10: free_space_tree 256: fs_tree \"root\" 257: fs_tree \"home\" 258: fs_tree \"www\" 259: fs_tree \"postgres\" 260: fs_tree \"toplevel@s1\" -7: tree_log_tree -5: orphan_root superblock:sn_root->roottree:label roottree:e->roottree:e toplevel FS_TREE \"toplevel\" 256: inode_item DIR 256: dir_item: \"root\" -> ROOT_ITEM 256 256: dir_item: \"home\" -> ROOT_ITEM 257 256: dir_item: \"var\" -> INODE_ITEM 257 256: dir_item: \"postgres\" -> ROOT_ITEM 259 256: dir_item: \"toplevel@s1\" -> ROOT_ITEM 260 257: inode_item DIR 257: dir_item: \"www\" -> ROOT_ITEM 258 roottree:root_fs->toplevel:label toplevels1 FS_TREE \"toplevel@s1\" 256: inode_item DIR 256: dir_item: \"root\" -> ROOT_ITEM 256 256: dir_item: \"home\" -> ROOT_ITEM 257 256: dir_item: \"var\" -> INODE_ITEM 257 256: dir_item: \"postgres\" -> ROOT_ITEM 259 257: inode_item DIR 257: dir_item: \"www\" -> ROOT_ITEM 258 roottree:root_sub_s1->toplevels1:label root FS_TREE \"root\" 256: inode_item DIR roottree:root_sub_root->root:label home FS_TREE \"home\" 256: inode_item DIR roottree:root_sub_home->home:label www FS_TREE \"www\" 256: inode_item DIR roottree:root_sub_www->www:label postgres FS_TREE \"postgres\" 256: inode_item DIR roottree:root_sub_postgres->postgres:label toplevel:toplevel_dir_root->roottree:root_sub_root toplevel:toplevel_dir_home->roottree:root_sub_home toplevel:toplevel_dir_postgres->roottree:root_sub_postgres toplevel:toplevel_dir_toplevels1->roottree:root_sub_s1 toplevel:toplevel_dir_www->roottree:root_sub_www toplevel:e->toplevel:e 在 ROOT_TREE 中增加了 260 号子卷，其内容复制自 toplevel 子卷，然后 FS_TREE toplevel 的 256 号 inode 也就是根目录中增加一个 dir_item 名叫 toplevel@s1 它指向 ROOT_ITEM 的 260 号子卷。这里看似是完整复制了整个 FS_TREE 的内容，这是因为 CoW b-tree 当只有一个叶子节点时就复制整个叶子节点。如果子卷内容再多一些，除了叶子之外还有中间节点， 那么只有被修改的叶子和其上的中间节点需要复制。从而创建快照的开销基本上是 O( level of FS_TREE )，而B树的高度一般都能维持在很低的程度，所以快照创建速度近乎是常数开销。 从子卷和快照的这种实现方式，可以看出： 虽然子卷可以嵌套子卷，但是对含有嵌套子卷的子卷做快照的语义有些特别 。上图中我没有画 toplevel@s1 下的各个子卷到对应 ROOT_ITEM 之间的虚线箭头， 是因为这时候如果你尝试直接跳过 toplevel 挂载 toplevel@s1 到挂载点， 会发现那些子卷没有被自动挂载，更奇怪的是那些子卷的目录项也不是个普通目录， 尝试往它们中放东西会得到无权访问的错误，对它们能做的唯一事情是手动将别的子卷挂载在上面。 推测原因在于这些子目录并不是真的目录，没有对应的目录的 inode ，试图查看它们的 inode 号会得到 2 号，而这是个保留号不应该出现在 btrfs 的 inode 号中。 每个子卷创建时会记录包含它的上级子卷，用 btrfs subvolume list 可以看到每个子卷的 top level subvolid ，猜测当挂载 A 而 A 中嵌套的 B 子卷记录的上级子卷不是 A 的时候， 会出现上述奇怪行为。嵌套子卷的快照还有一些别的奇怪行为，大家可以自己探索探索。 建议用平坦的子卷布局 因为上述嵌套子卷在做快照时的特殊行为， 我个人建议是 保持平坦的子卷布局 ，也就是说： 只让顶层子卷包含其它子卷，除了顶层子卷之外的子卷只做手工挂载，不放嵌套子卷 只在顶层子卷对其它子卷做快照，不快照顶层子卷 虽然可以在顶层子卷放子卷之外的东西（文件或目录），不过因为想避免对顶层子卷做快照， 所以避免在顶层子卷放普通文件。 btrfs 的子卷可以设置「可写」或者「只读」，在创建一个快照的时候也可以通过 -r 参数创建出一个只读快照。通常只读快照可能比可写的快照更有用，因为 btrfs send 命令只接受只读快照作为参考点。子卷可以有两种方式切换它是否只读的属性，可以通过 btrfs property set <subvol> ro 直接修改是否只读，也可以对只读子卷用 btrfs subvolume snapshot 创建出可写子卷，或者反过来对可写子卷创建出只读子卷。 只读快照也有些特殊的限制，在 SysadminGuide#Special_Cases 就提到一例，你不能把只读快照用 mv 移出包含它的目录，虽然你能用 mv 给它改名或者移动包含它的目录 到别的地方。 btrfs wiki 上给出这个限制的原因是子卷中记录了它的上级， 所以要移动它到别的上级需要修改这个子卷，从而只读子卷没法移动到别的上级（ 不过我还没搞清楚子卷在哪儿记录了它的上级，记录的是上级目录还是上级子卷）。不过这个限制可以通过 对只读快照在目标位置创建一个新的只读快照，然后删掉原位置的只读快照来解决。 2 ZFS 的文件系统、快照、克隆及其它 Btrfs 给传统文件系统只增加了子卷的概念，相比之下 ZFS 中类似子卷的概念有好几个，据我所知有这些： 数据集（dataset） 文件系统（filesystem） 快照（snapshot） 克隆（clone） 书签（bookmark）：从 ZFS on Linux v0.6.4 开始 检查点（checkpoint）：从 ZFS on Linux v0.8.0 开始 梳理一下这些概念之间的关系也是最初想写下这篇笔记的初衷。先画个简图，随后逐一讲讲这些概念： 上图中，假设我们有一个 pool ，其中有 3 个文件系统叫 fs1~fs3 和一个 zvol 叫 zv1 ，然后文件系统 fs1 有两个快照 s1 和 s2 ，和两个书签 b1 和 b2。pool 整体有两个检查点 cp1 和 cp2 。这个简图将作为例子在后面介绍这些概念。 2.1 ZFS 设计中和快照相关的一些术语和概念 数据集 ZFS 中把文件系统、快照、克隆、zvol 等概念统称为数据集（dataset）。 一些文档和介绍中把文件系统叫做数据集，大概因为在 ZFS 中，文件系统是最先创建并且最有用的数据集。 在 ZFS 的术语中，把底层管理和释放存储设备空间的叫做 ZFS 存储池（pool）， 简称 zpool ，其上可以容纳多个数据集，这些数据集用类似文件夹路径的语法 pool_name/​dataset_path@snapshot_name 这样来称呼。 存储池中的数据集一同共享可用的存储空间，每个数据集单独跟踪自己所消耗掉的存储空间。 数据集之间有类似文件夹的层级父子关系，这一点有用的地方在于可以在父级数据集上设定一些 ZFS 参数， 这些参数可以被子级数据集继承，从而通过层级关系可以方便地微调 ZFS 参数。在 btrfs 中目前还没有类似的属性继承的功能。 zvol 的概念和本文关系不大，可以参考我上一篇 ZFS 子系统笔记中 ZVOL 的说明 。用 zvol 能把 ZFS 当作一个传统的卷管理器，绕开 ZFS 的 ZPL（ZFS Posix filesystem Layer） 层。在 Btrfs 中可以用 loopback 块设备某种程度上模拟 zvol 的功能。 文件系统 创建了 ZFS 存储池后，首先要在其中创建文件系统（filesystem），才能在文件系统中存储文件。 容易看出 ZFS 文件系统的概念直接对应 btrfs 中的子卷。文件系统（filesystem）这个术语， 从命名方式来看或许是想要和（像 Solaris 的 SVM 或者 Linux 的 LVM 这样的）传统的卷管理器 与其上创建的多个文件系统（Solaris UFS 或者 Linux ext）这样的上下层级做类比。 从 btrfs 的子卷在内部结构中叫作 FS_TREE 这一点可以看出，至少在 btrfs 早期设计中大概也是把子卷称为 filesystem 做过类似的类比的。 和传统的卷管理器与传统文件系统的上下层级不同的是， ZFS 和 btrfs 中由存储池跟踪和管理可用空间， 做统一的数据块分配和释放，没有分配的数据块算作整个存储池中所有 ZFS 文件系统或者 btrfs 子卷的可用空间。 与 btrfs 的子卷不同的是， ZFS 的文件系统之间是完全隔离的，（除了后文会讲的 dedup 方式之外）不可以共享任何数据或者元数据。一个文件系统还包含了隶属于其中的快照（snapshot）、 克隆（clone）和书签（bookmark）。在 btrfs 中一个子卷和对其创建的快照之间虽然有父子关系， 但是在 ROOT_TREE 的记录中属于平级的关系。 上面简图中 pool 里面包含 3 个文件系统，分别是 fs1~3 。 快照 ZFS 的快照对应 btrfs 的只读快照，是标记数据集在某一历史时刻上的只读状态。 和 btrfs 的只读快照一样， ZFS 的快照也兼作 send/receive 时的参考点。 快照隶属于一个数据集，这说明 ZFS 的文件系统或者 zvol 都可以创建快照。 ZFS 中快照是排列在一个时间线上的，因为都是只读快照，它们是数据集在历史上的不同时间点。 这里说的时间不是系统时钟的时间，而是 ZFS 中事务组（TXG, transaction group）的一个序号。 整个 ZFS pool 的每次写入会被合并到一个事务组，对事务组分配一个严格递增的序列号， 提交一个事务组具有类似数据库中事务的语义：要么整个事务组都被完整提交，要么整个 pool 处于上一个事务组的状态，即使中间发生突然断电之类的意外也不会破坏事务语义。 因此 ZFS 快照就是数据集处于某一个事务组时的状态。 如果不满于对数据集进行的修改，想把整个数据集恢复到之前的状态，那么可以回滚（rollback ）数据集到一个快照。回滚操作会撤销掉对数据集的所有更改，并且默认参数下只能回滚到最近的一个快照。 如果想回滚到更早的快照，可以先删掉最近的几个，或者可以使用 zfs rollback -r 参数删除中间的快照并回滚。 除了回滚操作，还可以直接只读访问到快照中的文件。 ZFS 的文件系统中有个隐藏文件夹叫 \".zfs\" ，所以如果只想回滚一部分文件，可以从 \".zfs/snapshots/SNAPSHOT-NAME\" 中把需要的文件复制出来。 比如上面简图中 fs1 就有 pool/​fs1@s1 和 pool/​fs1@s2 这两个快照， 那么可以在 fs1 挂载点下 .zfs/​snapshots/​s1 的路径直接访问到 s1 中的内容。 克隆 ZFS 的克隆（clone）有点像 btrfs 的可写快照。因为 ZFS 的快照是只读的，如果想对快照做写入，那需要先用 zfs clone 从快照中建出一个克隆，创建出的克隆和快照共享元数据和数据， 然后对克隆的写入不影响数据集原本的写入点。 创建了克隆之后，作为克隆参考点的快照会成为克隆的依赖，克隆存在期间无法删除掉作为其依赖的快照。 一个数据集可以有多个克隆，这些克隆都独立于数据集当前的写入点。使用 zfs promote 命令可以把一个克隆「升级」成为数据集的当前写入点，从而数据集原本的写入点会调转依赖关系， 成为这个新写入点的一个克隆，被升级的克隆原本依赖的快照和之前的快照会成为新数据集写入点的快照。 比如上面简图中 fs1 有 c1 的克隆，它依赖于 s2 这个快照，从而 c1 存在的时候就不能删除掉 s2 。 书签 这是 ZFS 一个比较新的特性，ZFS on Linux 分支从 v0.6.4 开始支持创建书签的功能。 书签（bookmark）特性存在的理由是基于这样的事实：原本 ZFS 在 send 两个快照间的差异的时候，比如 send S1 和 S2 之间的差异，在发送端实际上只需要 S1 中记录的时间戳（TXG id），而不需要 S1 快照的数据， 就可以计算出 S1 到 S2 的差异。在接收端则需要 S1 的完整数据，在其上根据接收到的数据流创建 S2 。 因此在发送端，可以把快照 S1 转变成书签，只留下时间戳元数据而不保留任何目录结构或者文件内容。 书签只能作为增量 send 时的参考点，并且在接收端需要有对应的快照，这种方式可以在发送端节省很多存储。 通常的使用场景是，比如你有一个笔记本电脑，上面有 ZFS 存储的数据，然后使用一个服务器上 ZFS 作为接收端，定期对笔记本上的 ZFS 做快照然后 send 给服务器。在没有书签功能的时候， 笔记本上至少得保留一个和服务器上相同的快照，作为 send 的增量参考点， 而这个快照的内容已经在服务器上，所以笔记本中存有相同的快照只是在浪费存储空间。 有了书签功能之后，每次将定期的新快照发送到服务器之后，就可以把这个快照转化成书签，节省存储开销。 检查点 这也是 ZFS 的新特性， ZFS on Linux 分支从 v0.8.0 开始支持创建检查点。 简而言之，检查点（checkpoint）可以看作是整个存储池级别的快照，使用检查点能快速将整个存储池都恢复到上一个状态。 这边有篇文章介绍 ZFS checkpoint 功能的背景、用法和限制 ，可以看出当存储池中有检查点的时候很多存储池的功能会受影响（比如不能删除 vdev 、不能处于 degraded 状态、不能 scrub 到当前存储池中已经释放而在检查点还在引用的数据块）， 于是检查点功能设计上更多是给系统管理员准备的用于调整整个 ZFS pool 时的后悔药， 调整结束后日用状态下应该删除掉所有检查点。 2.2 ZFS 的概念与 btrfs 概念的对比 先说书签和检查点，因为这是两个 btrfs 目前完全没有的功能。 书签功能完全围绕 ZFS send 的工作原理，而 ZFS send 位于 ZFS 设计中的 DSL 层面，甚至不关心它 send 的快照的数据是来自文件系统还是 zvol 。在发送端它只是从目标快照递归取数据块，判断 TXG 是否老于参照点的快照，然后把新的数据块全部发往 send stream ；在接收端也只是完整地接收数据块， 不加以处理，。与之不同的是 btrfs 的 send 的工作原理是工作在文件系统的只读子卷层面， 发送端在内核代码中根据目标快照的 b 树和参照点快照的 generation 生成一个 diff （可以通过 btrfs subvolume find-new 直接拿到这个 diff ），然后在用户态代码中根据 diff 和参照点、目标快照的两个只读子卷的数据产生一连串修改文件系统的指令， 指令包括创建文件、删除文件、让文件引用数据块（保持 reflink ）等操作；在接收端则完全工作在用户态下， 根据接收到的指令重建目标快照。可见 btrfs send 需要在发送端读取参照点快照的数据（比如找到 reflink 引用），从而 btrfs 没法（或者很难）实现书签功能。 检查点也是 btrfs 目前没有的功能。 btrfs 目前不能对顶层子卷做递归的 snapshot ，btrfs 的子卷也没有类似 ZFS 数据集的层级关系和可继承属性，从而没法实现类似检查点的功能。 除了书签和检查点之外，剩下的概念可以在 ZFS 和 btrfs 之间有如下映射关系： ZFS 文件系统: btrfs 子卷 ZFS 快照: btrfs 只读快照 ZFS 克隆: btrfs 可写快照 对 ZFS 数据集的操作，大部分也可以找到对应的对 btrfs 子卷的操作。 zfs list: btrfs subvolume list zfs create: btrfs subvolume create zfs destroy: btrfs subvolume delete zfs rename: mv zfs snapshot: btrfs subvolume snapshot -r zfs rollback: 这个在 btrfs 需要对只读快照创建出可写的快照（用 snapshot 命令，或者直接修改读写属性），然后改名或者调整挂载点 zfs diff: btrfs subvolume find-new zfs clone: btrfs subvolume snapshot zfs promote: 和 rollback 类似，可以直接调整 btrfs 子卷的挂载点 可见虽然功能上类似，但是至少从管理员管理的角度而言， zfs 对文件系统、快照、克隆的划分更为清晰， 对他们能做的操作也更为明确。这也是很多从 ZFS 迁移到 btrfs ，或者反过来从 btrfs 换用 zfs 时，一些人困惑的起源（甚至有人据此说 ZFS 比 btrfs 好在 cli 设计上）。 不过 btrfs 子卷的设计也使它在系统管理上有了更大的灵活性。比如在 btrfs 中删除一个子卷不会受制于别的子卷是否存在，而在 zfs 中要删除一个快照必须先保证先摧毁掉依赖它的克隆。 再比如 btrfs 的可写子卷没有主次之分，而 zfs 中一个文件系统和其克隆之间有明显的区别，所以需要 promote 命令调整差异。还有比如 ZFS 的文件系统只能回滚到最近一次的快照， 要回滚到更久之前的快照需要删掉中间的快照，并且回滚之后原本的文件系统数据和快照数据就被丢弃了； 而 btrfs 中因为回滚操作相当于调整子卷的挂载，所以不需要删掉快照， 并且回滚之后原本的子卷和快照还可以继续保留。 加上 btrfs 有 reflink ，这给了 btrfs 在使用中更大的灵活性，可以有一些 zfs 很难做到的用法。 比如想从快照中打捞出一些虚拟机镜像的历史副本，而不想回滚整个快照的时候，在 btrfs 中可以直接 cp --reflink=always 将镜像从快照中复制出来，此时的复制将和快照共享数据块； 而在 zfs 中只能用普通 cp 复制，会浪费很多存储空间。 2.3 ZFS 中是如何存储这些数据集的呢 要讲到存储细节，首先需要 了解一下 ZFS 的分层设计 。不像 btrfs 基于现代 Linux 内核，有许多现有文件系统已经实现好的基础设施可以利用， 并且大体上只用到一种核心数据结构（CoW的B树）； ZFS 则脱胎于 Solaris 的野心勃勃， 设计时就分成很多不同的子系统，逐步提升抽象层次， 并且每个子系统都发明了许多特定需求下的数据结构来描述存储的信息。 在这里和本文内容密切相关的是 ZPL 、 DSL 、 DMU 这些 ZFS 子系统。 Sun 曾经写过一篇 ZFS 的 On disk format 对理解 ZFS 如何存储在磁盘上很有帮助，虽然这篇文档是针对 Sun 还在的时候 Solaris 的 ZFS ，现在 ZFS 的内部已经变化挺大，不过对于理解本文想讲的快照的实现方式还具有参考意义。这里借助这篇 ZFS On Disk Format 中的一些图示来解释 ZFS 在磁盘上的存储方式。 ZFS 的块指针 ZFS 中用的 128 字节块指针 zfs-block-pointer.svg 要理解 ZFS 的磁盘结构首先想介绍一下 ZFS 中的块指针（block pointer, blkptr_t ），结构如右图所示。 ZFS 的块指针用在 ZFS 的许多数据结构之中，当需要从一个地方指向任意另一个地址的时候都会 插入这样的一个块指针结构。大多数文件系统中也有类似的指针结构，比如 btrfs 中有个8字节大小的逻辑地址（logical address），一般也就是个 4字节 到 16字节 大小的整数写着扇区号、块号或者字节偏移，在 ZFS 中的块指针则是一个巨大的128字节（不是 128bit !）的结构体。 128字节块指针的开头是3个数据虚拟地址（DVA, Data Virtual Address），每个 DVA 是 128bit ，其中记录这块数据在什么设备（vdev）的什么偏移（offset）上占用多大（asize)，有 3个 DVA 槽是用来存储最多3个不同位置的副本。然后块指针还记录了这个块用什么校验算法（ cksum ）和什么压缩算法（comp），压缩前后的大小（PSIZE/LSIZE），以及256bit的校验和（checksum）。 当需要间接块（indirect block）时，块指针中记录了间接块的层数（lvl），和下层块指针的数量（fill）。 一个间接块就是一个数据块中包含一个块指针的数组，当引用的对象很大需要很多块时，间接块构成一棵树状结构。 块指针中还有和本文关系很大的一个值 birth txg ，记录这个块指针诞生时的整个 pool 的 TXG id 。一次 TXG 提交中写入的数据块都会有相同的 birth txg ，这个相当于 btrfs 中 generation 的概念。 实际上现在的 ZFS 块指针似乎记录了两个 birth txg ，分别在图中的9行和a行的位置， 一个 physical 一个 logical ，用于 dedup 和 device removal 。值得注意的是块指针里只有 birth txg ，没有引用计数或者别的机制做引用，这对后面要讲的东西很关键。 DSL 的元对象集 理解块指针和 ZFS 的子系统层级之后，就可以来看看 ZFS 存储在磁盘上的具体结构了。 因为涉及的数据结构种类比较多，所以先来画一张逻辑上的简图，其中箭头只是某种引用关系不代表块指针， 方框也不是结构体细节： zfs_layout_simple uberblock UBERBLOCK ... mos_blkptr mos Meta Object Set root dataset config ... uberblock:ub_rootbp->mos:mos_label root_dataset ROOT dataset dataset1 directory dataset2 directory ... mos:mos_root_dataset->root_dataset:rd_label ds1_directory DSL Directory ds1 property ZAP object ds1 child ZAP object ds1 dataset (active) ds1 snapshot1 ds1 snapshot2 ... root_dataset:rd_ds1->ds1_directory:ds1_label ds1_dataset ds1 DMU Object Set ... ds1_directory:ds1_dataset->ds1_dataset:ds1_ds_label ds1_snapshot1 ds1 snapshot1 DMU Object Set ... ds1_directory:ds1_s1->ds1_snapshot1:ds1_s1_label 如上简图所示，首先 ZFS pool 级别有个 uberblock ，具体每个 vdev 如何存储和找到这个 uberblock 今后有空再聊，这里认为整个 zpool 有唯一的一个 uberblock 。从 uberblock 有个指针指向元对象集（MOS, Meta Object Set），它是个 DMU 的对象集，它包含整个 pool 的一些配置信息，和根数据集（root dataset）。根数据集再包含整个 pool 中保存的所有顶层数据集，每个数据集有一个 DSL Directory 结构。然后从每个数据集的 DSL Directory 可以找到一系列子数据集和一系列快照等结构。最后每个数据集有个 active 的 DMU 对象集，这是整个文件系统的当前写入点，每个快照也指向一个各自的 DMU 对象集。 DSL 层的每个数据集的逻辑结构也可以用下面的图表达（来自 ZFS On Disk Format ）： zfs-dsl-infrastructure.svg ZFS On Disk Format 中 4.1 节的 DSL infrastructure ZFS On Disk Format 中 4.2 节的 Meta Object Set zfs-metaobjectset.svg 需要记得 ZFS 中没有类似 btrfs 的 CoW b-tree 这样的统一数据结构，所以上面的这些设施是用各种不同的数据结构表达的。 尤其每个 Directory 的结构可以包含一个 ZAP 的键值对存储，和一个 DMU 对象。 可以理解为， DSL 用 DMU 对象集（Objectset）表示一个整数（uinit64_t 的 dnode 编号）到 DMU 对象的映射，然后用 ZAP 对象表示一个名字到整数的映射，然后又有很多额外的存储于 DMU 对象中的 DSL 结构体。如果我们画出不同的指针和不同的结构体，那么会得到一个稍显复杂的图，见右边「ZFS On Disk Format 中 4.2 节的 Meta Object Set」，图中还只画到了 root_dataset 为止。 看到这里，大概可以理解在 ZFS 中创建一个 ZFS 快照的操作其实很简单：找到数据集的 DSL Directory 中当前 active 的 DMU 对象集指针，创建一个表示 snapshot 的 DSL dataset 结构，指向那个 DMU 对象集，然后快照就建好了。因为今后对 active 的写入会写时复制对应的 DMU 对象集，所以 snapshot 指向的 DMU 对象集不会变化。 3 创建快照这么简单么？那么删除快照呢？ 按上面的存储格式细节来看， btrfs 和 zfs 中创建快照似乎都挺简单的，利用写时拷贝，创建快照本身没什么复杂操作。 如果你也听到过别人介绍 CoW 文件系统时这么讲，是不是会觉得似乎哪儿少了点什么。创建快照是挺简单的， 直到你开始考虑如何删除快照 …… 或者不局限在删除单个快照上， CoW 文件系统因为写时拷贝，每修改一个文件内容或者修改一个文件系统结构， 都是分配新数据块，然后考虑是否要删除这个数据替换的老数据块，此时如何决定老数据块能不能删呢？ 删除快照的时候也是同样，快照是和别的文件系统有共享一部分数据和元数据的， 所以显然不能把快照引用到的数据块都直接删掉，要考察快照引用的数据块是否还在别的地方被引用着， 只能删除那些没有被引用的数据。 深究「如何删快照」这个问题，就能看出 WAFL 、 btrfs 、 ZFS 甚至别的 log-structured 文件系统间的关键区别，从而也能看到另一个问题的答案： 为什么 btrfs 只需要子卷的抽象，而 zfs 搞出了这么多抽象概念？ 带着这两个疑问，我们来研究一下这些文件系统的块删除算法。 3.1 日志结构文件系统中用的垃圾回收算法 讲 btrfs 和 zfs 用到的删除算法之前，先讲一下日志结构（log-structured）文件系统中的垃圾回收（ GC, Garbage Collection）算法。对熟悉编程的人来说，讲到空间释放算法，大概首先会想到 GC ，因为这里要解决的问题乍看起来很像编程语言的内存管理中 GC 想要解决的问题：有很多指针相互指向很多数据结构，找其中没有被引用的垃圾然后释放掉。 首先要澄清一下 日志结构文件系统（log-structured file system） 的定义，因为有很多文件系统用日志，而用了日志的不一定是日志结构文件系统。 在维基百科上有个页面介绍 日志结构文件系统 ，还有个 列表列出了一些日志结构文件系统 。通常说，整个文件系统的存储结构都组织成一个大日志的样子，就说这个文件系统是日志结构的， 这包括很多早期学术研究的文件系统，以及目前 NetBSD 的 LFS 、Linux 的 NILFS ，用在光盘介质上的 UDF ，还有一些专门为闪存优化的 JFFS 、 YAFFS 以及 F2FS 。日志结构文件系统不包括那些用额外日志保证文件系统一致性，但文件系统结构不在日志中的 ext4 、 xfs 、 ntfs 、 hfs+ 。 简单来说，日志结构文件系统就是把存储设备当作一个大日志，每次写入数据时都添加在日志末尾， 然后用写时复制重新写入元数据，最后提交整个文件系统结构。因为这里用了写时复制，原本的数据块都还留着， 所以可以很容易实现快照之类的功能。从这个特征上来说，写时拷贝文件系统（CoW FS）像 btrfs/zfs 这些在一些人眼中也符合日志结构文件系统的特征， 所以也有人说写时拷贝文件系统算是日志结构文件系统的一个子类。不过日志结构文件系统的另一大特征是利用 GC 回收空间，这里是本文要讲的区别，所以在我看来不用 GC 的 btrfs 和 zfs 不算是日志结构文件系统。 举个例子，比如下图是一个日志结构文件系统的磁盘占用，其中绿色是数据，蓝色是元数据（比如目录结构和 inode），红色是文件系统级关键数据（比如最后的日志提交点），一开始可能是这样，有9个数据块， 2个元数据块，1个系统块： 现在要覆盖 2 和 3 的内容，新写入 n2 和 n3 ，再删除 4 号的内容 ，然后修改 10 里面的 inode 变成 n10 引用这些新数据，然后写入一个新提交 n12 ，用黄色表示不再被引用的垃圾，提交完大概是这样： 日志结构文件系统需要 GC 比较容易理解，写日志嘛，总得有一个「添加到末尾」的写入点，比如上面图中的 n12 就是当前的写入点。空盘上连续往后写而不 GC 总会遇到空间末尾，这时候就要覆盖写空间开头， 就很难判断「末尾」在什么地方，而下一次写入需要在哪里了。 这时文件系统也不知道需要回收哪些块（图中的 o2 o3 o4 o10 和 o12），因为这些块可能被别的地方还继续 引用着，需要等到 GC 时扫描元数据来判断。 和内存管理时的 GC 不同的一点在于，文件系统的 GC 肯定不能停下整个世界跑 GC ，也不能把整个地址空间对半分然后 Mark-and-Sweep ，这些在内存中还尚可的简单策略直接放到文件系统中绝对是性能灾难。所以文件系统的 GC 需要并行的后台 GC ，并且需要更细粒度的分块机制能在 Mark-and-Sweep 的时候保持别的地方可以继续写入数据而维持文件系统的正常职能。 通常文件系统的 GC 是这样，先把整个盘分成几个段（segment）或者区域(zone)，术语不同不过表达的概念类似， 然后 GC 时挑一个老段，扫描文件系统元数据找出要释放的段中还被引用的数据块，搬运到日志末尾，最后整个释放一段。 搬运数据块时，也要调整文件系统别的地方对被搬运的数据块的引用。 物理磁盘上一般有扇区的概念，通常是 512B 或者 4KiB 的大小，在文件系统中一般把连续几个物理块作为一个数据块， 大概是 4KiB 到 1MiB 的数量级，然后日志结构文件系统中一个段(segment)通常是连续的很多块，数量级来看大约是 4MiB 到 64MiB 这样的数量级。相比之下 ufs/ext4/btrfs/zfs 的分配器通常还有 block group 的概念， 大概是 128MiB 到 1GiB 的大小。可见日志结构文件系统的段，是位于数据块和其它文件系统 block group 中间的一个单位。段大小太小的话，会显著增加空间管理需要的额外时间空间开销，而段大小太大的话， 又不利于利用整个可用空间，这里的抉择有个平衡点。 继续上面的例子，假设上面文件系统的图示中每一列的4块是一个段，想要回收最开头那个段， 那么需要搬运还在用的 1 到空闲空间，顺带修改引用它的 n10 ，最后提交 n12 ： 要扫描并释放一整段，需要扫描整个文件系统中别的元数据（图中的 n12 和 n10 和 11）来确定有没有引用到目标段中的地址，可见释放一个段是一个 \\(O(N)\\) 的操作，其中 N 是元数据段的数量，按文件系统的大小增长， 于是删除快照之类可能要连续释放很多段的操作在日志文件系统中是个 \\(O(N&#94;2)\\) 甚至更昂贵的操作。 在文件系统相对比较小而系统内存相对比较大的时候，比如手机上或者PC读写SD卡，大部分元数据块（ 其中包含块指针）都能放入内存缓存起来的话，这个扫描操作的开销还是可以接受的。 但是对大型存储系统显然扫描并释放空间就不合适了。 段的抽象用在闪存类存储设备上的一点优势在于，闪存通常也有擦除块的概念，比写入块的大小要大， 是连续的多个写入块构成，从而日志结构的文件系统中一个段可以直接对应到闪存的一个擦除块上。 所以闪存设备诸如U盘或者 SSD 通常在底层固件中用日志结构文件系统模拟一个块设备，来做写入平衡。 大家所说的 SSD 上固件做的 GC ，大概也就是这样一种操作。 基于段的 GC 还有一个显著缺陷，需要扫描元数据，复制搬运仍然被引用到的块，这不光会增加设备写入， 还需要调整现有数据结构中的指针，调整指针需要更多写入，同时又释放更多数据块， F2FS 等一些文件系统设计中把这个问题叫 Wandering Tree Problem ，在 F2FS 设计中是通过近乎「作弊」的 NAT 转换表 放在存储设备期待的 FAT 所在位置，不仅能让需要扫描的元数据更集中，还能减少这种指针调整导致的写入。 不过基于段的 GC 也有一些好处，它不需要复杂的文件系统设计，不需要特殊构造的指针， 就能很方便地支持大量快照。一些日志结构文件系统比如 NILFS 用这一点支持了「连续快照（continuous snapshots）」，每次文件系统提交都是自动创建一个快照，用户可以手动标记需要保留哪些快照， GC 算法则排除掉用户手动标记的快照之后，根据快照创建的时间，先从最老的未标记快照开始回收。 即便如此， GC 的开销（CPU时间和磁盘读写带宽）仍然是 NILFS 最为被人诟病的地方，是它难以被广泛采用的原因。 为了加快 NILFS 这类日志文件系统的 GC 性能让他们能更适合于普通使用场景，也有许多学术研究致力于探索和优化 GC ，使用更先进的数据结构和算法跟踪数据块来调整 GC 策略，比如这里有一篇 State-of-the-art Garbage Collection Policies for NILFS2 。 3.2 WAFL 早期使用的可用空间位图数组 从日志结构文件系统使用 GC 的困境中可以看出，文件系统级别实际更合适的， 可能不是在运行期依赖扫描元数据来计算空间利用率的 GC ，而是在创建快照时或者写入数据时就预先记录下快照的空间利用情况， 从而可以细粒度地跟踪空间和回收空间，这也是 WAFL 早期实现快照的设计思路。 WAFL 早期记录快照占用数据块的思路从表面上来看也很「暴力」，传统文件系统一般有个叫做「位图（bitmap ）」的数据结构，用一个二进制位记录一个数据块是否占用，靠扫描位图来寻找可用空间和已用空间。 WAFL 的设计早期中考虑既然需要支持快照，那就把记录数据块占用情况的位图，变成快照的数组。 于是整个文件系统有个 256 大小的快照利用率数组，数组中每个快照记录自己占用的数据块位图， 文件系统中最多能容纳 255 个快照。 上面每个单元格都是一个二进制位，表示某个快照有没有引用某个数据块。有这样一个位图的数组之后， 就可以直接扫描位图判断出某个数据块是否已经占用，可以找出尚未被占用的数据块用作空间分配， 也可以方便地计算每个快照引用的空间大小或者独占的空间大小，估算删除快照后可以释放的空间。 需要注意的是，文件系统中可以有非常多的块，从而位图数组比位图需要更多的元数据来表达。 比如估算一下传统文件系统中一块可以是 4KiB 大小，那么跟踪空间利用的位图需要 1bit/4KiB ， 1TiB 的盘就需要 32MiB 的元数据来存放位图； 而 WAFL 这种位图数组即便限制了快照数量只能有255个，仍需要 256bit/4KiB 的空间开销， 1TiB 的盘需要的元数据开销陡增到 8GiB ，这些还只是单纯记录空间利用率的位图数组，不包括别的元数据。 使用这么多元数据表示快照之后，创建快照的开销也相应地增加了，需要复制整个位图来创建一个新的快照， 按上面的估算 1TiB 的盘可能需要复制 32MiB 的位图，这不再是一瞬能完成的事情， 期间可能需要停下所有对文件系统的写入等待复制完成。 位图数组在存储设备上的记录方式也很有讲究，当删除快照时希望能快速读写上图中的一整行位图， 于是可能希望每一行位图的存储方式在磁盘上都尽量连续， 而在普通的写入操作需要分配新块时，想要按列的方式扫描位图数组，找到没有被快照占用的块， 从而上图中按列的存储表达也希望在磁盘上尽量连续。 WAFL 的设计工程师们在位图数组的思路下，实现了高效的数据结构让上述两种维度的操作都能快速完成， 但是这绝不是一件容易的事情。 位图数组的表达方式也有其好处，比如除了快照之外，也可以非常容易地表达类似 ZFS 的克隆和独立的文件系统这样的概念，这些东西和快照一样，占用仅有的 256 个快照数量限制。 这样表达的克隆可以有数据块和别的文件系统共享，文件系统之间也可以有类似 reflink 的机制共享数据块，在位图数组的相应位置将位置1即可。 使用位图数组的做法，也只是 WAFL 早期可能采用的方式，由于 WAFL 本身是闭源产品， 难以获知它具体的工作原理。哈佛大学和 NetApp 的职员曾经在 FAST10 (USENIX Conference on File and Storage Technologies) 上发表过一篇讲解高效跟踪和使用 back reference 的论文，叫 Tracking Back References in a Write-Anywhere File System ，可以推测在新一代 WAFL 的设计中可能使用了类似 btrfs backref 的实现方式，接下来会详细介绍。 3.3 ZFS 中关于快照和克隆的空间跟踪算法 How ZFS snapshots really work And why they perform well (usually) 幻灯片可以从这里下载 OpenZFS 的项目领导者，同时也是最初设计 ZFS 中 DMU 子系统的作者 Matt Ahrens 在 DMU 和 DSL 中设计并实现了 ZFS 独特的快照的空间跟踪算法。他也在很多地方发表演讲，讲过这个算法的思路和细节， 比如右侧就是他在 BSDCan 2019 做的演讲 How ZFS snapshots really work And why they perform well (usually) 的 YouTube 视频。 其中 Matt 讲到了三个删除快照的算法，分别可以叫做「🐢乌龟算法」、「🐰兔子算法」、「🐆豹子算法」， 接下来简单讲讲这些算法背后的思想和实现方式。 🐢乌龟算法：概念上 ZFS 如何删快照 乌龟算法没有实现在 ZFS 中，不过方便理解 ZFS 在概念上如何考虑快照删除这个问题，从而帮助理解 后面的🐰兔子算法和🐆豹子算法。 要删除一个快照， ZFS 需要找出这个快照引用到的「独占」数据块，也就是那些不和别的数据集或者快照共享的 数据块。 ZFS 删除快照基于这几点条件： ZFS 快照是只读的。创建快照之后无法修改其内容。 ZFS 的快照是严格按时间顺序排列的，这里的时间指 TXG id ，即记录文件系统提交所属事务组的严格递增序号。 ZFS 不存在 reflink 之类的机制，从而在某个时间点删除掉的数据块，不可能在比它更后面的快照中「复活」。 第三点关于 reflink 造成的数据复活现象可能需要解释一下，比如在（支持 reflink 的） btrfs 中有如下操作： btrfs subvolume snapshot -r fs s1 rm fs/somefile btrfs subvolume snapshot -r fs s2 cp --reflink = always s1/somefile fs/somefile btrfs subvolume snapshot -r fs s3 我们对 fs 创建了 s1 快照，删除了 fs 中某个文件，创建了 s2 快照，然后用 reflink 把刚刚删除的文件从 s1 中复制出来，再创建 s3 。如此操作之后，按时间顺序有 s1、s2、s3 三个快照： 其中只有 s2 不存在 somefile ，而 s1 、 s3 和当前的 fs 都有，并且都引用到了同一个数据块。 于是从时间线来看， somefile 的数据块在 s2 中「死掉」了，又在 s3 中「复活」了。 而 ZFS (目前还）不支持 reflink ，所以没法像这样让数据块复活。一旦某个数据块在某个快照中「死」了， 就意味着它在随后的所有快照中都不再被引用到了。 ZFS 的快照具有的上述三点条件，使得 ZFS 的快照删除算法可以基于 birth time 。回顾上面 ZFS 的块指针 中讲到， ZFS 的每个块指针都有一个 birth txg 属性，记录这个块诞生时 pool 所在的 txg 。于是可以根据这个 birth txg 找到快照所引用的「独占」数据块然后释放掉它们。 具体来说，🐢乌龟算法可以这样删除一个快照： 在 DSL 层找出要删除的快照（我们叫他 s ），它的前一个快照（叫它 ps ），后一个快照（叫它 ns ），分别有各自的 birth txg 叫 s.birth, ps.birth, ns.birth 。 遍历 s 的 DMU 对象集指针所引出的所有块指针。 这里所有块指针在逻辑上构成一个由块指针组成的树状结构，可以有间接块组成的指针树，可以有对象集的 dnode 保存的块指针，这些都可以看作是树状结构的中间节点。 每个树节点的指针 bp，考察如果 bp.birth <= ps.birth ，那么这个指针和其下所有指针都还被前一个快照引用着，需要保留这个 bp 引出的整个子树。 按定义 bp.birth 不可能 > s.birth 。 对所有满足 ps.birth < bp.birtu <= s.birth 的 bp ，需要去遍历 ns 的相应块指针（同样文件的同样偏移位置），看是否还在引用 bp 。 如果存在，继续递归往下考察树状结构中 bp 的所有子节点指针。因为可能共享了这个 bp 但 CoW 了新的子节点。 如果不存在，说明下一个快照中已经删了 bp 。这时可以确定地说 bp 是 s 的「独占」数据块。 释放掉所有找到的 s 所「独占」的数据块。 上述算法的一些边角情况可以自然地处理，比如没有后一个快照时使用当前数据集的写入点， 没有前一个快照时那么不被后一个快照引用的数据块都是当前要删除快照的独占数据块。 分析一下乌龟算法的复杂度的话，算法需要分两次，读 s 和 ns 中引用到的所有 ps 之后创建的数据块的指针，重要的是这些读都是在整个文件系统范围内的随机读操作，所以速度非常慢…… 🐰兔子算法：死亡列表算法（ZFS早期） 可以粗略地认为🐢乌龟算法算是用 birth txg 优化代码路径的 GC 算法，利用了一部分元数据中的 birth txg 信息来避免扫描所有元数据，但是概念上仍然是在扫描元数据找出快照的独占数据块， 而非记录和跟踪快照的数据块，在最坏的情况下仍然可能需要扫描几乎所有元数据。 🐰兔子算法基于🐢乌龟算法的基本原理，在它基础上跟踪快照所引用数据块的一些信息， 从而很大程度上避免了扫描元数据的开销。ZFS 在早期使用这个算法跟踪数据集和快照引用数据块的情况。 🐰兔子算法为每个数据集（文件系统或快照）增加了一个数据结构，叫死亡列表（dead list）， 记录 前一个快照中还活着，而当前数据集中死掉了的数据块指针 ，换句话说就是在本数据集中「杀掉」的数据块。举例画图大概是这样 上图中有三个快照和一个文件系统，共 4 个数据集。每个数据集维护自己的死亡列表， 死亡列表中是那些在该数据集中被删掉的数据块。于是🐰兔子算法把🐢乌龟算法所做的操作分成了两部分， 一部分在文件系统删除数据时记录死亡列表，另一部分在删除快照时根据死亡列表释放需要释放的块。 在当前文件系统删除数据块（不再被当前文件系统引用）时，负责比对 birth txg 维护当前文件系统的死亡列表。每删除一个数据块，指针为 bp 时，判断 bp.birth 和文件系统最新的快照（上图为 s3）的 birth： bp.birth <= s3.birth： 说明 bp 被 s3 引用，于是将 bp 加入 fs1 的 deadlist bp.birth > s3.birth：说明 bp 指向的数据块诞生于 s3 之后，可以直接释放 bp 指向的块。 创建新快照时，将当前文件系统（图中 fs1）的死亡列表交给快照，文件系统可以初始化一个空列表。 删除快照时，我们有被删除的快照 s 和前一个快照 ps 、后一个快照 ns ，需要读入当前快照 s 和后一个快照 ns 的死亡列表： 对 s.deadlist 中的每个指针 bp 复制 bp 到 ns.deadlist 对 ns.deadlist 中的每个指针 bp （其中包含了上一步复制来的） 如果 bp.birth > ps.birth ，释放 bp 的空间 否则保留 bp 换个说法的话， 死亡列表记录的是每个数据集需要负责删除，但因为之前的快照还引用着所以不能删除的数据块列表 。从当前文件系统中删除一个数据块时，这个职责最初落在当前文件系统身上，随后跟着创建新快照职责被转移到新快照上。 每个负责的数据集根据数据块的出生时间是否早于之前一个快照来判断现在是否能立刻释放该块， 删除一个快照时则重新评估自己负责的和下一个快照负责的数据块的出生时间。 从所做的事情来看，🐰兔子算法并没有比🐢乌龟算法少做很多事情。🐢乌龟算法删除一个快照， 需要遍历当前快照和后一个快照两组数据块指针中，新写入的部分； 🐰兔子算法则需要遍历当前快照和后一个快照两个死亡列表中，新删除的块指针。 但是实际🐰兔子算法能比🐢乌龟算法快不少，因为维护死亡列表的操作只在文件系统删除数据时和删除快照时， 顺序写入，并且删除快照时也只需要顺序读取死亡列表。在磁盘这种块设备上，顺序访问能比随机访问有数量级的差异。 不过记录死亡列表也有一定存储开销。最差情况下，比如把文件系统写满之后，创建一个快照， 再把所有数据都删掉，此时文件系统引用的所有数据块的块指针都要保存在文件系统的死亡列表中。 按 ZFS 默认的 128KiB 数据块大小，每块需要 128 字节的块指针，存储这些死亡列表所需开销可能要 整个文件系统大小的 1/1024 。如果用 4KiB 的数据块大小，所需开销则是 1/32 ， 1TiB 的盘会有 32GiB 拿来存放这些块指针，将高于用位图数组所需的存储量。 🐆豹子算法：死亡列表的子列表 🐆豹子算法是 ZFS 后来在 2009 年左右实现的算法。在🐰兔子算法中就可以看到，每次删除快照操作死亡列表的时候， 都需要扫描死亡列表中的块指针，根据指针中记录的 birth txg 做判断是否能直接释放或是需要保留到另一个快照的死亡列表。 于是🐆豹子算法的思路是，在死亡列表中记录块指针时，就把其中的块指针按 birth txg 分成子列表（sublist）。 比如上面🐰兔子算法中那4个死亡列表，可以这样拆成子列表： 这样拆成子列表之后，每次从死亡列表中释放数据块都能根据出生时间找到对应的子列表， 然后连续释放整个子列表。每次合并死亡列表时，也能直接用单链表穿起需要合并的子列表，不需要复制块指针。 死亡列表并不在跟踪快照的独占大小，而是在跟踪快照所需负责删除的数据块大小， 从这个数值可以推算出快照的独占大小之类的信息。 有了按出生时间排列的死亡列表子列表之后，事实上给任何一个出生时间到死亡时间的范围， 都可以找出对应的几个子列表，从而根据子列表的大小可以快速计算出每个快照范围的「独占」数据块、 「共享」数据块等大小，这不光在删除快照时很有用，也可以用来根据大小估算 zfs send 或者别的基于快照操作时需要的时间。 从直觉上理解，虽然 ZFS 没有直接记录每个数据块属于哪个数据集，但是 ZFS 跟踪记录了每个数据块的归属信息，也就是说由哪个数据集负责释放这个数据块。 在文件系统中删除数据块或者快照时，这个归属信息跟着共享数据块转移到别的快照中，直到最终被释放掉。 生存日志：ZFS 如何管理克隆的空间占用 Fast Clone Deletion by Sara Hartse 以上三种算法负责在 ZFS 中跟踪快照的空间占用，它们都基于数据块的诞生时间，所以都假设 ZFS 中对数据块的分配是位于连续的快照时间轴上。但是明显 ZFS 除了快照和文件系统， 还有另一种数据集可能分配数据块，那就是 克隆 ，于是还需要在克隆中使用不同的算法单独管理因克隆而分配的数据块。 OpenZFS Summit 2017 有个演讲 Fast Clone Deletion by Sara Hartse 解释了其中的细节。 首先克隆的存在本身会锁住克隆引用到的快照，不能删除这些被依赖的快照， 所以克隆无须担心靠快照共享的数据块的管理问题。因此克隆需要管理的，是从快照分离之后， 新创建的数据块。 和🐢乌龟算法一样，原理上删除克隆的时候可以遍历克隆引用的整个 DMU 对象集，找出其中晚于快照的诞生时间的数据块，然后释放它们。也和🐢乌龟算法一样， 这样扫描整个对象集的开销很大，所以使用一个列表来记录数据块指针。 克隆管理新数据块的思路和快照的🐰兔子算法维持死亡列表的思路相反， 记录所有新诞生的数据块，这个列表叫做「生存日志（livelist）」。 克隆不光要记录新数据块的诞生，还要记录新数据块可能的死亡，所以磁盘上保存的生存日志虽然叫 livelist ，但不像死亡列表那样是列表的形式，而是日志的形式，而内存中保存的生存日志则组织成了棵 自平衡树（AVLTree） 来加速查找。 磁盘上存储的生存日志如上图，每个表项记录它是分配（A）或者删除（F）一个数据块，同时记录数据块的地址。 这些记录在一般情况下直接记录在日志末尾，随着对克隆的写入操作而不断增长，长到一定程度则从内存中的 AVL Tree 直接输出一个新的生存日志替代掉旧的，合并其中对应的分配和删除操作。 生存日志可以无限增长，从而要将整个生存列表载入内存也有不小的开销，这里的解决方案有点像快照管理中用 🐆豹子算法改进🐰兔子算法的思路，把一个克隆的整个生存日志也按照数据块的诞生时间拆分成子列表。 Sara Hartse 的演讲 Fast Clone Deletion 中继续解释了其中的细节和优化方案，感兴趣的可以看看。 3.4 btrfs 的空间跟踪算法：引用计数与反向引用 理解了 ZFS 中根据 birth txg 管理快照和克隆的算法之后，可以发现它们基于的假设难以用于 WAFL 和 btrfs 。 ZFS 严格区分文件系统、快照、克隆，并且不存在 reflink ，从而可以用 birth txg 判断数据块是否需要保留，而 WAFL 和 btrfs 中不存在 ZFS 的那些数据集分工，又想支持 reflink ，可见单纯基于 birth txg 不足以管理 WAFL 和 btrfs 子卷。 让我们回到一开始日志结构文件系统中基于垃圾回收（GC）的思路上来，作为程序员来看， 当垃圾回收的性能不足以满足当前需要时，大概很自然地会想到：引用计数（reference counting）。 编程语言中用引用计数作为内存管理策略的缺陷是：强引用不能成环， 这在文件系统中看起来不是很严重的问题，文件系统总体上看是个树状结构，或者就算有共享的数据也是个 上下层级分明的有向图，很少会使用成环的指针，以及文件系统记录指针的时候也都会区分指针的类型， 根据指针类型可以分出强弱引用。 EXTENT_TREE 和引用计数 btrfs 中就是用引用计数的方式跟踪和管理数据块的。引用计数本身不能保存在 FS_TREE 或者指向的数据块中，因为这个计数需要能够变化，对只读快照来说整个 FS_TREE 都是只读的。 所以这里增加一层抽象， btrfs 中关于数据块的引用计数用一个单独的 CoW B树来记录，叫做 EXTENT_TREE ，保存于 ROOT_TREE 中的 2 号对象位置。 btrfs 中每个块都是按 区块（extent） 的形式分配的，区块是一块连续的存储空间，而非 zfs 中的固定大小。每个区块记录存储的位置和长度， 以及这里所说的引用计数。所以本文最开始讲 Btrfs 的子卷和快照 中举例的那个平坦布局，如果画上 EXTENT_TREE 大概像是下图这样，其中每个粗箭头是一个区块指针，指向磁盘中的逻辑地址，细箭头则是对应的 EXTENT_TREE 中关于这块区块的描述： Flat_layout_extents_on_disk superblock SUPERBLOCK ... root_tree ... roottree ROOT_TREE 2: extent_tree 3: chunk_tree 4: dev_tree 5: fs_tree 6: root_dir \"default\" -> ROOT_ITEM 256 10: free_space_tree 256: fs_tree \"root\" 257: fs_tree \"home\" 258: fs_tree \"www\" 259: fs_tree \"postgres\" -7: tree_log_tree -5: orphan_root superblock:sn_root->roottree:label toplevel FS_TREE \"toplevel\" 256: inode_item DIR 256: dir_item: \"root\" -> ROOT_ITEM 256 256: dir_item: \"home\" -> ROOT_ITEM 257 256: dir_item: \"var\" -> INODE_ITEM 257 256: dir_item: \"postgres\" -> ROOT_ITEM 259 257: inode_item DIR 257: dir_item: \"www\" -> ROOT_ITEM 258 roottree:root_fs->toplevel:label root FS_TREE \"root\" 256: inode_item DIR roottree:root_sub_root->root:label home FS_TREE \"home\" 256: inode_item DIR roottree:root_sub_home->home:label www FS_TREE \"www\" 256: inode_item DIR roottree:root_sub_www->www:label postgres FS_TREE \"postgres\" 256: inode_item DIR roottree:root_sub_postgres->postgres:label extent_tree EXTENT_TREE 0x2000 len=0x1000 : ref=1 gen=8 0x3000 len=0x1000 : ref=1 gen=8 0x11000 len=0x1000 : ref=1 gen=8 0x12000 len=0x1000 : ref=1 gen=6 0x13000 len=0x1000 : ref=1 gen=6 0x14000 len=0x1000 : ref=1 gen=6 0x15000 len=0x1000 : ref=1 gen=7 ... roottree:root_extent->extent_tree:label roottree:label->extent_tree:extent_roottree toplevel:label->extent_tree:extent_toplevel root:label->extent_tree:extent_root home:label->extent_tree:extent_home www:label->extent_tree:extent_www postgres:label->extent_tree:extent_postgres extent_tree:extent_extent->extent_tree:label btrfs 中关于 chattr +C 关闭了 CoW 的文件的处理 2020年2月20日补充 这里从 EXTENT_TREE 的记录可以看出，每个区块都有引用计数记录。对用 chattr +C 关闭了 CoW 的文件而言，文件数据同样还是有引用计数，可以和别的文件或者快照共享文件数据的。 这里的特殊处理在于，每次写入一个 nocow 的文件的时候，考察这个文件指向区块的引用计数， 如果引用计数 >1 ，表示这个文件的区块发生过 reflink ，那会对文件内容做一次 CoW 断开 reflink 并写入新位置；如果引用计数 =1 ，那么直接原地写入文件内容而不 CoW 。于是 nocow 的文件仍然能得到 reflink 和 snapshot 的功能， 使用这些功能仍然会造成文件碎片并伴随性能损失，只是在引用计数为 1 的时候不发生 CoW 。 包括 ROOT_TREE 和 EXTENT_TREE 在内，btrfs 中所有分配的区块（extent）都在 EXTENT_TREE 中有对应的记录，按区块的逻辑地址索引。从而给定一个区块，能从 EXTENT_TREE 中找到 ref 字段描述这个区块有多少引用。不过 ROOT_TREE 、 EXTENT_TREE 和别的一些 pool-wide 数据结构本身不依赖引用计数的，这些数据结构对应的区块的引用计数总是 1 ，不会和别的树共享区块；从 FS_TREE 开始的所有树节点都可以共享区块，这包括所有子卷的元数据和文件数据，这些区块对应的引用计数可以大于 1 表示有多处引用。 EXTENT_TREE 按区块的逻辑地址索引，记录了起始地址和长度，所以 EXTENT_TREE 也兼任 btrfs 的空间利用记录，充当别的文件系统中 block bitmap 的指责。比如上面例子中的 extent_tree 就表示 [0x2000,0x4000) [0x11000,0x16000) 这两段连续的空间是已用空间， 剩下的空间按定义则是可用空间。为了加速空间分配器， btrfs 也有额外的 free space cache 记录在 ROOT_TREE 的 10 号位置 free_space_tree 中，不过在 btrfs 中这个 free_space_tree 记录的信息只是缓存，必要时可以通过 btrfs check --clear-space-cache 扔掉这个缓存重新扫描 extent_tree 并重建可用空间记录。 比如我们用如下命令创建了两个文件，通过 reflink 让它们共享区块，然后创建两个快照， 然后删除文件系统中的 file2 ： write fs/file1 cp --reflink = always fs/file1 fs/file2 btrfs subvolume snapshot fs sn1 btrfs subvolume snapshot fs sn2 rm fs/file2 经过以上操作之后，整个 extent_tree 的结构中记录的引用计数大概如下图所示： btrfs_reflink_backref root ROOT_TREE sn1 sn2 fs sn1 FS_TREE sn1 leaf_node root:sn1->sn1:label sn2 FS_TREE sn2 leaf_node root:sn2->sn2:label fs FS_TREE fs leaf_node root:fs->fs:label extent EXTENT_TREE extent_tree root_tree : ref 1 sn1 fs_tree : ref 1 sn2 fs_tree : ref 1 sn1 sn2 leaf_node: ref 2 fs fs_tree : ref 1 fs leaf_node : ref 1 file1 : ref 3 root:label->extent:root snleaf FS_TREE leaf_node file1 file2 sn1:leaf->snleaf:label sn1:label->extent:sn1 sn2:leaf->snleaf:label sn2:label->extent:sn2 fsleaf FS_TREE leaf_node file1 fs:leaf->fsleaf:label fs:label->extent:fs snleaf:label->extent:snleaf snleaf:f1->extent:f1 snleaf:f2->extent:f1 fsleaf:label->extent:fsleaf fsleaf:f1->extent:f1 上图简化了一些细节，实际上每个文件可以引用多个区块（文件碎片）， 其中每个对区块的引用都可以指明引用到具体某个区块记录的某个地址偏移和长度， 也就是说文件引用的区块可以不是区块记录中的一整个区块，而是一部分内容。 图中可见，整个文件系统中共有5个文件路径可以访问到同一个文件的内容，分别是 sn1/​file1, sn1/​file2, sn2/​file1, sn2/​file2, fs/​file1 ， 在 extent_tree 中， sn1 和 sn2 可能共享了一个 B树 叶子节点，这个叶子节点的引用计数为 2 ，然后每个文件的内容都指向同一个 extent ，这个 extent 的引用计数为 3 。 删除子卷时，通过引用计数就能准确地释放掉子卷所引用的区块。具体算法挺符合直觉的： 从子卷的 FS_TREE 往下遍历 遇到引用计数 >1 的区块，减小该块的计数即可，不需要再递归下去 遇到引用计数 =1 的区块，就是子卷独占的区块，需要释放该块并递归往下继续扫描 大体思路挺像上面介绍的 ZFS 快照删除的🐢乌龟算法 ，只不过根据引用计数而非 birth txg 判断是否独占数据块。性能上说， btrfs 的B树本身内容就比较紧凑，FS_TREE 一个结构就容纳了文件 inode 和引用的区块信息， EXTENT_TREE 按地址排序也比较紧凑，所以删除算法的随机读写不像 ZFS 的🐢乌龟算法那么严重， 实际实现代码里面也可能通过 btrfs generation 做一些类似基于 birth txg 优化的快速代码路径。 即便如此，扫描 FS_TREE 仍然可能需要耗时良久，这个递归的每一步操作都会记录在 ROOT_TREE 中专门的结构，也就是说删除一个子卷的操作可以执行很长时间并跨越多个 pool commit 。 btrfs subvolume delete 命令默认也只是记录下这个删除操作，然后就返回一句类似： Delete subvolume (no-commit): /​subvolume/​path 的输出，不会等删除操作执行结束。 相比之下 ZFS 那边删除一个快照或文件系统必须在一个 txg 内执行完，没有中间过程的记录， 所以如果耗时很久会影响整个 pool 的写入，于是 ZFS 那边必须对这些操作优化到能在一个 txg 内执行完的程度(摧毁克隆方面 ZFS 还有 async_destroy 优化 可能有些帮助)。 只需要引用计数就足够完成快照的创建、删除之类的功能，也能支持 reflink 了（仔细回想， reflink 其实就是 reference counted link 嘛），普通读写下也只需要引用计数。 但是只有引用计数不足以知道区块的归属，不能用引用计数统计每个子卷分别占用多少空间， 独占多少区块而又共享多少区块。上面的例子就可以看出，所有文件都指向同一个区块，该区块的引用计数为 3 ，而文件系统中一共有 5 个路径能访问到该文件。可见从区块根据引用计数反推子卷归属信息不是那么一目了然的。 反向引用（back reference） 单纯从区块的引用计数难以看出整个文件系统所有子卷中有多少副本。 也就是说单有引用计数的一个数字还不够，需要记录具体反向的从区块往引用源头指的引用，这种结构在 btrfs 中叫做「反向引用（back reference，简称 backref）」。所以在上图中每一个指向 EXTENT_TREE 的单向箭头，在 btrfs 中都有记录一条反向引用，通过反向引用记录能反过来从被指针指向的位置找回到记录指针的地方。 反向引用（backref）是 btrfs 中非常关键的机制，在 btrfs kernel wiki 专门有一篇页面 Resolving Extent Backrefs 解释它的原理和实现方式。 对上面的引用计数的例子画出反向引用的指针大概是这样： btrfs_reflink_backref root ROOT_TREE sn1 sn2 fs sn1 FS_TREE sn1 leaf_node root:sn1->sn1:label sn2 FS_TREE sn2 leaf_node root:sn2->sn2:label fs FS_TREE fs leaf_node root:fs->fs:label extent EXTENT_TREE extent_tree root_tree : ref 1 sn1 fs_tree : ref 1 backref ROOT_TREE sn1 sn2 fs_tree : ref 1 backref ROOT_TREE sn2 sn1 sn2 leaf_node: ref 2 backref sn1 FS_TREE node backref sn2 FS_TREE node fs fs_tree : ref 1 backref ROOT_TREE fs fs leaf_node : ref 1 backref fs FS_TREE node file1 : ref 3 backref sn1 FS_TREE leaf_node file1 backref sn1 FS_TREE leaf_node file2 backref fs FS_TREE leaf_node file1 snleaf FS_TREE leaf_node file1 file2 sn1:leaf->snleaf:label sn2:leaf->snleaf:label fsleaf FS_TREE leaf_node file1 fs:leaf->fsleaf:label extent:br1->root:label extent:br2->root:label extent:br5->root:label extent:br3->sn1:label extent:br4->sn2:label extent:br6->fs:label extent:br7->snleaf:label extent:br8->snleaf:label extent:br9->fsleaf:label EXTENT_TREE 中每个 extent 记录都同时记录了引用到这个区块的反向引用列表。反向引用有两种记录方式： 普通反向引用（Normal back references）。记录这个指针来源所在是哪颗B树、 B树中的对象 id 和对象偏移。 对文件区块而言，就是记录文件所在子卷、inode、和文件内容的偏移。 对子卷的树节点区块而言，就是记录该区块的上级树节点在哪个B树的哪个位置开始。 共享反向引用（Shared back references）。记录这个指针来源区块的逻辑地址。 无论对文件区块而言，还是对子卷的树节点区块而言，都是直接记录了保存这个区块指针的上层树节点的逻辑地址。 有两种记录方式是因为它们各有性能上的优缺点： 普通反向引用: 因为通过对象编号记录，所以当树节点 CoW 改变了地址时不需要调整地址， 从而在普通的读写和快照之类的操作下有更好的性能， 但是在解析反向引用时需要额外一次树查找。 同时因为这个额外查找，普通反向引用也叫间接反向引用。 共享反向引用: 因为直接记录了逻辑地址，所以当这个地址的节点被 CoW 的时候也需要调整这里记录的地址。 在普通的读写和快照操作下，调整地址会增加写入从而影响性能，但是在解析反向引用时更快。 通常通过普通写入、快照、 reflink 等方式创建出来的引用是普通反向引用， 由于普通反向引用记录了包含它的B树，从而可以说绑在了某棵树比如某个子卷上， 当这个普通反向引用指向的对象不再存在，而这个反向引用还在通过别的途径共享时， 这个普通反向引用会转换共享反向引用；共享反向引用在存在期间不会变回普通反向引用。 比如上图反向引用的例子中，我们先假设所有画出的反向引用都是普通反向引用，于是图中标为 file1 引用数为 3 的那个区块有 3 条反向引用记录，其中前两条都指向 sn1 里面的文件，分别是 sn1/file1 和 sn1/file2 ，然后 sn1 和 sn2 共享了 FS_TREE 的叶子节点。 假设这时我们删除 sn1/file2，执行了代码 rm sn1/​file2 之后： btrfs_reflink_shared_backref root ROOT_TREE sn1 sn2 fs sn1 FS_TREE sn1 leaf_node root:sn1->sn1:label sn2 FS_TREE sn2 leaf_node root:sn2->sn2:label fs FS_TREE fs leaf_node root:fs->fs:label extent EXTENT_TREE extent_tree root_tree : ref 1 sn1 fs_tree : ref 1 backref ROOT_TREE sn1 sn2 fs_tree : ref 1 backref ROOT_TREE sn2 sn1 sn2 leaf_node: ref 2 backref sn1 FS_TREE node backref sn2 FS_TREE node fs fs_tree : ref 1 backref ROOT_TREE fs fs leaf_node : ref 1 backref fs FS_TREE node file1 : ref 4 backref FS_TREE leaf_node file1 backref FS_TREE leaf_node file2 backref fs FS_TREE leaf_node file1 backref sn1 FS_TREE leaf_node file1 sn1leaf FS_TREE leaf_node file1 sn1:leaf->sn1leaf:label snleaf FS_TREE leaf_node file1 file2 sn2:leaf->snleaf:label fsleaf FS_TREE leaf_node file1 fs:leaf->fsleaf:label extent:br1->root:label extent:br2->root:label extent:br5->root:label extent:br3->sn1:label extent:br4->sn2:label extent:br6->fs:label extent:br10->sn1leaf:label extent:br7->snleaf:label extent:br8->snleaf:label extent:br9->fsleaf:label 那么 sn1 会 CoW 那个和 sn2 共享的叶子节点，有了新的属于 sn1 的叶子，从而断开了原本 file1 中对这个共享叶子节点的两个普通反向引用，转化成共享反向引用（图中用虚线箭头描述）， 并且插入了一个新的普通反向引用指向新的 sn1 的叶子节点。 遍历反向引用(backref walking) 有了反向引用记录之后，可以给定一个逻辑地址，从 EXTENT_TREE 中找到地址的区块记录， 然后从区块记录中的反向引用记录一步步往回遍历，直到遇到 ROOT_TREE ，最终确定这个逻辑地址的区块在整个文件系统中有多少路径能访问它。 这个遍历反向引用的操作，在 btrfs 文档和代码中被称作 backref walking 。 比如还是上面的反向引用图例中 sn1 和 sn2 完全共享叶子节点的那个例子，通过 backref walking ，我们能从 file1 所记录的 3 个反向引用，推出全部 5 个可能的访问路径。 backref walking 作为很多功能的基础设施，从 btrfs 相当早期（3.3内核）就有，很多 btrfs 的功能实际依赖 backref walking 的正确性。列举一些需要 backref walking 来实现的功能： qgroup btrfs 的子卷没有记录子卷的磁盘占用开销，靠引用计数来删除子卷， 所以也不需要详细统计子卷的空间占用情况。不过对一些用户的使用场景，可能需要统计子卷空间占用。由于 可能存在的共享元数据和数据，子卷占用不能靠累计加减法的方式算出来，所以 btrfs 有了 qgroup 和 quota 功能，用来统计子卷或者别的管理粒度下的占用空间情况。为了实现 qgroup ，需要 backref walking 来计算区块共享的情况。 send btrfs send 在计算子卷间的差异时，也通过 backref walking 寻找能靠 reflink 共享的区块，从而避免传输数据。 balance/scrub balance 和 scrub 都会调整区块的地址，通过 backref walking 能找到所有引用到这个地址的位置并正确修改地址。 check 当需要打印诊断信息的时候，除了提供出错的数据所在具体地址之外，通过 backref walking 也能提供受影响的文件路径之类的信息。 btrfs 的 reflink-aware defrag 这里想提一下 btrfs 一直计划中，但是还没有成功实现的 reflink-aware defrag 。文件碎片一直是 CoW 文件系统的大问题，对 btrfs 和对 ZFS 都是同样。ZFS 完全不支持碎片整理， 而 btrfs 目前只提供了文件级别的碎片整理，这会切断现有的 reflink 。计划中的 reflink-aware defrag 也是基于 backref walking ，根据区块引用的碎片程度，整理碎片而某种程度上保持 reflink 。btrfs 曾经实现了这个，但是因为 bug 太多不久就取消了相关功能，目前这个工作处于停滞阶段。 可见 backref walking 的能力对 btrfs 的许多功能都非常重要（不像 ZPL 的 dnode 中记录的 parent dnode 那样只用于诊断信息 ）。不过 backref walking 根据区块共享的情况的不同，也可能导致挺大的运行期开销，包括算法时间上的和内存占用方面的开销。 比如某个子卷中有 100 个文件通过 reflink 共享了同一个区块，然后对这个子卷做了 100 个快照， 那么对这一个共享区块的 backref walking 结果可能解析出 10000 个路径。可见随着使用 reflink 和快照， backref walking 的开销可能爆炸式增长。最近 btrfs 邮件列表也有一些用户汇报，在大量子卷 和通过 reflink 做过 dedup 的 btrfs 文件系统上 send 快照时，可能导致内核分配大量内存甚至 panic 的情形，在 5.5 内核中 btrfs send 试图控制 send 时 clone reference 的数量上限来缓解这种边角问题。 值得再强调的是，在没有开启 qgroup 的前提下，正常创建删除快照或 reflink ，正常写入和覆盖区块之类的文件系统操作，只需要引用计数就足够，虽然可能需要调整反向引用记录（ 尤其是共享反向引用的地址），但是不需要动用 backref walking 这样的重型武器。 4 ZFS vs btrfs 的 dedup 功能现状 上面讨论 ZFS 的快照和克隆如何跟踪数据块时，故意避开了 ZFS 的 dedup 功能，因为要讲 dedup 可能需要先理解引用计数在文件系统中的作用，而 btrfs 正好用了引用计数。 于是我们再回来 ZFS 这边，看看 ZFS 的 dedup 是具体如何运作的。 稍微了解过 btrfs 和 ZFS 两者的人，或许有不少 btrfs 用户都眼馋 ZFS 有 in-band dedup 的能力，可以在写入数据块的同时就去掉重复数据，而 btrfs 只能「退而求其次」地选择第三方 dedup 方案，用外部工具扫描已经写入的数据，将其中重复的部分改为 reflink 。又或许有不少 btrfs 用户以为 zfs 的 dedup 就是在内存和磁盘中维护一个类似 Bloom filter 的结构，然后根据结果对数据块增加 reflink ，从而 zfs 内部大概一定有类似 reflink 的设施，进一步质疑为什么 btrfs 还迟迟没有实现这样一个 Bloom filter 。 或许还有从 btrfs 转移到 ZFS 的用户有疑惑， 为什么 ZFS 还没有暴露出 reflink 的用户空间接口 ，或者既然 ZFS 已经有了 dedup ， 能不能临时开关 dedup 来提供类似 reflink 式的共享数据块 而避免 ZFS 长期开 dedup 导致的巨大性能开销。 看过上面 ZFS 中关于快照和克隆的空间跟踪算法 之后我们会发现，其实 ZFS 中并没有 能对应 btrfs reflink 的功能，而是根据数据块指针中的 birth txg 来跟踪快照和克隆的共享数据块的。这引来更多疑惑： 4.1 ZFS 是如何实现 dedup 的？ Dedup Performance by Matt Ahrens ZFS 是在 Sun/OpenSolaris 寿命相当晚期的 2009 年获得的 dedup 功能，就在 Oracle 收购 Sun ，OpenSolaris 分裂出 Illumos 从而 ZFS 分裂出 Oracle ZFS 和 OpenZFS 的时间点之前。因此 关于 ZFS dedup 如何实现的文档相对匮乏 ，大部分介绍 ZFS 的文档或者教程会讲到 ZFS dedup 的用法，但是对 dedup 的实现细节、性能影响、乃至使用场景之类的话题就很少提了（甚至很多教程讲了一堆用法之后说类似， 「我评估之后觉得我不需要开 dedup ，你可以自己评估一下」这样的建议）。 OpenZFS Summit 2017 上 Matt 有个演讲，主要内容关于今后如何改进 dedup 性能的计划，其中讲到的计划还没有被具体实现，不过可以窥探一下 dedup 现在在 ZFS 中是如何工作的。 Chris 的博客也有两篇文章《 What I can see about how ZFS deduplication seems to work on disk 》和《 An important addition to how ZFS deduplication works on the disk 》介绍了他对此的认识，在这里我也尝试来总结一下 ZFS dedup 特性如何工作。 ZFS dedup 是存储池级别（pool-wide）开关的特性，所以大概在 MOS 之类的地方有存储一个特殊的数据结构， 叫 DeDup Table 简称 DDT 。DDT 目前是存储设备上的一个 hash table ，因为是存储池级别的元数据， 所以在 ZFS 中存储了三份完全一样的 DDT ，DDT 的内容是大概如下结构： Checksum DVA(Data Virtual Address) Refcount 0x12345678 vdev=1 addr=0x45671234 3 0x5678efab vdev=2 addr=0x37165adb 0 0x98765432 vdev=1 addr=0xac71be12 1 0xabcd1234 vdev=0 addr=0xc1a2231d 5 ... ... ... ... ... ... DDT 中对每个数据块存有3个东西：数据块的 checksum 、DVA （就是 ZFS 的块指针 中的 DVA）和引用计数。在存储池开启 dedup 特性之后，每次新写入一个数据块，都会先计算出数据块的 checksum ，然后查找 DDT ，存在的话增加 DDT 条目的引用计数，不存在的话插入 DDT 条目。每次释放一个数据块，同样需要查找 DDT 调整引用计数。 除了 DDT 之外，文件系统中记录的块指针中也有个特殊标志位记录这个块是否经过了 DDT 。读取数据不需要经过 DDT ，但是子卷、克隆或者文件系统正常删除数据块的时候， 需要根据块指针中的标志位判断是否需要检查和调整 DDT 。 从而关于 dedup 的实现可以得知以下一些特点： 开启 dedup 之后，每个写入操作放大成 3+1 个随机位置的写入操作，每个删除操作变成 1 个写入操作。没有 dedup 时删除块并不需要立刻写入，只需要记录在内存中并在 MOS 提交的时候调整磁盘占用情况即可。 只有开启 dedup 期间写入的数据块才会参与 dedup 。对已经有数据的存储池，后来开启的 dedup 不会影响已经写好的数据，从而即使后来新的写入与之前的写入有重复也得不到 dedup 效果。 DDT 中没有记录的数据块不会参与 dedup 。换句话说 DDT 中那些引用计数为 1 的记录也是必须存在的，否则这些数据块没有机会参与 dedup 。 关闭 dedup 之后，只要 DDT 中还存有数据，那么对这些数据的删除操作仍然有性能影响。 从直觉上可以这样理解：在 ZFS 中每个数据块都有其「归属」，没有 dedup 的时候，数据块归属于某个数据集（文件系统、快照、克隆）， 该数据集需要负责释放该数据块或者把从属信息转移到别的数据集（快照）上。 而在开启 dedup 期间，产生的写入的数据块实际归属于 DDT 而不是任何一个数据集，数据集需要查询和调整 DDT 中记录的引用计数来决定是否能释放数据块。 乍看起来 DDT 貌似挺像 btrfs 的 EXTENT_TREE ，但是本质上 EXTENT_TREE 是根据区块地址排序的， 而 DDT 因为是个 hashtable 所以是根据 checksum 排序的。并且 EXTENT_TREE 中记录的区块可以是任意大小，而 DDT 中记录的数据块是固定大小的，所以碎片不严重的情况下 DDT 要比 EXTENT_TREE 多记录很多数据块。这些区别都非常影响操作 DDT 时的性能。 DDT 本身是个 DMU 对象，所以对 DDT 的读写也是经过 DMU 的 CoW 读写，从而也经过 ARC 的缓存。想要有比较合理的 dedup 性能，需要整个 DDT 都尽量保持在内存 ARC 或者 L2ARC 缓存中， 于是 dedup 特性也有了非常占用内存的特点。每个 DDT 表项需要大概 192 字节来描述一个（ 默认 128KiB 大小的）数据块，由此可以估算一下平均每 2TiB 的数据需要 3GiB 的内存来支持 dedup 的功能。 Matt 的视频中后面讲到优化 ZFS dedup 的一些思路，大体上未来 ZFS 可以做这些优化： DDT 在内存中仍然是 hashtable ，在存储介质上则换成类似 ZIL 的日志结构，让 DDT 尽量保持在内存中，并且绕过 DMU 减少写入放大。 给 DDT 表项瘦身，从192字节缩减到接近64字节。 当遇到内存压力时，从 DDT 中随机剔除掉引用计数为 1 的表项。被剔除的表项没有了未来参与 dedup 的可能性，但是能减轻内存压力。剔除引用计数为 1 的表项仍然可以维持数据块的归属信息（ 处理上当作是没有 dedup 的形式），但是引用计数更高的表项没法剔除。 这些优化策略目的是想让 dedup 的性能损失能让更多使用场景接受。不过因为缺乏开发者意愿， 目前这些策略还只是计划，没有实现在 ZFS 的代码中。 因为以上特点， ZFS 目前 dedup 特性的适用场景极为有限，只有在 IO 带宽、内存大小都非常充裕， 并且可以预见到很多重复的数据的时候适合。听说过的 ZFS dedup 的成功案例是，比如提供虚拟机服务的服务商，在宿主文件系统上用 ZFS 的 zvol 寄宿虚拟机的磁盘镜像，客户在虚拟机内使用其它文件系统。大部分客户可能用类似版本的操作系统， 从而宿主机整体来看有很多 dedup 的潜质。不过这种应用场景下，服务商很可能偏向选择 CephFS 这样的分布式文件系统提供虚拟机镜像存储，而不是 ZFS 这样局限在单系统上的本地文件系统。 4.2 btrfs 的 dedup btrfs 目前没有内建的 dedup 支持，但是因为有 reflink 所以可以通过第三方工具在事后扫描文件块来实现 dedup 。这一点乍看像是某种将就之策，实际上了解了 ZFS dedup 的实现之后可以看出这个状况其实更灵活。 在 btrfs 中实现 in-band dedup 本身不算很复杂，增加一个内存中的 bloom filter 然后按情况插入 reflink 的正常思路就够了。在 btrfs kernel wiki 中有篇笔记 提到已经有了实验性的 in-band dedup 内核支持的实现。这个实现已经越来越成熟，虽然还有诸多使用限制， 不过实现正确性上问题不大，迟迟没有办法合并进主线内核的原因更多是性能上的问题。 如果 btrfs 有了 in-band dedup 这样系统性的 dedup 方案，那么不可避免地会增加文件系统中使用 reflink 的数量。这将会暴露出 backref walking 这样的基础设施中许多潜在的边角情况下的性能瓶颈。 前面解释过 backref walking 操作是个挺大开销的操作，并且开销随着快照和 reflink 的使用而爆炸式增长。直到最近的 btrfs 更新仍然在试图优化和改善现有 backref walking 的性能问题，可以预测 btrfs 的内建 dedup 支持将需要等待这方面更加成熟。 5 结论和展望 不知不觉围绕 btrfs 和 zfs 的快照功能写了一大篇，前前后后写了一个半月， 文中提及的很多细节我自己也没有自信，如果有错误还请指出。 稍微列举一些我觉得比较重要的结论，算是 TL;DR 的 takeaway notes 吧： ZFS 的快照非常轻量。完全可以像 NILFS2 的连续快照那样，每小时一个快照，每天24小时，每年 365天不间断地创建快照，实际似乎也有公司是这样用的。如此频繁的快照不同于 NILFS2 等文件系统提供的连续快照，但是也没有那些日志结构文件系统实现连续快照所需承担的巨大 GC 开销。 并且 ZFS 可以没有额外开销地算出快照等数据集的空间占用之类的信息。 btrfs 的快照相对也很轻量，比 LVM 和 dm-thin 的快照轻便很多，但是不如 ZFS 的快照轻，因为 btrfs 有维护反向引用的开销。 btrfs 要得知子卷的空间占用情况需要开启 qgroup 特性，这会对一些需要 backref walking 的操作有一些额外性能损失。 btrfs 对快照和 reflink 没有限制，日常桌面系统下使用也不太会遇到性能问题。 不过系统性地（自动化地）大量使用快照和 reflink ，在一些操作下可能会有性能问题，值得注意。 因为没有 reflink ， ZFS 的数据集划分需要一些前期计划。 ZFS 中共享元数据的方式只有快照， 所以要尽量多细分文件系统，方便以后能利用到快照特性，划分的粒度大致按照可能要回滚快照的粒度来。 btrfs 有 reflink ，于是这里有很多自由度，即便前期计划不够详细也可以通过 reflink 相对快速调整子卷结构。 dedup 在 zfs 和 btrfs 都是个喜忧参半的特性，开启前要仔细评估可能的性能损失。ZFS dedup 的成功案例是，比如虚拟机服务的服务商，在宿主文件系统上用 ZFS 寄宿虚拟机的磁盘镜像，客户在虚拟机可能用类似版本的操作系统，从而宿主机整体来看有很多 dedup 的潜质。一般桌面场景下 dedup 的收益不明显，反而有巨大内存和IO带宽开销。 相比 btrfs ，ZFS 更严格地遵守 CoW 文件系统「仅写一次」的特点，甚至就算遇到了数据块损坏， 修复数据块的时候也只能在原位写入。 btrfs 因为有反向引用所以在这方面灵活很多。 ZFS 不支持对单个文件关闭 CoW ，所有文件（以及所有 zvol）都经过 DMU 层有 CoW 语义，这对一些应用场景有性能影响。btrfs 可以对单个文件关闭 CoW ，但是关闭 CoW 同时也丢失了写文件的事务性语义。 ZFS 不支持碎片整理，靠 ARC 加大缓存来解决碎片带来的性能问题。 btrfs 有 defrag ，但是目前的实现会切断 reflink 。 最后关于 ZFS 没有 reflink 也没有反向引用的情况，想引用几段话。 FreeBSD 的发起人之一，FreeBSD 的 FFS 维护者， Kirk McKusick 曾经在 OpenZFS developer summit 2015 这么说过： I decided I'd add a wish list since I have a whole bunch of people here that could actually possibly consider doing this. Both competitors of ZFS, which are basically WAFL and BTRFS, kind of maintained back pointers. And back pointers allow a lot of things like disk migration, you can go through and tune up file layout, if you're working with direct-mapped flash it allows you to do that effectively. This has been a long -- and I understand big debate with the ZFS people and I'm not going to try and talk about that -- but there's a very nice paper that I've cited here, \"Tracking Back References in a Write Anywhere File System\", that is it integrates keeping track of the back pointers in a way that would work very well with ZFS. And so the cost is low, the cost of actually using it is a little higher, but it's not unreasonable. So there's the reference to that paper and if any of you are contemplating that you should read the paper because if nothing else it's a great paper. Kirk McKusick 呼吁 ZFS 开发者们考虑在 ZFS 中实现类似 backref 的基础设施，从而可能在未来获得更多有用的特性。 和 ZFS 实现 backref 相关的一点是目前 ZFS 的块指针的组织结构。对此 ZFS 的 ZPL 层原作者之一的 Mark Shellenbaum 在 OpenZFS developer summit 2016 也曾说过这样的话： (Q: Are there any things that we that we have regretted we did?) A: I guess not so much on the ZPL, but with the way block pointers maybe weren't fully virtualized, you know that things like that. 以及 ZFS 的最初的作者 Jeff 在 OpenZFS developer summit 2015 也曾说过： ... and then certainly one thing i'd always wish we had done but there really were always implementation difficulties was true virtual block addressing. Because it would made dedup simpler, or would have made you know compression of data, defragging, all that kind of stuff simpler. That would have been really nice to have. But we never did the way that was sort of tracable in terms of both the cost and the transactional semantics. ZFS 这些开发者元老们都希望 ZFS 能有某种类似 backref 的机制，或者让块指针记录的地址更抽象的机制。 关于这一点，ZFS 最重要的作者 Matt 如何看的呢？ Matt 近期似乎没有发表过看法，但是熟悉 ZFS 的人可能听到过 Matt 一直在计划的另一项 ZFS 特性中看出些端倪，叫 BP rewrite ，或者 BP virtualization 。从 Matt 还在 Sun 的时候开始，就试图在 ZFS 中实现 BP rewrite 特性，提供某种系统性的基础设施，能够快速地找到并改写大量数据块指针。 在网上搜索很多 ZFS 功能的实现细节，最终都会带到关于 BP rewrite 的讨论（甚至可以说论战）中。 Matt 最近给 OpenZFS 实现的两项功能， toplevel vdev removal 和 raidz expansion 如果有 BP rewrite 将会容易很多，而他们目前是在没有 BP rewrite 的前提下，通过一连串额外抽象实现的。 从 BP rewrite 这个兔子洞中，还能引出更多 btrfs 和 ZFS 关于设备管理的差异，这个有待今后再谈。","tags":"tech","url":"//farseerfc.me/zhs/btrfs-vs-zfs-difference-in-implementing-snapshots.html"},{"title":"ZFS 分层架构设计","text":"2020年2月9日更新过 ZFS 在设计之初源自于 Sun 内部多次重写 UFS 的尝试，背负了重构 Solaris 诸多内核子系统的重任，从而不同于 Linux 的文件系统只负责文件系统的功能而把其余功能（比如内存脏页管理， IO调度）交给内核更底层的子系统， ZFS 的整体设计更层次化并更独立，很多部分可能和 Linux/FreeBSD 内核已有的子系统有功能重叠。 似乎很多关于 ZFS 的视频演讲和幻灯片有讲到子系统架构，但是找了半天也没找到网上关于这个的说明文档。 于是写下这篇笔记试图从 ZFS 的早期开发历程开始，记录一下 ZFS 分层架构中各个子系统之间的分工。 也有几段 OpenZFS Summit 视频佐以记录那段历史。 早期架构 早期 ZFS 在开发时大体可以分为上下三层，分别是 ZPL， DMU 和 SPA ，这三层分别由三组人负责。 最初在 Sun 内部带领 ZFS 开发的是 Jeff Bonwick ，他首先有了对 ZFS 整体架构的构思，然后游说 Sun 高层，亲自组建起了 ZFS 开发团队，招募了当时刚从大学毕业的 Matt Ahrens 。作为和 Sun 高层谈妥的条件， Jeff 也必须负责 Solaris 整体的 Storage & Filesystem Team ，于是他又从 Solaris 的 Storage Team 抽调了 UFS 部分的负责人 Mark Shellenbaum 和 Mark Maybee 来开发 ZFS 。而如今昔日升阳已然日落， Jeff 成立了独立公司继续开拓服务器存储领域， Matt 是 OpenZFS 项目的负责人，两位 Mark 则留在了 Sun/Oracle 成为了 Oracle ZFS 分支的维护者。 The Birth of ZFS by Jeff Bonwick Story Time (Q&A) with Matt and Jeff ZFS First Mount by Mark Shellenbaum ZFS past & future by Mark Maybee 在开发早期，作为分工， Jeff 负责 ZFS 设计中最底层的 SPA ，提供多个存储设备组成的存储池抽象； Matt 负责 ZFS 设计中最至关重要的 DMU 引擎，在块设备基础上提供具有事务语义的对象存储； 而两位 Mark 负责 ZFS 设计中直接面向用户的 ZPL ，在 DMU 基础上提供完整 POSIX 文件系统语义。 ZFS 设计中这最初的分工也体现在了 ZFS 现在子系统分层的架构上，继续影响（增强或者限制） ZFS 今后发展的方向。 子系统整体架构 首先 ZFS 整体架构如下图，其中圆圈是 ZFS 给内核层的外部接口，方框是 ZFS 内部子系统（ 我给方框的子系统加上了超链接）： ZFS_Layer_Architecture clusterTOL TOL clusterSPA SPA Filesystem API Filesystem API VFS VFS Filesystem API->VFS Block device API Block device API /dev/zvol/... /dev/zvol/... Block device API->/dev/zvol/... ZFS Management API (libzfs) ZFS Management API (libzfs) /dev/zfs ioctl /dev/zfs ioctl ZFS Management API (libzfs)->/dev/zfs ioctl NFS/Samba API (libshare) NFS/Samba API (libshare) NFS/CIFS vop_rwlock NFS/CIFS vop_rwlock NFS/Samba API (libshare)->NFS/CIFS vop_rwlock VFS->NFS/CIFS vop_rwlock ZPL ZPL VFS->ZPL ZVOL ZVOL /dev/zvol/...->ZVOL DSL DSL /dev/zfs ioctl->DSL VDEV VDEV /dev/zfs ioctl->VDEV DMU DMU NFS/CIFS vop_rwlock->DMU ZAP ZAP ZPL->ZAP ZPL->DMU ZIL ZIL ZPL->ZIL ZVOL->DMU DSL->ZAP DSL->DMU ZAP->DMU ARC ARC DMU->ARC MetaSlab MetaSlab DMU->MetaSlab ZIO ZIO ARC->ZIO L2ARC L2ARC ARC->L2ARC ZIL->ZIO SLOG SLOG ZIL->SLOG ZIO->MetaSlab ZIO->VDEV L2ARC->ZIO L2ARC->VDEV SLOG->VDEV MetaSlab->VDEV physical storage devices physical storage devices VDEV->physical storage devices 接下来从底层往上介绍一下各个子系统的全称和职能。 SPA Storage Pool Allocator 从内核提供的多个块设备中抽象出存储池的子系统。 SPA 进一步分为 ZIO 和 VDEV 两大部分和其余一些小的子系统。 SPA 对 DMU 提供的接口不同于传统的块设备接口，完全利用了 CoW 文件系统对写入位置不敏感的特点。 传统的块设备接口通常是写入时指定一个写入地址，把缓冲区写到磁盘指定的位置上，而 DMU 可以让 SPA 做两种操作： write ， DMU 交给 SPA 一个数据块的内存指针， SPA 负责找设备写入这个数据块，然后返回给 DMU 一个 block pointer 。 read ，DMU 交给 SPA 一个 block pointer ，SPA 读取设备并返回给 DMU 完整的数据块。 也就是说，在 DMU 让 SPA 写数据块时， DMU 还不知道 SPA 会写入的地方，这完全由 SPA 判断， 这一点通常被称为 Write Anywhere ，在别的 CoW 文件系统比如 Btrfs 和 WAFL 中也有这个特点。 反过来 SPA 想要对一个数据块操作时，也完全不清楚这个数据块用于什么目的，属于什么文件或者文件系统结构。 VDEV Virtual DEVice VDEV 在 ZFS 中的作用相当于 Linux 内核的 Device Mapper 层或者 FreeBSD GEOM 层，提供 Stripe/Mirror/RAIDZ 之类的多设备存储池管理和抽象。 ZFS 中的 vdev 形成一个树状结构，在树的底层是从内核提供的物理设备， 其上是虚拟的块设备。每个虚拟块设备对上对下都是块设备接口，除了底层的物理设备之外，位于中间层的 vdev 需要负责地址映射、容量转换等计算过程。 除了用于存储数据的 Stripe/Mirror/RAIDZ 之类的 VDEV ，还有一些特殊用途的 VDEV ，包括提供二级缓存的 L2ARC 设备，以及提供 ZIL 高速日志的 SLOG 设备。 ZIO ZIO Pipeline by George Wilson ZFS I/O 作用相当于内核的 IO scheduler 和 pagecache write back 机制。 OpenZFS Summit 有个演讲整理了 ZIO 流水线的工作原理。 ZIO 内部使用流水线和事件驱动机制，避免让上层的 ZFS 线程阻塞等待在 IO 操作上。 ZIO 把一个上层的写请求转换成多个写操作，负责把这些写操作合并到 transaction group 提交事务组。 ZIO 也负责将读写请求按同步还是异步分成不同的读写优先级并实施优先级调度， 在 OpenZFS 项目 wiki 页有一篇描述 ZIO 调度 的细节。 除了调度之外， ZIO 层还负责在读写流水线中拆解和拼装数据块。上层 DMU 交给 SPA 的数据块有固定大小， 目前默认是 128KiB ，pool 整体的参数可以调整块大小在 4KiB 到 8MiB 之间。ZIO 拿到整块大小的数据块之后，在流水线中可以对数据块做诸如以下操作： 用压缩算法，压缩/解压数据块。 查询 dedup table ，对数据块去重。 加密/解密数据块。 计算数据块的校验和。 如果底层分配器不能分配完整的 128KiB （或 zpool 设置的大小），那么尝试分配多个小块，然后用多个 512B 的指针间接块连起多个小块的，拼装成一个虚拟的大块，这个机制叫 gang block 。通常 ZFS 中用到 gang block 时，整个存储池处于极度空间不足的情况，由 gang block 造成严重性能下降，而 gang block 的意义在于在空间接近要满的时候也能 CoW 写入一些元数据，释放亟需的存储空间。 可见经过 ZIO 流水线之后，数据块不再是统一大小，这使得 ZFS 用在 4K 对齐的磁盘或者 SSD 上有了一些新的挑战。 MetaSlab MetaSlab Allocation Performance by Paul Dagnelie MetaSlab 是 ZFS 的块分配器。 VDEV 把存储设备抽象成存储池之后， MetaSlab 负责实际从存储设备上分配数据块，跟踪记录可用空间和已用空间。 叫 MetaSlab 这个名字是因为 Jeff 最初同时也给 Solaris 内核写过 slab 分配器 ，一开始设计 SPA 的时候 Jeff 想在 SPA 中也利用 Solaris 的 slab 分配器对磁盘空间使用类似的分配算法。后来 MetaSlab 逐渐不再使用 slab 算法，只有名字留了下来。 MetaSlab 的结构很接近于 FreeBSD UFS 的 cylinder group ，或者 ext2/3/4 的 block group ，或者 xfs 的 allocation group ，目的都是让存储分配策略「局域化」， 或者说让近期分配的数据块的物理地址比较接近。在存储设备上创建 zpool 的时候，首先会尽量在存储设备上分配 200 个左右的 MetaSlab ，随后给 zpool 增加设备的话使用接近的 MetaSlab 大小。每个 MetaSlab 是连续的一整块空间，在 MetaSlab 内对数据块空间做分配和释放。磁盘中存储的 MetaSlab 的分配情况是按需载入内存的，系统 import zpool 时不需要载入所有 MetaSlab 到内存，而只需加载一小部分。当前载入内存的 MetaSlab 剩余空间告急时，会载入别的 MetaSlab 尝试分配，而从某个 MetaSlab 释放空间不需要载入 MetaSlab 。 OpenZFS Summit 也有一个对 MetaSlab 分配器性能的介绍，可以看到很多分配器内的细节。 ARC ELI5: ZFS Caching Explain Like I'm 5: How the ZFS Adaptive Replacement Cache works Adaptive Replacement Cache ARC 的作用相当于 Linux/Solaris/FreeBSD 中传统的 page/buffer cache 。 和传统 pagecache 使用 LRU (Least Recently Used) 之类的算法剔除缓存页不同， ARC 算法试图在 LRU 和 LFU(Least Frequently Used) 之间寻找平衡，从而复制大文件之类的线性大量 IO 操作不至于让缓存失效率猛增。最近 FOSDEM 2019 有一个介绍 ZFS ARC 工作原理的视频。 不过 ZFS 采用它自有的 ARC 一个显著缺点在于，不能和内核已有的 pagecache 机制相互配合，尤其在 系统内存压力很大的情况下，内核与 ZFS 无关的其余部分可能难以通知 ARC 释放内存。所以 ARC 是 ZFS 消耗内存的大户之一（另一个是可选的 dedup table），也是 ZFS 性能调优 的重中之重。 当然， ZFS 采用 ARC 不依赖于内核已有的 pagecache 机制除了 LFU 平衡的好处之外，也有别的有利的一面。 系统中多次读取因 snapshot 或者 dedup 而共享的数据块的话，在 ZFS 的 ARC 机制下，同样的 block pointer 只会被缓存一次；而传统的 pagecache 因为基于 inode 判断是否有共享， 所以即使这些文件有共享页面（比如 btrfs/xfs 的 reflink 形成的），也会多次读入内存。 Linux 的 btrfs 和 xfs 在 VFS 层面有共用的 reflink 机制之后，正在努力着手改善这种局面，而 ZFS 因为 ARC 所以从最初就避免了这种浪费。 和很多传言所说的不同， ARC 的内存压力问题不仅在 Linux 内核会有，在 FreeBSD 和 Solaris/Illumos 上也是同样，这个在 ZFS First Mount by Mark Shellenbaum 的问答环节 16:37 左右有提到 。其中 Mark Shellenbaum 提到 Matt 觉得让 ARC 并入现有 pagecache 子系统的工作量太大，难以实现。 因为 ARC 工作在 ZIO 上层，所以 ARC 中缓存的数据是经过 ZIO 从存储设备中读取出来之后解压、解密等处理之后的，原始的数据。最近 ZFS 的版本有支持一种新特性叫 Compressed ARC ，打破 ARC 和 VDEV 中间 ZIO 的壁垒，把压缩的数据直接缓存在 ARC 中。这么做是因为压缩解压很快的情况下，压缩的 ARC 能节省不少内存，让更多数据保留在 ARC 中从而提升缓存利用率，并且在有 L2ARC 的情况下也能增加 L2ARC 能存储的缓存。 L2ARC Level 2 Adaptive Replacement Cache 这是用 ARC 算法实现的二级缓存，保存于高速存储设备上。常见用法是给 ZFS pool 配置一块 SSD 作为 L2ARC 高速缓存，减轻内存 ARC 的负担并增加缓存命中率。 SLOG Separate intent LOG SLOG 是额外的日志记录设备。 SLOG 之于 ZIL 有点像 L2ARC 之余 ARC ， L2ARC 是把内存中的 ARC 放入额外的高速存储设备，而 SLOG 是把原本和别的数据块存储在一起的 ZIL 放到额外的高速存储设备。 TOL Transactional Object Layer 这一部分子系统在数据块的基础上提供一个事务性的对象语义层，这里事务性是指， 对对象的修改处于明确的状态，不会因为突然断电之类的原因导致状态不一致。TOL 中最主要的部分是 DMU 层。 DMU Data Management Unit 在块的基础上提供「对象（object）」的抽象。每个「对象」可以是一个文件，或者是别的 ZFS 内部需要记录的东西。 DMU 这个名字最初是 Jeff 想类比于操作系统中内存管理的 MMU(Memory Management Unit)， Jeff 希望 ZFS 中增加和删除文件就像内存分配一样简单，增加和移除块设备就像增加内存一样简单， 由 DMU 负责从存储池中分配和释放数据块，对上提供事务性语义，管理员不需要管理文件存储在什么存储设备上。 这里事务性语义指对文件的修改要么完全成功，要么完全失败，不会处于中间状态，这靠 DMU 的 CoW 语义实现。 DMU 实现了对象级别的 CoW 语义，从而任何经过了 DMU 做读写的子系统都具有了 CoW 的特征， 这不仅包括文件、文件夹这些 ZPL 层需要的东西，也包括文件系统内部用的 spacemap 之类的设施。 相反，不经过 DMU 的子系统则可能没法保证事务语义。这里一个特例是 ZIL ，一定程度上绕过了 DMU 直接写日志。说一定程度是因为 ZIL 仍然靠 DMU 来扩展长度，当一个块写满日志之后需要等 DMU 分配一个新块，在分配好的块内写日志则不需要经过 DMU 。所有经过 DMU 子系统的对象都有 CoW 语义，也意味着 ZFS 中不能对某些文件可选地关闭 CoW ，不能提供数据库应用的 direct IO 之类的接口。 「对象（object）」抽象是 DMU 最重要的抽象，一个对象的大小可变，占用一个或者多个数据块（ 默认一个数据块 128KiB ）。上面提到 SPA 的时候也讲了 DMU 和 SPA 之间不同于普通块设备抽象的接口，这使得 DMU 按整块的大小分配空间。当对象使用多个数据块存储时， DMU 提供间接块（indirect block）来引用这些数据块。 间接块很像传统 Unix 文件系统（Solaris UFS 或者 Linux ext2）中的一级二级三级间接块， 一个间接块存储很多块指针（block pointer），多个间接块形成树状结构，最终一个块指针可以引用到一个对象。 更现代的文件系统比如 ext4/xfs/btrfs/ntfs 提供了 extent 抽象，可以指向一个连续范围的存储块， 而 ZFS 不使用类似 extent 的抽象。DMU 采用间接块而不是 extent ，使得 ZFS 的空间分配更趋向碎片化，为了避免碎片化造成的性能影响，需要尽量延迟写入使得一次写入能在磁盘上 尽量连续，这里 ARC 提供的缓存和 ZIO 提供的流水线对延迟写入避免碎片有至关重要的帮助。 有了「对象（object）」的抽象之后， DMU 进一步实现了「对象集（objectset）」的抽象， 一个对象集中保存一系列按顺序编号的 dnode （ ZFS 中类似 inode 的数据结构），每个 dnode 有足够空间 指向一个对象的最多三个块指针，如果对象需要更多数据块可以使用间接块，如果对象很小也可以直接压缩进 dnode 。随后 DSL 又进一步用对象集来实现数据集（dataset）抽象，提供比如文件系统（filesystem ）、快照（snapshot）、克隆（clone）之类的抽象。一个对象集中的对象可以通过 dnode 编号相互引用， 就像普通文件系统的硬链接引用 inode 编号那样。 上面也提到因为 SPA 和 DMU 分离， SPA 完全不知道数据块用于什么目的；这一点其实对 DMU 也是类似， DMU 虽然能从某个对象找到它所占用的数据块，但是 DMU 完全不知道这个对象在文件系统或者存储池中是 用来存储什么的。当 DMU 读取数据遇到坏块（block pointer 中的校验和与 block pointer 指向的数据块内容不一致）时，它知道这个数据块在哪儿（具体哪个设备上的哪个地址）， 但是不知道这个数据块是否和别的对象共享，不知道搬动这个数据块的影响，也没法从对象反推出文件系统路径， （除了明显开销很高地扫一遍整个存储池）。所以 DMU 在遇到读取错误（普通的读操作或者 scrub/resilver 操作中）时，只能选择在同样的地址，原地写入数据块的备份（如果能找到或者推算出备份的话）。 或许有人会疑惑，既然从 SPA 无法根据数据地址反推出对象，在 DMU 也无法根据对象反推出文件，那么 zfs 在遇到数据损坏时是如何在诊断信息中给出损坏的文件路径的呢？这其实基于 ZPL 的一个黑魔法： 在 dnode 记录父级 dnode 的编号 。因为是个黑魔法，这个记录不总是对的，所以只能用于诊断信息，不能基于这个实现别的文件系统功能。 ZAP ZFS Attribute Processor 在 DMU 提供的「对象」抽象基础上提供紧凑的 name/value 映射存储， 从而文件夹内容列表、文件扩展属性之类的都是基于 ZAP 来存。 ZAP 在内部分为两种存储表达： microZAP 和 fatZAP 。 一个 microZAP 占用一整块数据块，能存 name 长度小于 50 字符并且 value 是 uint64_t 的表项， 每个表项 64 字节。 fatZAP 则是个树状结构，能存更多更复杂的东西。 fatZAP 是个 on disk 的散利表，指针表中是 64bit 对 name 的 hash ，指向单链表的子节点列表，子节点中的 value 可以是任意类型的数据（不光是 uint64_t ）。 可见 microZAP 非常适合表述一个普通大小的文件夹里面包含到很多普通文件 inode （ZFS 是 dnode）的引用。 fatZAP 则不光可以用于任意大小的文件夹，还可以表达 ZFS 的配置属性之类的东西，非常灵活。 在 ZFS First Mount by Mark Shellenbaum 的8:48左右 提到，最初 ZPL 中关于文件的所有属性（包括访问时间、权限、大小之类所有文件都有的）都是基于 ZAP 来存，也就是说每个文件都有个 ZAP ，其中有叫做 size 呀 owner 之类的键值对，就像是个 JSON 对象那样，这让 ZPL 一开始很容易设计原型并且扩展。然后文件夹内容列表有另一种数据结构 ZDS（ZFS Directory Service），后来常见的文件属性在 ZPL 有了专用的紧凑数据结构，而 ZDS 则渐渐融入了 ZAP 。 这些变化详见下面 ZPL 。 DSL Dataset and Snapshot Layer 数据集和快照层，负责创建和管理快照、克隆等数据集类型，跟踪它们的写入大小，最终删除它们。 由于 DMU 层面已经负责了对象的写时复制语义和对象集的概念，所以 DSL 层面不需要直接接触写文件之类来自 ZPL 的请求，无论有没有快照对 DMU 层面一样采用写时复制的方式修改文件数据。 不过在删除快照和克隆之类的时候，则需要 DSL 参与计算没有和别的数据集共享的数据块并且删除它们。 DSL 管理数据集时，也负责管理数据集上附加的属性。ZFS 每个数据集有个属性列表，这些用 ZAP 存储， DSL 则需要根据数据集的上下级关系，计算出继承的属性，最终指导 ZIO 层面的读写行为。 除了管理数据集， DSL 层面也提供了 zfs 中 send/receive 的能力。 ZFS 在 send 时从 DSL 层找到快照引用到的所有数据块，把它们直接发往管道，在 receive 端则直接接收数据块并重组数据块指针。 因为 DSL 提供的 send/receive 工作在 DMU 之上，所以在 DSL 看到的数据块是 DMU 的数据块，下层 SPA 完成的数据压缩、加密、去重等工作，对 DMU 层完全透明。所以在最初的 send/receive 实现中，假如数据块已经压缩，需要在 send 端经过 SPA 解压，再 receive 端则重新压缩。最近 ZFS 的 send/receive 逐渐打破 DMU 与 SPA 的壁垒，支持了直接发送已压缩或加密的数据块的能力。 ZIL ZFS Intent Log 记录两次完整事务语义提交之间的日志，用来加速实现 fsync 之类的文件事务语义。 原本 CoW 的文件系统不需要日志结构来保证文件系统结构的一致性，在 DMU 保证了对象级别事务语义的前提下，每次完整的 transaction group commit 都保证了文件系统一致性，挂载时也直接找到最后一个 transaction group 从它开始挂载即可。 不过在 ZFS 中，做一次完整的 transaction group commit 是个比较耗时的操作， 在写入文件的数据块之后，还需要更新整个 object set ，然后更新 meta-object set ，最后更新 uberblock ，为了满足事务语义这些操作没法并行完成，所以整个 pool 提交一次需要等待好几次磁盘写操作返回，短则一两秒，长则几分钟， 如果事务中有要删除快照等非常耗时的操作可能还要等更久，在此期间提交的事务没法保证一致。 对上层应用程序而言，通常使用 fsync 或者 fdatasync 之类的系统调用，确保文件内容本身的事务一致性。 如果要让每次 fsync/fdatasync 等待整个 transaction group commit 完成，那会严重拖慢很多应用程序，而如果它们不等待直接返回，则在突发断电时没有保证一致性。 从而 ZFS 有了 ZIL ，记录两次 transaction group 的 commit 之间发生的 fsync ，突然断电后下次 import zpool 时首先找到最近一次 transaction group ，在它基础上重放 ZIL 中记录的写请求和 fsync 请求，从而满足 fsync API 要求的事务语义。 显然对 ZIL 的写操作需要绕过 DMU 直接写入数据块，所以 ZIL 本身是以日志系统的方式组织的，每次写 ZIL 都是在已经分配的 ZIL 块的末尾添加数据，分配新的 ZIL 块仍然需要经过 DMU 的空间分配。 传统日志型文件系统中对 data 开启日志支持会造成每次文件系统写入操作需要写两次到设备上， 一次写入日志，再一次覆盖文件系统内容；在 ZIL 实现中则不需要重复写两次， DMU 让 SPA 写入数据之后 ZIL 可以直接记录新数据块的 block pointer ，所以使用 ZIL 不会导致传统日志型文件系统中双倍写入放大的问题。 ZVOL ZFS VOLume 有点像 loopback block device ，暴露一个块设备的接口，其上可以创建别的 FS 。对 ZFS 而言实现 ZVOL 的意义在于它是比文件更简单的接口，所以在实现完整 ZPL 之前，一开始就先实现了 ZVOL ，而且 早期 Solaris 没有 thin provisioning storage pool 的时候可以用 ZVOL 模拟很大的块设备，当时 Solaris 的 UFS 团队用它来测试 UFS 对 TB 级存储的支持情况 。 因为 ZVOL 基于 DMU 上层，所以 DMU 所有的文件系统功能，比如 snapshot / dedup / compression 都可以用在 ZVOL 上，从而让 ZVOL 上层的传统文件系统也具有类似的功能。并且 ZVOL 也具有了 ARC 缓存的能力，和 dedup 结合之下，非常适合于在一个宿主机 ZFS 上提供对虚拟机文件系统镜像的存储，可以节省不少存储空间和内存占用开销。 ZPL ZFS Posix Layer 提供符合 POSIX 文件系统语义的抽象，也就是包括文件、目录、软链接、套接字这些抽象以及 inode 访问时间、权限那些抽象，ZPL 是 ZFS 中对一个普通 FS 而言用户直接接触的部分。 ZPL 可以说是 ZFS 最复杂的子系统，也是 ZFS 作为一个文件系统而言最关键的部分。 ZPL 的实现中直接使用了 ZAP 和 DMU 提供的抽象，比如每个 ZPL 文件用一个 DMU 对象表达，每个 ZPL 目录用一个 ZAP 对象表达，然后 DMU 对象集对应到 ZPL 下的一个文件系统。 也就是说 ZPL 负责把操作系统 VFS 抽象层的那些文件系统操作接口，翻译映射到基于 DMU 和 ZAP 的抽象上。传统 Unix 中的管道、套接字、软链接之类的没有什么数据内容的东西则在 ZPL 直接用 dnode 实现出来。 ZPL 也需要进一步实现文件权限、所有者、访问日期、扩展属性之类杂七杂八的文件系统功能。 2020年2月9日添加 继续上述 ZAP 格式变化的讨论，在 ZPL 抛弃早期用 ZAP 的设计之后， ZPL 中 znode （ZPL 扩展的 dnode） 保存文件属性的机制成为了一个小的子系统，叫 ZFS System Attributes 。 SA 的设计照顾了旧版 ZPL znode 格式兼容问题，有新旧两代格式。旧版 znode 格式是固定偏移位置存取属性的 SA ，因此透过预先注册好的描述旧版 znode 格式的固定映射表， SA 依然能用同样的代码路径存取旧版的 znode 。而后来 灵活的新设计下的 SA 更有意思 ，ZFS 认识到，大部分 znode 的属性都可以用有限的几种属性集来表达， 比如普通文件有一组类似的属性（权限、所有者之类的）， zvol 有另一组（明显 zvol 不需要很多 ZPL 文件的属性），整个 ZFS dataset 可以「注册」几种属性布局，然后让每个 znode 引用其中一种布局， 这样 znode 保存的属性仍然是可以任意变化的，又不需要在每个 znode 中都记录所有属性的名字。 SA 的出现提升了 ZPL 的可扩展性。 ZPL 为了应付不同的操作系统之间文件系统 API 的差异，可以使用 SA 在 znode 之中加入针对不同操作系统和应用场景的属性。例如，在支持 NFSv4 ACL 的操作系统上，ZFS 既可以用现有方式把 DACL ACEs 放在独立于文件对象的单独对象中，也可以把 DACL ACEs 放在 SA 内。 在 ZFS First Mount by Mark Shellenbaum 中介绍了很多在最初实现 ZPL 过程中的坎坷， ZPL 的困难之处在于需要兼容现有应用程序对传统文件系统 API 的使用方式，所以他们需要大量兼容性测试。视频中讲到非常有意思的一件事是， ZFS 在设计时不想重复 Solaris UFS 设计中的很多缺陷，于是实现 VFS API 时有诸多取舍和再设计。 其中他们遇到了 VOP_RWLOCK ，这个是 UFS 提供的文件级别读写锁。对一些应用尤其是 NFS 而言，文件读写锁能保证应用层的一致性，而对另一些应用比如数据库而言， 文件锁的粒度太大造成了性能问题。在设计 ZPL 的时候他们不想在 ZFS 中提供 VOP_RWLOCK ，这让 NFS 开发者们很难办（要记得 NFS 也是 Solaris 对 Unix 世界贡献的一大发明）。 最终 ZFS 把 DMU 的内部细节也暴露给了 NFS ，让 NFS 基于 DMU 的对象创建时间（ TXG id ）而不是文件锁来保证 NFS 的一致性。结果是现在 ZFS 中也有照顾 NFS 的代码，后来也加入了 Samba/CIFS 的支持，从而在 ZFS 上设置 NFS export 时是通过 ZFS 的机制而非系统原生的 NFS export 机制。","tags":"tech","url":"//farseerfc.me/zhs/zfs-layered-architecture-design.html"},{"title":"和萌狼交换问题","text":"很抱歉萌狼很早就提过交换问题的事，被我一直咕咕了许久。 拖延症晚期有药么 我的提问和萌狼的回答 可以去萌狼的博客上看呀 Q1：除了博客的「关于」页面以外，还愿意再向咱介绍一下自己嘛？ 介绍自己啊。 写了删删了写，不知道该介绍点啥 就说点自己的兴趣？ 喜欢自由开源软件，喜欢 Arch Linux 。喜欢这些倒不是出于 RMS 和 FSF 那样道义上的原因， 我觉得商业软件公司要赚钱吃饭也是无可厚非的。 喜欢自由软件是因为，当我需要知道它到底怎么工作的时候，有可能去挖代码，必要的话能去改代码。 当然我一个人肯定不能读所有在用的软件，但是我知道我有读和修改代码的权利的话， 那么我认识的朋友们也同样有这样的权利，我不认识的广大社区有千千万万的人也同样有这样的权利， 从而我相信当我遇到问题的时候不至于卡在某些人某些公司某些集体的决策上而无法解决。 基于这个理由，我对开源社区也同样有公开全部细节的期待。我喜欢 Arch Linux 因为即便它的内部决策只是一小波人，但是导致决策的讨论以及决策的执行方式全是公开的，可以在网上翻阅， 可以追根溯源，这让我有种安心感。就像我不喜欢 Manjaro 的一点是它有太多细节是翻阅不到的， 虽然它也是开源社区，但是打包细节翻阅不到，包列表翻阅不到，决策的制定和执行的过程也翻阅不到， 通常就只是在他们的论坛上发个通知了事，这我很不喜欢。 除了喜欢自由开源软件之外，可能我在网上比较有特点的地方是用繁体字了吧， 也曾经年幼时在水木社区和别人因为这个吵过嘴，也在 知乎上写过篇「在知乎用繁体字是怎样一种体验」 。 致力于在我存在的地方为繁体字爱好者们提供一个安逸的环境，不过好像最近也不见很多反对的声音了。 除了网上之外，现实中的自己嘛，特点可能算是不知道自己属于哪儿了……一个漂泊的人。 小时候8岁前在陕西长大，把自己当作陕西人，但是身边的邻里街坊们却以河南人和江浙人居多。 厂办环境，好几个大型重工都从江浙搬到了陕西秦川一带，加上国共内战的时候河南黄河缺口造成的难民慌西逃， 构成了当时厂办的主要人口拿着城市户口，反而是当地的陕西人都是农民户口， 于是和厂办子弟们形成了鲜明的隔阂。我对社会主义，对苏式厂办，对整个国家结构的理解大概也是从那儿来的。 跟着邻里们学会了河南话，在家里说普通话，从老一辈们身上又学会了江浙的语调。 都说一个厂办是一个社会的缩影，那时候的环境可能算聚集了全国东南西北的样子吧。 8、9岁左右随父母到了上海，因为不会说上海话受同学们排挤，倒也不是很在意，渐渐和同学们学起了上海话， 可能还参杂点爷爷奶奶的江苏方言。十多年后考入大学，五湖四海的同学都有，就不算是在上海了。 大学毕业来了日本，一晃又是7年过去。至此我大概比起同龄人接触到更多全国各地的人， 也分不清自己的归属地了。但有一条，我知道自己是个中国人，为自己是个中国人自豪，觉得虽在他乡， 该为中国做点自己的贡献。 Q2：现在这个名字是怎么想到的呢？ farseerfc 这个名字嘛，来自 firechild 这个更早的网名，和魔兽争霸里面 farseer 这个英雄。 farseer 本算是 Anglish ，以日耳曼语系的构词法再造的英语词，对应拉丁构词法的话 far = tele ， seer = visioner ，于是 farseer 也就是 tele-visioner ，看得远的人，电视一词 television 的原本的词干的衍生词。 不过说为什么选 farseer 这个名字，更多是为了符合 fc 这个缩写，而 fc 来自 firechild 这个词。 再深挖黑历史也不再有什么意义了， farseerfc 作为网名只是一直以来的习惯吧。 Q3：觉得咱俩之间最令汝印象深刻的时候是什么？ 近期来看，印象最深刻的可能算是起草 Arch Linux 中文社区交流群指引 吧，看得出萌狼对社区发展的热心和好意。 再往前，印象深刻的时候可能是萌狼用 Pelican 搭博客吧，最初认识萌狼的时候觉得是 MediaWiki 方面的行家，还以为博客也会继续用 MediaWiki 打造，没想到能吃了 Pelican 的安利，外加萌狼写博文的产量着实让人望尘莫及。 然后 ArchWiki 上 Beginner's Guide 被删除之后，萌狼的博客多了一篇为新人们写的入门安装手册， 配有完整截图指引，详尽程度令人感叹。感觉得到萌狼作为一个「过来人」对新人们的照顾。 每次群中闹起争执，老用户们对新人发起调侃的时候，也是萌狼站出来为新人们解围， 帮助有能力的人适应群里的讨论环境。或许最初写交流群指引的时候也是出于这样的良苦用心吧。 Q4：对咱的印象怎么样？ 最早来 Arch Linux CN 的时候，似乎萌狼还不叫萌狼？不记得那时候用的名字了。只记得来自 AOSC ，和那边一众谈笑风声，着实令人羡慕，经常跑他们的聚会也令人羡慕。 后来有了萌狼的名字，群里的狼们也渐渐多了起来，一时间都分不清哪个狼是哪个了。 不过萌狼的口癖和说话方式总是在狼群中非常有标志性。 后来似乎发生了好多事情，我不知道的事情，也不敢妄加揣测。萌狼开始变身音游大佬， 群里的别的狼们渐渐也各忙东西。不知道什么原因，萌狼会偶尔退群，想问下前因后果， 又觉得自己不该多管闲事。不过无论萌狼退群多少次，总是在默默关心着社区发展， 关心着新人融入社区的环境。 似乎萌狼加入了 FSF ？玩起了 Parabola ，玩起了 linux-libre 。有能跑起完全自由的发行版的设备， 这一点也非常令人羡慕。似乎有很多设备，但是似乎又很不满于现状。看得出萌狼为了理想放弃了很多东西， 或许大家都是如此吧，也或许只是我多心。 还有就是萌狼用 Gnome ，感觉 AOSC 那边很多人都用 Gnome ，给 Gnome 贡献翻译之类的， 萌狼或许也是其中一员。DE 党争是水群久胜不衰的话题，或许我也有些责任，但是我觉得以发行版角度而言 DE 多样性非常重要，萌狼在社区中的作用也不可或缺。 Q5：在汝用过的 GNU/Linux 发行版之间汝最喜欢的是哪一个，为啥咧？ 最喜欢的当然是 Arch Linux 啦，喜欢的理由前面 Q1 算是提到了一些。其实别的发行版的很多特性也很眼馋， 眼馋 Fedora Silverblue 的 A/B 更新机制，眼馋 Fedora 的 SELinux 和诸多企业级特性支援，眼馋 openSUSE 的 OBS 和 btrfs 支持，眼馋 debian 的小巧和细化打包，眼馋 NixOS 的函数式包管理， 眼馋 Gentoo 的可定制性，眼馋 Parabola / GuixSD 的完全自由。 但是总得来说， Arch Linux 提供的基础足够让我折腾系统成自己喜欢的方式，足够顺手， 也在需要软件的时候足够自己打包使用，不需要等待某些远在天边的议会做决策，或许是让我留在 Arch Linux 的原因吧（当然更大原因可能是因为惯性）。发行版之间的技术区别可能并不那么重要， 重要的是该干活的时候能找到干活的人，这一点 Arch Linux 还是有很多人在认真做事情的。 没有繁琐的议会投票表决，没有细碎的打包步骤，用最快的方式把活干了，这在我看来是最重要的。 或许有一天，干活的人没了，或者我想要的特殊特性因为太复杂没人想带头干，而别的发行版有， 那时可能我会换去别的发行版吧。又或许我会自己干，谁知道呢。 比起发行版之争，甚至比起 Linux/Windows/macOS 的桌面系统地位之争，可能日后更关键的是别的平台 比如 Android 在手持设备甚至物联网设备上的兴起导致的 PC 桌面的衰落。虽然这些新设备大多都是跑着 Linux 的内核，但是其上的生态环境不能说像 GNU/Linux 那样自由。这一点上，自由软件该如何发挥优势 争取用户和生态可能是更关键的。 当然这些都于我而言过于遥远，一人之力难挽狂澜……我只希望自己和朋友们所在的自由的土地能保持下去， 或许我也仅能做到这些。 Q6：在 Arch Linux 做 Trusted Users 时有没有什么心得？ 说来非常惭愧，做 TU 这么4年了，实际做的事情着实有限，只能隔几天打打包而已。要做的事情太多， 而自己上面也说了有干活的人最重要，设身处地深刻体会到在开源社区的诸位志愿者们大家都不容易。 TU 应该做的事情，细数一下除了给 community 打包之外，还有处理包的 bug ，处理 AUR 的争议， 测试新包给反馈，以及沟通和反馈上游。反观自己做的事情，真的太少了。比起肥猫和其他 TU 们的辛勤， 总觉得自己不够格。「精力有限，凭着志愿者热情」，什么的说辞可以说很多， 但是良心上对着自己热爱的事情却不能百分百扑上去做，真的没有颜面腆着脸说…… 打包和沟通上游之类的心得倒是有不少，也一直想写点笔记记录一下，挖坑却没时间填上。该说， 或许应该换个本职工作了，又想，孰重孰轻哪边是本行需要自己掂量。 Q7：有什么话要对咱说嘛？ 不知何时起，不知萌狼经历了什么，有时候感觉萌狼傲娇的性格让人看不透，不过事后能看出萌狼都是本着好心。 或许，如果能更坦诚一些的话，也能更融入大家吧。虽然我也没资格这么说。 像前面写的，隐约能感觉到萌狼似乎为了理想放弃了很多，孰重孰轻是每个人自己的权衡。 以及还有感谢，感谢萌狼把我当作朋友，感谢萌狼的耐心。 最后还有抱歉，这篇拖了太久，是该治治我的拖延症了。","tags":"life","url":"//farseerfc.me/zhs/question-exchange-horo.html"},{"title":"东方歌词翻译迁移至 sak.uy","text":"最近几个月在这个博客发了不少歌词翻译 似乎有要转型成音乐博主的趋势 ，前段时间买了个新域名 sak.uy ，准备专门用来放这些东方歌曲的歌词翻译，于是分设了单独的博客「 Sakuya的音乐盒 」。主博客这边右侧边栏会有到音乐盒的链接。 曾经在这边的那些歌尽量保持 URL 跳转过去，新的歌词翻译会发到那边去，还想继续听歌的话请继续订阅那边的 RSS 呀。 主博客这边还是像往常一样保持记录生活点滴和技术经验好了。说道介绍技术， 有人问过我那些日语歌词上给汉字标注的假名都是我一个个手输的么？ 一开始是手输的，后来发现了不错的自动化方案，于是这里介绍一下。 首先是 python-furigana 这是个 python 写的小程序（严格说是库），可以把一段日文转换成标准的 HTML 形式的 <ruby> 标签的振假名( 振 ( ふ ) り 仮名 ( かな ) )。 它本身只是个方便的格式化库，实际工作是用 python-mecab 这个 binding 去查询 mecab 这个著名的日语语料分析库。要用它还得配合一些开源的 mecab 词典，这些在 [archlinuxcn] 都有打好的包了，直接安装： $ sudo pacman -Syu python-furigana mecab-git python-mecab mecab-ipadic 装好之后用法也很直接，甚至没有 binary 直接调用 python 的 module 就可以： $ python -m furigana.furigana \"振り仮名の例\" <ruby><rb>振</rb><rt>ふ</rt></ruby>り<ruby><rb>仮名</rb><rt>かめい</rt></ruby>の<ruby><rb>例</rb><rt>れい</rt></ruby> 就是提供日语作为输入，然后输出 HTML 形式的 <ruby> 标签而已。 像上面的例子中出现的错误（「振り仮名」完整的一个词中「仮名」意思是「平仮名」应该发音「がな」而非意为「假的人名」的「かめい」） 可以看出其实标注的准确率还是有些问题的。嘛日语作为一个非常依赖上下文判断的语言， 经常日本人都会搞错某些汉字的发音，这些也不能强求机械化的算法能 100% 正确实现。 好在单纯的词典匹配也能满足大部分标注的需要了，用这个标注总体来说 95% 以上的情况都是正确的（歌词的话正确率低一些，毕竟歌词中古语啦当て字啦训読み这些情况很常见）。 把输出插入我的博客 然后我的博客用 reStructuredText 语法写，不能直接用 HTML 标签（虽然我加了 :html: 这个 行内角色 ( inline role ) 但是大量用也不方便）。这个博客一开始用 Pelican 重写主题的时候 我就实现了个自己的 :ruby: 行内角色 ( inline role ) 用来标发音，于是一段 sed 就能把 python-furigana 的输出转换成我用的 rst 语法： $ which clipboard Co Ci Ct clipboard: aliased to xclip -selection clipboard Co: aliased to clipboard -o Ci: aliased to clipboard -i Ct () { t=$(mktemp /tmp/furigana-XXXX) python -m furigana.furigana $(Co) | sed 's@<ruby><rb>@ :ruby:`@g;s@</rb><rt>@|@g;s@</rt></ruby>@` @g' | sponge $t cat $t | tee /dev/tty | perl -pe 'chomp if eof' | Ci } 上面这些 alias 在我的 .bashrc 中。有了这些之后， 我只要把需要标注的日语文本放入剪切版，执行 Ct ，再粘帖结果就好了。 $ echo \"振り仮名の例\" | Ci $ Ct :ruby:`振|ふ` り :ruby:`仮名|かめい` の :ruby:`例|れい` 然后所有那些歌词上标注的假名都是这样一句一句标注好之后，再手动校对修改的。","tags":"life","url":"//farseerfc.me/zhs/move-lyrics-to-sakuy.html"},{"title":"用 usbip 转发 raspberry pi 的 USB 键盘鼠标给 Arch Linux 的 PC","text":"惠狐 megumifox 写了篇 用PulseAudio将电脑的声音用手机放出来 ，文末提到想知道我怎么用树莓派转发 USB 的，于是写篇文章记录一下。 起因 家里有个装了 Arch Linux ARM 的树莓派3B 闲置着，装了 Arch Linux ARM 偶尔上电更新一下， 不过因为性能实在不适合做别的事情于是一直在吃灰。某日 给老婆安利幻想万华镜 和老婆看片 的时候， 老婆不吃安利于是迁怒键盘鼠标 键盘鼠标被长长的 USB 线扯着感觉很难受 ，于是偶发奇想，能不能利用一下树莓派的多达 4 个 USB 2.0 端口接鼠标键盘呢， 这样鼠标键盘就可以跟着树莓派来回走，不用拖着长长的 USB 线了。 上网搜了一下， Linux 环境有个 usbip 工具正好能做到这个。原理也很直观， usbip 能把 USB 端口上的数据封装成 IP 协议通过网络转发出去，从而两个网络间相互联通的电脑就可以远程转发 USB 了。 设置好的话，就像是一台 PC 多了几个位于树莓派上的 USB 端口，插上树莓派的 USB 设备统统作为 PC 的设备。 这篇文章假设有一个装了 Arch Linux 的 PC ，和一个装了 Arch Linux ARM 的树莓派， 并且两者间能通过网络互相访问到。别的发行版上大概也可以这么做，只是我没有试过。 usbip 工具似乎普遍被发行版打包了，除此之外需要的也只是 Linux 内核提供好的功能而已。 设置 Arch Linux ARM 的树莓派端 假设树莓派上面网络已经设置妥当，开机插电就能自动联网。接下来安装 usbip 工具： $ sudo pacman -Syu usbip 然后需要记录一下树莓派的 IP 地址： $ ip addr 3: wlan0: ...... inet 192.168.0.117/24 brd 192.168.0.255 scope global noprefixroute wlan0 ...... 接下来给 udev 添加一个规则，当插入 usb 设备的时候，执行我的脚本 usbipall.sh 把 usb 设备通过 usbip 共享出去： $ cat /etc/udev/rules.d/usbipall.rules ACTION==\"add\", SUBSYSTEM==\"usb\", RUN+=\"/usr/bin/bash /usr/local/bin/usbipall.sh\" 这个 rules 文件 可以在我的 dotfiles 里面找到 。 然后规则调用的 usbipall.sh 我这么写的， 文件同样在我的 dotfiles 里面 ： #!/bin/sh ( allusb = $( usbip list -p -l ) for usb in $allusb do busid = $( echo \" $usb \" | sed \"s|#.*||g;s|busid=||g\" ) if [ \" $busid \" = \"1-1.1\" ] then # ignoring usb ethernet continue fi echo \" $( date -Iseconds ) : Exporting $busid \" usbip bind --busid = \" $busid \" done ) >>/var/log/usbipall.log 2 > & 1 这个脚本做了这样几件事。 调用 usbip list --local 列出本地所有 usb 设备。 针对每个设备 取出它的 busid 判断是不是树莓派的 USB 以太网卡，不是的话继续 通过 usbip bind --busid= 命令把这个 usb 设备导出到网上 最后把所有输出记录到 /var/log/usbipall.log 日志里面 树莓派这边设置就完成了。从此之后插入的 usb 设备就会统统导出出去。 这里需要注意一下，启用了 udev 规则之后，就没法插键盘鼠标到树莓派上控制它了……我都是从另一端 ssh 上树莓派操作的。如果有什么地方设置错误，可能需要把树莓派的 SD 卡拔下来插到电脑上，删除掉 rules 文件…… 仔细检查设置正确了之后，重新载入 udev 规则，或者重启树莓派： # systemctl restart systemd-udevd 这样树莓派这边就设置好了。 设置 Arch Linux 的 PC 端 同样假设 PC 这边也已经联网。接下来同样安装 usbip 工具： $ sudo pacman -Syu usbip 然后我写了个小脚本去链接树莓派端， 这个文件 usbiprpi3.sh 也在我的 dotfiles ： #!/bin/sh rpi3 = \"192.168.0.117\" modprobe vhci-hcd allusb = $( usbip list -p -r $rpi3 | cut -d \":\" -f1 -s | sed 's|&#94;[ \\t]*||;/&#94;$/d' ) for busid in $allusb do if [ \" $busid \" = \"1-1.1\" ] then # ignoring usb ethernet continue fi echo \"Attaching $busid \" usbip attach --remote = $rpi3 --busid = \" $busid \" done 其中脚本第一行填入上面记录下来的树莓派的 IP 地址，接下来脚本做了这么几件事： 用 modprobe 确认加载 vhci-hcd 通用虚拟键鼠驱动 用 usbip list --remote= 列出远程设备上已经导出了的 USB 设备，取出他们的 busid 对每个设备用 usbip attach 接上该设备 然后就已经准备妥当，接下来是见证奇迹的时刻： $ sleep 10 ; sudo ./usbiprpi3.sh Attaching 1-1.4.3 Attaching 1-1.4.1 因为只有一套键盘鼠标，所以先 sleep 个 10 秒，在此期间快速把键鼠拔下来插到树莓派的 USB 口上去。 如果对自己手速没自信也可以把时间设长一点。然后用 root 权限执行 usbiprpi3.sh 。 一切正常的话，先能观测插上树莓派的键盘鼠标被树莓派初始化了一下，比如键盘灯会亮， 然后这些设备会被导出出去，从而键盘灯灭掉，然后 10 秒等待结束后他们被远程接到了 PC 端， 又会被初始化一下，同时 PC 端这边会有上述 Attaching 的输出。然后键盘鼠标就能像平常一样用啦。 使用体验 因为就是通过 IP 转发 USB 嘛，所以就和普通地接 USB 的体验差不多，当然前提是网络环境足够稳定。 在我家间隔 5 米到无线路由器的环境下，基本感觉不到网络延迟的影响。 通过这种方式聊天上网应该和直接接 USB 设备完全一样。本文就是在通过树莓派转发的前提下用键盘打字写的。 不过如果网络负载本身就很大的话，可能会一些延迟，比如我开着 OBS 直播打东方的时候，原本就手残 的我感觉更加手残了…… 试过拿着树莓派在房间到处走，走到无线信号覆盖不到的地方， usbip 会断掉，PC 上的现象就像是 USB 设备被拔下来了……所以如果无线网络不稳的话，可能需要对上面脚本做个循环？不过那样可能会用起来很别扭吧。 以及，上述操作 usbip 是走 TCP 3240 端口，数据包大概完全没有加密，所以考虑安全性的话， 最好还是在内网环境使用。不过转念一想，万一有别人接上了我导出出去的 USB ，也就是截获我的键盘， PC 这边没法 attach 设备了，应该马上会发现吧。我敲打 sudo 之类命令的时候 shell 里面没有回显， 就不会再继续敲密码了。而且似乎对攻击者也没有什么好处？要是他 usb attach 到了我的设备上， 我就能控制他的键盘了耶~","tags":"tech","url":"//farseerfc.me/zhs/usbip-forward-raspberrypi.html"},{"title":"【听译】君さえいなけりゃよかった","text":"君さえいなけりゃよかった 如果你从未出现过该多好 降り出した雨の中で 君に出会った时から 下起雨的那一刻 从遇到你那时起 君がいないということが 当たり前じゃなくなった 身边没有你的情况 就已经不再是平常 ああ こんなはずじゃない 啊 不应该是这样的 ずっと自分胜手にさ 过ごせたはずなのに 明明一直是散漫地过着自己的日子 まるで仆じゃないような仆が さらけ出されてくよ 就像是带出了不是我的另一面的我 君さえいなけりゃよかった こんな気持ちは知らないから 如果你从未出现过该多好 就不会知道这种心情 やらなくちゃいけないことが 手つかずのまま积もってく 一堆不得不做的事情 堆在手头越积越多 仆じゃなくてもいいのなら こっちを见て笑わないでよ 如果不是我也可以的话 就别看着我这边笑啊 大袈裟じゃなくてそれだけで 忘れられなくなるの 甚至那些不重要的事情 都变得难以忘记了 君の适当な话も 全部心に刺さります 你无意间随口说的话 全都刺在心头 気にしなけりゃいいのにな 残らずかき集めちゃうの 虽说只要不在意就可以了 却一句不剩全收集了起来 ああ こんなはずじゃない こんなはずじゃない 啊 不应该是这样的 不应该是这样的 君に出会わなきゃよかった こんなに寂しくなるのなら 如果没遇到过你该多好 就不会变得如此寂寞 君じゃなくてもいいことが もう见つからないの 已经找不到 和你无关也可以的情况了 忘れられないから 君じゃなかったら 无法忘记了 要不是你的话 いっそ见损なってしまうような そんなひとだったらなあ 干脆变成根本看不起的人 如果是那种人的话 でもそれでも どうせ无理そう 嫌いになれないや 但是即使如此 大概反正也不可能 无法变得讨厌 仆がいなくてもいいなら いっそ不幸になってしまえ 如果不是我也可以的话 干脆变得不幸吧 最后にまた仆の元に 泣きついてくればいい 最后还是会回到我身边 哭着凑过来的话就可以 君さえいなけりゃよかった こんな気持ちは知らないから 如果没有你该多好 就不会知道这种心情 やらなくちゃいけないことが 手つかずのまま积もってく 一堆不得不做的事情 堆在手头越积越多 仆じゃなくてもいいのなら こっちを见て笑わないでよ 如果不是我也可以的话 就别看着我这边笑啊 大袈裟じゃなくてそれだけで 甚至那些不重要的事情 君のこと 间违いなく 对你 毫无疑问 苦しいほど 好きになっちゃうよ 刻骨铭心地 变得喜欢上了啊 忘れられないから 君じゃなかったら 因为无法忘记 如果不是你的话 君に出会わなきゃ 仆じゃなかったら 要是没遇到过你 如果不是我的话 君さえいなけりゃよかった 如果你从未出现过该多好","tags":"life","url":"//farseerfc.me/zhs/kimisaeinakerya.html"},{"title":"【译】使用 GNU stow 管理你的点文件","text":"译注 这篇是翻译自 Brandon Invergo 的博客的英文文章 Using GNU Stow to manage your dotfiles 。 Brandon Invergo 的博客采用 CC-BY-SA 3.0 授权，因此本文也同样采用 CC-BY-SA 3.0 ，不同于其它我写的文章是 CC-BY-NC-SA 4.0 授权。 我自己已经使用此文中介绍的方案管理 我自己的 dotfiles 快 3 年了。最早想采用这样的管理方案是为了方便在多台 Arch Linux 系统之间同步配置， 后来逐渐主力系统也更新换代了一次，又同步到了自己的 vps 上去，目前管理多个 Arch Linux 上都多少都有这套配置。甚至装好 Arch Linux 添加好用户最初做的事情就是安装 stow git 然后 clone 了我自己的 dotfiles repo 下来，然后按需取想要的配置，快捷方便有效。 废话不多说，下面是原文和翻译。与之前的翻译一样，正文部分给出原文引用以便对照参考。 使用 GNU stow 管理你的点文件 我昨天偶然间发现一些我觉得值得分享的经验，就是那种「为毛我没有早点知道这个？」那一类的。 我将在这篇文章中介绍如何使用 GNU Stow 管理你的 GNU/Linux 系统中位于用户家目录里的各种配置文件 （通常又叫「点文件(dotfiles)」比如 .bashrc）。 I accidentally stumbled upon something yesterday that I felt like sharing, which fell squarely into the \"why the hell didn't I know about this before?\" category. In this post, I'll describe how to manage the various configuration files in your GNU/Linux home directory (aka \"dotfiles\" like .bashrc) using GNU Stow. 这件事的困难之处在于，如果能用版本管理系统(VCS, Version Control System)比如 Git, Mercurial(hg), Bazaar(bzr) 管理点文件的话会非常方便，但是这些点文件大部分都位于家目录的顶级目录下， 在这个位置不太适合初始化一个版本管理仓库。这些年下来我试过很多程序，设计目的在于解决这个问题， 帮你把这些配置文件安置在某个下级目录中，然后安装或者链接这些文件到它们应该在的位置。 尝试下来这些程序没有一个真正能打动我。它们要么有很多依赖（比如 Ruby 和一大坨库）， 要么需要我记住如何用它，考虑到同步配置这种不算经常使用的场合，要记住用法真的挺难。 The difficulty is that it would be helpful to manage one's configuration files with a version control system like Git, Mercurial or Bazaar, but many/most dotfiles reside at the top-level of your home directory, where it wouldn't be a good idea to initialize a VCS repository. Over time I've come across various programs which aim to manage this for you by keeping all the files in a subdirectory and then installing or linking them into their appropriate places. None of those programs ever really appealed to me. They would require a ton of dependencies (like Ruby and a ton of libraries for it) or they would require me to remember how to use them, which is difficult when really for such a task you rarely use the program. 最近我在用 GNU Stow 来管理我从源代码在本地编译安装到 /​usr/​local/​ 中的一些程序。 基本上说，在这种常见用法下，是你把这些本地编译的包配置安装到 /​usr/​local/​stow/​${PKGNAME}-{PKGVERSION} 这样的位置，然后在 /​usr/​local/​stow/​ 目录中执行 # stow ${PKGNAME}-${PKGVERSION} ，然后它就会为程序所有的文件创建符号链接放在 /​usr/​local 中合适的地方。然后当你想用 Stow 卸载这个程序的时候，就不必再考虑会留下什么垃圾文件， 或者找不到安装时用的 Makefile 了。这种安装方式下也可以非常容易地切换一个程序的不同版本 （比如我想尝试不同配置选项下的 dwm 或者 st 的时候）。 Lately I've been using GNU Stow to manage programs I install from source to /usr/local/. Basically, in this typical usage, you install locally built packages to /usr/local/stow/${PKGNAME}-{PKGVERSION} and then from /usr/local/stow/ you run # stow ${PKGNAME}-${PKGVERSION} and the program generates symbolic links to all the programs' files into the appropriate places under /usr/local/. Then, when you uninstall a program via Stow, you don't have to worry about any stray files that you or a provide Makefile may have missed. It also makes handling alternate versions of a program quite easy (i.e. when I'm experimenting with different configurations of dwm or st). 前段时间在我扫邮件列表的时候，看到某个帖子中某人在说使用 Stow 管理安装他的点文件。 当时我没特别在意这个帖子，但是大概我大脑潜意识把它归档保存为今后阅读了。 昨天我想起来试试这种用法，试过后我不得不说，这比那些专门设计用来做这任务的点文件管理器要方便太多了， 虽然表面上看起来这种用法没那么显而易见。 Some time ago I happened across a mailing list posting where someone described using Stow to manage the installation of their dotfiles. I didn't pay much attention to it but my brain must have filed it away for later. Yesterday I decided to give it a try and I have to say that it is so much more convenient than those other dedicated dotfile-management programs, even if it wasn't an immediately obvious option. 方法很简单。我建了个 ${HOME}/​dotfiles 文件夹，然后在里面为我想管理的每个程序配置都 创建一个子文件夹。然后我把这些程序的配置从原本的家目录移动到这每一个对应的子文件夹中， 并保持它们在家目录中的文件夹结构。比如，如果某个文件原本应该位于家目录的顶层文件夹里， 那它现在应该放在这个程序名子目录的顶层文件夹。如果某个配置文件通常应该位于默认的 ${XDG_CONFIG_HOME}/​${PKGNAME} 位置 ( ${HOME}/​.config/​${PKGNAME} )， 那么现在它应该放在 ${HOME}/​dotfiles/​${PKGNAME}/​.config/​${PKGNAME} ，如此类推。然后在那个 dotfiles 文件夹里面，直接运行 $ stow $PKGNAME 命令， Stow 就会为你自动创建这些配置文件的符号链接到合适的位置。接下来就很容易为这个 dotfiles 目录初始化版本管理仓库，从而记录你对这些配置文件做的修改（并且这也可以极度简化在不同电脑之间 共享配置，这也是我想要这么做的主要原因）。 The procedure is simple. I created the ${HOME}/dotfiles directory and then inside it I made subdirectories for all the programs whose cofigurations I wanted to manage. Inside each of those directories, I moved in all the appropriate files, maintaining the directory structure of my home directory. So, if a file normally resides at the top level of your home directory, it would go into the top level of the program's subdirectory. If a file normally goes in the default ${XDG_CONFIG_HOME}/${PKGNAME} location (${HOME}/.config/${PKGNAME}), then it would instead go in ${HOME}/dotfiles/${PKGNAME}/.config/${PKGNAME} and so on. Finally, from the dotfiles directory, you just run $ stow $PKGNAME and Stow will symlink all the package's configuration files to the appropriate locations. It's then easy to make the dotfiles a VCS repository so you can keep track of changes you make (plus it makes it so much easier to share configurations between different computers, which was my main reason to do it). 举个例子，比如说你想管理 Bash, VIM, Uzbl 这三个程序的配置文件。Bash 会在家目录的顶层文件夹 放几个文件； VIM 通常会有在顶层文件夹的 .vimrc 文件和 .vim 目录；然后 Uzbl 的配置位于 ${XDG_CONFIG_HOME}/​uzbl 以及 ${XDG_DATA_HOME}/​uzbl 。于是在迁移配置前，你的家目录的文件夹结构应该看起来像这样： For example, let's say you want to manage the configuration for Bash, VIM and Uzbl. Bash has a couple files in the top-level directory; VIM typically has your .vimrc file on the top-level and a .vim directory; and Uzbl has files in ${XDG_CONFIG_HOME}/uzbl and ${XDG_DATA_HOME}/uzbl. So, your home directory looks like this: home/ brandon/ .config/ uzbl/ [...some files] .local/ share/ uzbl/ [...some files] .vim/ [...some files] .bashrc .bash_profile .bash_logout .vimrc 然后迁移配置的方式是，应该建一个 dotfiles 子目录，然后像这样移动所有配置文件： You would then create a dotfiles subdirectory and move all the files there: home/ /brandon/ .config/ .local/ .share/ dotfiles/ bash/ .bashrc .bash_profile .bash_logout uzbl/ .config/ uzbl/ [...some files] .local/ share/ uzbl/ [...some files] vim/ .vim/ [...some files] .vimrc 然后执行以下命令： Then, perform the following commands: $ cd ~/dotfiles $ stow bash $ stow uzbl $ stow vim 然后，瞬间，所有你的配置文件（的符号链接）就安安稳稳地放入了它们该在的地方，无论原本这些目录结构 有多么错综复杂，这样安排之后的 dotfiles 文件夹内的目录结构立刻整理得有条有理， 并且可以很容易地转换成版本控制仓库。非常有用的一点是，如果你有多台电脑，可能这些电脑并没有 安装完全一样的软件集，那么你可以手选一些你需要的软件配置来安装。在你的 dotfiles 文件夹中总是 可以找到所有的配置文件，但是如果你不需要某个程序的某份配置，那你就不对它执行 stow 命令，它就不会扰乱你的家目录。 And, voila, all your config files (well, symbolic links to them) are all in the correct place, however disorganized that might be, while the actual files are all neatly organized in your dotfiles directory, which is easily turned into a VCS repo. One handy thing is that if you use multiple computers, which may not have the same software installed on them, you can pick and choose which configurations to install when you need them. All of your dotfiles are always available in your dotfiles directory, but if you don't need the configuration for one program, you simply don't Stow it and thus it does not clutter your home directory. 嗯，以上就是整个用法介绍。希望能有别人觉得这个用法有用！我知道对我来说这个非常有帮助。 Well, that's all there is to it. Hopefully someone else out there finds this useful! I know I've found it to be a huge help.","tags":"tech","url":"//farseerfc.me/zhs/using-gnu-stow-to-manage-your-dotfiles.html"},{"title":"为什么 Linus Torvalds 不愿意将 Linux 变成 GPLv3 授权？","text":"从 知乎 转载 和上篇文章一样，这篇也是来自一个知乎上我回答的问题。 原问题：为什么 Linus Torvalds 不愿意将 Linux 变成 GPLv3 授权？ DebConf 14: Q&A with Linus Torvalds Youtube Youku 我的回答： 这里有段 Linus Torvalds 在 DebConf 14 上的 Q&A: https://youtu.be/1Mg5_gxNXTo?t=47m20s 其中关于 GPLv3 和协议的那一段在47:20开始到57:00左右。 里面 Linus 对自己的观点澄清得很清楚了。 看u2b或者听英语有困难的请留评论，我抽空可以试着翻译一下。 然后接下来就是我承诺的翻译了 问：你是否同意说你贬低了 GPLv3 ? 以及…… Q: Do you agree that you undermine GPLv3? and ... L: 是的 L: Yes 问：我们如何才能让你别这么做？ Q: How can we get you to stop? L: 什么？ L: What? 问：我们如何才能让你别这么做？ Q: How can we get you to stop? L: 哦我讨厌 GPLv3 ，我是在故意贬低它。实际上我觉得 GPLv3 的扩展非常可怕。 我能理解为什么人们想要做这个，但是我觉得它本应是一个全新的协议。 L: Oh I hate GPLv3. I undermined it on purpose. I actually thought the GPLv3 extensions were horrible. I understand why people would want to do them but I think it should have been a completely new license. 嗯我喜欢版本 2 的那些理由，并且我仍然觉得版本 2 是一个非常棒的协议， 理由是：「我给你源代码，你给我你对它的修改，我们就扯平了」 对吧？这是我用 GPL 版本 2 的理由，就是这么简单。 Emm my argument for liking version 2, and I still think version 2 is a great license, was that, \"I give you source code, you give me your changes back, we are even.\" Right? That's my take on GPL version 2, right, it's that simple. 然后版本 3 的扩展在某些方面让我个人觉得非常不舒服，也就是说「我给你源代码， 这意味着你必须服从我的一些规则，否则你不能把它用在你的设备上。」 对我来说，这是违反了版本 2 协议所追求的所有目的。然而我理解为什么 FSF 要这么做， 因为我知道 FSF 想要达成什么，但是对我来说这完全是不同的协议了。 And version 3 extended that in ways that I personally am really uncomfortable with, namely \"I give you source code, that means that if you use that source code, you can't use it on your device unless you follow my rules.\" And to me that's, that's a violation of everything version 2 stood for. And I understand why the FSF did it because I know what the FSF wants. But to me it's not the same license at all. 所以我当时非常不安，并且表明了自己的观点，并且这是在版本 3 发布的数月之前。 在那很久之前曾经有过一场讨论……在版本 3 之前有一个早期的版本， 事实上几年之前，那时我就说过：「不，这不可能工作」。 并且在那个早期的讨论阶段我已经在内核里写好了「嘿，我可没有写过版本 2 或者更高版本」。所以之后也没有过（争议）……随后版本 3 出来的时候我非常开心， 因为我早在大概 5 年前做了预防，之后也就再也没有过关于内核的协议究竟是哪个 版本的讨论。 So I was very upset and made it very clear, and this was months before version 3 was actually published. There was a discussion about this long before... There was an earlier version of version 3, years before actually, where I said \"No, this is not gonna fly.\" And during that earlier discussion I had already added to the kernel that, \"Hey, I don't have the version 2 or later\". And there was no... And I was really happy then when version 3 came out, that I have done that something like 5 years before, because there was ever never any question about what the license for the kernel was. 不过事实上我觉得版本 3 是……呃不……我事实上觉得版本 3 是个 不错 的协议， 对吧。我坚定地相信「如果是你写的代码，那么你有权利决定它应该用什么协议」。 并且版本 3 是个不错的选择。版本 3 不好的地方在……「我们给你了版本 2 ，然后我们试图偷偷混入这些新的规则，并且想逼着所有人都跟着升级」这是我不喜欢版本 3 的地方。并且 FSF 在其中做了很多见不得人的事情，我觉得做得很不道德。 But I actually thought that version 3 is ... Uh, no ... I actually think version 3 is a FINE license, right. I'm a firm believer in, \"If you write your code, it is your choice to pick a license.\" And version 3 is a fine license. Version 3 was not a good ... \"Here we give you version 2, and then we tried to sneak in these new rules, and tried to force everybody to upgrade.\" That was the part I disliked. And the FSF did some really sneaky stuff, downright immoral in my opinion. 问：所以你在说 Tivoization 的事情么？ Q: So you are talking about Tivoization ? 译注： 关于 Tivoization Tivoization 是 FSF 发明的一个词，表示 TiVo 的做法。 TiVo 是一个生产类似电视机顶盒之类的设备的厂商，他们在他们的设备中用到了 Linux 内核和很多别的开源组件，并且他们根据 GPLv2 协议开放了他们使用的组件的源代码。 然而他们在他们出售的设备中增加了数字签名，验证正在执行的系统和软件是他们自己 编制的软件，从而限制了用户修改运行软件的自由。这种做法在 FSF 看来是钻了 GPLv2 的法律上的空子，所以 FSF 提出了 GPLv3 封堵这种做法。 L: 没错，Tivoization 的事情一直是我反对版本 3 的主要根据。并且，FSF 在这件事上表现得极不诚实。「嘿，其实我们允许你无效化 Tivoization 条款」，这样他们试图， 应该说他们是在明白着欺骗别人，并且说「嘿，这意味着你可以使用除去 Tivoization 部分的 GPLv3」。 这很……在场的诸位中有谁从 FSF 那儿听过这个说法？（请举手） L: Ehmm, yeah the Tivoization is always my main, eh dislike of version 3. And, the FSF was being very dishonest thing. \"Hey, we actually allow you to invalidate the Tivoization clause\" and they tried to, they literally lied to people, and say \"Hey, so that means that you can use GPLv3 without the Tivoization part\", right. This is ... How many people heard this particular statement from the FSF? (Please raise your hands) 好吧，或许他们只试过对我用这套说辞，但是他们真的试过。我的反应是「我可不傻」，对吧。是的， 的确你可以…… GPLv3 允许你说「好， Tivoization 的事情对我们来说不是问题」， 但是它同时又允许别人接过这个项目，并且说「嘿，我觉得……去掉了 Tivoization 的 GPLv3 是兼容完整的 GPLv3 的，所以我可以 fork 这个项目，然后我将在自己的 fork 上用完整的 GPLv3 写驱动。」然后我就囧了。我的困境在于说「嘿，我给了你我的源代码，现在我却不能拿回你对它 的修改了」。这是彻底违背了我用这个协议最初的目的了。 Ok, maybe they only tried to convince me with that one. But they did try. And it was like, \"I'm not stupid\", right. Yes, you can ... The GPLv3 allows you to say \"Ok, Tivoization is not an issue for us\". But it allows somebody else to take the project, and say \"Hey, I ... The GPLv3 without Tivoization is compatible with the full GPLv3, so I will now make my own fork of this, and I will start doing drivers that use the full version of version 3\" And where am I stuck then? I am stuck saying \"Hey I give you the source code, and now I can't take it back your changes\". That's completely against the whole point of the license in the first place. 所以 FSF 是，我是说那时他们暗地里做的那些事情，让我当下决定永远不再和 FSF 有任何瓜葛。 所以如果你想捐钱给一个行善的组织，那就捐给 EFF 吧。FSF 充满了疯狂难处的人。这只是我的观点。 呃其实我……嗯……我说得有点过分了。FSF 里有很多不错的人，不过其中有些人有点过激。 So the FSF was, I mean the kind of stuff that was going on behind the scenes, ah, made me once and for all to decide to never had any thing to do with the FSF again. So if you wanted to give money to an organization that does good? Give it to the EFF. The FSF is full of crazy bittered people. That's just mine opinion. Uh, actually I have ... Ah ... I overstated that a bit, right. The FSF has a lot of nice people in it, but some of them are bit too extreme. 问: 嗯我也希望 EFF 能更多的关注于软件的自由方面。但是你能……你觉得 Tivoization 这种行为也能在某种方式上让我作为用户获益么？ Q: Well I wish the EFF care more about software freedom. But, uh, can you ... Do you think that Tivoization benefits me as a user somehow? L: 不，我不觉得。我的意思是……这从来都不是我的论据，这不是我选择了 GPLv2 的理由。 并不是说我觉得 Tivoization 是某种值得你去争取的权利，而是说在我的世界观中，这是你的决定。 如果你生产硬件去锁住了其中的软件，这是你作为一个硬件提供者的决定。 这完全不影响我作为一个软件提供者给你软件的决定。你能看出我的立场在哪儿了么？ 我不喜欢上锁的硬件，但是同时这也从来不是我想要给 Linux 加上的的社会契约。 L: No, no I don't. I mean that ... But that was never my argument. That was not why I selected the GPLv2. This is my whole point. It's not that I think Tivoization is necessarily something that you should strive for. But it is something that in my world view, it's your decision. If you make hardware that locks down the software, that's your decision as a hardware maker. That has no impact on my decision as a software maker to give you the software. Do you see where I am coming from? I don't like the locked down hardware, but at the same time that was never the social contract I intended with Linux. 对我来说，呃我想说，大家可能知道或者不知道， GPLv2 并不是 Linux 的最初的协议。 对我来说重要的部分一直是「我给你软件，你可以用它做任何你想要做的事情。如果你做了任何改进， 你需要把它交还给我。」这是协议最初的样子。最早的协议还有一条完全错误的条款，写得完全不合理， 那时我很傻。嘿我也傻过。我最初的协议说你不能用它赚钱。这是失策，这明显是不对的不好的， 因为它和我真正想要做的事情没有任何关系。但是那时我很傻很天真， 我没意识到钱的事情在其中完全不重要。然后我发现了其中的问题，我看到了 GPLv2 然后说「嘿， 这是个完美的协议」。然后我看到了 GPLv3 我说「不，这做得过分了，这不是我想要的」 所以我让 Linux 成为了仅限 GPLv2 ，对吧。 To me, umm, I mean, people may or may not realize GPLv2 wasn't even the first license for Linux. To me the important part was always \"I give you software, you can do whatever you want with it. If you making improvements, you have to give them back.\" That was the first version of the license. It also had a completely broken clause which was completely insane and I was stupid. Hey it happened. My origin license says that you can't make money change hands. And that was a mistake. That was clearly just wrong and bad because it really didn't have anything to do with what I wanted. But I was young, I was poor, I didn't realize that the whole money thing wasn't the important part. And I have saw the errors in my ways, I saw the GPLv2 and said \"Hey, that's the perfect license\". And I saw the GPLv3 and I said \"No, that's overreaching a lot, that's not what I wanted\". And so I made Linux GPLv2 only, right. 问: 所以你是否认为，即使你不能修改跑着这个软件的设备，拿回对软件的修改也还是同样重要的？ Q: So do you think getting the patches back is as useful even if you can't modify the device that it is used on? L: 是的，当然。我想说 TiVo 它自己实际上就是一个例子。他们的修改有点复杂，但是我想说他们基本 是，一开始基本是运行在一套相当标准的 MIPS 设备上。然后他们的修改是想绕开他们用到的芯片上的 一些问题，并且这些是合格的修改。之后的事情是他们觉得他们需要锁住他们的硬件，我不喜欢这个。 但是就像我已经说的，我觉得这是他们的决定。 L: Yeah, absolutely. And I mean TiVo itself is actually an example of this. Their patches were kind of crafty but I mean they were basically running on a, originally a fairly standard MIPS thing. And their patches were working around bugs in the chipsets they used. And they were valid patches. The fact that they then felt that their hardware had to be locked down someway. I didn't like it. But as I have mentioned, I felt that that was their decision. 并且他们有真正的理由去这么做。这是有时人们忽视的地方。有时是真的有理由去做 TiVo 他们做的事情。有时强加给你这种限制的是，无线运营商。有时强加给你的是迪士尼。 有时强加给你限制的甚至是法律。 GPLv3 在医疗设备之类的场合其实允许最后一种情况，我记得。 我的观点是，整个 Tivoization 的事情有时是有理由去这么做的。如果你生产…… 我是说我不是硬件设计者，我觉得 FPGA 之类的东西很酷，但是我……我的意思是我真的不想把我对世界的 看法强加给别人。你不是非得要用 Linux ，如果你想要用 Linux ，那么我唯一要求你做的事情是把源代码（变更）还给我。然后在 GPLv2 中还有很多繁文缛节规定了详细的细节，这些都不重要。这是我一直以来的观点。 And they had real reasons for that. That's something people sometimes missed. There are sometimes reasons to do what TiVo did. Sometimes it's imposed on you by, wireless carriers. Sometimes it's imposed on you by Disney. Uh sometimes it's imposed on you by laws. The GPLv3 actually accepts the last one when it comes to things like medical equipment I think. But the point is that the whole Tivoization thing is, sometimes it's, there is a reason for it. And if you make ... I mean I am not a hardware designer. I think FPGA and stuff like that is really cool. But I always ... I mean I really don't want to impose my world view on anybody else. You don't have to use Linux. If you do use Linux, the only thing I asked for is source code back. And there is all these other verbiages in the GPLv2 about exact details, those aren't important. And that was always my standpoint. 问: 好吧那我就不浪费时间了。 Q: Ok, well I will stop my non-point of making noise now. 译注： 关于 ISC 协议 ISC 协议是一个开源软件协议，和两句的 BSD 协议功能相同。OpenBSD 项目选择尽量用 ISC 协议公开他们新写的代码。 L: 我的意思是别误解……我也喜欢别的协议。我用过……到底是哪个 BSD 协议是可以接受的？ 有一个 BSD 协议实际上非常不错。它实际上是……什么？ L: I mean don't get me ... I mean I like other licenses too. I have used like the four, emmm... Which BSD license is the acceptable one? One of the BSD license is actually really nice. And it's actually the... What? 观众： ISC A: ISC L: ISC？并且事实上我在鼓励那些不在意拿回修改但是在意「嘿，我做了一个很酷的东西，请用它」。 我鼓励这些人去用 BSD 协议做这些事情。我想说 BSD 协议在这种场合是完美的。 只是碰巧我觉得对于我的项目，拿回修改也同样重要，所以对我而言 BSD 不好。但是重点是 对我而言 。 GPLv3 可能对你们想要做的事情而言是完美的协议，这很好，并且这时你就应该去用 GPLv3 。只是当代码是别人写的时候，你没有这个选择权。 L: ISC? And I actually encourage people who don't care about the giving code back but care about the \"Hey, I did something cool, please use it\". I encourage people to use the BSD license for that. And I mean the BSD license is wonderful for that. It so happens that I thought that for my project the giving back is equally important so I, for me BSD is bad. But the point is for me . The GPLv3 maybe the perfect license for what you guys want to do. And that's fine. And then it's the license you should use. It's just that when somebody else wrote the code you don't get that choice.","tags":"import","url":"//farseerfc.me/zhs/why-linus-torvalds-undermine-gplv3.html"},{"title":"C语言中\".\"与\"->\"有什么区别？","text":"从 知乎 转载 转载几篇知乎上我自己的回答，因为不喜欢知乎的排版，所以在博客里重新排版一遍。 原问题：C语言中\".\"与\"->\"有什么区别？ 除了表达形式有些不同，功能可以说完全一样阿。那为何又要构造两个功能一样的运算符？ 效率有差异？可是现在编译器优化都那么强了，如果真是这样岂不是有些多此一举 刚刚翻了下书，说早期的C实现无法用结构直接当作参数在函数间传递，只能用指向结构的指针在函数间进行传递！我想这应该也是最直观的原因吧。 我的回答 首先 a->b 的含义是 (*a).b ，所以他们是不同的，不过的确 -> 可以用 * 和 . 实现，不需要单独一个运算符。 嗯，我这是说现代的标准化的 C 语义上来说， -> 可以用 * 和 . 的组合实现。 早期的 C 有一段时间的语义和现代的 C 的语义不太一样。 稍微有点汇编的基础的同学可能知道，在机器码和汇编的角度来看，不存在变量，不存在 struct 这种东西，只存在寄存器和一个叫做内存的大数组。 所以变量，是 C 对内存地址的一个抽象，它代表了一个位置。举个例子，C 里面我们写： a = b 其实在汇编的角度来看更像是 * A = * B 其中 A 和 B 各是两个内存地址，是指针。 好，以上是基本背景。 基于这个背景我们讨论一下 struct 是什么，以及 struct 的成员是什么。 假设我们有 struct Point { int x ; int y ; }; struct Point p ; struct Point * pp = & p ; 从现代语义上讲 p 就是一个结构体对象， x 和 y 各是其成员，嗯。 从汇编的语义上讲， p 是一个不完整的地址，或者说，半个地址，再或者说，一个指向的东西是虚构出来的地址。而 x 和 y 各是在 Point 结构中的地址偏移量。也就是说，必须有 p 和 x 或者 p 和 y 同时出现，才形成一个完整的地址，单独的一个 p 没有意义。 早期的 C 就是在这样的模型上建立的。所以对早期的 C 而言， *pp 没有意义，你取得了一个 struct ，而这个 struct 不能塞在任何一个寄存器里，编译器和 CPU 都无法表达这个东西。 这时候只有 p.x 和 p.y 有意义，它们有真实的地址。 早期的 C 就是这样一个看起来怪异的语义，而它更贴近机器的表达。 所以对早期的 C 而言，以下的代码是对的： p . x = 1 ; int * a ; a = & ( p . x ); 而以下代码是错的： ( * pp ). x = 1 ; 因为作为这个赋值的目标地址表达式的一部分， *pp ，这个中间结果没法直译到机器码。 所以对早期的 C 而言，对 pp 解引用的操作，必须和取成员的偏移的操作，这两者紧密结合起来变成一个单独的操作，其结果才有意义。 所以早期的 C 就发明了 -> ，表示这两个操作紧密结合的操作。于是才能写： pp -> x = 1 ; 嗯，这就是它存在的历史原因。 而这个历史原因现在已经不重要了，现代的符合标准的 C 编译器都知道 (*pp).x 和 pp->x 是等价的了。 说句题外话， C++ 里面还发明了 .* 和 ->* 这两个运算符（注意 ->* 不是单独的 -> 和 * 并排放的意思），关于为什么要发明这两个运算符，而不能直接说 a ->* b 的意思就是 a ->(*b) ，这个就作为课堂作业吧。","tags":"import","url":"//farseerfc.me/zhs/dot-and-arrow-in-c.html"},{"title":"启用 GitHub Issue 作为博客留言系统","text":"从今天起本博客将启用 GitHub Issue 作为留言系统。 原本使用的 Disqus 将继续保留一段时间，目前没有关闭的计划。 换用 GitHub Issue 是计划了好久的事情了，最初重做这个主题的时候就有考虑过。 这个想法的契机是看到了这篇 GitHub hosted comments for GitHub hosted blogs ，然后立马觉得这个想法很符合寄宿在 GitHub Pages 上的博客。 一个限制是要求评论者必须有 GitHub 账户，考虑到我的博客的受众这个要求估计不算太过分。 使用 GitHub Issue 的好处么，比如自带的 GFMD 富文本格式，邮件通知，还有订阅和取消订阅通知，邮件回复， 这些方面都不比第三方留言系统逊色。 换用 GitHub Issue 另一方面原因是最近听说 Disqus 被部分墙了，想必以后墙也会越来越高。之前曾经试过在这个博客换上多说， 然而效果我并不喜欢，多说喜欢侵入页面加很多奇怪的东西，比如用户的头像通常是 http 的……也试过结合新浪微博的评论，而新浪微博越来越封闭，API 也越来越不靠谱。 使用 GitHub Issue 作为评论的方式比较简单，上面那篇博客里面提到了，代码量不比 加载 Disqus 多多少，而且没有了 iframe 的困扰，唯一麻烦的地方就是要稍微设计一下布局方式让它融入 现有的页面布局。 我参考上面的实现在这里 。 这个加载代码使用两个变量加载 Issue Comments ，一个是在 pelicanconf.py 里的 GITHUB_REPO ，可以指向任何 Repo ，我指向 farseerfc/farseerfc.github.io 的这个 GitHub Page repo ，另一个变量是每篇文章里需要加上 issueid 的元数据，关连文章到每个 Issue 上。 还有一个稍微麻烦的事情是现在每写一篇文章之后都要新建一个 issue 了。 手动操作有点累人，于是我 写了个脚本 自动搜索 pelican 的 content 文件夹里面文章的 slug 并且对没有 issueid 关连的 文章创建 issue 。 好啦新的留言系统的外观样式还在测试中，希望大家多留言帮我测试一下！ 2016年8月7日19:30更新 新增了对 GitHub Issue comments 里面 reactions 的支持，套用 font-awesome 的图标（似乎没 GitHub 上的图标好看）。这个还属于 GitHub API 的实验性功能，要加入 Accept: application/​vnd.github.squirrel-girl-preview HTTP 头才能拿到。 2016年8月7日23:16更新 感谢 @iovxw 的测试让我发现 github 的高亮回复和邮件回复是需要特殊处理的。 高亮回复用上了 这里的 CSS 邮件引言的展开事件直接用 jQuery 做了： $ ( \".email-hidden-toggle > a\" ). on ( \"click\" , function ( e ){ e . preventDefault (); $ ( \".email-hidden-reply\" , this . parent ). toggle (); }); 还得注意邮件的回复需要 CSS 里面 white-space: pre-wrap 。","tags":"tech","url":"//farseerfc.me/zhs/github-issues-as-comments.html"},{"title":"PacVis: visualize pacman local database","text":"PacVis Motivation for PacVis I must admit that I love Arch Linux, largely because Arch Linux made me feel like I really own the whole system. In my Arch Linux system, I know clearly every package I have installed and why I installed it. I can find which package brings in a give file. A Debian/Fedora/openSUSE user with enough experience may achieve this with their favorite package manager too, but they must overcome a much higher complexity with their distro's fine-grinding packaging strategy. Usually they have 3 to 10 times more packages than Arch Linux on a similar setup. And with regard to packaging system, they must work with much more details than Arch's simple PKGBUILD based packaging. Every user who successfully installed Arch Linux should have learned that, after the initial installation, you will only get a minimum setup. The most important step in the installation guide on ArchWiki is a command pactrap /​mnt base , which will use /​mnt as the filesystem root and call pacman -S base inside that root to install the whole base group. And that's basically all you will get after the install. The initial system has nearly nothing. Everything you need will be installed afterwards, manually by using pacman . It is nothing unnecessary, only for your own need. But after using the system for a long time, there are unavoidably some packages inside the system which are installed and used for awhile and abandoned. They are like the old furnitures inside your house, taking space and covered by dusts. We have pacman -Qtd to help you find all orphan packages, namely those installed as dependency for other packages once but not needed for now , but for manually installed packages, we have no good tool but manually checking them one by one. So I was looking for a tool to help me understand the relations in my system. In particular, I want a tool to help me do these things: Find packages that I installed manually but not needed now Find those large and space-consuming packages Understand the relationships between packages Android System Architecture About the last thing \"relations between packages\", I once saw the diagram of macOS Architecture and Android System Architecture, and I was impressed by the layered hierarchy in these diagrams. I was wondering since then, is it possible to draw a similar layered architecture diagram for modern Linux desktop ? Or will a Linux desktop be much different ? I can find out hierarchy diagrams for Linux kernel or Xorg graphic stack on Wikipedia or other sites, but I don't know such diagrams for the whole distribution. And further I thought, can I draw such diagram from the dependency relationships between packages automatically ? Predecessors of PacVis Before working on PacVis, I have tried several similar tools. Some of them meet some of my needs, but they all lack certain features that I considered important. These tools became the prototype of PacVis, as they enlightened me of how PacVis should be. pactree pactree started as an individual project , but now it is part of pacman . From its manpage we can see that the output of pactree is a dependency tree starting from a given package. By appending --graph parameter, pactree can also output a diagram in dot format, then we can render this diagram using dot command: pactree pacvis-git -d3 --graph | dot -Tpng >pacvis-pactree.png $ pactree pacvis-git -d3 pacvis-git ├─python-tornado │ └─python │ ├─expat │ ├─bzip2 │ ├─gdbm │ ├─openssl │ ├─libffi │ └─zlib ├─pyalpm │ ├─python │ └─pacman │ ├─bash │ ├─glibc │ ├─libarchive │ ├─curl │ ├─gpgme │ ├─pacman-mirrorlist │ └─archlinux-keyring └─python-setuptools └─python-packaging ├─python-pyparsing └─python-six $ pactree pacvis-git -d3 --graph | dot -Tpng >pacvis-pactree.png From the rendered diagram we can see that, because some packages may share common dependencies, the whole diagram is no longer a tree in graph theory . During the initial prototyping of PacVis, I tried to parse the output of pactree and pacman using bash/python scripts, to draw a single diagram for the whole system. However the rendered picture is so large that it takes hours for dot to layout them, and the result is barely viewable in an image viewer or a browser. I need to say that there will be no PacVis if there is no pactree. Even the pyalpm library that I used in PacVis is a python binding for alpm, which is born during the rewrite of pactree in C language. pacgraph The output of pacgraph pacgraph is developped by a Arch Linux Trusted User keenerd . It is written in Python, as is PacVis. Comparing with pactree, pacgraph is definitely more suitable for my needs. It will draw a diagram for all the packages in the system, using a clever layout algorithm that surpass the performance of dot's layout. The output of pacgraph is an artistic diagram with different font size of package names showing their disk usage. By viewing pacgraph's output, we can determine the overall system structure, e.g. whether the system is a desktop system or a server. We can easily find large packages and consider remove them. There's more. pacgraph provided an interactive GUI called pacgraph-tk, written clearly in tk. You can zoom in to see details or zoom out to see the whole graph in GUI, and you can highlight one package to see its relations to others. And pacgraph support to render the dependencies of a selected group of packages, not all, like pactree does. But pacgraph does not meet all my needs. I want a diagram to show the architecture of the system, but pacgraph don't differ \"the packages that this package depend on\" and \"the packages that depends on this package\". In other words, pacgraph draws a undirected graph , but I want a directed graph , that reflects the layered hierarchy of dependency relationship . So here is PacVis PacVis on startup With these predecessors, I started working on PacVis. The development takes me 2 month, and largely break into 2 stages. In the first stage I wrote basic logics and a prototype of the UI. In the second stage I applied the templates from https://getmdl.io/ . Now finally it is usable for others. So several days ago I made a PKGBUILD for pacvis on AUR: pacvis-git . Now it's fairly easy to run pacvis locally on a Arch Linux system. You can use any aurhelper you familiar with, or build it directly from AUR: ~$ git clone aur@aur.archlinux.org:pacvis-git.git ~$ cd pacvis-git ~/pacvis-git$ makepkg -si ~/pacvis-git$ pacvis Start PacVis at http://localhost:8888/ Following the instruction, open http://localhost:8888/ in a browser then you can see PacVis's result of your own system. As a demonstration you can also visit PacVis on my Arch Linux server : https://pacvis.farseerfc.me/ . It is showing a minimal server setup, that might load and layout faster than a normal desktop system. PacVis on Windows msys2 As a side note, pacvis only depends on pyalpm and tornado, so there should be no problem running it on other pacman-based systems, including msys2 on Windows (altough building a msys2 python-tornado may take some non-trival effort). The legend and usage of PacVis PacVis resembles the UI of a map app such as Google Maps. You can use wheel of mouse to zoom and drag to move, or pinch gestures on a touch screen. There is a side panel on the right top corner and you can hide it when you don't need it. There are some zoom buttons on the right bottom corner. The dependencies of pacvis-git package The whole diagram is made up of small circles and arrows in between circles. A circle represent a package, while an arrow represents a dependency relationship. If you zoom into details, you can see text under the circles showing their package names. Hover on packages will also give you infos about the package. You can select a package, and in the side panel there will be more detailed infomation about that package. The above picture is showing the dependencies of pacvis-git package itself. It dependes on pyalpm, python-tornado and python-setuptools, while pyalpm is in-turn depend on pacman. A package in purple means it is installed manually, while a package in orange means it is installed as a dependency for other packages. The color of arrows usually follow their origin package's color. Note that most arrows in the diagram are pointing bottom-up, this is because PacVis will do a topology sort based on the dependencies of packages. From the topology sort, PacVis assigned a topology level to each package, e.g. pacvis-git has a topo-level of 39, its dependency pyalpm has a topo-level of 38, and pacman is sat on the topo-level 37. Layering packages with their topo-level is the main difference of PacVis with pacgraph. Besides manually zoom-in to look around, you can also use PacVis's search box to locate a particular package by its name. And when you select a package, the related package names will be shown in the Dep and Req-By tabs in the sidebar. These package names are made as buttons so you can click them to browse the whole dependency graph. Let me describe some arguments related to the implementation: Max Level This will limit the max topo-level that PacVis renders. When there are too many packages, the layout algorithm will take a lot of time. Limiting this is very useful during debug of PacVis. Max Required-By This will limit the max required-by-relationship that PacVis renders. If you play around in PacVis, you will soon find that most packages in the system directly depends on glibc or gcc-libs. Rendering these well-known dependency may result in a lot of long arrows, that reduce the readability of the whole diagram. You can limit this to a lower number so that PacVis will not render these well-known dependencies. Some facts you can learn from PacVis A normal KDE desktop Full image（17M） You may find many facts by playing around in PacVis. An example will be the aforementioned \"most packages depends on glibc\". Besides that, I will give some more examples below. Dependency hierachy The packages in the system is clearly divided into several layers: glibc, etc. C runtime Bash/Perl/Python etc. script languages coreutils/gcc/binutils etc. core binary utilities pacman/systemd etc. large system utilities gtk{2,3}/qt{4,5} etc. GUI toolkit chromium etc. GUI Applications Plasma/Gnome etc. Desktop environments This largely meet my overall understanding, but some details are interesting to me. For example, zsh dependes on gdbm which in-turn depends on bash, which means that you can not get rid of bash even if you only use zsh. For another example, python package (which is python3 in Arch Linux) and python2 and pypy sit roughly on the same topo-level in the diagram. zsh indirectly depends on bash because of gdbm However there are some facts beyond common knowledge, e.g. qt5-base < qt4 < gtk2 < gtk3 with regard to topo-level. Qt5 was split into several packages therefore it is understandable that qt5-base is lower than qt4. The fact that gtk is more high level than qt may beyond most expectations (including mine). Circular dependencies There are some packages that have circular dependencies in between. An example will be freetype2 and harfbuzz. freetype2 is a library for font rendering, and harfbuzz is a library to deal with OpenType font shapes. They depend on each other. Another example is kio and kinit of KDE. kio provides VFS-like and FUSE-like resource abstraction for KDE applications, while kinit is in charge of initializing KDE desktop environment. Circular dependency between freetype2 and harfbuzz Because of these circular dependencies, PacVis cannot simply apply topology sort directly. Before that, PacVis will firstly find all circles in the dependency graph to break these circles. It renders the relationship that will cause a circle as red arrows in the diagram. Some packages don't have dependency relationship man-pages and licenses don't have dependencies There are some packages that don't depend on others, and don't depended by others. They are isolated in the whole diagram, e.g. man-pages and licenses. These packages sit on the most top level of the diagram, with a topo-level of 0. PacVis will render them as blue squares specially. Linux (the kernel) is unimportant, if we only look at dependencies All userspace program depend on glibc, which calls the kernel using well-defined syscalls. As a result, if we only look at userspace dependencies, glibc and other GNU components are the center of the GNU/Linux distribution, while Linux the kernel is just located in a random place deeply blew the dependency graph. On my demo server the Linux package is even located on the most bottom level because it depends on mkinitcpio which in-turn depend on many components in the system. pacman -Qtd cannot find orphan packages with circle dependency msys2 packages with circle dependency I saw an archipelago of packages from mingw repo when testing PacVis on msys2. To my surprise, they don't connected to any manually installed packages, something strange as I routinely run pacman -Qtd and remove the results on all my systems. After zoomed in I found that they contained a circle dependency which indicated pacman -Qtd cannot find these orphan packages, not like a GC algorithm. The future of PacVis Currently PacVis is what I planned to make, with some features added during the development. Some of these added features are related to the poor performance of the layout algorithm (e.g. limiting the max level). In the future I planned to add more features: More reasonable behavior for optdeps. Currently PacVis draw optdeps but do not consider it during the topology sort. More reasonable dependency resolution . Sometimes the dependency is not written directly as package names, instead they appear in provides array in the metadata. Currently PacVis resolve all dependencies using alpm directly, which will lose these information. Currently PacVis did not consider the repository (core/extra/community) and package group that a package belongs to. In the future PacVis may consider these infomation to render a clearer hierarchy. Currently PacVis cannot show only part of the packages. In the future we may provide the ability to draw only a part of all the installed packages like pactree/pacgraph does. If you want some features in PacVis, please leave me an issue .","tags":"tech","url":"//farseerfc.me/en/pacvis.html"},{"title":"PacVis: 可视化 pacman 本地数据库","text":"PacVis 我为什么要做 PacVis 我喜欢 Arch Linux ，大概是因为唯有 Arch Linux 能给我对整个系统「了如指掌」的感觉。 在 Arch Linux 里我能清楚地知道我安装的每一个包，能知道系统里任何一个文件是来自哪个包， 以及我为什么要装它。或许对 Debian/Fedora/openSUSE 足够熟悉了之后也能做到这两点， 不过他们的细致打包的结果通常是包的数量比 Arch 要多个 3 到 10 倍，并且打包的细节也比 Arch Linux 简单的 PKGBUILD 要复杂一个数量级。 每一个装过 Arch Linux 的人大概都知道，装了 Arch Linux 之后得到的系统非常朴素，按照 ArchWiki 上的流程一路走下来的话，最关键的一条命令就是 pacstrap /​mnt base ， 它在 /​mnt 里作为根调用 pacman -S base 装上了整个 base 组， 然后就没有然后了。这个系统一开始空无一物，你需要的任何东西都是后来一点点用 pacman 手动装出来的，没有累赘，按你所需。 然而时间长了，系统中难免会有一些包，是你装过用过然后忘记了， 然后这些包就堆在系统的角落里，就像家里陈年的老家具，占着地，落着灰。虽然 pacman -Qtd 能方便地帮你找出所有 曾经作为依赖被装进来，而现在不被任何包依赖 的包，但是对于那些你手动指定的包， 它就无能为力了。 于是我就一直在找一个工具能帮我梳理系统中包的关系，方便我： 找出那些曾经用过而现在不需要的包 找出那些体积大而且占地方的包 厘清系统中安装了的包之间的关系 Android 系统架构 关于最后一点「厘清包的关系」，我曾经看到过 macOS 系统架构图 和 Android 的系统架构图，对其中的层次化架构印象深刻，之后就一直在想，是否能画出现代 Linux 桌面系统上类似的架构图呢？又或者 Linux 桌面系统是否会展现完全不同的样貌？ 从维基百科或者别的渠道能找到 Linux 内核、或者 Linux 图形栈， 或者某个桌面环境的架构，但是没有找到覆盖一整个发行版的样貌的。 于是我便想，能不能从包的依赖关系中自动生成这样一张图呢。 PacVis的老前辈们 在开始写 PacVis 之前，我试过一些类似的工具，他们都或多或少能解决一部分我的需要， 又在某些方面有所不足。这些工具成为了 PacVis 的雏形，启发了 PacVis 应该做成什么样子。 pactree pactree 曾经是一个 独立的项目 ，现在则是 pacman 的一部分 了。 从手册页可以看出， pactree 的输出是由某个包开始的依赖树。 加上 --graph 参数之后 pactree 还能输出 dot 格式的矢量图描述，然后可以用 dot 画出依赖图： pactree pacvis-git -d3 --graph | dot -Tpng >pacvis-pactree.png $ pactree pacvis-git -d3 pacvis-git ├─python-tornado │ └─python │ ├─expat │ ├─bzip2 │ ├─gdbm │ ├─openssl │ ├─libffi │ └─zlib ├─pyalpm │ ├─python │ └─pacman │ ├─bash │ ├─glibc │ ├─libarchive │ ├─curl │ ├─gpgme │ ├─pacman-mirrorlist │ └─archlinux-keyring └─python-setuptools └─python-packaging ├─python-pyparsing └─python-six $ pactree pacvis-git -d3 --graph | dot -Tpng >pacvis-pactree.png 从画出的图可以看出，因为有共用的依赖，所以从一个包开始的依赖关系已经不再是一棵 图论意义上的树(Tree) 了。最初尝试做 PacVis 的早期实现的时候，就是试图用 bash/python 脚本解析 pactree 和 pacman 的输出，在 pactree 的基础上把整个系统中所有安装的包全都包含到一张图里。 当然后来画出的结果并不那么理想，首先由于图非常巨大，导致 dot 的自动布局要耗费数小时，最后画出的图也过于巨大基本上没法看。 然而不得不说没有 pactree 就不会有 PacVis ，甚至 pacman 被分离出 alpm 库也和 pactree 用 C 重写的过程有很大关系，而 PacVis 用来查询 pacman 数据库的库 pyalpm 正是 alpm 的 Python 绑定。因为 pactree 的需要而增加出的 alpm 库奠定了 PacVis 实现的基石。 pacgraph pacgraph 的输出 pacgraph 是一位 Arch Linux 的 Trusted User keenerd 写的程序，和 PacVis 一样也是用 Python 实现的。 比起 pactree ， pacgraph 明显更接近我的需求，它默认绘制整个系统的所有安装包， 并且用聪明的布局算法解决了 dot 布局的性能问题。 pacgraph 的输出是一个富有艺术感的依赖图，图中用不同的字体大小表示出了每个包占用 的磁盘空间。通过观察 pacgraph 的输出，我们可以清楚地把握系统全局的样貌， 比如一眼看出这是个桌面系统还是个服务器系统，并且可以很容易地发现那些占用磁盘空间 巨大的包，考虑清理这些包以节约空间。 更棒的是 pacgraph 还提供了一个交互性的 GUI 叫做 pacgraph-tk ，显然通过 tk 实现。 用这个 GUI 可以缩放观察整幅图的细节，或者选中某个包观察它和别的包的依赖关系。 pacgraph 还支持通过参数指定只绘制个别包的依赖关系，就像 pactree 那样。 不过 pacgraph 也不是完全满足我的需要。如我前面说过，我希望绘制出的图能反应 这个发行版的架构面貌 ，而 pacgraph 似乎并不区别「该包依赖的包」和「依赖该包的包」 这两种截然相反的依赖关系。换句话说 pacgraph 画出的是一张无向图， 而我更想要一张有向图，或者说是 有层次结构的依赖关系图 。 于是就有了 PacVis PacVis 刚打开的样子 总结了老前辈们的优势与不足，我便开始利用空余时间做我心目中的 PacVis 。 前后断断续续写了两个月，又分为两个阶段，第一阶段做了基本的功能和雏形， 第二阶段套用上 https://getmdl.io/ 的模板，总算有了能拿得出手给别人看的样子。 于是乎前两天在 AUR 上给 pacvis 打了个 pacvis-git 包，现在想在本地跑 pacvis 应该很方便了，用任何你熟悉的 aurhelper 就可以安装，也可以直接从 aur 下载 PKGBUILD 打包： ~$ git clone aur@aur.archlinux.org:pacvis-git.git ~$ cd pacvis-git ~/pacvis-git$ makepkg -si ~/pacvis-git$ pacvis Start PacVis at http://localhost:8888/ 按照提示说的，接下来打开浏览器访问 http://localhost:8888/ 就能看到 PacVis 的样子了。仅仅作为尝试也可以直接打开跑在我的服务器上的 demo: https://pacvis.farseerfc.me/ ，这个作为最小安装的服务器载入速度大概比普通的桌面系统快一点。 在 Windows msys2 跑 PacVis 另外补充一下，因为 PacVis 只依赖 pyalpm 和 tornado ，所以在别的基于 pacman 的系统上跑它应该也没有任何问题，包括 Windows 上的 msys2 里（尽管在 msys2 上编译 tornado 的包可能要花些功夫）。 PacVis 的图例和用法 操作上 PacVis 仿照地图程序比如 Google Maps 的用法，可以用滚轮或者触摸屏的手势 缩放、拖拽，右上角有个侧边栏，不需要的话可以点叉隐藏掉，右下角有缩放的按钮和 回到全局视图的按钮，用起来应该还算直观。 pacvis-git 包的依赖 先解释图形本身，整张图由很多小圆圈的节点，以及节点之间的箭头组成。 一个圆圈就代表一个软件包，而一条箭头代表一个依赖关系。缩放到细节的话， 能看到每个小圆圈的下方标注了这个软件包的名字，鼠标悬浮在圆圈上也会显示响应信息。 还可以点开软件包，在右侧的边栏里会有更详细的信息。 比如图例中显示了 pacvis-git 自己的依赖，它依赖 pyalpm, python-tornado 和 python-setuptools ，其中 pyalpm 又依赖 pacman 。图中用 紫色 表示手动安装的包， 橙色 表示被作为依赖安装的包， 箭头的颜色也随着包的颜色改变。 值得注意的是图中大多数箭头都是由下往上指的，这是因为 PacVis 按照包的依赖关系做 了拓扑排序，并且给每个包赋予了一个拓扑层级。比如 pacvis-git 位于 39 层，那么它依赖的 pyalpm 就位于 38 层，而 pyalpm 依赖的 pacman 就位于 37 层。根据层级关系排列包是 PacVis 于 pacgraph 之间最大的不同之处。 除了手动缩放， PacVis 还提供了搜索框，根据包名快速定位你感兴趣的包。 以及在右侧边栏中的 Dep 和 Req-By 等页中，包的依赖关系也是做成了按钮的形式， 可以由此探索包和包之间的关联。 最后稍微解释一下两个和实现相关的参数： Max Level 这是限制 PacVis 载入的最大拓扑层。系统包非常多的时候 PacVis 的布局算法会显得很慢，限制层数有助于加快载入，特别是在调试 PacVis 的时候比较有用。 Max Required-By 这是限制 PacVis 绘制的最大被依赖关系。稍微把玩一下 PacVis 就会发现系统内绝大多数 的包都直接依赖了 glibc 或者 gcc-libs 等个别的几个包，而要绘制这些依赖的话会导致 渲染出的图中有大量长直的依赖线，不便观察。于是可以通过限制这个值，使得 PacVis 不绘制被依赖太多的包的依赖关系，有助于让渲染出的图更易观察。 从 PacVis 能了解到的一些事实 一个 KDE 桌面的 PacVis 结果全图， 放大（17M） 稍微玩一下 PacVis 就能发现不少有趣现象，上述「绝大多数包依赖 glibc 」就是一例。 除此之外还有不少值得玩味的地方。 依赖层次 系统中安装的包被明显地分成了这样几个层次： glibc 等 C 库 Bash/Perl/Python 等脚本语言 coreutils/gcc/binutils 等核心工具 pacman / systemd 等较大的系统工具 gtk{2,3}/qt{4,5} 等 GUI toolkit chromium 等 GUI 应用 Plasma/Gnome 等桌面环境 大体上符合直观的感受，不过细节上有很多有意思的地方，比如 zsh 因为 gdbm 间接依赖了 bash，这也说明我们不可能在系统中用 zsh 完全替代掉 bash。 再比如 python （在 Arch Linux 中是 python3）和 python2 和 pypy 几乎在同一个拓扑层级。 zsh 因为 gdbm 间接依赖了 bash 不过偶尔显示的依赖层级不太符合直观，比如 qt5-base < qt4 < gtk2 < gtk3 。 qt5 因为被拆成了数个包所以比 qt4 更低级这可以理解，而 gtk 系比 qt 系更高级这一点是很多人（包括我）没有预料到的吧。 循环依赖 有些包的依赖关系形成了循环依赖，一个例子是 freetype2 和 harfbuzz，freetype2 是绘制字体的库，harfbuzz 是解析 OpenType 字形的库，两者对对方互相依赖。 另一个例子是 KDE 的 kio 和 kinit，前者提供类似 FUSE 的资源访问抽象层， 后者初始化 KDE 桌面环境。 freetype2 和 harfbuzz 之间的循环依赖 因为这些循环依赖的存在，使得 PacVis 在实现时不能直接拓扑排序，我采用环探测 算法找出有向图中所有的环，并且打破这些环，然后再使用拓扑排序。 因此我在图中用红色的箭头表示这些会导致环的依赖关系。 有些包没有依赖关系 man-pages 和 licenses 没有依赖关系 有些包既不被别的包依赖，也不依赖别的包，而是孤立在整张图中，比如 man-pages 和 licenses 。这些包在图中位于最顶端，拓扑层级是 0 ，我用 蓝色 正方形特别绘制它们。 只看依赖关系的话 Linux 内核完全不重要 所有用户空间的程序都依赖着 glibc ，而 glibc 则从定义良好的 syscall 调用内核。 因此理所当然地，如果只看用户空间的话， glibc 和别的 GNU 组件是整个 GNU/Linux 发行版的中心，而 Linux 则是位于依赖层次中很深的位置，甚至在我的 demo 服务器上 Linux 位于整个图中的最底端，因为它的安装脚本依赖 mkinitcpio 而后者依赖了系统中的众多组件。 pacman -Qtd 不能找到带有循环依赖的孤儿包 msys2 中带有循环依赖的孤儿包 这是我在 msys2 上测试 PacVis 的时候发现的，我看到在渲染的图中有一片群岛， 没有连上任何手动安装的包。这种情况很不正常，因为我一直在我的所有系统中跑 pacman -Qtd 找出孤儿包并删掉他们。放大之后我发现这些包中有一条循环依赖， 这说明 pacman -Qtd 不能像语言的垃圾回收机制那样找出有循环依赖的孤儿包。 PacVis 的未来 目前的 PacVis 基本上是我最初开始做的时候设想的样子，随着开发逐渐又增加了不少功能。 一些是迫于布局算法的性能而增加的（比如限制层数）。 今后准备再加入以下这些特性： 更合理的 optdeps 处理。目前只是把 optdeps 关系在图上画出来了。 更合理的 依赖关系抉择 。有时候包的依赖关系并不是直接根据包名，而是 provides 由一个包提供另一个包的依赖。目前 PacVis 用 alpm 提供的方式抉择这种依赖，于是这种关系并没有记录在图上。 目前的层级关系没有考虑包所在的仓库 (core/extra/community/...) 或者包所属的组。 加入这些关系能更清晰地表达依赖层次。 目前没有办法只显示一部分包的关系。以后准备加入像 pactree/pacgraph 一样显示部分包。 如果你希望 PacVis 出现某些有趣的用法和功能，也 请给我提 issue 。","tags":"tech","url":"//farseerfc.me/zhs/pacvis.html"},{"title":"X 中的混成器与 Composite 扩展","text":"在上篇文章 「桌面系统的混成器简史」 中我介绍了其它桌面系统中的混成器的发展史和工作原理， 话题回到我们的正题 Linux 系统上，来说说目前 X 中混成器是如何工作的。 这篇文章将比上一篇深入更多技术细节，不想看太多细节的可以直接跳过看 结论 。 原始的 X 的绘图模型 首先，没有混成器的时候 X 是这样画图的： X 的应用程序没有统一的绘图 API 。GTK+ 在 3.0 之后统一用 Cairo 绘图， 而 Cairo 则是基于 PDF 1.4 的绘图模型构建的， GTK 的 2.0 和之前的版本中也有很大一部分的绘图是用 Cairo 进行， 其余则通过 xlib 或者 xcb 调用 X 核心协议提供的绘图原语绘图。 QT 的情况也是类似，基本上用 QPaint 子系统绘制成位图然后交给 X 的显示服务器。 显示服务器拿到这些绘制请求之后，再在屏幕上的相应位置绘制整个屏幕。 当然还有很多老旧的不用 GTK 或者 QT 的程序，他们则直接调用 X 核心协议提供的绘图原语。 值得注意一点是 X 上除了没有统一的绘图模型，也没有统一的矢量图格式。 X 核心协议的绘图原语提供的是像素单位的绘图操作，没有类似 GDI+ 或者 Quartz 提供的 设备无关 ( Device Independence ) 的「点」的抽象。所以只用 X 的绘图原语的话，我们可以把 (1,1) 这个像素点涂黑，但是不能把 (0.5, 0.5) 这个点涂黑，这一设计缺陷在 Unix Hater's Handbook 中已经被吐槽过了。因为这个缺陷，所以直接用 X 绘图原语绘制的图像不能像 矢量图那样进行无损缩放。同样的缺陷导致 X 绘图原语绘制的字符不能做到 子像素级 ( subpixel-level ) 抗锯齿 ( anti-aliasing ) （这解释了默认配置下的 xterm 和 urxvt 中的字体渲染为什么难看 ）。相比之下 GDI 有对应的 WMF 矢量图格式， Quartz 有对应的 PDF 矢量图格式， 而 X 中没有这样的格式对应。因为没有统一的矢量图格式，所以无论是 Cairo 、QPaint 还是没有用这些绘图库但是同样在意字体和曲线渲染效果的程序（比如 Firefox 和 Chromium）都需要首先渲染到内部的 XPixMap 位图格式，做好子像素渲染和矢量缩放，然后再把渲染好的位图转交给 X 图形服务器。 通过 Composite 扩展重定向窗口输出 2004年发布的 X11R6.8 版本的 Xorg 引入了 Composite 扩展 。这个扩展背后的动机以及前因后果在一篇文章 The (Re)Architecture of the X Window System 中有详细的表述。Composite 扩展允许某个 X 程序做这几件事情： 通过 RedirectSubwindows 调用将一个窗口树中的所有窗口渲染重定向到 内部存储 ( off-screen storage ) 。重定向的时候可以指定让 X 自动更新窗口的内容到屏幕上或者由混成器手动更新。 通过 NameWindowPixmap 取得某个窗口的内部存储。 通过 GetOverlayWindow 获得一个特殊的用于绘图的窗口， 在这个窗口上绘制的图像将覆盖在屏幕的最上面。 通过 CreateRegionFromBorderClip 取得某个窗口的边界剪裁区域（不一定是矩形）。 有了 Composite 扩展，一个 X 程序就可以调用这些 API 实现混成器。 这里有篇 教学解释如何使用 Composite 扩展 。开启了混成的 X 是这样绘图的： 整个 X 的混成器模型与 Mac OS X 的混成器模型相比，有如下几点显著的区别： 混成的部分是交由外部的程序完成的，对混成的绘制方式和绘制普通窗口一样。 出于效率考虑，绝大多数 X 上的混成器额外使用了 XRender 扩展或者 OpenGL/EGL 来加速绘制贴图。不过即使如此，还是不能避免同样的位图（内容不一定完全一致， 比如 X 可以在窗口交给它的位图上加上边框然后再返还给混成器） 在不同的三个程序之间来回传递 。 RedirectSubwindows 调用针对的是一个窗口树，换句话说是一个窗口 及其全部子窗口，不同于 Mac OS X 中混成器会拿到全部窗口的输出。 这个特点其实并不算是限制，因为 X 中每个虚拟桌面都有一个根窗口，只要指定这个根窗口 就可以拿到整个虚拟桌面上的全部可见窗口输出了。 反而这个设计提供了一定的自由度，比如我们可以用这个调用实现一个截图程序， 拿到某个特定窗口的输出，而不用在意别的窗口。 为了让窗口有输出，窗口必须显示在当前桌面上，不能处于最小化 状态或者显示在别的虚拟桌面，用 X 的术语说就是窗口必须处于 被映射 ( mapped ) 的状态。因此直接用上述方法 不能得到没有显示的窗口的输出 ，比如不能对最小化的窗口 直接实现 Windows 7 中的 Aero Peak 之类的效果。这个限制可以想办法绕开， 比如在需要窗口输出的时候临时把窗口映射到桌面上，拿到输出之后再隐藏起来， 不过要实现这一点需要混成器和窗口管理器相互配合。 不像 Mac OS X 的基于 OpenGL Surface 的绘图模型是 设备无关 ( device independent ) 的，这里 X 的绘图模型是 设备相关 ( device dependent ) 的。 这既是优点也是缺点。从缺点方面而言，显示到 X 的位图输出因为设备相关性， 所以严格对应显示器的点阵，并不适合作为文档格式打印出来。当然无论是 Cairo 还是 QPaint 都提供了到 PostScript 或者 PDF 后端的输出，所以实用层面这个并不构成问题。 设备相关这一点的优点在于，绘制到 XPM 位图的时候，程序和绘图库是能拿到输出设备（显示器） 的特殊属性的，从而绘图库能考虑不同的色彩、分辨率、 DPI 或者 子像素布局 ( subpixel layout ) 这些属性以提供最好的渲染效果。 Mac OS X 10.4 在设计的时候也曾考虑过提供无极缩放的支持，而这种支持到了 Mac OS X 10.5 中就缩水变成了 Retina 的固定 2 倍缩放。这种局面在 X 上没有发生正是因为 X 的绘图模型的这种设备相关性，而 Mac OS X 的混成器采用的 OpenGL Surface 则无视了这些设备相关的属性。 输入事件的重定向，这可能做到么？ 通过上述 Composite 扩展提供的 API ，混成器可以把窗口的 输出 重定向到自己的窗口上。 但是仅仅重定向输出，整个 X 还不处于可用状态，因为 没有重定向输入 。 考虑一下用户试图用鼠标点击某个按钮或者文本框，这时鼠标处于的位置是在 OverlayWindow 上绘制的位置，这个鼠标事件会交给 OverlayWindow ，而用户期待这个事件被发送给他看到的按钮上。 需要重定向的事件主要有键盘和鼠标事件两大类（暂时先不考虑触摸屏之类的额外输入）。 由于 Composite 扩展并没有直接提供这方面的重定向 API ，这使得输入事件处理起来都比较麻烦， 假设要重定向键盘事件，混成器需要效仿输入法框架（fcitx, ibus, scim） 那样处理一部分按键事件并把其余事件转给具有输入焦点的程序。 看看现有的输入法框架和诸多程序间的问题，我们就能知道这里的坑有多深。 于是 大部分 X 的混成器都不处理键盘事件重定向 。再来看重定向鼠标事件，这边的坑比重定向键盘事件的坑更多， 因为不像重定向窗口输出那样只需要考虑 顶层 ( top-level ) 窗口， 重定向鼠标输入的时候要考虑所有子窗口（它们有独立的事件队列）， 以及要准确记录输入事件事件发生时的键盘组合键状态，还要正确实现 ICCCM/EWMH 中描述的转交窗口焦点的复杂规则，所有这些都已经在 X 中实现过的事情需要重新实现一遍。 由于坑太多难以实现，所以所有 X 下的混成器的实现方式都是直接忽略这个繁重的任务， 不重定向输入事件 而把它交给 X 处理。具体的实现方式就是通过 XFixes 扩展提供的 SetWindowShapeRegion API 将 OverlayWindow 的 输入区域 ShapeInput 设为空区域，从而忽略对这个 OverlayWindow 的一切鼠标键盘事件。 这样一来对 OverlayWindow 的点击会透过 OverlayWindow 直接作用到底下的窗口上。 因为选择了不重定向输入事件， X 下的混成器通常会处于以下两种状态： 选择状态下可以缩放窗口的大小，扭曲窗口的形状，并且可以把窗口绘制在任意想要绘制的位置上 （并不是移动窗口的位置）， 但是不能让用户与窗口的内容交互 。 正常状态下可以让用户与窗口的内容交互，但是 绘制的窗口位置、大小和形状必须严格地和 X 记录的窗口的位置、大小和形状保持一致 。持续时间短暂的动画效果可以允许位置和形状稍有偏差，但是在动画的过程中如果用户点击了 变形缩放过的窗口，那么鼠标事件将发往错误的（ X 记录中的而非显示出的）窗口元素上。 可以发现这两种状态就直接对应了 Gnome 3 的普通状态和缩略图状态（点击 活动 ( Activity ) 或者戳画面左上角之后显示的状态），这也解释了为什么尽管 Gnome 3 的窗口有硕大的关闭按钮，但是在缩略图状态下 Gnome 3 仍然需要给窗口加上额外的关闭按钮： 因为处于缩略状态下的窗口只是一张画而不能点 。 Composite 扩展的这些限制使得 X 下的混成器目前只能实现 Mac OS X 那样的 Exposé 效果，而不能实现 LG3D 那样直接在 3D 空间中操纵窗口内容。 解决重定向问题曾经的一缕曙光是 升阳公司 ( Sun Microsystems ) 在开发 LG3D 的过程中同时提议过另一个 X 扩展叫做 Event Interception 或者简称 XEvIE ，这个扩展的设计目的就是提供 API 让某个程序接收并操纵全部的键盘和鼠标事件。可惜这个扩展随着升阳公司本身的陨落而 处于无人维护的状态，这一点也在它的官方网页上说明了： It has been suggested that this extension should not be used because it is broken and maintainerless. Composite 扩展的不足 通过上面的介绍，我们就已经可以看到 Composite 扩展的不足之处了。 总结起来说，主要有两大不足： 绘图效率低。因为同样的位图从应用程序传到 Xorg ，再从 Xorg 传到混成器， 最后从混成器再绘制到屏幕上，绕了一个大弯。这就是为什么 Wayland 的开发者在他的slide the real story behind Wayland and X 里这么说： and what's the X server? really bad IPC 那么 X 服务器到底做了什么呢？ 非常糟糕的进程间通讯 没有重定向输入事件。如果我们要在 X 的混成器里做这个事情， 基本上我们要全部重写一遍 X 已经写好的窗口事件分发逻辑。 既然同样要重写，为什么不直接重写一遍 X 呢，扔掉那些历史负担，扔掉那些无用的 API ，重新设计可扩展的 API ，做好快速安全的 IPC —— 嗯，重写 X 就是 Wayland 的目的。 不过这么重写了的 Wayland 还是我们熟悉可爱的 X 么？它有哪些地方变样了？ 这将是我下一篇文章的内容。 附录：扩展阅读 我自己没有写过窗口管理器，没有写过混成器，没有写过 Wayland 程序，以上说的都是我从互联网上看到的整理出来的内容。写下本文的过程中我参考了这些文章： The (Re)Architecture of the X Window System 这篇2004年写的文章描述了 Composite 扩展出现的动机和历史，介绍了绘图库的实现情况，涉及了上面所说的那些 X 扩展被用到的情况和可能。 同时这篇文章还展望了很多现在的 X 已然实现了的功能，比如 OpenGL 和 X 的结合方面我们有了 GLX 和 AIGLX ，比如内核的显卡支持方面我们有了 DRI 和 KMS 。总之这是一篇描述 Linux 桌面未来的发展轨迹的非常有阅读价值的历史文献。 so you want to build a compositor 这是一篇 2008 年写的博文，介绍如何用 Clutter 实现一个最简单的混成器。 Composite tutorial 这是另一篇介绍如何实现一个简单的混成器的博文，用 Qt 实现，但是同样很底层。 unagi 这是一个可用的（但是已经长期没有开发的）类似 xcompmgr 的混成器。这个项目貌似 是一位研究生的硕士毕业设计，同时他公开了硕士学位的毕业论文 Master thesis: Writing an X compositing manager 其中也对实现一个简单的混成器做了详尽描述，包括介绍了相关的 X 扩展和调用。","tags":"tech","url":"//farseerfc.me/zhs/compositor-in-X-and-compositext.html"},{"title":"桌面系统的混成器简史","text":"（原本是想写篇关于 Wayland 的文章，后来越写越长感觉能形成一个系列， 于是就先把这篇背景介绍性质的部分发出来了。） Linux 系统上要迎来 Wayland 了，或许大家能从各种渠道打听到 Wayland 是一个混成器，替代 X 作为显示服务器。 那么 混成器 是个什么东西，桌面系统为什么需要它呢？ 要理解为什么桌面系统需要 混成器 （或者它的另一个叫法， 混成窗口管理器 ( Compositing Window Manager ) ），在这篇文章中我想回顾一下历史， 了解一下混成器出现的前因后果。 首先介绍一下混成器出现前主要的一类窗口管理器，也就是 栈式窗口管理器 ( Stacking Window Manager ) 的实现方式。 本文中所有桌面截图来自维基百科，不具有著作权保护。 早期的栈式窗口管理器 栈式窗口管理器的例子，Windows 3.11 的桌面 我们知道最初图形界面的应用程序是全屏的，独占整个显示器（现在很多游戏机和手持设备的实现仍旧如此）。 所有程序都全屏并且任何时刻只能看到一个程序的输出，这个限制显然不能满足人们使用计算机的需求， 于是就有了 窗口 的概念，有了 桌面隐喻 。 在 桌面隐喻 ( Desktop Metaphor ) 中每个窗口只占用显示面积的一小部分， 有其显示的位置和大小，可以互相遮盖。于是栈式窗口管理器就是在图形界面中实现桌面隐喻的核心功能， 其实现方式大体就是：给每个窗口一个相对的\"高度\"或者说\"远近\"，比较高的窗口显得距离用户比较近， 会覆盖其下比较低的窗口。绘图的时候窗口管理器会从把窗口按高低排序，按照从低到高的顺序使用 画家算法 绘制整个屏幕。 这里还要补充一点说明，在当时图形界面的概念刚刚普及的时候，绘图操作是非常\"昂贵\"的。 可以想象一下 800x600 像素的显示器输出下，每帧 真彩色 位图就要占掉 \\(800 \\times 600 \\times 3 \\approx 1.4 \\text{MiB}\\) 的内存大小，30Hz 的刷新率（也就是30FPS）下每秒从 CPU 传往绘图设备的数据单单位图就需要 \\(1.4 \\times 30 = 41 \\text{MiB}\\) 的带宽。对比一下当时的 VESA 接口 总的数据传输能力也就是 \\(25 \\text{MHz} \\times 32 \\text{bits} = 100 \\text{MiB/s}\\) 左右， 而 Windows 3.1 的最低内存需求是 1MB，对当时的硬件而言无论是显示设备、内存或是CPU， 这无疑都是一个庞大的负担。 于是在当时的硬件条件下采用栈式窗口管理器有一个巨大 优势 ：如果正确地采用画家算法， 并且合理地控制重绘时 只绘制没有被别的窗口覆盖的部分 ，那么无论有多少窗口互相 遮盖，都可以保证每次绘制屏幕的最大面积不会超过整个显示器的面积。 同样因为实现方式栈式窗口管理器也有一些难以回避的 限制 ： 窗口必须是矩形的，不能支持不规则形状的窗口。 不支持透明或者半透明的颜色。 为了优化效率，在缩放窗口和移动窗口的过程中，窗口的内容不会得到重绘请求， 必须等到缩放或者移动命令结束之后窗口才会重绘。 以上这些限制在早期的 X11 窗口管理器比如 twm 以及 XP 之前经典主题的 Windows 或者经典的 Mac OS 上都能看到。 在这些早期的窗口环境中，如果你拖动或者缩放一个窗口，那么将显示变化后的窗口边界， 这些用来预览的边界用快速的位图反转方式绘制。当你放开鼠标的时候才会触发窗口的 重绘事件。 虽然有很多方法或者说技巧能绕过这些限制，比如 Windows XP 上就支持了实时的 重绘事件和不规则形状的窗口剪裁，不过这些技巧都是一连串的 hack ，难以扩展。 NeXTSTEP 与 Mac OS X 中混成器的发展 NeXTSTEP 桌面 转眼进入了千禧年， Windows 称霸了 PC 产业，苹果为重振 Macintosh 请回了 Jobs 基于 NeXTSTEP 开发 Mac OSX 。 NeXTSTEP 在当时提供的 GUI 界面技术相比较于同年代的 X 和 Windows 有一个很特别的地方： 拖动滚动条或者移动窗口的时候，窗口的内容是 实时更新 的，这比只显示一个缩放大小的框框来说被认为更直观。 而实现这个特性的基础是在 NeXTSTEP 中运用了 Display PostScript (DPS) 技术，简单地说，就是每个窗口并非直接输出到显示设备，而是把内容输出到 (Display) PostScript 格式交给窗口管理器，然后窗口管理器再在需要的时候把 PostScript 用软件解释器解释成位图显示在屏幕上。 比起让窗口直接绘制，这种方案在滚动和移动窗口的时候不需要重新渲染保存好的 DPS ， 所以能实现实时渲染。到了实现 Mac OS X 的时候，为了同时兼容老的 Mac 程序 API (carbon) 以及更快的渲染速度，以及考虑到 Adobe 对苹果收取的高昂的 Display PostScript 授权费， Mac OS X 的 Quartz 技术在矢量图的 PDF 描述模型和最终渲染之间又插入了一层抽象： Mission Control 也就是说在 Mac OS X 中无论窗口用何种方式绘图，都会绘制输出成一副内存中的位图交给混成器， 而后者再在需要的时候将位图混成在屏幕上。这种设计使得 2001年3月发布的 Mac OS X v10.0 成为了第一个广泛使用的具有软件混成器的操作系统。 到了 Mac OS X v10.2 的时候，苹果又引入了 Quartz Extreme 让最后的混成渲染这一步发生在 显卡上。然后在 2003年1月公开亮相的 Mac OS X v10.3 中，他们公布了 Exposé (后来改名为 Mission Control) 功能，把窗口的缩略图（而不是事先绘制的图标）并排显示在桌面上， 方便用户挑选打开的窗口。 由于有了混成器的这种实现方式，使得可能把窗口渲染的图像做进一步加工，添加阴影、三维和动画效果。 这使得 Mac OS X 有了美轮美奂的动画效果和 Exposé 这样的方便易用的功能。 或许对于乔布斯而言，更重要的是因为有了混成器，窗口的形状终于能显示为他 梦寐以求 的 圆角矩形 了！ 插曲：昙花一现的 Project Looking Glass 3D 在苹果那边刚刚开始使用混成器渲染窗口的 2003 年，昔日的 升阳公司 ( Sun Microsystems ) 则在 Linux 和 Solaris 上用 Java3D 作出了另一个炫酷到没有朋友的东西，被他们命名为 Project Looking Glass 3D （缩写LG3D，别和 Google 的 Project Glass 混淆呀）。这个项目的炫酷实在难以用言语描述， 好在还能找到两段视频展示它的效果。 Youtube Youku Youtube Youku LG3D 如视频中展示的那样， LG3D 完全突破了传统的栈式窗口管理方式， 在三维空间中操纵二维的窗口平面，不仅像传统的窗口管理器那样可以缩放和移动窗口， 还能够旋转角度甚至翻转到背面去。从视频中难以体会到的一点是， LG3D 在实现方式上与 Mac OS X 中的混成器有一个本质上的不同，那就是处于（静止或动画中）缩放或旋转状态 下的窗口是 可以接受输入事件 的。这一重要区别在后面 Wayland 的说明中还会提到。 LG3D 项目展示了窗口管理器将如何突破传统的栈式管理的框架，可以说代表了窗口管理器的未来发展趋势。 LG3D 虽然以 GPL 放出了实现的源代码，不过整个项目已经停滞开发许久了。 官方曾经放出过一个 预览版的 LiveCD 。可惜时隔久远（12年前了）在我的 VirtualBox 上已经不能跑起来这个 LiveCD 了…… 更为可惜的是，就在这个项目刚刚公开展示出来的时候，乔布斯就致电升阳， 说如果继续商业化这个产品，升阳公司将涉嫌侵犯苹果的知识产权 （时间顺序上来看，苹果最初展示 Exposé 是在 2003年6月23日的 Apple Worldwide Developers Conference ，而升阳最初展示 LG3D 是在 2003年8月5日的 LinuxWorld Expo）。 虽然和乔布斯的指控无关，升阳公司本身的业务也着重于服务器端的业务， 后来随着升阳的财政困难，这个项目也就停止开发并不了了之了。 Windows 中的混成器 Longhorn 中的 Wobbly 效果 Youtube Youku 上面说到， Windows 系列中到 XP 为止都还没有使用混成器绘制窗口。 看着 Mac OS X 上有了美轮美奂的动画效果， Windows 这边自然不甘示弱。 于是同样在 2003 年展示的 Project Longhorn 中就演示了 wobbly 效果的窗口， 并且跳票推迟多年之后的 Windows Vista 中实现了完整的混成器 Desktop Window Manager (DWM) 。整个 DWM 的架构和 Mac OS X 上看到的很像： 和 Mac OS X 的情况类似， Windows Vista 之后的应用程序有两套主要的绘图库，一套是从早期 Win32API 就沿用至今的 GDI（以及GDI+），另一套是随着 Longhorn 计划开发出的 WPF 。 WPF 的所有用户界面控件都绘制在 DirectX 贴图上，所以使用了 WPF 的程序也可以看作是 DirectX 程序。而对老旧的 GDI 程序而言，它们并不是直接绘制到 DirectX 贴图的。首先每一个 GDI 的绘图操作都对应一条 Windows Metafile (WMF) 记录，所以 WMF 就可以看作是 Mac OS X 的 Quartz 内部用的 PDF 或者 NeXTSTEP 内部用的 DPS，它们都是矢量图描述。随后，这些 WMF 绘图操作被通过一个 Canonical Display Driver (cdd.dll) 的内部组建转换到 DirectX 平面，并且保存起来交给 DWM。最后， DWM 拿到来自 CDD 或者 DirectX 的平面，把它们混合起来绘制在屏幕上。 值得注意的细节是，WPF 底层的绘图库几乎肯定有 C/C++ 绑定对应， Windows 自带的不少应用程序 和 Office 2007 用了 Ribbon 之后的版本都采用这套绘图引擎，不过微软没有公开这套绘图库的 C/C++ 实现的底层细节，而只能通过 .Net 框架的 WPF 访问它。这一点和 OS X 上只能通过 Objective-C 下的 Cocoa API 调用 Quartz 的情况类似。 另外需要注意的细节是 DirectX 的单窗口限制在 Windows Vista 之后被放开了，或者严格的说是 基于 WDDM 规范下的显卡驱动支持了多个 DirectX 绘图平面。 在早期的 Windows 包括 XP 上，整个桌面上同一时刻只能有一个程序的窗口处于 DirectX 的 直接绘制 模式，而别的窗口如果想用 DirectX 的话，要么必须改用软件渲染要么就不能工作。 这种现象可以通过打开多个播放器或者窗口化的游戏界面观察到。 而在 WDDM 规范的 Vista 中，所有窗口最终都绘制到 DirectX 平面上，换句话说每个窗口都是 DirectX 窗口。又或者我们可以认为，整个界面上只有一个真正的窗口也就是 DWM 绘制的全屏窗口， 只有 DWM 处于 DirectX 的直接渲染模式下，而别的窗口都输出到 DirectX 平面里（可能通过了硬件加速）。 由 DWM 的这种实现方式，可以解释为什么 窗口模式下的游戏总是显得比较慢 ，原因是整个桌面有很多不同的窗口都需要 DWM 最后混成，而如果在全屏模式下，只有游戏 处于 DirectX 的直接渲染方式，从而不会浪费对游戏而言宝贵的 GPU 资源。 由于 DWM 实现了混成器，使得 Vista 和随后的 Windows 7 有了 Aero Glass 的界面风格， 有了 Flip 3D 、Aero Peek 等等的这些辅助功能和动画效果。 这套渲染方式延续到 Windows 8 之后，虽然 Windows 8 还提出了 Modern UI 不过传统桌面上的渲染仍旧是依靠混成器来做的。 这就结束了？ Linux 桌面呢？ 别急，我写这些文章的目的是想聊聊 Linux 中的混成器，尤其是 X 下现有的混成器和 Wayland ，这篇文章只是个背景介绍。关于 X 中混成器的实现方式和限制，且听我下回分解。","tags":"tech","url":"//farseerfc.me/zhs/brief-history-of-compositors-in-desktop-os.html"},{"title":"避免在博文中写「简单地」","text":"我的 RSS 订阅着一个博客叫 The Old New Thing ，作者是Windows开发者之一的 Raymond Chen ，记录 Windows 中的很多有趣的技术细节。 这个博客中的一些精彩内容还被他写成了一本书，中文名叫《Windows编程启示录》 (ISBN: 978-7-111-21919-4 ) 而英文书名就叫 The Old New Thing — Practical Development Throughout the Evolution of Windows (ISBN: 978-0-321-44030-3 )。 今天看到这个博客的一篇文章说 你用「简单地」次数越多我越怀疑你不懂这个词的意思 ， 描述他看到某个博客上指导读者打开命令行、执行某条魔法命令、从命令输出抽取参数、 改写配置文件、用魔法命令重启服务，并把这些工作描述为「简单地」。 的确正如 Raymond 指出，一个人觉得简单的事情对别人并不一定是简单的。 搜了一下我自己写的东西，的确很多地方写了「简单」二字，这的确对读者不友好。 从今往后避免用「简单」来描述。","tags":"life","url":"//farseerfc.me/zhs/stop-write-simply.html"},{"title":"用 Travis-CI 生成 Github Pages 博客","text":"2015年2月21日更新 上次介绍过 这个博客改换了主题 ， 本以为这个话题可以告一段落了，没想到还能继续写呢。 寄宿在 Github Pages 上的静态博客通常有两种方案，其一是使用 Jekyll 方式撰写，这可以利用 Github Pages 原本就有的 Jekyll支持 生成静态网站。另一种是在 本地 也就是自己的电脑上生成好，然后把生成的 HTML 网站 push 到 Github Pages ，这种情况下 Github Pages 就完全只是一个静态页面宿主环境。 我用 Pelican 生成博客，当然就只能选择后一种方式了。这带来一些不便，比如本地配置 pelican 还是有一点点复杂的，所以不能随便找台电脑就开始写博客。有的时候只是想修正一两个错别字， 这时候必须打开某台特定的电脑才能编辑博客就显得不太方便了。再比如 pelican 本身虽然是 python 写的所以跨平台，但是具体到博客的配置方面， Windows 环境和 Linux/OSX/Unix-like 环境下还是有 些许出入 的。还有就是没有像 wordpress 那样的基于 web 的编辑环境，在手机上就不能随便写一篇博客发表出来（不知道有没有勇士尝试过在 Android 的 SL4A 环境下的 python 中跑 pelican ，还要配合一个 Android 上的 git 客户端 ）。 当然并不是因此就束手无策了，感谢 Travis-CI 提供了免费的 持续整合 ( Continuous integration ) 虚拟机环境， 通过它全自动生成静态博客成为了可能。 关于 Travis-CI 持续整合 原本是 敏捷开发 ( Agile Development ) 或者 极限编程 ( Extreme Programming ) 中提到的概念，大意就是说在开发的过程中， 一旦有微小的变更，就全自动地 持续 合并到主线中， 整合 变更的内容到发布版本里。 这里的 整合 实际上可以理解为 全自动测试 加上 生成最终产品 。 可以看到 持续整合 实际强调 全自动 ，于是需要有一个服务器不断地监听主线开发的变更内容， 一旦有任何变更（可以理解为 git commit ）就自动调用测试和部署脚本。 于是要用持续整合就需要一个整合服务器，幸而 Travis-CI 对 github 上的公开 repo 提供了免费的整合服务器虚拟机服务，和 github 的整合非常自然。所以我们就可以用它提供的虚拟机 为博客生成静态网站。 启用 Travis-CI 自动编译 这一步很简单，访问 https://travis-ci.org/ 并用你的 Github 账户登录， 授权它访问你的账户信息就可以了。然后在 https://travis-ci.org/repositories 里开启 需要编译的 repo ，这样 Travis-CI 就会监视对这个 repo 的所有 push 操作，并且对 每个 push 调用测试了。 在 Travis-CI 中开启对 Github Repo 的持续整合 然后在 repo 的根目录放一个 .travis.yml 文件描述编译的步骤。 暂时 测试的目的下我写的 .travis.yml 大概是下面这样。 language : python python : - \"2.7\" before_install : - sudo apt-add-repository ppa:chris-lea/node.js -y - sudo apt-get update - sudo apt-get install nodejs ditaa doxygen parallel install : - sudo pip install pelican - sudo pip install jinja2 - sudo pip install babel - sudo pip install beautifulsoup4 - sudo pip install markdown - sudo npm install -g less - wget \"http://downloads.sourceforge.net/project/plantuml/plantuml.jar?r=&ts=1424308684&use_mirror=jaist\" -O plantuml.jar - sudo mkdir -p /opt/plantuml - sudo cp plantuml.jar /opt/plantuml - echo \"#! /bin/sh\" > plantuml - echo 'exec java -jar /opt/plantuml/plantuml.jar \"$@\"' >> plantuml - sudo install -m 755 -D plantuml /usr/bin/plantuml - wget https://bintray.com/artifact/download/byvoid/opencc/opencc-1.0.2.tar.gz - tar xf opencc-1.0.2.tar.gz - cd opencc-1.0.2 && make && sudo make install && cd .. - sudo locale-gen zh_CN.UTF-8 - sudo locale-gen zh_HK.UTF-8 - sudo locale-gen en_US.UTF-8 - sudo locale-gen ja_JP.UTF-8 script : - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - mkdir output - env SITEURL=\"farseerfc.me\" make publish Travis-CI 提供的虚拟机是比较标准的 Ubuntu 12.04 LTS ，打上了最新的补丁，并且根据你指定的 语言选项会把相应的解释器和编译器升级到最新版（或者指定的版本）。这里用 python 语言的配置， 所以 python 是 2.7 的最新版并且有 pip 可以直接用。 配置中的 before_install 和 install 的区别其实不大，其中任何一个失败的话算作 build errored 而不是 build fail ，而如果在 script 里失败的话算作 build fail 。 为了编译我的模板，还需要比较新的 less.js ，所以添加了 ppa 装了个最新的 nodejs 并用它装上了 less 。 还从源码编译安装上了最新版的 opencc 1.0.2 ，因为 Ubuntu 源里的 opencc 的版本比较老(0.4)， 然后 doxygen 作为 opencc 的编译依赖也装上了。 其它安装的东西么，除了 pelican 之外都是插件们需要的。以及我还需要生成 4 个语言的 locale 所以调用了 4 次 locale-gen 。由于是比较标准的 Ubuntu 环境，所以基本上编译的步骤和在本地 Linux 环境中是一样的，同样的这套配置应该可以直接用于本地 Ubuntu 下编译我的博客。 写好 .travis.yml 之后把它 push 到 github ，然后 travis 这边就会自动 clone 下来开始编译。 travis 上能看到编译的完整过程和输出，一切正常的话编译结束之后 build 的状态就会变成 passing ，比如 我的这次的build 。 从 Travis-CI 推往 Github 上面的测试编译通过了之后，下一步就是让 travis-ci 编译的结果自动推到 Github Pages 并发布出来。要推往 Github 自然需要设置 Github 用户的身份，在本地设置的时候是把 ssh key 添加到 github 账户就可以了，在编译细节都通过 github repo 公开了的 travis 上 当然不能放推送用的私有 key ，所以我们需要另外一种方案传递密码。 Github 上创建 Personal Access Token 好在 Github 支持通过 Personal Access Token 的方式验证，这个和 App Token 一样可以随时吊销，同时完全是个人创建的。另一方面 Travis-CI 支持加密一些私密数据，通过环境变量的方式传递给编译脚本，避免公开密码这样的关键数据。 首先创建一个 Personal Access Token ，这里需要勾选一些给这个 Token 的权限，我只给予了最小的 public_repo 权限，如侧边里的图。 生成之后会得到一长串 Token 的散列码。 如果你不能使用 travis 命令 2015年2月21日更新 使用 travis encrypt 命令来加密重要数据最方便，不过如果有任何原因， 比如 ruby 版本太低或者安装不方便之类的，那么不用担心，我们直接通过 travis api 也能加密数据。 第一步用这个命令得到你的repo的 pubkey ： curl -H \"Accept: application/vnd.travis-ci.2+json\" https://api.travis-ci.org/repos/<github-id/repo>/key | python2 -m json.tool | grep key | sed 's/.*\"key\": \"\\(.*\\)\"/\\1/' | xargs -0 echo -en | sed 's/ RSA//' > travis.pem 其中的 <github-id/repo> 替换成 github 上的 用户名/repo名， 比如我的是 farseerfc/farseer 。travis api 获得的结果是一个 json ，所以还用 python 的 json 模块处理了一下，然后把其中包含 key 的行用 grep 提取出来，用 sed 匹配出 key 的字符串本身，然后 xargs -0 echo -en 解释掉转义字符，然后删掉其中的 \"<空格>RSA\" 几个字（否则 openssl 不能读）， 最后保存在名为 travis.pem 的文件里。 有了 pubkey 之后用 openssl 加密我们需要加密的东西并用 base64 编码： echo -n 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' | openssl rsautl -encrypt -pubin -inkey travis.pem | base64 -w0 替换了相应的身份信息和token之后，这行得到的结果就是 secure 里要写的加密过的内容。 然后我们需要 travis 命令来加密这个 token ， archlinux 用户可以安装 aur/​ruby-travis ，其它用户可以用 gems 安装： $ gem install travis 装好之后，在设定了 Travis-CI 的 repo 的目录中执行一下 travis status ， 命令会指导你登录 Travis-CI 并验证 repo 。正常的话会显示最新的 build 状态。 然后同样在这个 repo 目录下执行： $ travis encrypt 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' 当然上面一行里的相应信息替换为个人的信息，作为这个命令的执行结果会得到另一长串散列码， 把这串散列写入刚才的 .travis.yml 文件： env : - secure : \"long secure base64 string\" 有了这段声明之后， Travis-CI 就会在每次编译之前，设置上面加密的环境变量。 然后在编译脚本中利用这些环境变量来生成博客： script : - git config --global user.email \"$GIT_EMAIL\" - git config --global user.name \"$GIT_NAME\" - git config --global push.default simple - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - git clone --depth 1 https://$GH_TOKEN@github.com/farseerfc/farseerfc.github.io output - env SITEURL=\"farseerfc.me\" make publish after_success : - cd output - git add -A . - git commit -m \"update from travis\" - git push --quiet 这里要注意最后 git push 的时候一定要加上 --quiet ，因为默认不加的时候会把 代入了 $GH_TOKEN 的 URL 显示出来，从而上面的加密工作就前功尽弃了…… 根据 travis 的文档 ， after_success 里写的步骤只有在 script 里的全都完全无错执行完之后才会执行，这正是我们 push 的条件。目前 after_success 的成功与否不会影响到 build 的状态。 具体我用的配置见 这里的最新版 。 在我的 make github 中 调用了 git push 命令，从而执行了 make github 之后就会自动部署到 github 上。 用 Web 编辑并发布静态博客 经过以上设置之后，一切正常的话，每次对主 repo 推送更新的同时， Travis-CI 就会自动 拉来更新然后编译并发布了。可以放置这样的图标 在项目的 Readme.md 中显示编译状态。 这样设置之后的另一个好处就在于可以利用 Github 的 Web 界面编辑文章内容。在 Github 里 编辑和保存之后会自动作为一个 commit 提交，所以也会触发 Travis-CI 的自动编译。 在 Github 的 Web 界面中直接编辑文章内容 以及虽然目前还没有好用的 Github 的手机客户端，不过直接用 Android/iPhone 的浏览器登录 github 并编辑文章的可用性也还不错，所以同样的方式也可以直接在手机上发布博文了。 That is all, happy blogging ~","tags":"tech","url":"//farseerfc.me/zhs/travis-push-to-github-pages-blog.html"},{"title":"从天气预报谈谈日本的学术氛围","text":"最近 mazk 说我 life 分类里的文章太少 ，所以想了想写了这篇。 很多人问过我为什么要来日本留学，嘛原因之一是我英语太差了，相对而言日语比较好。 另一方面，我比较喜欢日本的学术氛围。这个当然是主观体会，而不是客观的评价，只是我 觉得相对于 欧美喜欢研究基础架构技术 ， 日本则偏向实用层面 。 说个具体一点例子，最近看到这篇新闻说 卢布贬值影响中央气象台预报准确率？ ，其中提到： 因为卢布贬值，天气预报的准确率会有所降低 也说道： 不过经我多年的观察，中国中央气象台的预报准确率实在是不怎么样，具体到我生活的地区， 实际天气状况和中国中央气象台预报的出入较大…… 相信不少人也有类似的体会。 天气预报是事关人们生活的重要信息，其准确度对生产生活当然有很大影响。 说到增加天气预报的准确度，人们自然会想到高性能的超级计算机比如 天河二号 ，想到环绕在地球高空的 气象卫星 ，想到遍布世界各地的气象站观测台。想想这么多耗资不菲的高尖端项目被国家投入， 用来改善天气预报的准确程度，看起来这的确是一个困难的科研课题。 话说回来，准确预测气温、气压、湿度、降水概率等等这些事情对于生产生活固然重要， 不过对一般民众而言，天气预报最重要的作用就只是回答 明天我该穿多厚的衣服，出门是否需要打伞 这种问题。一年四季换衣服的时机其实并不那么频繁，气温提升五度或者降低两度这种程度下人们估计也 不能感觉得到，大体上只要根据「昨天穿什么衣服，昨天觉得冷不冷」就能作出判断。另一方面， 出门是否需要打伞 这样的问题的确只能依靠天气预报来回答。 那么解决 出门是否需要打伞 这个问题需要那么高尖端的技术么？ 我所在的大阪大学情报科学研究科有个已经毕业的学长 今城 健太郎 ( いまじょう けんたろう ) 就对此作出了解答。他的专业不是气象预测，而是图像分析处理，纯粹的计算机科学学科。 而他的本科毕业设计就着眼于「仅仅分析气象云图，能否高精度预测降水概率」， 其研究成果，就是一个叫 ないんたん 的降水概率预测系统 。 这个系统有数个会卖萌的Twitter机器人 @ninetan ，每时每刻对 其预测地区的降水情况做播报，同时也有详细的降水概率曲线图对 大阪 ( @ninetan_osaka )， 京都 ( @ninetan_kyoto )， 东京 ( @ninetan_tokyo )， 兵库 ( @ninetan_hyogo )， 和歌山 ( @ninetan_wakayam ) 的各个大学所在校区 两个半小时内做精确的降水概率预测。比如今天晚上大阪大学三个校区的降水概率图如下： 今天晚上大阪大学三个校区的降水概率图 从上面的图可以看出这个系统的预测精度是以 分为单位 的，可以看到 两个半小时内各地的降水量的大小。比如我可以根据这张图看出，我所在的吹田校区 将在 21时35分 开始有微弱的概率下起 0.1mm/h~1mm/h 的毛毛雨，到 22时05分 左右这个降水概率 爬升到最高大约45%，从而作出判断： 我最好在晚上九点左右离开学校回家，避免淋雨。 自从研究室的前辈给我介绍这个天气预报系统开始，我用了它两三年了，直观感觉是 这个系统的预测精度惊人得准确，基本上能接近 《魔法的禁书目录》中的「树形图设计者」 能做的天气预报的程度， 它说何时会下雨就一定下雨，它说何时雨停就一定雨停。同学们出门和回家的时候一般都会 看一眼这个天气预报然后决定是否出门。「啊今天晚上9点开始下雨所以早点回家」 或者「啊还有30分钟雨就停了，再在研究室里留一会儿」。 这只是一个本科生的毕业设计，所以覆盖面小（只有5所大学的十几个校区，只能预测 未来两个多小时的降水概率），不过仅此而已能做到如此的精度以至于实用，实在让我 惊讶。系统的测试之初就有人说： 最近ないんたん予报あたりすぎてないんたんが雨降らせてるんじゃないかという疑惑 — すみのネコ歩き (@sumi_eee) 2011 7月 6日 最近ないんたん预告实在太准了，甚至让人怀疑是不是ないんたん把雨招来的。 不过最近身边的日本人似乎已经把这个系统的准确当作习以为常了，就像日本的电车 掐着秒表准点到站一样，理所当然。 把天气预报这种高尖端的技术做到如此实用的地步，这基本上可以代表我对 日本学术界研究方式和研究目的的总体印象了。 嗯今天就写这么多，9点到了，我要按照天气预报的预测，准时回家了。 ——写于2015羊年除夕夜，9点。","tags":"life","url":"//farseerfc.me/zhs/weather-forcast-academic-in-japan.html"},{"title":"archlinux 上用 chrome 实现 透明计算 远程登录","text":"透明计算 具体是什么，因为他们没有公开技术细节所以我并不知道，只是看 公开出来的演示视频 ，感觉似乎只要能从手机上远程登录系统桌面，就能算是透明计算了。 如果透明计算真是这个意思，那么我似乎已经用着这个技术很多年了嘛。 Xorg 上常用的远程桌面工具有很多，基于 VNC 协议的、基于NX的和基于 RDP 协议的都能找到， 直接 ssh X forwarding 效果也不错。只是这些方案的一个 不太易用 的地方在于，需要 通过 ip 访问到远程的电脑，所以在跨越 NAT 之类的情况下不太容易使用。 于是今天介绍一个使用方便设置也简单的方法： 通过 chrome-remote-desktop 在 archlinux 上使用远程桌面。这个方案的优势在于，借助 Google 的云端服务器（内部貌似是XMPP协议下的握手） 方便地实现了 NAT 穿透，无论什么网络环境基本都能使用。当然，要支持远程登录， 位于远端的登录的计算机必须一直开着 Chrome Remote Desktop 的后台服务。 Chrome Remote Desktop 插件 Chrome Remote Desktop 的客户端 虽然可能有很多人不知道，不过 Chrome 内包括远程桌面的功能很久了。只是这个功能的界面默认 没有提供界面，要使用它需要安装 Google 官方出品的 remote-desktop 插件 。 装好之后远程桌面的客户端就准备好，可以用来远程访问别的计算机桌面了（无论是 Windows/OS X 还是 Linux 都支持）。并且不光可以自己远程访问自己账户的桌面，还可以远程协助朋友的桌面。 Archlinux 上设置远程登录的服务器 有了客户端之后还要设置一下才能让桌面作为远程登录的服务器。Windows 和 OS X 上 Chrome 会自动下载需要的安装包，无脑下一步就能装好了。Linux上由于发行版众多，桌面配置各异， 所以需要一点手动配置。官方的设置步骤记载在 这里 其中给出了 debian 用的二进制包和 Ubuntu 12.10 上的设置方式，以下设置是参考官方步骤。 首先要安装 chrome-remote-desktop 这个包，这个包实际上对应了 Windows/OS X 上用安装程序 安装的 Remote Desktop Host Controller。 archlinux 上开启了 [archlinuxcn] 仓库的话，可以直接安装打好的包。或者可以从 AUR 装。 $ pacman -Ss chrome-remote-desktop archlinuxcn/ chrome-remote-desktop 40.0.2214.44-1 Allows you to securely access your computer over the Internet through Chrome. 装好之后从会说这么一段话： groupadd：无效的组 ID \"chrome-remote-desktop\" Please create ~/.config/chrome-remote-desktop folder manually, if it doesn't exist, or else you can't use CRD. The needed files are created by the Chrome app, inside the chrome-remote-desktop folder, after Enabling Remote Connections. To {enable,start} the service use systemctl --user {enable,start} chrome-remote-desktop You may need to create a ~/.chrome-remote-desktop-session file with commands to start your session Go to https://support.google.com/chrome/answer/1649523 for more information. 那句报错是 AUR 里打的包还没跟上上游 Google 的更改导致的错误， 首先我们需要把远程登录的用户添加入 chrome-remote-desktop 这个用户组里。 新版本的 chrome remote desktop 提供了一个命令做这个事情，所以执行以下命令就可以了： $ /opt/google/chrome-remote-desktop/chrome-remote-desktop --add-user 然后我们需要手动创建 ~/​.config/​chrome-remote-desktop 这个文件夹，内容是空的 就好了，随后 chrome 会往这里面放 host#.json 文件用于身份验证。 $ mkdir ~/.config/chrome-remote-desktop 然后我们要创建一个 shell 脚本 ~/​.chrome-remote-desktop-session ，这是远程 登录时的 .xinitrc ，内容么就是启动你想在远程登录时用的桌面环境。 这里可以指定一个和你正在登录的 WM/DE 不同的桌面，比如我启动 xfce4： $ cat ~/.chrome-remote-desktop-session # !/bin/bash startxfce4 $ chmod 755 .chrome-remote-desktop-session 接下来需要从 Chrome 的插件里启用远程桌面。打开 Chrome 的 Remote Desktop 插件，这时 应该可以看到一个「启用远程链接」的按钮。 Chrome Remote Desktop 插件中「启用远程链接」的按钮 在撰写本文的时候， Archlinux 官方源里的 chromium 的版本和 aur/google-chrome 的版本尚且还是 40.0.2214.111 ，而 Chrome Web Store 中提供的 Chrome Remote Desktop 的插件的版本是 41.0.2272.41 。虽然通常并不要求两者版本一致，不过貌似最近 Chrome 内部的 Remoting 功能更改了 API 导致可能出问题。如果你找不到 「启用远程链接」的按钮，请尝试一下新版本的 Chrome 比如 google-chrome-dev 。 在这一步启用之后，老版本的 chrome 应该也就能使用远程桌面了。 在32位的 Linux 版本上，最近更新的 Chrome Remote Desktop 插件可能无法正确识别 Host 的版本，具体 参考这个 bug 。 点击「启用远程链接」，设定一个 PIN 密码（不需要很复杂，这里首先有 Google 帐号验证保证只有 你才能访问），然后就能看到这套电脑的 hostname 出现在「我的电脑」列表里。 启用远程链接之后的样子 同时，启用了远程链接之后，可以在刚刚创建的 ~/.config/chrome-remote-desktop 文件夹中找到记录了验证信息的文件。 $ ls .config/chrome-remote-desktop chrome-profile host#8cfe7ecfd6bb17955c1ea22f77d0d800.json pulseaudio#8cfe7ecfd6 然后就可以启动对应的 systemd 用户服务了，如果想自动启动服务要记得 systemctl --user enable ： $ systemctl --user start chrome-remote-desktop.service 如果上面的设置一切正常，就可以看到 chrome-remote-desktop 启动了另外一个 Xorg 执行你 刚刚指定的桌面环境： htop 中看到的 chrome-remote-desktop 启动的另外一个 Xorg 然后就可以试着通过 Remote Desktop 插件登录到这个新开的 Xorg 了： 「远程」登录到新的 XFCE4 Linux 版本的 Chrome远程桌面 和 Windows/ OS X 上的区别 通过上面的设置步骤也可以看出，Linux版本的远程桌面会在后台开一个独立的 X 会话，而不能 复用现在已有的 X 会话。对远程登录的用法而言这还能接受，对远程协助的功能而言有点问题， 因为正在使用的人不能观察协助者做了什么，协助者也不能继续请求协助的人的操作。 当然目前 Chrome 远程桌面的 Linux Host Controller 还只是 beta 版本，官方只测试支持 Ubuntu 12.04 和 12.10 （14.04之后似乎有 Bug ），所以不能要求太多。希望以后能改善吧。 Bonus： 手机远程登录 手机上的 Chrome 远程桌面 App 通过上面的设置就可以从任何一个 Chrome 远程桌面客户端登录刚刚设置的这台电脑了。 因为 Chrome 在三大桌面系统 Windows / OS X / Linux 上都有，所以应该能覆盖大多数桌面 系统了。 除了桌面的 Chrome 之外还有一个客户端是 Android 上的 Chrome 远程桌面 App 经过上面的设置之后，从这个 App 也能看到并登录： 手机远程登录 好啦，开始享受国家自然科学一等奖的透明计算技术吧！","tags":"tech","url":"//farseerfc.me/zhs/arch-chrome-remote-desktop.html"},{"title":"换到 farseerfc.me 域名","text":"上个月就在 狗爹 ( godaddy ) 上买了个自己的域名 farseerfc.me 准备用在这个 博客上，当时试着转到过这个域名，发现 自定义域名 ( custom domain ) 只支持 http 不支持 https ，想着还要买自己的证书，于是就扔在了一旁。不用自定义域名的话， 放在 github.io 上是可以用 HTTPS 的。 今天在 #archlinux-cn 上受大牛 quininer 和 lilydjwg 点播， 发现 cloudflare 有提供 免费的支持 SSL 的 CDN 服务 赶快去申请了一个，感觉非常赞，于是就换过来了。 设置的方法按照 这篇博文 说的一步步做下来，如它所述，用 CloudFlare 的优点如下： CDN 加速 SSL (HTTPS) 加密 支持 SPDY 协议 支持 IPv6 2015年12月29日更新 现在不光支持 SPDY 而且支持 HTTP/2 了。 然后 免费账户 的一些缺点有： CloudFlare 和 github.io 之间的数据不是加密的，因为 github 自定义域名 ( custom domain ) 还不支持使用自己的证书。这也是一开始我没用 自定义域名的原因嘛，这没有办法…… CloudFlare 给免费账户签名的 SSL 证书比较新，不支持一些老的设备和浏览器，比如不支持 老的 XP 系统的 IE 或者 2.x 的 Android。这种情况下没办法只能用没有加密的 HTTP 了。 不支持 HSTS 头 ，所以不能从服务器这边强制浏览器用 HTTPS。当然可以放个 javascript 跳转， 也可以用 HTTPSEverywhere 这种方案。 2015年12月29日更新 如评论中 提到的 现在支持 HSTS 了。 设置步骤 基本按照默认的选项下一步就可以了。 和那个博主一样我把 安全级别 ( Security profile ) 降到了 Low ，即使是可疑流量也 不会要求输入 CAPTCHA 。 把 SSL 方式开在 Flexible SSL，访客到 CloudFlare 是加密的，而 CloudFlare 到 github.io 是不加密的。 把 CDN 开到了 CDT+Full Optimization ，可以对访问加速。由于是完全静态的博客，没有 动态变化的内容，所以应该比较安全。 服务器设置的一步需要将 域名解析服务器 ( DNS nameservers ) 从狗爹的服务器改到 CloudFlare 的，如下图： 更改狗爹的域名服务器 申请好之后就由 CloudFlare 接管域名解析了，接下来在 CloudFlare 的 DNS 设置添加一条 A 类规则指向 github pages 的 IP 。 更改CloudFlare的DNS规则 等一切都反映到 DNS 服务器上就设置完成了，接下来给 farseerfc.github.io push 一个 CNAME 文件 写上我的域名就可以了。我用 Makefile 配合我的 pelican 配置做这个： publish : rmdrafts cc clean theme [ ! -d $( OUTPUTDIR ) ] || find $( OUTPUTDIR ) -mindepth 1 -not -wholename \"*/.git*\" -delete rm -rf cache echo $( SITEURL ) > content/static/CNAME $( PELICAN ) $( INPUTDIR ) -o $( OUTPUTDIR ) -s $( PUBLISHCONF ) $( PELICANOPTS ) $( MAKE ) rsthtml github : ( cd $( OUTPUTDIR ) && git checkout master ) env SITEURL = \"farseerfc.me\" $( MAKE ) publish ( cd $( OUTPUTDIR ) && git add . && git commit -m \"update\" && git push ) SITEURL = '//' + getenv ( \"SITEURL\" , default = 'localhost:8000' ) STATIC_PATHS = [ 'static' , 'images' , 'uml' , 'images/favicon.ico' , 'static/CNAME' ] EXTRA_PATH_METADATA = { 'images/favicon.ico' : { 'path' : 'favicon.ico' }, 'static/CNAME' : { 'path' : 'CNAME' } } 然后把生成的静态网站 push 到 github 之后可以从项目设置里看到域名的变化： Github 配置好自定义域名之后的变化 最后把Disqus的评论也迁移到新的域名，disqus有方便的迁移向导，一直下一步就可以了。 这样就一切都设置妥当了。 致谢 最后要感谢提供消息的 quininer 和 lilydjwg ，感谢撰写设置步骤的 Jonathan J Hunt ， 感谢 CloudFlare 提供免费 SSL CDN 服务，感谢 Github 提供 方便免费的 Pages 托管。","tags":"tech","url":"//farseerfc.me/zhs/switch-to-farseerfc-dot-me-domain.html"},{"title":"重新设计了 Pelican 的主题与插件","text":"2015年2月14日更新 前言: 新天新地，将一切都更新了 [1] 不知不觉间放任这边长草很久了，从上次 折腾主题 到现在都快三年了， 而从上次 写了篇告白信 到现在也有快两年了。 这期间曾经把主题配色从 Bootstrap 2 默认的 白底黑字改成了让眼睛更舒适的黑底白字，也不过是用 drop-in 的配色方案而已，没有本质上的改进。 洞中一日世上千载，两年里 Bootstrap 已经升上 v3.3 , 而 Pelican 则已经升到 3.5 了。 早就眼馋 Bootstrap 和 Pelican 中的诸多新功能新设计，不过无奈于时间有限只能饱饱眼福。 近日想写的东西越积越多，终于下定决心花了前前后后 两个月 的时间重新设计了一遍 Pelican 的主题，配合一些我觉得有用的插件。于是本博客就变成你们现在看到的样子了。 （以及本篇博文也用了两个月的时间写完，其间还发了几篇别的短文，算是恢复写博客的尝试吧。） 在迈阿密参加 ICSR 2015 的时候 拍到的街边一家叫 Pelican 的旅馆 Bootstrap 3 的新设计 全新的 优先移动设备 ( mobile-first ) 响应式 ( responsive ) 设计。 原本Bootstrap 2虽然有响应式设计， 不过诸多细节不能符合我的需求，最终还是得手工 hack @media 查询去微调。 现在的 优先移动设备 ( mobile-first ) 响应式 ( responsive ) 栅格系统 ( grid system ) 则相对显得科学很多了，也终于能在手持 设备上看起来舒服一些。诸位可以尝试改变窗口宽度，或者在不同的手持设备上打开这个 blog ，体验一下这个页面在不同显示器大小中的效果。如果仍有问题欢迎 发 Issue 给我 。 科学的 导航栏 ( Navbar ) 。 比 Bootstrap 2 那个科学很多了。无论是 保持 ( sticky ) 在上端还是跟着浮动， 或者像这边这样 自动隐藏 都很简单。 更多细节参考 Bootstrap 3 主页 。 Pelican 3.5 的新功能 Python 2 和 Python 3 统一代码： 再没有恼人的 unicode 相关的问题了。这对 blog 系统来说相当重要啊。 而且还能方便切换 pypy 等不同的解释器。 全新的插件系统：非常多功能强大的 插件 等着你。 增强了导入系统：嗯总算可以导入我的中文的 wordpress 博客了。（虽然那边长草更久了……） 站内链接 ：不用 硬编码 ( hard code ) 目标页面的链接了，可以直接写源文件的位置然后让 pelican 处理，这样能简化各种 插件 ( plugin ) 和 主题 ( theme ) 的实现。 更多细节参考 Pelican 文档 。 新的文件夹布局 Pelican 的新文件夹布局 . ├── cache 生成页面的 pickle 缓存 ├── content 读取的全部内容 │ ├── <categories> 按分类存放的文章 │ ├── pages 像 About 这样的固定页面 │ └── static 文章内用到的静态内容 ├── drafts 文章的草稿箱 ├── Makefile 生成用的 makefile ├── pelicanconf.py 测试时用的快速 Pelican 配置 ├── publishconf.py 部署时用的耗时 Pelican 配置 ├── output -> ../farseerfc.github.io ├── plugins -> ../pelican-plugins └── theme -> ../pelican-bootstrap3 之前的博客 仍然留在 github 上，其中的内容完全搬过来了。开始写老博客的时候 Pelican 版本较早，没有形成好的 文件夹布局，导致生成的文章、使用的模板和撰写的内容全都混在一起，非常难以管理， 于是趁改版之际用了新的文件夹布局方式，并分为 4 个 git repo 分别管理历史。 首先是存放 总的博客内容的 repo ， 其布局是如图那样的。这样将生成的静态网站和生成网站用的配置啦内容啦分开之后，顿时清晰了很多。 然后这个内容 repo 中的三个符号链接分别指向三个子 repo（没用 git submodule 管理纯粹是因为偷懒）。 theme 指向 pelican-bootstrap3 ，是我修改过的 pelican 主题。 plugins 指向 pelican-plugins ，由于 plugins 的质量有些参差不齐，其中不少 plugin 都按我的需要做了些许修改，一些是功能改进，另一些则是修bug（比如不少plugin只支持 python 2）。 最后 output 指向 farseerfc.github.io 也就是发布的静态网站啦。 接下来从 主题 和 插件 两个方面介绍一下改版的细节。 主题： Material Design 风格的 Bootstrap 3 上篇 博文 就总结了我为了这个博客寻找了一堆 CSS 框架，并且最终决定用 bootstrap-material-design , DandyDev/pelican-bootstrap3 和 Bootstrap 3 这三个项目结合的方式实现这个模板的主题。 这三个项目都或多或少经过了我的修改，修改后的项目以 pelican-bootstrap3 为基础放在 这里 ，包括 Bootstrap3 样式 和 Material 样式 。 对 Bootstrap 3 的定制 由于架构完善，修改 Bootstrap 3 感觉非常简单。另一方面我在 Web 前端技术上的技能点也不多， 所以修改的地方非常有限，只能按我自己的需求定制而已。 响应式设备的大小 修改了 Bootstrap 3 响应式设备的大小 @ screen-xs : 320px ; @ screen-sm : 598px ; /* 768px; */ @ screen-md : 952px ; /* 992px; */ @ screen-lg : 1350px ; /* 1200px; */ @ screen-xl : 2030px ; @ container-sm : 582px ; /* 750px; */ @ container-md : 930px ; /* 970px; */ @ container-lg : 1320px ; /* 1170px; */ @ container-xl : 1990px ; 首先把 Bootstrap 3 默认适配的几个 响应式设备的大小 改成了我需要的大小。 xs 和 sm 的大小分别按照我的手机屏幕 竖屏 和 横屏 时候的浏览器页面宽度来算， md 是想兼容 Nexus 7 横屏 960 的宽度以及 一个常见上网本 1024 的宽度。 lg 的大小则按照常见的笔记本 1366 宽的屏幕来适配。 这里 Bootstrap 3 支持的设备大小的一个问题是，它最多考虑到 1200 像素宽的显示器，而更宽的 比如 1600、 2048 甚至 2560 像素宽的显示器现在也并不少见，其结果就是页面中左右两侧 有很大的空间被浪费掉了。作为深受这一问题困扰的用户之一，我用 这里介绍的方法 给 bootstrap 增加了一类「 比大更大 ( bigger than bigger ) 」的 xl 响应式设备尺寸，宽度设为支持 2048 像素宽的显示器，具体的修改反映在 variables.less 文件里。 根据宽度自动分栏和瀑布式布局 接下来目标是让主页的文章列表像 Google+ 主页那样根据显示器宽度自动调整分栏，使得宽度不同的 显示器上每个分栏的宽度接近。想要达到的效果是，根据上面定义的屏幕宽度尺寸： xs 用单栏 流动 ( fluid ) 布局 sm 用上方单栏文章列表、下方双栏 侧边栏 ( sidebar ) 固定布局 md 用单栏文章列表、单栏 侧边栏 固定布局 导航栏 ( Navbar ) 文章 侧边栏 底栏 导航栏 文章 侧边栏 1 侧边栏 2 底栏 ( footer ) 导航栏 文章 1 侧边栏 1 文章 2 侧边栏 2 底栏 ( footer ) lg 用双栏文章列表、单栏 侧边栏 固定布局 xl 用三栏文章列表、双栏 侧边栏 固定布局 导航栏 文章 1 文章 3 侧边栏 1 文章 2 文章 4 侧边栏 2 底栏 ( footer ) 导航栏 文章 1 文章 3 文章 5 侧边栏 1 文章 2 文章 4 文章 6 侧边栏 2 底栏 ( footer ) 一开始纯粹用 Bootstrap3 的响应式栅格实现这个分栏布局，结果发现效果不太理想， 因为文章列表和侧边栏的高度是变化的，会导致栅格间留下大片空白。后来改用 这里示范的纯CSS瀑布式布局 实现文章和侧边栏的布局，具体的实现代码在 waterfall.less ，总算达到了想要的布局了。 正文的样式 最最重要的是文章正文的样式。这里我想要达到的效果是，在大屏幕上用更大的字号，让读者 看起来更舒适，同时在小屏幕上用比较小的字号，最终保证基本上「一行」的文字数接近。这个修改 主要针对 .jumbotron ， 用了 不太科学的方式 代码太长就不贴全了。 一些细微的定制 把主题配色改成了现在这样的淡紫色 @brand-primary: darken(#6B5594, 6.5%); ，配合我的头像风格， 这个修改只需要一行。 接着删掉了 .btn 的 white-space: nowrap; 让按钮的文字可以换行， 这也只是一行修改。 2015年1月29日更新 另外我也不太喜欢 Bootstrap 3 默认在手机上的 折叠导航栏 ( collapsed navbar ) ， 折叠之后的操作不够直观方便而且依赖 javascript 所以有 bug …… 于是我把它关掉了， 具体方式是在 variables.less 把 @grid-float-breakpoint 和 @grid-float-breakpoint-max 都设为0就可以了。 对 bootstrap-material-design 的定制 这里定制的地方不多。原样式中一个不太科学的做法是所有 .btn 都强制加上了阴影 效果，这在已经有阴影的环境里用的话非常碍眼，像是 Win9x 风格的厚重睫毛膏。既然可以单独 给每个样式加阴影，于是就把 .btn 强制的阴影去掉了，只保留鼠标悬停之后强调的阴影。 其它定制的细节么就是统一配色风格，修补漏洞错误，微调响应式效果而已，这里不细说。 将以上两者整合在 pelican-bootstrap3 里 Pelican 实现显示源代码按钮 显示源代码按钮借用了 Pelican 配置中自带的 OUTPUT_SOURCES 选项将源文件复制到输出文件夹： OUTPUT_SOURCES = True OUTPUT_SOURCES_EXTENSION = '.rst' 然后在 Makefile 里用 pygmentize 把所有源代码文件着色： find -iname \"*.rst\" | parallel -I@ pygmentize -f html -o @.html @ 最后在按钮按下的时候用 jQuery 载入源代码： < a onclick = \"$.get('{{SITEURL}}/{{article.slug}}.rst.html', function(data){$('#source-code').html(data)});$('#article-content').toggle();$('#source-content').toggle();\" > 虽然难看的 hack 比较多，但是能用！ 虽说 pelican-bootstrap3 是我 fork 出来的，不过由于我修改的地方实在太多，代码看来基本上 接近重写了一份。好在之前有给 pelican 写 bootstrap 2 主题的经验，这次修改算得上驾轻就熟。 可以对比一下 上游作者的博客 和这里的样子体会一下感觉。 具体修改过的地方包括： 套用 bootstrap-material-design 的各个元素样式。 在文章列表模板应用上面提到的 Bootstrap 3 的栅格布局和瀑布式布局。 翻译到多个语言，这里在后面的 i18n-subsite 插件里详述。 套用后面会介绍到的各种插件。 统一侧边栏的样式到一个模板里。 添加 Atom 订阅按钮和 breadcrumb 条。 对正文中出现的插图，添加点击放大的功能，通过 Bootstrap 的 modal 实现。 上面提到的用 这个bootstrap插件 让导航栏自动隐藏。 显示源代码按钮 ，也就是每篇文章信息栏中的 按钮。 插件: 发挥 Pelican 和 reStructuredText 的优势 先列举一下我目前用到的所有插件： PLUGINS = [ \"i18n_subsites\" , \"plantuml\" , \"youku\" , \"youtube\" , 'tipue_search' , 'neighbors' , 'series' , 'bootstrapify' , 'twitter_bootstrap_rst_directives' , \"render_math\" , 'extract_toc' , 'summary' ] 嗯其实不算多。接下来逐一介绍一下这些各具特色的插件。 i18n-subsites 这个插件的目的是创建 国际化 ( internationalization ) 子站 ( subsite ) 。 之前介绍 Pelican 配置的时候就提到过， 原本的 Pelican 就支持一篇文章用多种语言书写，有 lang 属性注明这篇文章使用的 语言，以及 slug 属性注明多语言的翻译之间的关联，换句话说同一篇文章的多个语言 版本应该有相同的 slug 和不同的 lang 。然后原本 Pelican 里对多语言的 实现方式是，首先有一个 主语言 是模板和大部分文章采用的语言，文章列表中会优先列出 用 主语言 撰写的文章，然后从 主语言 的文章链接到别的翻译版本。 很多博客系统和CMS对多语言的支持都是这样的，这种处理方式的缺点也显而易见：作为 主语言 的语言必须足够通用，才能让进来的人找到合适的翻译版本，所以通常 主语言 都是英语。 而这个插件做的事情描述起来很简单：将文章按语言属性分到多个子站，每个子站独立放在各自的文件夹。 比如主站是 https://farseerfc.github.io/ 的话，那么英语的子站就可以是 https://farseerfc.github.io/en/ 。 然后分别对多个子站生成静态页面。具体的实现方式是对 pelican 的页面生成步骤做了拆分： pelican 按正常情况读入文章，生成元信息。 i18n-subsites 针对每个语言，覆盖掉 pelican 的一些选项设置比如路径和 URL ， 分别调用 pelican 的页面生成器按模板生成文章。 对共用的静态内容比如模板的 js 和 css 文件，只在主站中生成，子站中的相应链接全部链回主站。 虽然描述起来简单，但是这个插件可以说最大化利用了 Pelican 的插件系统，实现细节相对比较 复杂，大概是我用的这些插件里面最复杂的了。不夸张的说 Pelican 3.4 支持的新插件 API 和 站内链接功能基本上就是为了配合这个插件的。至于具体它会覆盖哪些 Pelican 的配置，请参阅它的 README.md文件 。 按内容拆分多语言子站的做法只解决了问题的一半，还留下另一半的问题，也即对模板的翻译。 对这个问题， i18n-subsites 提供了两套方案供选择： 用覆盖配置路径的方式让每个子站套用不同的模板。这配置起来简单，但是对模板维护起来有点困难。 用 jinja2 的 i18n 插件，配合 Python 的 gettext 库实现内容翻译。这个方案 配置起来比较复杂 ，但是配置好之后用起来就很方便了。 只是要记得每次修改了模板都要更新翻译，处理 *.po 和 *.mo 文件等等琐碎事宜。 这里我用 jinja2 的 i18n 插件的方式实现了模板的翻译， 各个语言的翻译在这里 ， 然后用 这里的 SCons 脚本 根据内容是否变化自动更新 po 和 mo 文件。 配置好这一套方案之后，还要注意在模板和文章中处理好链接。用 Pelican 3.4 之后推荐的 新的文章间链接的写法以及将 SITEURL 设置为实际 URL 并且关闭 RELATIVE_URLS 之后，应该就不会出没什么问题了（可能还要考虑使用的模板和插件的兼容性，大部分都是写死了 URL 的问题）。 plantuml 嵌入 PlantUML 的示例 PlantUML 是一个Java实现的， 用接近文字描述的语言绘制 UML 图或者 GUI 界面图的工具，非常适合嵌入在 Markdown、 reStructuredText、 AsciiDoc 等这种轻量级标记语言里。 然后么这个 plantuml 插件就是定义了一个新的 reStructuredText 指示符 ( directive ) .. uml:: ，把嵌入的内容提取出来调用 plantuml 命令处理 成图像然后再插入到文章中。 比如示例里的这个 UML 图就是用这样一段简单的文字描述生成的： .. uml :: Object <|-- ArrayList Object : equals() ArrayList : Object[] elementData ArrayList : size() 实际用起来这个插件实现上稍微有点小问题：首先它只支持 python2，所以我把它改写成了 python 2 和 3 都通用的语法；其次它原本输出的文件夹似乎会被 pelican 删掉，所以把它改了个位置； 然后它输出的 URL 也和 i18n-subsites 插件间有不兼容的问题，也顺带修掉了。 修改之后的代码在这里 。 2015年1月30日更新 嵌入 Ditaa 的示例 plantuml 是绘制UML的，除此之外还有一个类似的工具是绘制一般的 流程图 ( diagram ) 的，叫 ditaa ，和 plantuml 非常像，也比较像 reStructuredText 的表格。 于是我也照猫画虎实现了一个 ditaa 的 指示符 ( directive ) ，用起来类似这样： .. ditaa :: +-------------+ | ditaa |-------+ | Diagram | | +-------------+ | PNG out &#94; | | ditaa in | | v +--------+ +--------+----+ /----------------\\ | | --+ Pelican +--> | | | Text | +-------------+ | Beautiful Blog | |Document| | !magic! | | | | {d}| | | | | +---+----+ +-------------+ \\----------------/ : &#94; | Lots of work | +-----------------------------------+ render-math 嵌入公式的示例 示范行内公式 \\(A_\\text{c} = (\\pi/4) d&#94;2\\) . 整行公式 \\begin{equation*} \\alpha{}_t(i) = P(O_1, O_2, \\ldots O_t, q_t = S_i \\lambda{}) \\end{equation*} 这个插件提供在 reStructuredText 中用 LaTeX 语法插入数学公式的能力，定义了 :math: 行内角色 ( role ) 和 .. math:: 指示符 ( directive ) 。 实际工作的渲染库当然是大名鼎鼎的 MathJax ，这个插件 会用 MathJax 的 CDN 载入，所以也没有额外的依赖文件。（只是不知道是否会被国内墙掉， 如果公式显示不正常请 务必 告诉我。） youtube 和 youku 顾名思义，这两个插件分别实现嵌入 youtube 和 youku 视频。其中 youtube 是原本就有的插件， youku 是我照猫画虎抄的。 之前写了一篇 KDE5 Plasma 之跳动卖萌的活动按钮 用到了这两个插件。 tipue_search Tipue search 是一个非常有意思也很强大的搜索工具， 通过 jQuery 实现静态博客的站内搜索功能。实现方式是，它需要你写一个 json 文件，包含 整个网站的 全部 文章的标题和文字内容，然后在搜索的时候读入这个 json 做搜索（是不是有点耍赖）。 虽然听起来会有性能问题，但是应用在小型的静态博客上效果意外很不错，比如本站的所有文章内容 放在一起的 json 也只有 300KiB 左右。 这个插件就是自动在 pelican 输出完全部静态网页之后，调用 beautifulsoup4 从所有网页中抽取出 纯文本，产生这个 json 给 Tipue 用。 neighbors 和 series 这两个插件比较类似也都比较简单， neighbors 提供一篇文章的前后文章信息， 在主题模板里可以用来制作 上一篇 和 下一篇 按钮。 series 提供将多篇文章归类为一个 系列 的支持，当然也需要在 主题模板中定义显示「文章系列」的列表。这两个插件的效果都能在本文末尾，评论区上方的部分看到。 bootstrapify 和 twitter_bootstrap_rst_directives 这两个插件让文章的 正文 套用上 Bootstrap 的样式。 bootstrapify 这个插件实现得比较简单，用 beautifulsoup4 在静态网页的结果里面过滤元素， 对 table , img , embed , iframe , video , object 这几个标签套用上 响应式嵌入对象的类 让他们更美观。 twitter_bootstrap_rst_directives 这个插件则是增加了几个 reStructuredText 的 行内角色 ( role ) 和 指示符 ( directive ) 。 它实现的 行内角色 ( role ) 包括： 用 :kbd: 实现如 Ctrl+C 这样的键盘快捷键， 用 :code: 嵌入代码片段，用 :glyph: 嵌入字符图标。 它实现的 指示符 ( directive ) 包括： labels 行内标签 ， alerts 提示段落 ， panels 嵌入面板 ， 以及还有一个 media 混排图标 。 对其中的 panel 我改写了它在文章正文中的样式，在 lg 或者 xl 的屏幕宽度下，分别用 \\(\\frac{1}{2}\\) 和 \\(\\frac{1}{3}\\) 大小的嵌入面板， 简单实现和正文文字的图文混排。 除此以外我还在 twitter_bootstrap_rst_directives 这个插件里套用它的框架实现了两个额外 的 行内角色 ( role ) ， 分别是 :ruby: ：通过 html5 的 <ruby> 标签实现文字上方的注音（firefox下 不支持 ，会使用文字后的括号显示）， 以及 :html: ：在 行内插入 裸 ( raw ) html 标签（这属于 Markdown 的基本功能，在 reStructuredText 这边由于要考虑多种输出格式于是就比较麻烦了）。这两个 行内角色 ( role ) 的 实现代码在这里 。 2015年2月3日更新 今天又在 twitter_bootstrap_rst_directives 里增加了两个 行内角色 ( role ) 。 一个是 :twi: 用来写 twitter 用户的链接，比如 @farseerfc ，另一个是 :irc: 用来指向 freenode 的 channel ，比如 #yssyd3 。 2015年2月14日更新 今天增加了 .. friend:: 用来写好友链接，以及 fref 用来引用好友， 比如 LQYMGT 这样。 extract_toc 和 summary 最后是这两个有点「名不副实」的插件。 reStructuredText 原本就有自动生成 目录 ( toc ) 的功能，用起来也非常简单，只需要在想要插入目录的地方写一行 .. contents:: ，剩下的都由 docutils 自动生成了。 只是当然这样生成的目录肯定会插入在文章的正文里，而 extract_toc 这个插件的作用就是简单地 把这个目录抽取出来，让模板能在别的地方放置这个目录。比如我这里就把目录放在了一个 panel 里。 然后 Pelican 也原本就有从文章中抽取 总结 ( summary ) 显示在文章列表的功能。 Pelican 原始的实现似乎是按照文字数抽取前半段，不总是适合作为总结。 于是这个 summary 插件的作用其实是允许在正文中以特殊的注释的方式标注哪些部分应该被抽出来作为总结。 summary 这个插件原本的实现只允许抽取一段文字，我又对它的实现做了少许扩充，允许标注多段 文字合并起来作为总结。 2015年1月29日更新 今天在 extract_toc 插件的帮助下，在侧边栏里放了一个 Bootstrap affix 的目录， 它保持在页面的右侧位置不变，方便导航到文章的各个地方。具体实现方法除了 Bootstrap 3 的 Affix 文档 ，还参考了 这篇更详细的说明 。 结语 这个博客的配置都可以在 github 上找到 ，包括用来 自动生成整个博客的 Makefile ，由于比较长，这里就不再贴了。 折腾这个主题前后历时两个月，期间学会了不少东西，也算是不错的收获吧。 现在既然基础打好了，接下来就要开始多写博客了。（希望拖延症不会再犯……） 最近发现除了我的博客之外还有一个网站 Kansas Linux Fest fork 了我的主题，不过他们用了我修改的早期版本，还是原本的 Bootstrap 3 和 bootstrap-material-design 样式。自己草草修改的东西被别人用到果然还是有点小激动呢， 以及接下来不能马马虎虎地写 commit 消息了。 [1] 赛65:17「看哪！我造新天新地」启21:5「我将一切都更新了。」","tags":"tech","url":"//farseerfc.me/zhs/redesign-pelican-theme.html"},{"title":"总结一下 Material Design 的 CSS 框架","text":"现在这里的界面风格要从 Google 在 I/O 2014 大会 上公布Android L 也即 后来的 Lollipop 说起。 他们在谈论界面设计的时候公布了他们的 设计准则： Material Design ( 中文非官方翻译 )。 当然这只是一些准则，总结并描述了之前在 Web 设计和移动端 App 界面设计方面的一些规范， 并且用材料的类比来形象化的比喻这个准则。关于 Material Design 的更多中文资料可 参考这里 。 看到 Material Design 之后就觉得这个设计风格非常符合直觉，于是想在这边也用上 Material Design。 但是我在 Web 前端科技树上没点多少技能点，所以想找找别人实现好的模板 或者框架直接套用上。在网络上搜索数日找到了这几个： Polymer Paper Elements Polymer Polymer logo Google 官方提供的参考实现应该是 Polymer 中的 Paper Elements 。 由于是 官方参考实现 ，这个框架的确非常忠实地实现了 Material Design 的设计，但是同时 由于它基于 HTML5 Web Components 构建，相关技术我还 不太懂，浏览器兼容性和其余 HTML 技术的兼容性也还不太完善的样子…… 并且对于我这个 Web 开发的半吊子来说，Polymer 只是提供了一组设计组建，没有完善的 响应式 (responsive) 布局支持，也没有 Navbar 这种常见的框架组建，真的要用起来的话还 需要手工实现不少东西。于是口水了半天之后只好放弃……以后可能真的会换用这个，只是目前需要学 的东西太多了。 Angular Material Design AngularJS AngularJS 是 Google 对 Web Components 技术的另一个 尝试。而这额 Angular Material Design 项目 就是基于 AngularJS 构建的Material Design 库啦，同样是 Google 出品所以应该算得上半个 官方实现吧。 相比于 Polymer, AngularJS 算是实用了很多，提供了基于 CSS Flexbox 的布局。有人对这两者的评价是， 如果说 Polymer 代表了 未来趋势 ，那么 AngularJS 就是 眼下可用 的 Web Components 实现了。 只不过同样是因为它是 Components 的框架，对 WebApp 的支持很丰富，大量采用 Ajax 等 JavaScript 技术， 对于我这个静态博客来说仍然稍显高级了……非常担心还不支持 HTML5 的浏览器 比如 w3m 甚至 cURL 对它的支持程度。 于是最终也没有使用它。 Materialize Materialize Materialize 这是一批(自称?)熟悉 Android 上 Material Design 的设计师们新近出炉的框架，试图提供一个接近 Bootstrap 的方案。 最早是在 Reddit 上看到对它的讨论的，立刻觉得这个想法不错。 体验一下官网的设计就可以看出，他们的动画效果非常接近 Polymer 的感觉，响应式设计的布局 也还不错。 只是同样体验一下他们现在的官网就可以看出，他们目前的 bug 还比较多 ，甚至一些 bug 在他们自己的主页上也有显现。 虽然不想给这个新出炉的项目泼凉水，不过看来要达到他们声称的接近 Bootstrap 的易用度还任重而道远…… bootstrap-material-design + bootstrap3 这是我最终选择的方案。这个方案将三个项目组合在了一起，分别是 bootstrap-material-design , pelican-bootstrap3 和 Bootstrap 3 。 Bootstrap 3 想必不用再介绍了，很多网站都在使用这套框架，定制性很高。 bootstrap-material-design 是在 Bootstrap 3 的基础上套用 Material Design 风格 制作的一套 CSS 库，当然也不是很完善并且在不断改进中，一些细节其实并不是很符合我的要求。 最后 pelican-bootstrap3 是用 Bootstrap 3 做的 pelican 模板。 这三个项目或多或少都有点不合我的口味，于是嘛就把 pelican-bootstrap3 fork了一套放在 这里 ，其中还包括我自己改 过的 Bootstrap3 样式 和 Material 样式 ，需要的可以自取。 至于细节上我定制了哪些地方，敬请听下回分解……","tags":"tech","url":"//farseerfc.me/zhs/summarize-material-design-css-framework.html"},{"title":"从非缓冲输入流到 Linux 控制台的历史","text":"这篇也是源自于水源C板上板友的一个问题，涉及Linux上的控制台的实现方式和历史原因。因为内容比较长，所以在这里再排版一下发出来。 原帖在这里 。 可以设置不带缓冲的标准输入流吗？ WaterElement(UnChanged) 于 2014年12月09日23:29:51 星期二 问到： 请问对于标准输入流可以设置不带缓冲吗？比如以下程序 #include <stdio.h> #include <unistd.h> int main ( int argc , char * argv []) { FILE * fp = fdopen ( STDIN_FILENO , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 似乎还是需要在命令行输入后按回车才会让 fgets 返回，不带缓冲究竟体现在哪里？ 这和缓存无关，是控制台的实现方式的问题。 再讲细节一点，这里有很多个程序和设备。以下按 linux 的情况讲： 终端模拟器窗口（比如xterm）收到键盘事件 终端模拟器(xterm)把键盘事件发给虚拟终端 pty1 pty1 检查目前的输入状态，把键盘事件转换成 stdin 的输入，发给你的程序 你的程序的 c 库从 stdin 读入一个输入，处理 标准库说的输入缓存是在 4 的这一步进行的。而行输入是在 3 的这一步被缓存起来的。 终端pty有多种状态，一般控制台程序所在的状态叫「回显行缓存」状态，这个状态的意思是: 所有普通字符的按键，会回显到屏幕上，同时记录在行缓存区里。 处理退格( BackSpace )，删除( Delete )按键为删掉字符，左右按键移动光标。 收到回车的时候把整个一行的内容发给stdin。 参考： http://en.wikipedia.org/wiki/Cooked_mode 同时在Linux/Unix下可以发特殊控制符号给pty让它进入「raw」状态，这种状态下按键 不会被回显，显示什么内容都靠你程序自己控制。 如果你想得到每一个按键事件需要用raw状态，这需要自己控制回显自己处理缓冲， 简单点的方法是用 readline 这样的库（基本就是「回显行缓存」的高级扩展，支持了 Home/End，支持历史）或者 ncurses 这样的库（在raw状态下实现了一个简单的窗口/ 事件处理框架）。 参考： http://en.wikipedia.org/wiki/POSIX_terminal_interface#History 除此之外， Ctrl-C 转换到 SIGINT ， Ctrl-D 转换到 EOF 这种也是在 3 这一步做的。 以及，有些终端模拟器提供的 Ctrl-Shift-C 表示复制这种是在 2 这一步做的。 以上是 Linux/unix 的方式。 Windows的情况大体类似，只是细节上有很多地方不一样： 窗口事件的接收者是创建 cmd 窗口的 Win32 子系统。 Win32子系统接收到事件之后，传递给位于 命令行子系统 的 cmd 程序 cmd 程序再传递给你的程序。 Windows上同样有类似行缓存模式和raw模式的区别，只不过实现细节不太一样。 strace查看了下 WaterElement(UnChanged) 于 2014年12月10日21:53:54 星期三 回复： 感谢FC的详尽解答。 用strace查看了下，设置标准输入没有缓存的话读每个字符都会调用一次 read 系统调用， 比如输入abc： read(0, abc \"a\", 1) = 1 read(0, \"b\", 1) = 1 read(0, \"c\", 1) = 1 read(0, \"\\n\", 1) = 1 如果有缓存的话就只调用一次了 read 系统调用了： read(0, abc \"abc\\n\", 1024) = 4 如果想感受一下 raw mode 没错，这个是你的进程内C库做的缓存，tty属于字符设备所以是一个一个字符塞给你的 程序的。 如果想感受一下 raw mode 可以试试下面这段程序（没有检测错误返回值） #include <stdio.h> #include <unistd.h> #include <termios.h> static int ttyfd = STDIN_FILENO ; static struct termios orig_termios ; /* reset tty - useful also for restoring the terminal when this process wishes to temporarily relinquish the tty */ int tty_reset ( void ){ /* flush and reset */ if ( tcsetattr ( ttyfd , TCSAFLUSH , & orig_termios ) < 0 ) return - 1 ; return 0 ; } /* put terminal in raw mode - see termio(7I) for modes */ void tty_raw ( void ) { struct termios raw ; raw = orig_termios ; /* copy original and then modify below */ /* input modes - clear indicated ones giving: no break, no CR to NL, no parity check, no strip char, no start/stop output (sic) control */ raw . c_iflag &= ~ ( BRKINT | ICRNL | INPCK | ISTRIP | IXON ); /* output modes - clear giving: no post processing such as NL to CR+NL */ raw . c_oflag &= ~ ( OPOST ); /* control modes - set 8 bit chars */ raw . c_cflag |= ( CS8 ); /* local modes - clear giving: echoing off, canonical off (no erase with backspace, &#94;U,...), no extended functions, no signal chars (&#94;Z,&#94;C) */ raw . c_lflag &= ~ ( ECHO | ICANON | IEXTEN | ISIG ); /* control chars - set return condition: min number of bytes and timer */ raw . c_cc [ VMIN ] = 5 ; raw . c_cc [ VTIME ] = 8 ; /* after 5 bytes or .8 seconds after first byte seen */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 0 ; /* immediate - anything */ raw . c_cc [ VMIN ] = 2 ; raw . c_cc [ VTIME ] = 0 ; /* after two bytes, no timer */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 8 ; /* after a byte or .8 seconds */ /* put terminal in raw mode after flushing */ tcsetattr ( ttyfd , TCSAFLUSH , & raw ); } int main ( int argc , char * argv []) { atexit ( tty_reset ); tty_raw (); FILE * fp = fdopen ( ttyfd , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 终端上的字符编程 vander(大青蛙) 于 2014年12月12日08:52:20 星期五 问到： 学习了！ 进一步想请教一下fc大神。如果我在Linux上做终端上的字符编程，是否除了用ncurses库 之外，也可以不用该库而直接与终端打交道，就是你所说的直接在raw模式？ 另外，终端类型vt100和linux的差别在哪里？为什么Kevin Boone的KBox配置手册里面说必 须把终端类型设成linux，而且要加上terminfo文件，才能让终端上的vim正常工作？term info文件又是干什么的？ Linux控制台的历史 嗯理论上可以不用 ncurses 库直接在 raw 模式操纵终端。 这里稍微聊一下terminfo/termcap的历史，详细的历史和吐槽参考 Unix hater's Handbook 第6章 Terminal Insanity。 首先一个真正意义上的终端就是一个输入设备（通常是键盘）加上一个输出设备（打印 机或者显示器）。很显然不同的终端的能力不同，比如如果输出设备是打印机的话，显 示出来的字符就不能删掉了（但是能覆盖），而且输出了一行之后就不能回到那一行了 。再比如显示器终端有的支持粗体和下划线，有的支持颜色，而有的什么都不支持。 早期Unix工作在电传打字机（TeleTYpe）终端上，后来Unix被port到越来越多的机器上 ，然后越来越多类型的终端会被连到Unix上，很可能同一台Unix主机连了多个不同类型 的终端。由于是不同厂商提供的不同的终端，能力各有不同，自然控制他们工作的方式 也是不一样的。所有终端都支持回显行编辑模式，所以一般的面向行的程序还比较好写 ，但是那时候要撰写支持所有终端的「全屏」程序就非常痛苦，这种情况就像现在浏览 器没有统一标准下写HTML要测试各种浏览器兼容性一样。 通常的做法是 使用最小功能子集 假设终端是某个特殊设备，不管别的设备。 水源的代码源头 Firebird2000 就是那样的一个程序，只支持固定大小的vt102终端。 这时有一个划时代意义的程序出现了，就是 vi，试图要做到「全屏可视化编辑」。这在 现在看起来很简单，但是在当时基本是天方夜谭。 vi 的做法是提出一层抽象，记录它所需要的所有终端操作，然后有一个终端类型数据库 ，把那些操作映射到终端类型的具体指令上。当然并不是所有操作在所有终端类型上都 支持，所以会有一堆 fallback，比如要「强调」某段文字，在彩色终端上可能 fallback 到红色，在黑白终端上可能 fallback 到粗体。 vi 一出现大家都觉得好顶赞，然后想要写更多类似 vi 这样的全屏程序。然后 vi 的作 者就把终端抽象的这部分数据库放出来形成一个单独的项目，叫 termcap （Terminal Capibility），对应的描述终端的数据库就是 termcap 格式。然后 termcap 只是一个 数据库（所以无状态）还不够方便易用，所以后来又有人用 termcap 实现了 curses 。 再后来大家用 curses/termcap 的时候渐渐发现这个数据库有一点不足：它是为 vi 设 计的，所以只实现了 vi 需要的那部分终端能力。然后对它改进的努力就形成了新的 terminfo 数据库和 pcurses 和后来的 ncurses 。 然后 VIM 出现了自然也用 terminfo 实现这部分终端操作。 然后么就是 X 出现了， xterm 出现了，大家都用显示器了，然后 xterm 为了兼容各种 老程序加入了各种老终端的模拟模式。不过因为最普及的终端是 vt100 所以 xterm 默 认是工作在兼容 vt100 的模式下。然后接下来各种新程序（偷懒不用*curses的那些） 都以 xterm/vt100 的方式写。 嗯到此为止是 Unix 世界的黑历史。 知道这段历史的话就可以明白为什么需要 TERM 变量配合 terminfo 数据库才能用一些 Unix 下的全屏程序了。类比一下的话这就是现代浏览器的 user-agent。 然后话题回到 Linux 。 大家知道 Linux 早期代码不是一个 OS， 而是 Linus 大神想 在他的崭新蹭亮的 386-PC 上远程登录他学校的 Unix 主机，接收邮件和逛水源（咳咳 ）。于是 Linux 最早的那部分代码并不是一个通用 OS 而只是一个 bootloader 加一个 终端模拟器。所以现在 Linux 内核里还留有他当年实现的终端模拟器的部分代码，而这 个终端模拟器的终端类型就是 linux 啦。然后他当时是为了逛水源嘛所以 linux 终端 基本上是 vt102 的一个接近完整子集。 说到这里脉络大概应该清晰了， xterm终端类型基本模拟 vt100，linux终端类型基本模 拟 vt102。这两个的区别其实很细微，都是同一个厂商的两代产品嘛。有差别的地方差 不多就是 Home / End / PageUp / PageDown / Delete 这些不在 ASCII 控制字符表里的按键的映射关系不同。 嗯这也就解释了为什么在linux环境的图形界面的终端里 telnet 上水源的话，上面这些 按键会错乱…… 如果设置终端类型是 linux/vt102 的话就不会乱了。在 linux 的 TTY 里 telnet 也不会乱的样子。 写到这里才发现貌似有点长…… 总之可以参考 Unix hater's Handbook 里的相关历史评论和吐槽，那一段非常有意思。","tags":"tech","url":"//farseerfc.me/zhs/from-unbuffered-stdin-to-history-of-linux-tty.html"},{"title":"Jumping KDE5 Plasma Activities Button","text":"I found this when using activities under KDE5 today. One can drag the activities button out of the edge of the screen, then it will jump back and forth at the edge. Here is a video: Youtube Youku Of course you can drag it back, so it is not a serious problem. It is just so cute that I had to note this. By comparison, the jumping window in Gnome3 is far worse than this: Youtube Youku BTW, I saw another cute translation error of mute screen in KDE5: KDE5のミュート画面の中国語翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","url":"//farseerfc.me/en/jumping-kde5-plasma-activities-button.html"},{"title":"KDE5 Plasma の踊る活動ボタン","text":"今日 KDE5 Plasma の「活動」を切り替えている際に偶々この現象を発見しました。 この活動ボタンを画面の外に持ち出すと、デスクトップの縁で踊り出します。 ビデオはこちらに： Youtube Youku 勿論画面の中に引っ張ってきたら問題はなくなるので、大したバグではない。単なる面白い現象です。 この前に Gnome3 にも画面がおかしくなるバグがありました。それを比べて KDE5 のほうはよぽと増しと思います。 Youtube Youku ちなみにですが、KDE5 Plasma のミュート画面の中国語翻訳もなかなか面白いミスがございます： KDE5のミュート画面の中国語翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","url":"//farseerfc.me/jp/jumping-kde5-plasma-activities-button.html"},{"title":"KDE5 Plasma 之跳动卖萌的活动按钮","text":"今天尝试 KDE5 Plasma 的活动的时候无意间发现这个现象。 只要把活动按钮拖出桌面，它就会在桌面边缘来回跳动。 视频如下： Youtube Youku 当然你可以把它再拖回来，所以这个问题还无伤大雅，只是卖萌。 比比之前 Gnome3 那个跳动的界面真是好太多了： Youtube Youku 顺便，今天还看到一个卖萌的 KDE5 Plasma 静音图标的翻译： KDE5のミュート画面の中国语翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","url":"//farseerfc.me/zhs/jumping-kde5-plasma-activities-button.html"},{"title":"Will You Marry Me?","text":"After rendering Above is a image, the playable version is below: * Use WASD←→ to move，need WebGL support","tags":"life","url":"//farseerfc.me/en/marry-me.html"},{"title":"嫁になってくれませんか？","text":"画像はこのように 上のは飾りだけ、遊べるのはこれ： * WASD←→ で移動する，WebGL が必要","tags":"life","url":"//farseerfc.me/jp/marry-me.html"},{"title":"嫁给我好么","text":"渲染的样子 可以玩的是下面这个： * 用 WASD←→ 移动，需要 WebGL 支持","tags":"life","url":"//farseerfc.me/zhs/marry-me.html"},{"title":"ICSE 2012","text":"June 6 Keynote 1 没怎么听懂，只记得讲到了finance is not money但是没听懂这个和软件有什么关系。 Cost Estimation for Distributed Software Project 讲到他们试图改善现有的模型去更精确地评估软件开发的开销。 他们会给PM建议之前的项目的历史数据，然后对于新项目，他们建议历史上已有 的项目的数据，从而帮助PM得到更精确的评估。他们试图尽量减少项目评估对PM 的经验的需求，从而帮助即使经验很少的PM也能准确评估项目的开销。 他们的观点： Context-specfic solutions needed! 我们需要更上下文相关的解决方案！ Early user paticipation is key! 早期用户的参与是关键 Characterizing Logging Practices in Open-Source Software Common mistakes in logging messages 在日志记录中容易犯的错误 他们学习了历史上的log记录，然后试图找到重复修改的输出log的语句，确定log 中存在的问题。他们首先确定修改是事后修改。 通常的修改的比例（9027个修改） 45% 静态文本 27% 打印出的变量 26% 调试等级verbosity 2% 日志输出的位置 他们发现有调试等级的变化，是因为安全漏洞之类的原因，或者在开销和数据 之间的权衡。 大多数对log的变量的修改都是为了增加一个参数。他们之前的LogEnhancer是为了 解决这个问题而提出的，通过静态检查，提醒程序员是否忘记了某个参数 对text的修改是因为要改掉过时的代码信息，避免误导用户。 他们的实验是采用了基于code clone 的技术，找到所有log语句，然后找不一致 的clone，然后自动提出建议。 Combine Functional and Imperative Pgrm for Multicore Sw: Scala & Java 趋势：到处都是多核，但是并发程序呢？ 他们研究的对象是Scala和Java，因为可以编译后确认JVM字节码的语义。 Java: 共享内存 显示创建的线程 手动同步 Wait/Notify机制 Scala: 高阶函数 Actors, 消息传递 lists, filters, iterators while 共享状态, OO import java.* 能从java导入任何库 auto type inferance 自动类型推导 实验的参与者都经过4周的训练，实验项目是工业等级的开发项目 结果： scala 的项目平均比java多花38%的时间，主要都是花在Test和debug上的时间。 程序员的经验和总体时间相关，但是对test和debug没有显著影响。 scala的为了让编程更有效率的设计，导致debug更困难。比如类型推导，debug 的时候需要手动推导，来理解正在发生什么。 scala的程序比java小，中位数2.6%，平均15.2% 性能比较： 单核：scala的线性程序的性能比java好 4核： scala 7s @ 4 threads java 4si @ 8 threads median 83s scala 98s java 32core: best scala 34s @ 64 threads 结论 java有更好的scalability scala类型推导 45%说对携带码有帮助 85%说导致程序错误 调试 23%认为scala简单 77%认为java简单 multi-paradigram are better Sound Empirical Evidence in Software Testing Test data generation 测试数据自动生成 Large Empirical Studies - not always possible For open source software - big enough Identifing Linux Bug Fixing Patch current practice: manual Current research: keywords in commits link bug reports in bugzilla Try to solve classification problem issue pre-identified post-identified data from commit log feature extraction text pre-process stemmed non-stop words model learning research questions Active Refinement of Clone Anomaly Reports motivating code clones, clone groups clone used to detect bugs anomaly : inconsistent clone group many anomaly clone are note bug, high false positive approach reorder by sorted bug reports June7 Keynotes 2: Sustainability with Software - An Industrial Perspective Sustainability Classic View: Idenpendent view with overlap Social Environment Economic Nested viw Environment Social Economic Triple bottom line economic -global business, networks , global econ env natural res, climate change, population grow social awareness, connectivity, accountability Green IT reduce IT energy more than 50% cooling - doing nothing mini e-waste: not properly recycled 80% in EU 75% in US foster dematerialization In-Memory Technology: Expected Sustainable Benefits What can we do? consider all software lifecycle phases in your design avoid energy expensive behavior in your codes design lean architectures Green by IT 2% green IT 98% green IT On How Often code is cloned across repositories Line based hashing code clone detection never do anything harder than sorting hashing a window of 5 lines of normalized (tokenized) code, dropping 3/4 of the hashing 把ccfinder一个月的工作缩短到了3, 4天。没有比较presion和recall。 14% type1 16% type2 17% type3 (not really type2) Graph-based analysis and prediction for sw evolution graph are everywhere internet topology social net chemistry biology in sw - func call graph - module dependency graph developer interaction graph - commit logs - bug reports experiment 11 oss, 27~171 release, > 9 years predictors NodeRank similar to pagerank of google measure relative importance of each node func call graph with noderank compare rank with severity scale on bugzilla correlation between noderank and BugSeverity func level 0.48 ~ 0.86 varies among projects. model level > func level ModularityRatio cohesion/coupling ratio: IntraDep(M)/InterDep(M) forecast mantencance effort use for identify modules that need redesign or refactoring EditDistance bug-based developer collaboration graphs ED(G1,G2)=|V1|+|V2|-2|V1交V2|+|E1|+|E2|-2|E1交E2| use for release planning resource allocation graph metrics graph diameter average node degree indicates reuse clustering coefficient assortativity num of cycles Conclusion \"Actionable intelligence\" from graph evolution studie 11 large long-live projs predictors identify pivotal moments in evolution What make long term contributors: willingness and opportunity in OSS OSS don't work without contributors form community mozilla (2000-2008) 10&#94;2.2 LTC <- 2 order -> 10&#94;4.2 new contributors <- 3.5 order -> 10&#94;7.7 users gnome (1999-2007) 10&#94;2.5 LTC <- 1.5 order -> 10&#94;4.0 new contributors <- 3.5 order -> 10&#94;6.5 users approach read issues of 20 LTC and 20 non-LTC suvery 56 (36 non-LTC and 20 LTC) extract practices published on project web sites summeray Ability/Willingness distinguishes LTCs Environment macro-climate popularity micro-climate attention bumber of peers performance of peers regression model newcomers to LTC conversion drops actions in first month predicts LTCs 24% recall 37% precision develop of auxiliary functions: should you be agile? a empirial assessment of pair programming and test-first programming can agile help auxiliary functions? experiment pair vs solo test-first vs test-last students vs professors research questions r1: can pair help obtain more correct impl r2: can test-first r3: dst test1 encourage the impl or more test cases? r4: does test1 course more coverage result test-first higher coverage non change with correctness pair improve on correctness longer total programming time Static Detection of Resource Contention Problems in Server-side script Addressed the race condition of accessing database or filesystem of PHP Amplifying Tests to Validate Exception Handling Code 异常处理的代码不但难写，而且难以验证。各种组合情况难以估计，尤其是手机 系统上。 A tactic-centric approach automating traceability of quality concerns tactic traceability information models","tags":"life","url":"//farseerfc.me/zhs/icse2012.html"},{"title":"MSR 2012 @ ICSE","text":"Mining Software Repository 2012 @ ICSE I participated MSR of this year. We came to University of Zurich early in the morning. The registration got something wrong when it seems that Swisses cannot tell the difference among Asians so that name cards of 3 Chinese with family name of Yang are misplaced. And also the organization field of Hotta was \"Japan, Japan\", as if he represented the Japan. MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) The first talk was the keynote given by Mrs Zhang from MSR(MicroSoft Research @ Asia), so it turned out to be MSR gave keynote of MSR. The talk was about Software Analysis and their clone detection tool called XIAO. XIAO was a clone detector developed by MSRA which can be used as a plugin for Microsoft Visual Studio. XIAO has two part, or system state: the statics state analysis all the clones which didn't consider the running time, while the dynamic state need real time response. The thing I need to develop for Samsung is something like dynamic mode. I wanted to know more about the internal details about XIAO but the talk was finished there. Towards Improving BTS with Game Mechanisms The contents of this talk is very much like this blog: http://www.joelonsoftware.com/items/2008/09/15.html The talk discussed whether the same game mechanism can be applied to the things like issue tracking or similar. From my point of view, it is useless to use game mechanism in this situation. The reason that stackoverflow can success lies on that they just captured the use of fade system in opensource community, as all hackers like to be approved as great hacker, as what is happening in Wikipedia. Whether the same theory can be applied in issue tracking systems inside a internal company is questionable. Although MSDN has basic the same structure as Wikipedia, the content of MSDN and Wikipedia have different involvement of users. So I myself didn't approve this research. GHTorrent They slide of this talk can be found from here: http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Main part of data of Github, namely the hosted code, are already exposed as git repos, and wiki of repos are stored in git repo. So the aim of this project is to expose other data such as issues, code comments, etc. The project access github api and fetch the needed data as distributed system in order to overcome the limitations of the github api. The project will provide download history as torrents. The json data from github api is stored as bson in MongoDB and the parsed data is stored in MySQL with schema. From my point of view, it will be better if the format of data can be uniformed and all data are stored in the git repo as wiki pages. As the history stored in git repo is more nature, and using git blame to trace author of code comments should also be more useful. Of course it is harder to read and write the raw data of git as we need more understanding of the internal format of git. Maybe only people from github can do this. Topic Mining I can not understand the two parameters, DE, AIC, used in this research, study this later. The experiment target of this research are Firefox, Mylyn and Eclipse. They are trying to analysis the identifiers and comments from source codes in software repos and find the relationship between topics and bugs, like what kind of topics are more likely to contain buggy codes. The result of this research is not so clear. Such as it said that the core functions of Firefox have more bug reports, but it said no reason about this. Maybe this only means that the core features are well tested, rather than that the core features are more buggy. But the slides showed by author are pretty and easy to understand. The evolution of software The keynote talk of the second day. It is about how should we combine the social media with software development. Maybe this is the reason why Github succeeded. In the talk she told about accessing tags, uBlogs, blogs etc. directly from Integrated Development Environments, or should we need cloud IDE such as Cloud9. Do Faster Releases Improve Software Quality? Used Firefox as example. The conclusion is that faster releases will lead to more bugs and more frequent crash, but bugs are get fixed more quickly and user will switch to new released more quickly. Security vs Performance Bugs in Firefox Performance bugs are regression, blocks release. Some of my thoughts Separation of commits based on Semantic analysis The user of some tools (such as git) are not following the design purposes of these tools which brings some difficulty to MSR. For example git has a prefect branch system, so it is desired for users of git to commit per topic. Commit per topic means that user send a commit for a single implementation of a feature or a bug fix, etc. If it is difficult to contain all modifications in a commit, then it should be in a separate branch and merged into master branch. But actually user tends to send very large commits, that contains many logical features, and they can not predict to open a new branch until a few commits. Maybe this is not the fault of the user of tools, this is the tools that are not smart enough. We should separate the commits according to the semantic topics inside a commit. About the slide systems used today The study with title Incorporating Version Histories in Information Retrieval Based Bug Localization used the slides made by beamer. It contains many equations, used many overlays are iterations, with few figures, is a typical beamer slide. It also used mindmap very well. There are at least 3 slides that are made by beamer today. The study with title Towards Improving Bug Tracking Systems with Game Mechanisms presented with prezi. It have many pictures and many transitions. But because of it is made by prezi, there are no headers and footers so no page numbers and section titles etc. This is not so convenient in such a official occasions because people need to refer to the page number in question session. There are at lease 6 presents used Apple Keynote. It is really difficult to tell the difference between slides made by PowerPoint and Keynote. 2 of them used the default theme of keynote. The rest are using PowerPoint. Mrs Zhang from Microsoft used PowerPoint but her slides looks like beamer very much such as the usage of footer and header and overlays. If these are made by PowerPoint that will involve many manually operations. It is worth to mention that the slides of a study with title Green Mining: A Methodology of Relating Software Change to Power Consumption are all badly drawn hand paintings. The effect of these slide are well received, they are green and clean and cute. You can refer to the following animation for the effect but it is not exactly the same version with what we saw : http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv Microsoft is MEANING It is not a news. But Microsoft is the sponsor of Mining Challenge, and the prize of this challenge will be Xbox and Kinect and the topic of this year is: Mining Android Bug I see what you are doing there Microsoft ......","tags":"life","url":"//farseerfc.me/en/msr2012.html"},{"title":"MSR 2012 @ ICSE","text":"Mining Software Repository 2012 @ ICSE 今年のMSRを参加しました、会場はチューリッヒ大学にあります。朝早く大学に 着いて、登録するときちょっと事情をありました。スイス人は明らかに中国人 の名前をわからないから、３つの中国からの楊（Yang）の名札を間違えた。そ して堀田先輩の名札に\"Japan, Japan\"になって、日本代表になった。 MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) まず一番目のKeynoteはマイクロソフトアジア研究院(MicroSoft Research @ Asia ,MSR Asia)のZhang氏が発表する、こうしてMSRがMSRに発表するになった。 Zhangの発表はSoftware AnalysisとXIAOの２つの紹介です。XIAOはマイクロソフト が開発したCode Clone Detector、ある会社が私達に任せるのもこのようなシステム です。もっと詳しく知りたいが、実装に関わるものは言ってなかった。 Towards Improving BTS with Game Mechanisms これの内容は基本的にこのブロクに書いています： http://www.joelonsoftware.com/items/2008/09/15.html 同じ理論をIssue Trackingとかに応用できるかを言いました。個人的にこれは 意味ない気がします。stackoverflowの成功はOpen Software Communityにもと もとある名誉システムを具現化したですから、それを会社の中に応用するのは 難しい気がする。 GHTorrent この研究のスライドはこちらに： http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Githubの主なデータはコード、それは既にgitから アクセスできます、wikiはgitとして保存しているからそれも含まれている。 ですからこのプロジェクトの目的は他のデータを表せる、つまりissues, commit commentsなど。このプロジェクトはgithub apiを通じて、分布システムとして apiの制限を超える、そしてtorrentの形で歴史をdownloadできます。元のデータ はbsonとしてMongoDBの保存して、Schemaを追加したデータはMySQLに保存する。 わたしの意見では、データをgitのrepoの形で保存するの方がいいかもしれない。 今のwikiのように、そしてgitoliteも全てのデータをgit自身の中に保存している。 The evolution of software 二日目のkeynotes, social mediaをソフトウェア開発に巻き込めるについて 話しました。もしかしてこれはGithubの成功の理論かもしれない。IDEの中に social mediaのアクセスを欲しいと言いました。 Do Faster Releases Imporve Software Quality? Firefoxを例として研究しました。 結論としては、早い発行はbugを多く持たされ、crashがもっと頻繁になるが、 bugの修復も早くなって、そしてユーザー側はもっと早く新しい発行に移動する ことをわかりました。 Security vs Performance Bugs in Firefox 性能に関するbugはregression テストが要る、そして発行を阻止する。 思いつき topicに基づいてcommitの分析と分割 よく使うツール（例えばgit）のユーザーはツールの設計者の意図を従って ツールを使うことはない、設計者が思った用途以外にも使っていることが多い、 それはMiningに対しては色々困難を持たされています。例えばgitには完璧な branch機能がある、通常にgitのユーザーが一つのcommitに一つの機能を実現 してほしい、例としてはbugの修復とか、機能の追加とか。それは難しいなら branchを使って、一連のcommitを一つのbranchになって、一つのbranchに一つ の機能を実現してほしい。それなのに、現状では、沢山の編集を一つのcommit に含まれていて、後の管理とか情報の収集とかが困難になってしまう。 それはユーザーの悪いと思わない、ツールの方がもっと頑張らないとユーザー は正しく使えない。もしcommitの時、自動的にcommitの内容を分析して、 その中にtopicによって分けて、ユーザーに推薦するのをてきたらいいなぁ、 と思っています。このように一つのcommitを多くに分割したら、commitの履歴 をもっと見やすくなって、続いて分析とかも便利になるはずです。 今回に皆使っているslideのシステム タイトルは Incorporating Version Histories in Information Retrieval Based Bug Localization の人が使っているのはbeamerです。数式が多くて、 overlayも多くて，iterateも多い、図だけ少ない、典型的にbeamerに作れそうな スライドです。mindmapの使いもうまい。今日の一日に少なくとも3個のslideは beamerで作られています。 タイトルは Towards Improving Bug Tracking Systems with Game Mechanisms の人はpreziを使いました、図が多くて、transitionも多い。但しスライド としては必要なページ数とかがなくて、このような国際会議の場合にはもっと 工夫をした方がいいかもしれな。 少なくとも六人以上はAppleのKeynoteをつかていまう。Keynoteによる作った スライドはPowerpointのになかなか区別しがたいですが、その中に二人は defaultのthemeを使ったからわかります、他の人はPPTに決してありえない アニメションを使っていますから、多分keynote。 残りは勿論Powerpointです。MSRAの張さんが作ったのはpowerpointなんですけど、 すごくbeamerの感じがします、例えばheaderとfooterの使い方とか、overlay 見たいのものでページのitemを一つずつ展開するとか。それらを全部powerpoint で作るのは相当手間がかかりそうです。 ちなみに言いたいのは一つタイトルは Green Mining: A Methodology of Relating Software Change to Power Consumption のスライドは全部 下手 な手描きの漫画で表せている、火狐のアイコンさえ手描きする、効果は意外に 評判がいい。省エネでグリンで環境にいいで可愛らしい。具体的な効果は下の リンクから見えます、現場で見たのは別のバージョンなんですけど： http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv マイクロソフトは腹黒っ子! まぁ大したニュースではないですけど、MSR2012のMining Challengeのスバンサー はマイクロソフトで、商品はXboxとKinectですけど、今年のチャレンジのテーマは： Mining Android Bug マイクロソフトの殺意を感じしました。","tags":"life","url":"//farseerfc.me/jp/msr2012.html"},{"title":"MSR 2012 @ ICSE","text":"Mining Software Repository 2012 @ ICSE 参加了今年的MSR，会场在University of Zurich。一大早来到大学，注册有点 小插曲，显然瑞士人搞不清楚中国人的名字，3个杨（Yang）姓的中国人的名牌 被搞错了。然后堀田学长的所属被写作了\"Japan, Japan\"，成为了全日本的代表。 MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) 首先是来自微软亚洲研究院（MicroSoft Research @ Asia, MSR Asia）的Keynots， 于是就变成了MSR在MSR的演讲。MSR的张冬梅（Dongmei Zhang）女士的演讲 分为关于Software Analysis和XIAO的两部分。XIAO是MSRA开发的Code Clone Detector，似乎我要给井上研做的就是这个。想更多了解Xiao的细节，不过张女士 演讲结束的时候的鼓掌导致了话筒的小故障。 Towards Improving BTS with Game Mechanisms 感觉这篇的内容基本上就是关于 http://www.joelonsoftware.com/items/2008/09/15.html 这里写到的东西，然后说同样的理论是否可以用于Issue Tracking之类的事情上。 个人感觉这个意义不大，stackoverflow之所以成功是因为它把开源社区本身就 具有的名誉体系具现化了，本着大家都喜欢被别人奉为大牛的心态，就如同 wikipedia一样。同样的理论如果用于公司内部的Issue Tracking系统上，会得到 完全不同的东西吧。就像MSDN的组织方式虽然和wikipedia是一样的，但是在MSDN 里找信息的感觉和在wikipedia完全不一样。个人不太看好这个方向。 GHTorrent 这篇的slide在这里可以看到： http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Github的主要数据，代码，已经可以通过git接口 获得了，wiki是git的形式保存的。所以这个项目的目的就是暴露别的数据，主要 是issue tracking，code comments，这种。代码访问github api，然后用分布式 实现以克服api的限制，然后提供torrents形式的history下载。github api获得 的json数据以bson的形式保存在MongoDB里，解析过的有了Schema之后的数据保存 在MySQL里并可以导出SQL。 个人的想法，觉得数据如果能够更统一，全部存在Git里或许更好，像Wiki一样。 同样是要暴露全部历史记录的目的，用Torrent自己实现的历史远不如用Git的 接口实现的历史记录方便吧，git blame之类的也更方便追踪code comment之类的 作者信息。当然对git的raw date直接读写，需要对git的内部原理有足够的理解， 或许只有github的人有这种能力了。 Topic Mining 用得两个参数， DE 和 AIC，完全不能理解，过后研究。实验针对了Firefox, Mylyn, Eclipse三个软件。试图从Repo中分析源代码的identifier和comments， 找到topic和bug之间的关系，比如怎样的topic更容易导致bug。得出的结论似乎 也很暧昧，只是说核心功能被报告的bug更多，但是不知道原因。这只能表示核心 功能受到更多关注和更多测试吧，并不能说明核心功能就容易产生bug。 不过这个的Slide做得很漂亮，很容易理解。 SeCold A linked data platform for mining software repositories 没听懂这个项目的目的。 The evolution of software 第二天的Keynotes，关于将Social Media和Software Development相结合的想法。 或许就是Github赖以成功的基础。讲到代码中的comment, Tags, uBlog, blog之类 的social的特性和IDE的融合的趋势。 Do Faster Releases Imporve Software Quality? 使用Firefox作为例子。 结论是快速发布导致bug更多，更容易crash，但是bug更快得到修复，并且用户 更快转向新的发布。 Security vs Performance Bugs in Firefox Performance bugs are regression, blocks release. 一些感想 基于自然语义分析的commit分割 经常工具（比如git）的使用者并没有按照工具设计者的意图使用工具，这给MSR 带来很多困难。举个例子，git有非常完美的branch系统，通常期望git的使用者 能够在一次commit里commit一个功能，比如一个bug的修复，或者一个feature的 添加，但是事实上经常有很多逻辑上的commit被合并在一个里面了。 或许这不是使用者的错，而是工具仍然不够人性的表现。或许我们可以自动把 一次的commit按照语义分割成多个。 分割之后，可以更容易地把issue和commit关联，也更容易组织更多的研究。 关于这次发表中大家用的slides系统 题目为``Incorporating Version Histories in Information Retrieval Based Bug Localization''的人用的slide是beamer的。公式很多，overlay很多，列表 很多，图片很少，典型的beamer做出的slide。思维导图用得很不错。今天一天 有至少3个slide是用beamer做的。 题目为``Towards Improving Bug Tracking Systems with Game Mechanisms'' 的人用了prezi，图片很多，过度很多。但是比如没有页号没有页眉页脚，正式 会议的场合不太方便。 至少有六个以上用了Apple Keynotes，Keynotes做出来的东西真的和Powerpoint 做出来的很难区别，其中两个人用了初始的主题所以才看出来。 剩下的自然是PPT。MSRA的张女士做的虽然是PPT，倒是有很多beamer的感觉， 比如页眉页脚和overlay的用法。这些如果都是PPT做出来的，会多很多额外的 人力吧。 值得一提的是有一个题目为``Green Mining: A Methodology of Relating Software Change to Power Consumption''的人的slide全是``劣质''的手绘漫画， 效果意外地好，很低碳很环保很绿色很可爱。具体效果可以参考下面的动画，虽然 现场看到的不是一个版本： http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv 微软是个腹黑娘！ 嘛虽然这也不是什么新闻了。MSR2012的Mining Challenge的赞助商是微软，管理 组织者来自微软研究院，奖品是Xbox和Kinect。然后今年的题目是： Mining Android Bug 我看到了微软满满的怨气……","tags":"life","url":"//farseerfc.me/zhs/msr2012.html"},{"title":"Pyssy 项目","text":"简介 Pyssy 是用于 上海交通大学 饮水思源站 的一系列 Python 脚本和工具。 Pyssy 被有意设计为既可以托管寄宿在 SAE [1] 上，也可以在单机上独立使用。 项目地址： http://pyssy.sinaapp.com/ Github上的源代码地址： https://github.com/yssy-d3/pyssy [1] Sina App Engine ，新浪云平台，类似 Google App Engine 的东西。 依赖关系 Pyssy 使用 Flask 作为网页服务器， 并且使用 Memcached 或者 Redis 作为抓取 水源Web 的缓存。 SAE Python 环境下请开启 Memcached 支持。 本地环境下请安装 Redis-py 并运行 redis-server 服务器程序。","tags":"tech","url":"//farseerfc.me/zhs/pyssy.html"},{"title":"PyRuby","text":"Today I saw a package called PyRuby in Github. The readme says: PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } Even PyPI has listed this as a package. In the beginning I thought this was again a Ruby implementation by PyPy project. Or at least it use some magic trick to write ruby code directly in Python. Then I browse into the source code of it. It contains only one file: ruby.py # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) Yes, indead. The idea of using Ruby in Python is totally mad.","tags":"tech","url":"//farseerfc.me/en/mix-ruby.html"},{"title":"PyRuby","text":"きょう、Githubに PyRuby というプロジェクトを見ました。それの説明にこう書いています: PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } さらに、 PyPI にそれのパッケージもあった。 最初に、これはもう一つのPyPyで実現したRubyだと思った。少なくとも、本当のRubyをPythonから呼び出すの何かの魔法も可能かもしれない。 それのソースコートはこうなっています。 ruby.py # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) 本当だ、Pythonの中にRubyを呼び出すという考えはアホだ。","tags":"tech","url":"//farseerfc.me/jp/mix-ruby.html"},{"title":"PyRuby","text":"今天在GitHub上闲逛的时候看到一个叫做 PyRuby 的项目。项目的Readme说得很好： PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } 甚至 PyPI 上还有这个项目的包。 一开始我还以为这又是一个野心勃勃的基于PyPy的Ruby实现，或者某种trick在Python里面直接调用Ruby解释器。 然后我想看看这个的源代码 只有一个ruby.py文件，内容是： # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) 是的……的确……这种尝试把Python和Ruby放在一起的想法绝对是疯了……","tags":"tech","url":"//farseerfc.me/zhs/mix-ruby.html"},{"title":"Discuss C++ Template Downcast","text":"This is a discuss in C board in bbs.sjtu.edu.cn, about type down-cast in C++ template. Original Discuss http://bbs.sjtu.edu.cn/bbstcon,board,C,reid,1330078933,file,M.1330078933.A.html The problem Today I read a book about we can do cast-down in template, so I write this to test: template < bool _Test , class _Type = void > struct enable_if { }; template < class _Type > struct enable_if < true , _Type > { typedef _Type type ; }; class A { }; class B : A { }; template < typename T > struct traits { static int const value = false ; }; template <> struct traits < A > { static int const value = true ; }; template < typename T > void f ( T , typename enable_if < traits < T >:: value >:: type * = 0 ) { } template <> void f < A > ( A , enable_if < traits < A >:: value >:: type * ) { } template < typename T > class BB {}; template < typename T > class DD : public BB < T > {}; template < typename T > void ff ( BB < T > ) {}; int main ( int argc , char * argv []) { A a ; B b ; DD < long > dd ; //f(b); ff ( dd ); } It is strange when f it don't allow my specified f<A>` . But in ff it allowed ff<BB<long>>` . Tested under VC10 and GCC3.4 My answer to the problem Let's think ourself as compiler to see what happened there. Define mark # : A#B is the instantiated result when we put B into the parameter T of A<T> . First we discuss ff DD < long > dd ; After this sentense, the compiler saw the instantiation of DD<long> , so it instantiate DD#long , and also BB#long . ff ( dd ); This sentense required the compiler to calculate set of overloading functions. Step 1 we need to infer T of ff<T> from argument DD#long -> BB<T> . Based on the inference rule: Argument with type :code:`class_template_name<T>` can be use to infer :code:`T``. So compiler inferred T as long . Here if it is not BB but CC which is complete un-related, we can also infer, as long as CC is a template like CC<T> . Step 2 Template Specialization Resolution. There is only one template here so we matched ff<T> . Step 3 Template Instantiation After inferred long -> T , compiler instantiated ff#long . Set of available overloading functions : {ff#long} Then overloading resolution found the only match ff#long` , checked its real parameter DD#long can be down-cast to formal parameter BB#long . Then we discuss f f ( b ); Calculate set of overloading functions. Step 1 infer all template parameters for template f . According to inference rule: Parameter with type T can be used to infer T 。 So B -> T is inferred. Step 2 Template Specialization Resolution. Here B is not A so we can not apply specialization of f<A> , remaining f<T> as the only alternative. Step 3 Template Instantiation. When we put B into f<T> to instantiate as f#B , we need to instantiate traits#B` . There is no specialization for B so we use template traits<T> , traits#B::value=false , so enable_if#false didn't contains a type , an error occurred. The only template is mismatch, available overloading functions is empty set. So we got an error.","tags":"tech","url":"//farseerfc.me/en/discuss-cpp-template-downcast.html"},{"title":"关于C++模板的类型转换的讨论","text":"这两天在饮水思源的C板，关于C++模板的类型转换的一个讨论，后面是我的解答。 讨论地址 http://bbs.sjtu.edu.cn/bbstcon,board,C,reid,1330078933,file,M.1330078933.A.html 原问题 今天在书上看到模板演绎的时候可以允许cast-down，于是我写了个东西： template < bool _Test , class _Type = void > struct enable_if { }; template < class _Type > struct enable_if < true , _Type > { typedef _Type type ; }; class A { }; class B : A { }; template < typename T > struct traits { static int const value = false ; }; template <> struct traits < A > { static int const value = true ; }; template < typename T > void f ( T , typename enable_if < traits < T >:: value >:: type * = 0 ) { } template <> void f < A > ( A , enable_if < traits < A >:: value >:: type * ) { } template < typename T > class BB {}; template < typename T > class DD : public BB < T > {}; template < typename T > void ff ( BB < T > ) {}; int main ( int argc , char * argv []) { A a ; B b ; DD < long > dd ; //f(b); ff ( dd ); } 奇怪的是重载决议的时候， f 的情况下它就不让我特化的 f<A> 进来。 但是在 ff 的情况下， ff<BB<long>> 却进来了。 在VC10和GCC3.4下测试 我的解答 我们来设身处地地作为编译器，看一遍到底发生了什么。 约定符号 # : A#B 是把 B 带入 A<T> 的参数 T 之后实例化得到的结果。 首先看ff的情况。 DD < long > dd ; 处理到这句的时候，编译器看到了 DD<long> 的实例化，于是去实例化 DD#long ，继而实例 化了 BB#long 。 ff ( dd ); 这句，首先计算重载函数集合。 第一步，需要从参数 DD#long -> BB<T> 推断 ff<T> 的 T 。根据函数模板参数推断规则： :code:`class_template_name<T>` 类型的参数，可以用于推断 :code:`T` 。 于是编译器推断 T 为 long 。这里就算不是 BB 而是完全无关的 CC 都可以推断成功，只要 CC 也 是一个 CC<T> 形式的模板。 第二步，模板特化匹配。因为只有一个模板，所以匹配了最泛化的 ff<T> 。 第三步，模板实例化。 推断了 long -> T 之后，编译器实例化 ff#long 。 重载函数集合： {ff#long} 然后重载抉择找到唯一的可匹配的实例 ff#long ，检查实际参数 DD#long 可以隐式转换到 形式参数 BB#long ，从而生成了这次函数调用。 再来看f的情况。 f ( b ); 计算候选重载函数集合。 第一步，对所有 f 模板推断实参。根据函数模板参数推断规则： 带有 :code:`T` 类型的参数，可以用于推断 :code:`T` 。 于是 B -> T 被推断出来了。 第二步，模板特化匹配。 这里 B 不是 A ，所以不能用 f<A> 特化，只能用 f<T> 模板。 第三步，模板实例化。 B 带入 f<T> 实例化成 f#B 的过程中，实例化 traits#B 。 由于没有针对 B 的特化，所以用 traits<T> 模板， traits#B::value=false ，进而 enable_if#false 没有 type ，出错。 唯一的模板匹配出错，重载函数集合为空，SFINAE原则不能找到合适的匹配，于是报错。","tags":"tech","url":"//farseerfc.me/zhs/discuss-cpp-template-downcast.html"},{"title":"Give a try to Pelican","text":"It seems in one night all geeks have their own Github User Page and Octopress Blog. Like everyone posted in their blogs, Static Blog is indeed more convenient than traditional Blog systems such as WordPress. I have been wanting my own Octopress since then. But it seems that Octopress isn't for me At first I was confused by Setup Steps of Octopress . What is this RVM thing? And what is that rbenv thing? It seems the high pace of Ruby community has beyond my imagination to a degree that they need a version manager to ensure the compatibility of different versions of Ruby. Althrough the same compatibility issue also troubles Python community [1] , but at least Python don't need a version manager (yet) to control this mass [2] . Real problem for me is that I haven't yet a Linux box that I can play around freely. (I really want one ... ) Both RVM and rbenv needs to run on Unix/Linux/MacOSX. One can not be a geek if he use Windows ? (Maybe it's true...) Remaining problem is the battle between Ruby and Python campaign. I haven't tried Markdown , and I rather like ReST . It seems that both sides depend on Pygments as code block highlighter so Rubyists need Python environment anyway. I simply don't want to depend on any Ruby component. It is better when it is in pure Python, no C extensions so that I can debug into it and make minor modifications. So I started searching for Static Blog Engine in Python on Github. The author of the great framework Flask , mitsuhiko , wrote a rstblog , but it's not well developed. Hyde seems to be complete enough, but it use MarkDown as its default markup language, and the design of its homepage is too fashion to be used as blog. Finally I found Pelican . [1] Such as the difference between Python 2.x and 3.x , and also difference in C-API of implementations of PyPy , CPython , Stackless , Cython . [2] Yes, we have easy_install and pip , but all these are package manager, running in a perticular Python implementation. Python implementation itself don't need a manager. Version issue of Python largely have been solved by lightweight converters such as 2to3.py and 3to2.py , you don't need to store multiple implementations of Python in your disk for different packages. Yes you can use virtualenv if you need to preserve stablility but this is another story. Let it be Pelican For my own use, Pelican offers me some advantages over Octopress : Implemented in pure Python . This means that I can use different implementation of Python other than CPython easily. I use PyPy myself. Translation of multi-languages. The original author of Pelican is a France. This is unnecessory for most people, but I will post my blog mainly in three languages: English, Japanese and Chinese. ReST . So that I can use the @auto-rst feature of Leo . And also I don't need to switch between my blog and documentation of my projects. But it seems that Pelican was less contributed than Octopress . Some minor issues remains in latest version: Support of pelican-import from WordPress for Chinese and Japanese articles are buggy. Datetime format, timezone, and locale support for multi-language blogs are not so natural. I will work on this in these days There are not so many templates compared to Octopress . And less plugins . I hope more people from Python community can contribute to this excellent project, then all these issues will be fixed soon. My settings To install Pelican is simple: $ pip install pelican Write posts in ReST , with rst extensions, and put them in pages folder. (Re)Build all pages is simply: $ pelican -s settings.py Push to Github: $ git commit -am \"Commit message\" $ git push And following is my settings.py : # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , ' %a , %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a ' ), 'jp' :( 'jpn' , '%Y/%m/ %d ( %a )' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","url":"//farseerfc.me/en/try-pelican.html"},{"title":"Pelicanを試してみた","text":"一日の間に全ての ギーク たち が 自分の Githubユーザーページ と Octopress ブログを導入したような気がします。皆がブログに書いた通りに、静的ブログは確かに WordPress などの従来の動的ブログ・エンジンより便利だと思います。これらブログを見ると、私も自分の Octopress ブログを立ちましょう とずっと思っています。 ですが Octopress は私に向いてないかも 初めのところに Octopressの配置手順 に迷わされた。 RVM とはなに？ rbenv とは何のこと？見るところ Ruby コミュニティーの発展するハイペースは既に私の想像に超えましたみたい。 彼らは Ruby の各バージョン間に互換性を持つために、バージョン管理が必要らしいです。同様の互換性問題が Python コミュニティーにもある ですが [1] 、 Python は今のところこのようなバージョン管理の必要がないと思います [2] 。 実際に迷惑したのは、私は今自由に持って遊べる Linux 環境が持っていないということ（ほしいなぁ……）。 ですが RVM それとも rbenv 両方も Unix/Linux/MacOSX しか実行できないらしいです。ギークとしたの皆は絶対に Windows つかっじゃいけないんですか？（本当かも……）。 残りは Ruby と Python の争いです。私は Markdown に詳しくない、比べると ReST のほうが私に向いています。それに、どっちでも Pygments を依存しシンタックス・ハイライトをしているから、 Rubyist 達も少なくとも Python を入れなきゃダメみたいです。 私の好みは一切の Ruby コンポーネントを頼らず、 C 拡張もない純粋な Python の実現がほしいです。 そこから Github に Python で実現した静的ブログ・エンジンを探し始めた。 Flask の作者である mitsuhiko 氏が書いた rstblog が素晴らしいが、あんまり他人に使われていないようです。 Hyde は多く使われているけれと、ホームページにブログの感じがみえないです。最後に Pelican を見かけました。 [1] 例えば Python 2.x と 3.x の間にあまりにも巨大なる差、それと PyPy 、 CPython 、 Stackless 、 Cython など各実現間に微妙な違いがあります。 [2] はい、こっちに easy_install とか pip があります、ですがそれらはパッケージ管理、特定なPython環境を入れた後の話です。Python自身はまだ管理する必要がないです。 Python のバージョン問題も 2to3.py とか 3to2.py のようなツールで変換すればいいです、違うソフトを実行するためたくさんの Python バージョンを残る必要はないです。もしバージョンの違いが気にするなら virtualenv を使うのも構わないが、それも別のことです。 それでは Pelican にしよう 私自身にとって、 Pelican は Octopress よりいいところ： 純粋な Python で実現した。ですから CPython のほかべつの実現を使うのも心配がない。例えばわたしは PyPy を使ています。 多言語。 Pelican の原作者はフランス人らしいです。ほとんどの人はこれの必要がないと思うが……できるだけ、わたしは三つの言語で書く。 ReST 。それなら Leo の @auto-rst を使って直接 ReST をかけます。 でも Pelican は Octopress のほど注目されていないから、一部問題があります。 pelican-import は WordPress から導入する時、日本語や中国語は問題となります。 多言語の機能と日付、タイムゾーンなどにバグがある。 私は改善しています。 テンプレートは少ない。 プラグインも少ない…… こんなに優れたツールにもっと注目されてほしい。 配置 Pelican を入れるのは簡単： $ pip install pelican 文章を ReST で書いて、 posts フォルダーに置きます。ページを生成する： $ pelican -s settings.py Github に送る: $ git commit -am \"Commit message\" $ git push 私の配置ファイル： # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , ' %a , %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a ' ), 'jp' :( 'jpn' , '%Y年%m月 %d 日( %a )' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","url":"//farseerfc.me/jp/try-pelican.html"},{"title":"尝试一下 Pelican","text":"似乎一夜之间所有的 极客们 都 有了 自己 的 Github主页 和 Octopress 博客。就像所有人在他们的博客中指出的，静态博客的确比传统的WordPress方式具有更多优势。 自从看到这些 我就一直在想着自己搭一个 Octopress 。 但是似乎 Octopress 不适合我 一上手就被 Octopress的搭建步骤 烦到了。 RVM 是什么？ rbenv 又是什么？ 看来 Ruby 社区的快节奏发展已经超过了我的想象，他们似乎需要一套发行版管理器来调和不同版本之间的 Ruby 的兼容性问题。 虽然同样的兼容性问题在 Python 社区也有 [1] ，不过总觉得 Python 至少还没到需要一个发行版管理器的程度 [2] 。 真正的问题是我手上还没有一个可以让我随便玩的 Linux 环境（真的想要……）。 而无论是 RVM 还是 rbenv 似乎都只支持 Unix/Linux/MacOSX 。 身为极客就注定不能用 Windows 么？（或许是的……）。 剩下的问题就是 Ruby 和 Python 两大阵营的对立问题了。我不熟悉 Markdown ， 相对来说比较喜欢 ReST 。 似乎无论哪边都要 依赖 Pygments 作为代码着色器，那么其实 Rubyist 也至少需要安装 Python 。 我倾向于不依赖任何 Ruby 组件，最好没有 C 扩展 的纯 Python 实现。 于是我开始在 Github 上找 Python 的静态博客引擎。 Flask 的作者 mitsuhiko 写的 rstblog 看起来不错，不过似乎没有多少人在用。 Hyde 似乎很完善，不过默认的标记语言是 MarkDown ， 又依赖于几个 Ruby 组建，而且官方网站的设计实在太前卫。 最终我看到了 Pelican 。 [1] 比如 Python 2.x 与 3.x 之间看似难以跨越的鸿沟，以及 PyPy 、 CPython 、 Stackless 、 Cython 等各个实现之间的微妙差别。 [2] 是的，我们有 easy_install ，我们有 pip ， 不过这些都是包管理器，都是装好特定的Python实现之后的事情。 Python实现本身还不需要包管理器来管理。 Python 的版本问题基本上也只需要 2to3.py 和 3to2.py 这样的轻量级转换器就可以了，你不需要为了安装多个软件而在硬盘里留下多个不同版本的 Python 。 如果为了引用的稳定性，你可以用 virtualenv ，不过这又是另一回事情了。 那么就 Pelican 吧 对我而言， Pelican 相比于 Octopress 有几个好处： 纯 Python 实现。 这意味着我可以换用任何 Python 解释器而不必担心兼容性问题。比如我就换成了 PyPy 。 多语言支持。因为 Pelican 的作者似乎是个法国人。不过这个似乎大部分人不需要…… 我是想尽量把一篇博客写成三种语言作为锻炼吧。 ReST 。这样我就可以用 Leo 的 @auto-rst 直接写 ReST了。简单方便快捷有效。 不过似乎 Pelican 的关注度不如 Octopress 那么高，现在一些部分还有细微的问题： pelican-import 从 WordPress 导入的时候对中文、日文的支持似乎很成问题。 日期格式、时区、字符集、和多语言功能的结合度还不够。 我在尝试改善它。 模板还不够丰富。 插件也不够多…… 希望这么优秀的工具能够受到更多关注，以上这些问题都是增加关注度之后很快就能解决的问题。 我的设置 settings.py 安装 Pelican 很容易，一句话就够了： $ pip install pelican 然后把文章写成ReST的格式，放在`pages`文件夹里面。(重新)生成只要： $ pelican -s settings.py 上传到 Github: $ git commit -am \"Commit message\" $ git push 就这么简单。附上我的配置文件： # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , ' %a , %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a ' ), 'jp' :( 'jpn' , '%Y/%m/ %d ( %a )' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","url":"//farseerfc.me/zhs/try-pelican.html"},{"title":"关于我的Blogs","text":"从 farseerfc.wordpress.com 导入 很久没有写过blog或者之类的东西了。这边一直荒废着。 由于国内被墙的原因，另一个wordpress： http://fchome.sinaapp.com/ 应该会同步更新这里的内容。 抽空写点什么吧。","tags":"import","url":"//farseerfc.me/zhs/about-my-blogs.html"},{"title":"\"…if we do this work … \" --Bill Gates","text":"Imported from renren \"…if we do this work … and the result is that Linux works great …\" --Bill Gates From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf If this is the reason that Xen 4.0 is still not fully support ACPI 3.0, then f*ck you Bill Gates!","tags":"import","url":"//farseerfc.me/en/if-we-do-this-work.html"},{"title":"\"…if we do this work … \" --Bill Gates","text":"renren から導入した。 From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf もしこれは今更Xen4.0の上にACPI 3.0完全的なサポートが得ない原因、ならBill Gatesを呪います！","tags":"import","url":"//farseerfc.me/jp/if-we-do-this-work.html"},{"title":"\"…if we do this work … \" --Bill Gates","text":"导入自 renren From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf 如果这就是我至今在Xen4.0上得不到ACPI 3.0的完善支持的原因，那么我诅咒Bill Gates！","tags":"import","url":"//farseerfc.me/zhs/if-we-do-this-work.html"},{"title":"[zz]\"西厢计划\"原理小解","text":"从 farseerfc.wordpress.com 导入 好神奇的想法，先存着，以后慢慢研究 原文： http://blog.youxu.info/2010/03/14/west- chamber/ 待月西厢下，迎风户半开。隔墙花影动，疑是玉人来。 最近推上最流行的一个关键词是\"西厢计划\", 这个计划名字取得很浪漫，客户端叫做张生，对，就是西厢记里面那个翻墙去见崔莺莺小姐的张生；显然，服务器端必然叫做崔莺莺。客户端的张生是最重要的部件，可以不依赖于服务端工作。因为西厢计划的作者只是简要的介绍了一下原理，其他报道又语焉不详，我当时就觉得很好奇，花了昨天一个晚上详细读了一下源代码，终于知道怎么回事了，觉得原理非常漂亮，所以写篇文章介绍总结一下。 先说大方向。大家都知道，连接被重置的本质，是因为收到了破坏连接的一个 TCP Reset 包。以前剑桥大学有人实验过，客户端和服务器都忽略 Reset, 则通信可以不受影响。但是这个方法其实只有理论价值，因为绝大多数服务器都不可能忽略 Reset 的 (比如 Linux, 需要 root 权限配置iptables, 而且这本身也把正常的 Reset 给忽略了)。只要服务器不忽略 Reset, 客户端再怎么弄都没用，因为服务器会停止发送数据，Reset 这条连接。所以，很多报道说西厢计划是忽略 Reset, 我从源代码来看应该不是这样。在我看来，西厢计划是利用了墙的一个可能的弱点–墙只在连接发起的时候把一个 TCP 连接加入监听序列，如果墙认为这个连接终止了，就会从监听序列中去掉这条记录，这样，这条连接上后续的包就不会被监听。西厢计划就是让墙\"认为\"这个连接终止的一个绝妙的方法。只要墙认为这个连接两端都是死老虎，墙就不会触发关键词检测，其后所有的数据，都不存在连接被重置的问题了。 如何让一个连接置之死地而后生，就是西厢计划那帮黑客神奇的地方了。这也不是一日之功。 首先，这帮牛人发现，墙的是一个入侵检测系统，把含有关键字的包当成一种\"入侵\"来对待。采取这种设计有很多好处，但缺点是入侵检测系统可能具有的问题，墙都可能有。西厢计划主页上那篇著名的论文就是讲这些七七八八的漏洞的。可以说处理这些七七八八的漏洞是非常困难的，迫使墙的设计者\"拆东墙，补西墙\"。这样补来补去，外表看起来好像很牛逼的墙，其实有很多本质上无法简单修补的漏洞，其中有一个致命的，就是 TCP 连接状态的判定问题。 出于入侵检测系统这种设计的局限，墙没有，也没办法准确判定一条 TCP 连接的状态，而只是根据两边收到的数据来\"推测\"连接的状态。而所有的关键词检测功能，都是基于\"连接还活着\"的这个推测的结果的。因为墙的规则是在连接发起的时候开始对这条连接的检测，在连接终止的时候停止对这条连接的检测，所以，一旦对连接的状态推测错误，把还活着的连接当成已经关闭的连接，墙就会放弃对这条连接上随后所有的包的检测，他们都会都透明的穿过墙的入侵检测。 上面只是想法，具体到 TCP 协议实现这一层，就要只迷惑墙，还不能触及我要通信的服务器。最理想的情况下，在任何有效通信之前，就能让墙出现错误判断，这些，就需要对 TCP 协议有深刻理解了。西厢计划的那帮黑客，居然真的去读 TCP 几百页的 RFC，还居然就发现了方法（这里我假设读者都知道 TCP 的三次握手过程和序列号每次加一的规则）。 我们都知道，三次握手的时候，在收到服务器的 SYN/ACK 的时候，客户端如果发送 ACK 并且序列号+1 就算建立连接了，但是客户端如果发送一个序列号没 +1 的 FIN （表示连接终止，但是服务器知道，这时候连接还没建立呢， FIN 这个包状态是错的，加上序列号也是错的，服务器自己一判断，就知道这个包是坏包，按照标准协议，服务器随手丢弃了这个包）, 但这个包，过墙的时候，在墙看来，是表示连接终止的(墙是 ma de in china, 是比较山寨的，不维护连接状态，并且，墙并没有记下刚才服务器出去的 SYN/ACK 的序列号，所以墙不知道序列号错了）。所以，墙很高兴的理解为连接终止，舒了一口气去重置其他连接了， 而这个连接，就成了僵尸，墙不管你客户端了，而这时候，好戏才刚刚开始。 事实上，墙是双向检测的（或者说对每个包都检测的），因此，对服务器和客户端实现相同的对待方法，所以，墙不管客户端还不行，假如服务端有关键词传给客户端，墙还是有可能要发飙的（这里说有可能，因为我也不知道）。所以，最好的办法就是，让服务端也给墙一个终止连接的标志就好了。可是这个说起来简单，做起来难，怎么能让不受自己控制的服务器发一个自己想要的包呢？ 西厢计划的那帮黑客，再次去读几百页的 RFC, 令人惊讶的发现，他们居然在 RFC 上发现了一个可以用的特性。我们上面说了，三次握手的时候，在收到 SYN/ACK 后，客户端要给服务器发送一个序列号+1 的ACK，可是，假如我不+1呢，直接发 ACK 包给服务器。 墙已经认为你客户端是死老虎了，不理你了，不知道你搞什么飞机，让这个 ACK 过了。可是服务器一看，不对啊，你给我的不是我期待的那个序列号， RFC 上说了，TCP 包如果序列号错了的话，就回复一个 Reset. 所以，服务器就回复了一个 Reset。这个 Reset 过墙的时候，墙一看乐了，服务器也终止连接了，好吧，两边都是死老虎了，我就不监听这条连接了。而至于客户端，这个服务器过来的 Reset 非常好识别，忽略就是。随后，客户端开始正确的发送 ACK, 至此，三次握手成功，真正的好戏开始，而墙则认为客户端和服务器都是死老虎，直接放过。所以，张生就这样透明的过了墙。 至于过墙以后所有的事情，《西厢记》里面都有记载，各位读者自行买书学习。 现在的西厢计划客户端，即\"张生\"模块的防连接重置的原理就是这样，服务器端，即莺莺模块的实现也是类似的。防DNS那个，不懂 DNS 协议，所以看不懂。我猜想，因为开发人员都是黑客，所以自然喜欢用最经得起折腾和高度定制的 Linux 开发。 现在看西厢计划的实现，因为依赖于 Linux 内核模块 netfilter, 在 Linux 上如鱼得水，但往其他平台的移植可能是个亟待解决的问题。 我觉得，在其他平台上，可以通过 libpcap 和 libnet ，在用户态实现相同的功能，就是有点麻烦而已，有兴趣的懂网络的可以照西厢计划原理，在家自行做出此功能；当然，全中国人民都用 Linux 最好 :) PS 1: 据说是西厢计划一个作者画的原理图： http://img.ly/DIi PS 2: 我对 TCP 的理解仅限于课本，如果上面的对技术的理解有错，请大家指出。 PS 3: 有些漏洞，可能是设计上本质缺陷，不是那么容易修复的。 PS 4: 除了最后一个图，本文没有其他相关链接，如需相关资料，自行Google。","tags":"import","url":"//farseerfc.me/zhs/zz-introducing-scholarzhang.html"},{"title":"Write a program to keep CPU usage as sin funcion","text":"Imported from: renren . It is said that this is a problem from interview of Microsoft. Write a program, which makes the CPU usage curve in Windows Task Manager shows a Sin function. The program below is written in java: public class sincpu { private static final int cycle = 1024 , tick = 256 ; public static void main ( String [] args ) throws InterruptedException { for ( int i = 0 ;; i ++ ){ work ( calcNextSleep ( i % cycle )); sleep ( tick - calcNextSleep ( i % cycle )); } } private static long calcNextSleep ( long i ){ return ( int )( Math . sin (( double ) i * 2 * Math . PI / cycle ) * tick + tick ) / 2 ; } private static void sleep ( long sleepTime ) throws InterruptedException { if ( sleepTime < 2 ) Thread . yield (); else Thread . sleep ( sleepTime ); } private static void work ( long period ) { long start = System . currentTimeMillis (); for (;;){ Math . sin ( 1 ); if ( System . currentTimeMillis () - start >= period ) break ; } } } Be careful you need to turn off other cores if you have multi-core CPU.","tags":"import","url":"//farseerfc.me/en/sine-cpu.html"},{"title":"写程序让CPU占用率保持正弦函数","text":"导入自 renren 据说是一道微软的面试题。如题，写程序，让Windows的任务管理器中的性能监视器呈现正弦曲线。 潜心钻研良久，得代码：（java） public class sincpu { private static final int cycle = 1024 , tick = 256 ; public static void main ( String [] args ) throws InterruptedException { for ( int i = 0 ;; i ++ ){ work ( calcNextSleep ( i % cycle )); sleep ( tick - calcNextSleep ( i % cycle )); } } private static long calcNextSleep ( long i ){ return ( int )( Math . sin (( double ) i * 2 * Math . PI / cycle ) * tick + tick ) / 2 ; } private static void sleep ( long sleepTime ) throws InterruptedException { if ( sleepTime < 2 ) Thread . yield (); else Thread . sleep ( sleepTime ); } private static void work ( long period ) { long start = System . currentTimeMillis (); for (;;){ Math . sin ( 1 ); if ( System . currentTimeMillis () - start >= period ) break ; } } } 多核CPU上测试时要注意关掉一个CPU：","tags":"import","url":"//farseerfc.me/zhs/sine-cpu.html"},{"title":"关于神创论的一些见解","text":"导入自 renren 看到陈骉同学很有感想的一篇神创论与命运日志，觉得近日很久没有看到这样的评论了。想说几句自己的观点。 首先我认为，神创论与宿命论没有多少关联，甚至进化论者相较于神创论者更容易接受宿命论的观点。因为神创论主张意志的存在，人所具有的个体意志与神的意志，因此在神创论者的眼中事件的结果是可以通过意志来改变的，亦即如果我从物理楼11楼跳下，那么我就可以改变自己死亡时间的宿命。上帝的意志同样可以左右事件的结果，也就是所谓的宿命不复存在。而进化论者不承认意志独立于物质世界的存在，你我的思考、行为，都受到物理学法则诸如量子力学的约束，这就引出了北大物理系教授的那句\"宇宙中的一切都是可以计算的\"，亦即宿命论。如我我选择现在从物理楼上跳下，我这一行为并不是处于个人的独立意志，乃是想证明这一点，亦即我跳楼这一举动是有其背后的动机与原因的，就如同计算机的输入必然导致了输出，宿命的必然终结于此。 其次，关于事件的复杂度所导致的随机化，在大量混沌随机中也存在着如统计学和随机分形学这样的规律，并不是否认宿命的充分理由。 关于神创论的合理性问题。我认为是否相信神的存在只是一个boolean二值问题，它为true为false本身并不重要，重要的是确定它的取值之后得到的推论与结果。如果否认神的存在，如现代数学这样的完美又何以存在，进化论者的解释是事物最终会向着更好更高级的方向发展，产生现代数学乃至现代科学是发展的必然。而这种论调显然有悖于物理中以热力学第二定律为首的，预言事物会随时间推演愈发混乱的论断。更进一步，甚至整个人类、整个生物系统的存在都是有悖于热力学推论的现象，是某种理论只能以\"小概率事件\"解释的现象。 神创论的核心观点之一，是神的唯一存在性，按照邹恒明的比喻，这就如同数学中集合中元素的的唯一性一般至关重要。数学乃至近代科学的发展，其起源在于这种对神性的探求，而不仅仅是好奇心就可以解释的。反观东方文化中数学的发展，开始时领先于西方科学千余每年，但是始终作为一种craft-oriented的实用主义学科。可以说没有了神的唯一性支持，人们就不能确信自己能找到这样一种完美高效的学科，只能在实用的基础上发展其基础算数。可以想象，没有神的完美与唯一性，数学必将发展成现代化学或者微软软件这样，庞大而充满特例，到处都是修补与查表，怎么会像现在的完美、简洁与和谐。 神创论者并不是将难题推与\"神\"然后放任不管，他们相信神是最为理智的存在，创人时人同样得到了神的智慧和理智，也就是神可以用人的理智来理解。 引用牛顿《自然哲学的数学原理》中终章的话\"太阳、恒星、行星的这个极精致的结构不可能存在，除非通过一个有理智的和有权能的存在的设计和主宰……他不是作为宇宙的灵魂，而是作为一切的主宰而统治所有……\" 以上…… (发现最近的哲理思维果然慢了不少，写作思绪也一片混乱&#94;_&#94;)","tags":"import","url":"//farseerfc.me/zhs/some-thought-on-creationism.html"},{"title":"由记忆棒误差故障引发的关于面向对象设计的九点思考","text":"从 farseerfc.wordpress.com 导入 故障描述: MMC Memory Stick Duo记忆棒未经Adapter适配器，直接插入SD Reader，致使MMC卡入SD Reader中。 栈展开： 某日下午，无课。 忙于数分作业，想查询用手机拍摄的板书照片。 取出手机中的MMC。 未经装配Adapter，直接插入SD Reader。 (A runtime exception was thrown.) 尝试翻转笔记本机身，倒出MMC，未果。(rethrow) 尝试用手指甲取出，未果。(rethrow) 考虑到有\"推入反弹\"机制，尝试将MMC推入更深，反弹机制由于类型不匹配而失效，未果。(rethrow) (The exception spread across the border of the model.) 电脑维修技师接手(catch) 技师未能发现问题所在，由我解说原委。 (Because the exception lose the information, RTTI was asked to recall the information) 技师发现问题，尝试用镊子镊出MMC，未果。 技师开解机箱(expose the data structure) 技师制作钩子，勾出MMC(hooker link to the structure) 取出MMC，故障解除 故障总结 1.接收到没有完全了解、或没有适当工具解决的exception时，不要尝试用不成熟的技术解决，应尽快寻求能解决它的代码。否则，被反复rethrow的exception，尤其是通过模块边界的exception，有可能由subclass退化为superclass，并因此而丧失一些信息。尽量不要让exception丢失信息，必要时，通过RTTI机制寻回信息。 2.超负荷运转，多线程执行，这种种复杂性都有可能导致错误，应避免。无论你有多么信任你的代码或能力。 3.在设计class的interface时，相匹配的interface应该满足is-a的关系。因此，任何能插入SD Reader的object，即任何实现了SD interface的object，都应该is-a SD card。这次故障中，interface接受了MMC，但MMC不是SD。即使这种情况下throw an exception，都不能使事态缓和。能提供compile-time error时，尽量让错误以compile-time error的形式展现，并在事先解决。类型匹配问题是应该能在事先解决的问题。 4.Design patterns中的Adapter pattern应该只是迫不得已情况之下的解决方案。只有当你无权改变现状时，才能使用Adapter。如果能改变现状，应该改变设计以符合interface。 5.因为上条，所有相似功能的对象应具有相同的interface，不同的interface是本次故障的根源所在。 6.特殊情况下，破坏封装机制并expose the data structure是必要的，应该有方法支持这种做法。C的指针和C#的Reflection技术都以不同的方式支持这种做法。其他的一些语言机制，比如serializing(序列化)或streaming(流化)，也可以以某种方式间接支持这一做法。当然，机制还应避免这种做法被滥用。 7.相反功能具有相同操作的设计，容易造成使用的混乱，应适当避免。比如SD Reader的推入反弹设计，即插入和弹出使用同一个向里推的操作的设计。同样的设计还包括，C++中的setNewHandle使用同一个函数，同时设置和返回handle。以及有些书中提倡的，使用同名函数重载的方式，实现setter/getter的设计。 8.特殊工具(hooker)对于解决特定问题，通常比手工解决有效。不要嫌麻烦而不愿意构造特殊工具。 9.栈语义，即FILO顺序，总在不知不觉中影响我们。违反了FILO顺序的操作极易造成混乱。本故障发生时正确的处理顺序为： 装配Adapter 插入SD Reader 读取数据 停用设备 拔出SD Reader 拆解Adapter 本次故障的原因就是违反了FILO顺序，违反了栈语义。","tags":"import","url":"//farseerfc.me/zhs/9-thoughts-about-oop-from-wrongly-insert-memory-stick.html"},{"title":"Program Development in Java Preface","text":"从 farseerfc.wordpress.com 导入 程序开发原理 ——抽象、规格与面向对象设计 Barbara Liskov 、John Guttag 著 杨嘉晨 等译 关于翻译风格： 多年来阅读计算机类的著作及译作，感觉总体的困难在于一大堆没有标准译名的技术术语。由于通行于工业界和学术界的还是英文原名和术语，我决定保留大量的英文术语。这样的翻译风格借鉴于台湾著名的译者和作者侯捷先生。对于译与不译的权衡，主要考虑阅读的流畅，以及读者的理解能力，或许难免带有一些主观色彩。 前言 Preface 构建产品级质量的程序——可以在很长一段时间内使用的程序——众所周知是极其困难的。本书的目标就是改善程序员解决这项任务的效率。我希望读者在阅读本书之后成为一名好程序员。我相信本书的成功在于改善编程技巧，因为我的学生告诉我这已经发生在他们身上。 怎么才算是一名好程序员？是产生整个程序产品的效率。关键是要在每一阶段减少浪费掉的努力。解决的方法包括：在开始编写代码之前就仔细考虑你的实现方案，通过未雨绸缪的方法来编写代码，使用严格的测试在早期发现错误，以及仔细注意模块化编程，这样当错误出现时，只需要改动极少数代码就可以修正整个程序。本书涉及所有这些领域的技术。 模块化编程(Modularity)是编写好程序的关键。把程序分解成许多小模块，每一个模块通过良好定义的狭窄接口和别的模块交互作用(interact)。有了模块化，可以修正一部分程序中的错误而不考虑程序的其他部分，而且可以仅仅理解一部分程序而不必理解整个程序。没有模块化，程序是一大堆有着错综复杂的相互关系的部分的拼凑。很难去领悟和修改这样一个程序，同样也很难让它正常工作。 因此本书的重点在于创建模块化的程序：怎样把程序组织成一系列精心挑选的模块。本书认为模块化就是抽象(abstraction)。每一个模块意味着一个抽象，比如说指引一系列文档中的关键字的目录，或者在文档中使用目录来查找匹配某个问题的文档的过程。着重强调面向对象编程思想——在程序中使用数据抽象和对象的思想。 这本书使用Java作为它的编程示例的语言。我们没有假定读者已经熟悉Java。尽管可能没什么价值，但是本书中的思想是语言无关的，并且可以在任何语言的编程中使用。 怎样使用这本书？ How Can the Book Be Used 本书《程序开发原理》有两种使用方法。其一是作为课本教材，讲述如何用面向对象的方法来设计和实现复杂系统；其二是编程专家使用，帮助他们改善编程技能，增进他们的关于模块化和Object-Oriented(面向对象)设计的知识。 作为教材使用时，本书一般作为第二或第三门程序设计课程。我们已经在MIT使用本书很多年，给大一大二的本科生教授第二门编程课。在这一阶段，学生们已经知道怎样编写小程序。课程在两方面利用这一点：让学生更仔细地思考小程序，以及教他们如何利用小程序作为组件构建大型程序。这本书也可以在专业（如软件工程）后期教学中使用。 建立在本书基础上的课程适合于所有计算机科学专业。尽管许多学生可能永远不会成为真正的大型程序的设计师，他们可以在开发部门工作，在那儿他们负责设计和实现能与整个结构耦合的子系统。模块化设计的子系统是这种任务中心，这对那些从事大型程序设计任务的人来说也同样重要。 这本书讲什么？What Is This Book About 通观全篇三分之二的书致力于讨论在构建独立的程序模块时产生的问题，剩下的部分讨论怎样运用这些模块构建大型程序。 程序模块Program Modules 这一部分的书集中讨论抽象机制(abstraction mechanism)。它讨论procedure(子程序)和exception(异常)，数据抽象，遍历(iteration)抽象，数据抽象系列(family)以及多态(polymorphic)抽象。 在对抽象的讨论中，三个步骤是重要的。首先是决定被抽象的东西到底是什么：它提供给它的用户哪些行为。创造抽象是设计的关键，因此本书讨论如何在众多选择中挑选，以及怎样才能创造出好的抽象。 第二步是通过为一个抽象制定一个规格(specification)来获取它的意义。如果没有一些描述，一个抽象就会含糊不清，而变得没有使用价值。specification则提供了需要的描述。本书定义了一种specification的格式，讨论了一份好的specification应有的属性，并且提供了许多示例。 第三步是实现抽象。本书讨论怎样设计一份实现，以及在简洁性和执行性能之间怎样权衡利弊。书中强调封装(encapsulation)的重要性以及在一份实现中履行规格中定义的行为的重要性。书中同样提供一些技术——尤其是不变式断言(representation invariant)和抽象函数(abstraction function)——来帮助读者理解代码和它的原因。不变式断言和抽象函数都实现到尽可能的程度，这对于除错和调试很有用。 关于类型层次(type hierarchy)的材料注重讨论使用它作为抽象的技术——一种把相关联的一组数据抽象归入同一系列的技术。这里很重要的一点是，是否应当将一个类型作为另一个类型的子类。本书定义了替换原则——通过比较子类和父类的specification，来决定是否建立子类关系的方法 [1] 。 本书同样涉及除错和调试。书中讨论怎样得到足够数量的测试情况，来准备通过黑箱和白箱测试，它同样强调了复查(regression)测试的重要性。 编写大型程序 Programming in the Large 本书的其后部分讲解怎样用模块化的方法设计和实现大型程序。它建立在前文有关abstraction和specification的材料的基础之上。 编写大型程序涵盖四个主要议题。首先讲解需求分析——怎样才能领悟程序中需要什么。本书讨论怎样实施需求分析，也讨论书写产生的需求规格的方式，通过使用一种描述程序的抽象阶段的数据模型。使用这种模型将产生一份更为正式的specification，同时它也使需求检查更加严格，这样可以更好的领悟需求。 编写大型程序的第二项议题是程序设计，这通常是一个循序渐进的过程。设计过程围绕构建有用的抽象来组织，这些抽象作为整个程序之中理想的构建组建。这些抽象在设计时被仔细的编写规格，这样当程序实现时，那些实现抽象的模块可以独立地开发。这种设计使用设计笔记编写文档，包括描述整个程序结构的模块间依赖性的图示。 第三项议题是实现和测试。本书讨论了前置设计分析对于实现的必要性，以及怎样进行设计复审。它同样讨论了设计和实现的顺序。这一部分比较了自顶而下与自底而上的组织方式，讨论如何使用驱动程序和占位程序 [2] (stub)，并且强调了制定一个事先的顺序策略的必要性，以满足开发组织和客户的需求。 本书以一章设计模式(design pattern)结束。一些模式在前面的章节介绍过，比如遍历抽象是算法的主要组建。最后的章节讨论前文中没有涉及到的模式。希望它作为这一教材的介绍。有兴趣的读者可以继续阅读其它书中更完善的讨论 [3] 。 [1] 译注：如果子类的specification包括了所有父类的specification，就是说父类的要求也是子类的要求，或者子类的要求更为严格，那么可以建立父子关系。而替换原则的说法是，对于具有父子关系的类，任何需要一个父类对象的地方，都可以替换为一个子类对象。 [2] 译注：在测试某一组建时，由于其余组建还未实现，这一组建与其余组建的接口衔接部分无法工作。此时可以针对这一组建编写其余组建的占位程序(stub)，预留出接口的衔接代码。占位代码通常不做任何有价值的事情，只报告组建的衔接部位工作正常。 [3] 译注：作者指的是设计模式的开山之作——《Design Patterns—Elements of Reusable Object-Oriented Software》,作者为设计模式界著名的\"四人帮\"GoF(Gang of Four)。此书详尽讨论了三大类共23个广泛使用的设计模式的适用范围、依存关系、实现细节以及已有的应用领域等问题。书中以C++和Smalltalk为示例语言，不过书中所涉及的模式适用于所有面向对象的语言。","tags":"import","url":"//farseerfc.me/zhs/program-development-in-java-preface.html"},{"title":"C++ Tricks 3.2 标号、goto，以及switch的实现","text":"从 farseerfc.wordpress.com 导入 3.2 标号、goto，以及switch的实现 goto语句及标号(label)是最古老的C语言特性，也是最早被人们抛弃的语言特性之一。像汇编语言中的jmp指令一样，goto语句可以跳转到同一函数体中任何标号位置： void f() {int i=0; Loop: //A label ++i; if(i<10)goto Loop; //Jump to the label } 在原始而和谐的早期Fortran和Basic时代，我们没有if then else，没有for和while，甚至没有函数的概念，一切控制结构都靠goto(带条件的或无条件的)构件。软件工程师将这样的代码称作\"意大利面条\"代码。实践证明这样的代码极容易造成混乱。 自从证明了结构化的程序可以做意大利面条做到的任何事情，人们就开始不遗余力地推广结构化设计思想，将goto像猛兽一般囚禁在牢笼，标号也因此消失。 标号唯一散发余热的地方，是在switch中控制分支流程。 很多人不甚了解switch存在的意义，认为它只是大型嵌套if then else结构的缩略形式，并且比if语句多了很多\"不合理\"的限制。如果你了解到switch在编译器内部的实现机制，就不难理解强加在switch之上的诸多限制，比如case后只能跟一个编译期整型常量，比如用break结束每一个case。首先看一个switch实例： switch (shape.getAngle()) { case 3: cout<<\"Triangle\";break; case 4: cout<<\"Square\";break; case 0:case1: cout<<\"Not a sharp!\";break; default: cout<<\"Polygon\"; } 任何程序员都可以写出与之对应的if结构： int i= getAngle(shape); if (i==3) cout<<\"Triangle\"; else if(i==4) cout<<\"Square\"; else if(i==0||i==1) cout<<\"Not a sharp!\"; else cout<<\"Polygon\"; 看起来这两段代码在语义上是完全一样的，不是么？ 不！或许代码的执行结果完全一样，但是就执行效率而言，switch版本的更快！ 要了解为什么switch的更快，我们需要知道编译器是怎样生成switch的实现代码的： 首先，保留switch之后由{}括起来的语具体，仅将其中case、default和break替换为真正的标号： switch (getAngle(shape)) { _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 随后，对于所有出现在case之后的常量，列出一张只有goto的跳转表，其顺序按case后的常量排列： goto _case_0; goto _case_1; goto _case_3; goto _case_4; 然后，计算case之后的常量与跳转表地址之间的关系，如有需要，在跳转表中插入空缺的项目： 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; //因为没有case 2，所以插入此项以条转到default 100120: goto _case_3; 100125: goto _case_4; 假设一个goto语句占用5个字节，那么在本例中，goto的地址=case后的常量*5+100105 之后，生成跳转代码，在其余条件下跳转至default，在已知范围内按照公式跳转，全部的实现如下： { int i= getAngle(shape); if (i<0||i>=5)goto _default; i=i*5+100105; //按照得出的公式算出跳转地址 goto i; //伪代码，C中不允许跳转到整数，但是汇编允许 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; 100120: goto _case_3; 100125: goto _case_4; _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 经过这样处理整个switch结构，使得无论switch后的变量为何值，都可以通过最多两次跳转到达目标代码。相比之下if版本的代码则采用线性的比较和跳转，在case语句很多的情况下效率极低。 由此,我们也可以知道,为什么case后跟的一定是编译期整型常数，因为编译器需要根据这个值制作跳转表。我们可以明白为什么case与case之间应该用break分隔，因为编译器不改变switch语句体的结构，case其本身只是一个具有语义的标号而已，要想跳出switch，就必须用break语句。","tags":"import","url":"//farseerfc.me/zhs/c-tricks-3-2-label-goto-and-implementation-of-switch.html"},{"title":"C++ Tricks 3.1 左值右值与常量性(lvalue，rvalue & constant)","text":"从 farseerfc.wordpress.com 导入 3.1 左值右值与常量性(lvalue，rvalue & constant) 首先要搞清楚的是，什么是左值，什么是右值。这里给出左值右值的定义： 1、左值是可以出现在等号(=)左边的值，右值是只能出现在等号右边的值。 2、左值是可读可写的值，右值是只读的值。 3、左值有地址，右值没有地址。 根据左值右值的第二定义，值的左右性就是值的常量性——常量是右值，非常量是左值。比如： 1=1;//Error 这个复制操作在C++中是语法错误，MSVC给出的错误提示为\"error C2106: '=' : left operand must be l-value\"，就是说'='的左操作数必须是一个左值，而字面常数1是一个右值。可见，严格的区分左值右值可以从语法分析的角度找出程序的逻辑错误。 根据第二定义，一个左值也是一个右值，因为左值也可读，而一个右值不是一个左值，因为右值不可写。 通常情况下，声明的变量是一个左值，除非你指定const将它变成一个右值： int lv=1; const int rv=lv; 由于右值的值在程序执行期间不能改变，所以必须用另一个右值初始化它。 一个普通变量只能用右值初始化，如果你想传递左值，必须声明一个引用或一个指针： int & ref=lv;//用引用传递左值 int * plv=&lv;//传递指针以间接传递左值 必须用左值初始化引用，然而，可以用右值初始化常量引用： int & r1=1; //Error! const int & r2=1; //OK 这实际上相当于： int _r2=1; const int & r2=_r2; 这样的写法在函数体内没什么作用，但是在传递函数参数时，它可以避免潜在的(传递左值时的)复制操作，同时又可以接受右值。 通常情况下，函数的参数和返回值都只传回右值，除非你明确的通过引用传递左值。 明确了左值与右值的区别，有助于我们写函数时确定什么时候应该有const，什么时候不该有。比如，我们写了一个代表数学中复数的类Complex： class Complex; 然后，我们写针对Complex的运算符重载：operator+和operator=。问题在于，参数和返回值应该是什么类型，可选类型有四种： Complex、const Complex、Complex&、const Complex&。 对于operator+，我们不会改变参数的值，所以可以通过const Complex&传递参数。至于返回值类型，由于int类型的加法返回右值，所以根据Do as the ints do的原则，返回值类型为const Complex： const Complex operator+(const Complex&,const Complex&); 对于operator=，同样要思考这些问题。我们写入第一个参数，所以第一个参数为Complex&，我们只读取第二个参数，所以第二个参数为const Complex&。至于返回值，还是Do as the ints do。int的赋值返回左值，不信你可以试一试： int i; (i=1)=2; 虽然比较傻，先将i赋为1，再将其改为2，但是这是被C++语法支持的做法，我们就理应遵守。所以返回第一个参数的左值： Complex& operator=(Complex&,const Complex&); const是C++引入的语言特性，也被ANSI C99借鉴，在经典版本的C语言中是没有的。关于const的历史，有几点值得玩味。最初Bjarne Stroustrup引入const时，可写性是和可读性分开的。那时使用关键字readonly和writeonly。这个特点被首先提交到C的ANSI标准化委员会(当时还没有C++标准化的计划)，但是ANSI C标准只接受了readonly的概念，并将其命名为const。随后，有人发现在多线程同步的环境下，有些变量的值会在编译器的预料之外改变，为了防止过度优化破坏这些变量，C++又引入关键字violate。从语义特点来看，violate是const的反义词，因为const表示不会变的量，而violate表示会不按照预期自行变化的量。从语法特点而言，violate与const是极为相似的，适用于const的一切语法规则同样适用于violate。 值的常量性可以被划分为两种：编译期常量和运行期常量。C++语法并没有严格区分这两种常量，导致了少许混乱： const int i=5;const int * pi=&i; const_cast<int&>i=1;//对于运行期常量，在需要时可以去除它的常量性 int a[i];//对于编译期常量，可以用它来指定数组大小 cout<<i<<sizeof(a)/sizeof(a[0])<<*pi; 这种将编译期与运行期常量的特性混用的方法，势必导致语义的混乱。数组a的大小最终是5，因为采用了i的编译期值，而不管i在运行期是否被改变了值。最后一句代码将（有可能）输出551，第一个i的值作为一种优化在编译期绑定，第二个值标明了a的大小，第三个值通过指针显示地输出i的运行期真实值。 在C++的近亲C#的语法中，这两种常量被严格地区分开：编译期常量由const指定，只能是内建类型变量；运行期常量由readonly指定，可以是任何类型。永远不会改变的常量，如圆周率pi的值，应该用const声明；而其它有可能改变的常量，皆由readonly声明。 C++中的const的特点更倾向于C#中的readonly，虽然语法上允许使用const的编译期常量性，但正如上文所展示的，这容易造成混乱。为了得到C#中const的语义，在C++中，我们不必回归恶魔#define的怀抱，可以使用所谓\"匿名enum技巧\"。当匿名声明一个enum类型时，其中的枚举值就是一个int类型的编译期常量，比如： enum{Size=5;}; int a[Size]; 这种使用匿名enum来声明编译期常量的做法，被广泛应用于STL、boost等模板库的实现代码中。","tags":"import","url":"//farseerfc.me/zhs/c-tricks-3-1-lvalue-rvalue-constant.html"},{"title":"C++ Tricks 2.2 I386平台的内存布局","text":"从 farseerfc.wordpress.com 导入 2.2 I386平台的内存布局 众所周知，I386是32位体系结构。因此对于绝大多数I386平台的C++编译器而言，sizeof(int)=sizeof(long)=sizeof(void*)=4。当然C++标准对此没有任何保证，我们也不应该试图编写依赖于此的代码。 32位指针的可寻址空间为4GB。为充分利用这么大的寻址空间，也是为了支持其它更先进的技术比如多任务技术或者动态链接库技术，WinNT使用虚拟内存技术，给与每个应用程序全部4GB的内存空间。4GB的地址被一分为二，前2GB供应用程序自己使用，后2GB由系统内核分配和管理。这2GB的内存地址，通常被划分成3种内存区使用： 1 代码及静态数据区 由代码加载器从动态链接库镜像(通常是exe或dll文件)加载，通常定位到镜像文件中指定的基址开始的内存区。如果基址所在内存已被占用，动态连接器会将代码或数据重定向到其它可用地址。 在C++中，静态数据包括：名字空间(namespace)和全局(global)对象、函数的static对象、类的static数据成员。这些静态数据由编译器分配地址(但可能被重定向)，由静态连接器写入代码文件(通常是exe或dll)的静态数据区段。所以标准说，这些静态数据在编译期就已经具有地址。 2 栈(Stack) 栈是最常用的动态数据存储区，所有函数的non-static对象和函数参数都在程序运行期在栈上分配内存。在数据结构中，术语\"栈(Stack)\"意指先进后出(FILO，First In Last Out)，与\"队列(Queue)\"所指的FIFO相对。相对于基于堆的对象分配技术，默认使用栈的对象分配有两点优势： 一、栈的FILO与人的思维方式相同 现实生活中有许多事例都使用FILO的方式，比如人们必须先提起话筒再拨打号码，而后挂断电话之后再放下话筒。使用FILO的栈，可以保证事物的销毁顺序以其诞生顺序相反的顺序进行，不会产生在挂断电话之前就放下话筒的尴尬。 二、栈的分配管理仅需要两个额外指针：栈顶(esp)和栈底(ebp)指针 从实现的技术层面而言，栈的管理比其它动态分配技术要简单很多。I386平台上的动态栈管理，仅需要栈顶和栈底两个指针。这两个指针的存储显然不能放置于栈中，置于静态数据区又有损效率。I386平台为管理动态栈专门预留了两个通用寄存器变量esp与ebp，分别代表栈顶(esp,Extended Stack Pointer)与栈底(Extended Bottom Pointer)指针。其中的extended代表它们是32位指针，以区分16位的sp和bp寄存器。 栈是动态存储区的特点，表明它的内存占用将随着程序的运行而变化。I386平台上WinNT将应用程序的栈置于程序空间，向下增长。程序初始化时，由操作系统将esp指向系统分配的栈空间的顶部。当程序需要在栈上分配变量时，就将esp减去变量所需字节数，这被称作\"压栈(Push)\"；随后又要销毁变量时，就将esp加上变量所需字节数，这被称作\"弹出(Pop)\"。esp与ebp两者之间所夹的空间，就是当前函数正在使用的栈空间。由于栈向下增长，esp(栈顶)的值总是小于ebp(栈底)的值，新分配的变量地址总是小于旧变量的地址。 3 堆(Heap)和自由存储区 栈中的变量对于分配与释放的顺序有特定要求，这在一定程度上限制了栈的适用范围。面向对象(OO，Object Oriented)的程序设计思想也要求能自由地控制变量的分配与销毁。由此，现代操作系统都提供了被称作\"堆(Heap)\"的自由存储区，以允许由程序员控制的对象创建和销毁过程。C标准库函数malloc和free则是对操作系统提供的堆操作的封装。C++提供的自由存储区运算符new和delete则通常是malloc和free的又一层封装。 操作系统经由malloc和free控制对堆的访问。堆的存储管理技术各不相同，简单的使用双链表管理，复杂的可以比拟一个完整的文件系统。 由于额外的管理需求，使用系统提供的通用分配器在堆上分配和销毁变量的代价，无论从空间角度还是效率角度而言，都比在栈上分配对象要高昂很多。对于sizeof上百的大型对象，这样的高昂代价还是可以接受的，但是对于sizeof只有个位数的小对象，这样的代价通常是一个数量级的差距。正因为这个原因，STL不使用new和delete，转而使用分配子(alllocor)分配对象。","tags":"import","url":"//farseerfc.me/zhs/c-tricks-2-2-i386-memory-layout.html"},{"title":"C++ Tricks","text":"从 farseerfc.wordpress.com 导入 C++ Tricks By FarseerFc 从今天起，我再将在 Live Space 和 QQZone 同时发表一系列文章，暂定名为\"C++Tricks\"。 本文旨在记录和阐述一些本人学习C++时所得的心得、技巧。总体来看，本文涉及的内容是每一个C++程序员都应该知道的，但是很少见诸C++教材。希望对各位同仁学习C++有所帮助。 也可以通过QQ或MSN向我索要此文的DOC版或PDF版，会比网页上的更新的快一点。 1 词法问题(Lexical Problems) 1.1 条件运算符(?:) 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱 2 X86体系结构 2.1 X86概述 2.2 I386平台的内存布局 2.3 I386平台C函数内部的栈分配 2.4 I386平台C函数调用边界的栈分配 2.5 I386平台的边界对齐(Align) 2.6 I386平台C函数的可变参数表(Variable Arguments) 2.7 I386平台的其它函数调用模型 3 过程式编程 3.1 左值右值与常量性(lvalue，rvalue & constant) 3.2 标号、goto，以及switch的实现","tags":"import","url":"//farseerfc.me/zhs/c-tricks.html"},{"title":"C++ Tricks 2.3 I386平台C函数内部的栈分配","text":"从 farseerfc.wordpress.com 导入 2.3 I386平台C函数内部的栈分配 函数使用栈来保存局部变量，传递函数参数。进入函数时，函数在栈上为函数中的变量统一预留栈空间，将esp减去相应字节数。当函数执行流程途径变量声明语句时，如有需要就调用相应构造函数将变量初始化。当执行流程即将离开声明所在代码块时，以初始化的顺序的相反顺序逐一调用析构函数。当执行流程离开函数体时，将esp加上相应字节数，归还栈空间。 为了访问函数变量，必须有方法定位每一个变量。变量相对于栈顶esp的位置在进入函数体时就已确定，但是由于esp会在函数执行期变动，所以将esp的值保存在ebp中，并事先将ebp的值压栈。随后，在函数体中通过ebp减去偏移量来访问变量。以一个最简单的函数为例： void f() { int a=0; //a的地址被分配为ebp-4 char c=1; //c的地址被分配为ebp-8 } 产生的汇编代码为： push ebp ;将ebp压栈 mov ebp,esp ;ebp=esp 用栈底备份栈顶指针 sub esp,8 ;esp-=8，为a和c预留空间，包括边界对齐 mov dword ptr[ebp-4],0 ;a=0 mov byte ptr[ebp-8],1 ;c=1 add esp,8 ;esp+=8，归还a和c的空间 mov esp,ebp ;esp=ebp 从栈底恢复栈顶指针 pop ebp ;恢复ebp ret ;返回 相应的内存布局是这样： 09992:c=1 <-esp 09996:a=0 10000:旧ebp <-ebp 10004:…… 注:汇编中的pop、push、call、ret语句是栈操作指令，其功能可以用普通指令替换 push ebp相当于: add esp,4 mov dword ptr[esp],ebp pop ebp相当于： mov ebp,dword ptr[esp] sub esp,4 call fun_address相当于： push eip jmp fun_address ret相当于 add esp,4 jmp dword ptr[esp-4] 带参数的ret ret 8相当于 add esp,12 jmp dword ptr[esp-4] 所有局部变量都在栈中由函数统一分配，形成了类似逆序数组的结构，可以通过指针逐一访问。这一特点具有很多有趣性质，比如，考虑如下函数，找出其中的错误及其造成的结果： void f() { int i,a[10]; for(i=0;i<=10;++i)a[i]=0;/An error occurs here! } 这个函数中包含的错误，即使是C++新手也很容易发现，这是老生常谈的越界访问问题。但是这个错误造成的结果，是很多人没有想到的。这次的越界访问，并不会像很多新手预料的那样造成一个\"非法操作\"消息，也不会像很多老手估计的那样会默不作声，而是导致一个，呃，死循环！ 错误的本质显而易见，我们访问了a[10]，但是a[10]并不存在。C++标准对于越界访问只是说\"未定义操作\"。我们知道，a[10]是数组a所在位置之后的一个位置，但问题是，是谁在这个位置上。是i! 根据前面的讨论，i在数组a之前被声明，所以在a之前分配在栈上。但是，I386上栈是向下增长的，所以，a的地址低于i的地址。其结果是在循环的最后，a[i]引用到了i自己！接下来的事情就不难预见了，a[i]，也就是i，被重置为0，然后继续循环的条件仍然成立……这个循环会一直继续下去，直到在你的帐单上产生高额电费，直到耗光地球电能，直到太阳停止燃烧……呵呵，或者直到聪明的你把程序Kill了……","tags":"import","url":"//farseerfc.me/zhs/c-tricks-2-3-i386-stack-allocation-in-c-functions.html"},{"title":"C++ Tricks 2.4 I386平台C函数调用边界的栈分配","text":"从 farseerfc.wordpress.com 导入 2.4 I386平台C函数调用边界的栈分配 当调用一个函数时，主调函数将参数以声明中相反的顺序压栈，然后将当前的代码执行指针(eip)压栈，然后跳转到被调函数的入口点。在被调函数中，通过将ebp加上一个偏移量来访问函数参数，以声明中的顺序(即压栈的相反顺序)来确定参数偏移量。被调函数返回时，弹出主调函数压在栈中的代码执行指针，跳回主调函数。再由主调函数恢复到调用前的栈。 函数的返回值不同于函数参数，通过寄存器传递。如果返回值类型可以放入32位变量，比如int、short、char、指针等类型，通过eax寄存器传递。如果返回值类型是64位变量，如_int64，同过edx+eax传递，edx存储高32位，eax存储低32位。如果返回值是浮点类型，如float和double，通过专用的浮点数寄存器栈的栈顶返回。如果返回值类型是用户自定义结构，或C++类类型，通过修改函数签名，以引用型参数的形式传回。 同样以最简单的函数为例： void f(){ int i=g(1,2); } int g(int a,int b){ int c=a+b； return c; } 产生的汇编代码如下： f: push ebp ;备份ebp mov ebp,esp ;建立栈底 sub esp,4 ;为i分配空间 mov eax,2 ;准备参数b的值2 push eax ;将b压栈 mov eax,1 ;准备参数a的值1 push eax ;将a压栈 call g ;调用g add esp,8 ;将a和b一起弹出，恢复调用前的栈 mov dword ptr[ebp-4],eax ;将返回值保存进变量i mov esp,ebp ;恢复栈顶 pop ebp ;恢复栈底 g: push ebp ;备份ebp mov ebp,esp ;建立栈底 sub esp,4 ;为局部变量c在栈中分配内存 mov eax,dword ptr[ebp+8] ;通过ebp间接读取参数a的值 mov ebx,dword ptr[ebp+12] ;通过ebp间接读取参数b的值 add eax,ebx ;将a和b的值相加，之和存在eax中 mov dword ptr[ebp-4],eax ;将和存入变量c mov eax,dword ptr[ebp-4] ;将c作为返回值，代码优化后会删除此句 add esp,4 ;销毁c的内存 mov esp,ebp ;恢复栈顶 pop ebp ;恢复栈底 ret ;返回函数f 栈的内存布局如下： 100076:c <- g的esp 100080:f的ebp=100100 <- g的ebp 100084:f的eip 100088:a=1 100092:b=2 100096:i 100100:旧ebp <-f的ebp 100104:…… 注意在函数g的汇编代码中，访问函数的局部变量和访问函数参数的区别。局部变量总是通过将ebp减去偏移量来访问，函数参数总是通过将ebp加上偏移量来访问。对于32位变量而言，第一个局部变量位于ebp-4，第二个位于ebp-8，以此类推，32位局部变量在栈中形成一个逆序数组；第一个函数参数位于ebp+8，第二个位于ebp+12，以此类推，32位函数参数在栈中形成一个正序数组。 由于函数返回值通过寄存器返回，不需要空间分配等操作，所以返回值的代价很低。基于这个原因，旧的C语法约定，不写明返回值类型的函数，返回值类型为int。这一规则与现行的C++语法相违背，因为C++中，不写明返回值类型的函数返回值类型为void，表示不返回值。这种语法不兼容性是为了加强C++的类型安全，但同时也带来了一些问题。","tags":"import","url":"//farseerfc.me/zhs/c-tricks-2-4-i386-stack-allocation-accross-function-invocation.html"},{"title":"C++ Tricks 2.5 I386平台的边界对齐(Align)","text":"从 farseerfc.wordpress.com 导入 2.5 I386平台的边界对齐(Align) 首先提问，既然I386上sizeof(int)==4、sizeof(char)==1，那么如下结构(struct)A的sizeof是多少？ struct A{int i;char c;}; 答案是sizeof(A)==8……1+5=8？ 呵呵，这就是I386上的边界对齐问题。我们知道，I386上有整整4GB的地址空间，不过并不是每一个字节上都可以放置任何东西的。由于内存总线带宽等等的技术原因，很多体系结构都要求内存中的变量被放置于某一个边界的地址上。如果违反这个要求，重则导致停机出错，轻则减慢运行速度。对于I386平台而言，类型为T的变量必须放置在sizeof(T)的整数倍的地址上，char可以随便放置，short必须放在2的整数倍的地址上，int必须放在4的整数倍的地址上，double必须放在8的整数倍的地址上。如果违反边界对齐要求，从内存中读取数据必须进行两次，然后将独到的两半数据拼接起来，这会严重影响效率。 由于边界对齐问题的要求，在计算struct的sizeof的时候，编译器必须算入额外的字节填充，以保证每一个变量都能自然对齐。比如如下声明的struct: struct WASTE { char c1; int i; char c2; } 实际上相当于声明了这样一个结构： struct WASTE { char c1; char _filling1 [3];//三个字节填充，保证下一个int的对齐 int i; char c2； char _filling2 [3];//又三个字节填充 } 值得注意的是尾部的3个字节填充，这是为了可以在一个数组中声明WASTE变量，并且每一个都自然对齐。因为有了这些填充，所以sizeof(WASTE)==12。这是一种浪费，因为只要我们重新安排变量的声明，就可以减少sizeof： struct WASTE { int i; char c1,c2; } 像这样的安排，sizeof就减少到8，只有2个字节的额外填充。为了与汇编代码相兼容，C语言语法规定，编译器无权擅自安排结构体内变量的布局顺序，必须从左向右逐一排列。所以，妥当安排成员顺序以避免内存空间的浪费，就成了我们程序员的责任之一。一般的，总是将结构体的成员按照其sizeof从大到小排列，double在最前，char在最后，这样总可以将结构的字节填充降至最小。 C++继承了C语言关于结构体布局的规定，所以以上的布局准则也适用于C++的class的成员变量。C++进一步扩展了布局规定，同一访问区段(private、public、protected)中的变量，编译器无权重新排列，不过编译器有权排列访问区段的前后顺序。基于这个规则，C++中有的程序员建议给每一个成员变量放在单独区段，在每一个成员声明之前都加上private:、public:、protected:标志，这可以最大限度的利用编译器的决策优势。 在栈中按顺序分配的变量，其边界也受到对齐要求的限制。与在结构中不同的是，栈中的变量还必须保证其后续变量无论是何种类型都可以自由对齐，所以在栈中的变量通常都有平台相关的对齐最小值。在MSVC编译器上，这个最小值可以由宏_INTSIZEOF(T)查询： #define _INTSIZEOF(T) ( (sizeof(T) + sizeof(int) - 1) & ~(sizeof(int) - 1) ) _INTSIZEOF(T)会将sizeof(T)进位到sizeof(int)的整数倍。 由于在栈中分配变量使用_INTSIZEOF而不是sizeof，在栈上连续分配多个小变量(sizeof小于int的变量)会造成内存浪费，不如使用结构(struct)或数组。也就是说： char c1,c2,c3,c4;//使用16字节 char c[4];//使用4字节 当然，使用数组的方法在访问数组变量(比如c[1])时有一次额外的指针运算和提领(dereference)操作，这会有执行效率的损失。这又是一种空间(内存占用)vs时间(执行效率)的折中，需要程序员自己根据情况权衡利弊。 sizeof的大小可能比我们预期的大，也可能比我们预期的小。对于空类： class Empty {}; 在通常情况下，sizeof(Empty)至少为1。这是因为C++语法规定，对于任何实体类型的两个变量，都必须具有不同的地址。为了符合语法要求，编译器会给Empty加入1字节的填充。所以sizeof()的值不可能出现0的情况。可是对于以下的类声明： class A:public Empty{vitual ~A(){}}; sizeof(A)有可能是6，也有可能是5，也有可能是4！必不可少的四个字节是一个指向虚函数表的指针。一个可能有的字节是Empty的大小，这是是因为编译器在特定情况下会将Empty视作一个\"空基类\"，从而实施\"空基类优化\"，省掉那毫无作用的一字节填充。另一个字节是A的一字节填充，因为从语法上讲，A没有成员声明，理应有1字节填充，而从语义上讲，编译器给A的声明加入了一个指向虚函数表的指针，从而A就不再是一个\"空类\"，是否实施这个优化，要看编译器作者对语法措词的理解。也就是说，sizeof也会出现4+1+1=4的情况。具体要看编译器有没有实施\"空基类优化\"和\"含虚函数表的空类优化\"。 结构和类的空间中可能有填充的字节，这意味着填充字节中可能有数值，虽然这数值并不影响结构的逻辑状态，但是它也可能不知不觉中影响到你。比如说，你手头正好有一组依赖于底层硬件(比如多处理器)的函数，他们在操纵连续字节时比手动编码要快很多，而你想充分利用这种硬件优势： bool BitCompare(void* begin,void* end,void* another); 这个函数将区间[begin,end)之间的字节与another开始的字节相比较，如果有一位不同就返回false，否则返回true。 比如你想将这个函数用于你自己的类的operator==中，这样可以利用硬件加快速度。不过你在动手前要充分考虑，你的class是否真的要比较每一位。如果在类的成员中存在编译器填充的字节数，那么应用以上的函数就是不正确的，因为填充的字节中可以有不同的值。为了保证你可以用Bitwise Compare，你必须确保填充的字节中的值也是相同的。这不仅要求你在类的构造函数中初始化类的每一bit而不是每一个成员，也要求你在复制初始化和复制赋值函数中也同时保证bitwise copy语义，而不是编译器默认产生的memberwise语义。当然，你可能通过与BitCompare一同提供的BitCopy来完成这个艰巨的任务。","tags":"import","url":"//farseerfc.me/zhs/c-tricks-2-5-address-alignment.html"},{"title":"C++ Tricks 2.6 I386平台C函数的可变参数表(Variable Arguments)","text":"从 farseerfc.wordpress.com 导入 2.6 I386平台C函数的可变参数表(Variable Arguments) 基于前文(2.4节)分析，我们可以不通过函数签名，直接通过指针运算，来得到函数的参数。由于参数的压栈和弹出操作都由主调函数进行，所以被调函数对于参数的真实数量不需要知晓。因此，函数签名中的变量声明不是必需的。为了支持这种参数使用形式，C语言提供可变参数表。可变参数表的语法形式是在参数表末尾添加三个句点形成的省略号\"...\"： void g(int a,char* c,...); 省略号之前的逗号是可选的，并不影响词法语法分析。上面的函数g可以接受2个或2个以上的参数，前两个参数的类型固定，其后的参数类型未知，参数的个数也未知。为了知道参数个数，我们必须通过其他方法，比如通过第一个参数传递： g(3,\"Hello\",2,4,5);//调用g并传递5个参数，其中后3个为可变参数。 在函数的实现代码中，可以通过2.4节叙述的，参数在栈中的排列顺序，来访问位于可变参数表的参数。比如: void g(int a,char* c...){ void *pc=&c;int* pi=static_cast<int*>(pc)+1;//将pi指向首个可变参数 for(int i=0;i<a;i++)std::cout<<pi[i]<<\" \"； std::cout<<c<<std::endl; } 我们甚至可以让一个函数的所有参数都是可变参数，只要有办法获知参数的数量即可。比如，我们约定，在传递给addAll的参数都是int，并且最后一个以0结束： int addAll(...); int a=f(1,4,2,5,7,0); 那么addAll可以这样实现： int addAll(...){ int sum=0;int *p=&sum; //p指向第一个局部变量 p+=3; //跳过sum，ebp，eip，现在p指向第一个参数 for(;*p;++p) //如果p不指向0就继续循环 sum+=*p; return sum; } 可变参数表的最广泛应用是C的标准库函数中的格式化输入输出：printf和scanf。 void printf(char *c,...); void scanf(char *c,...); 两者都通过它的首个参数指出后续参数表中的参数类型和参数数量。 如果可变参数表中的参数类型不一样，那么操纵可变参数表就需要复杂的指针运算，并且还要时刻注意边界对齐(align)问题，非常令人头痛。好在C标准库提供了用于操纵可变参数表的宏(macro)和结构(struct)，他们被定义在库文件stdarg.h中: typedef struct {char *p;int offset;} va_list; #define va_start(valist,arg) #define va_arg(valist,type) #define va_end(valist) 其中结构va_list用于指示参数在栈中的位置，宏va_start接受一个va_list和函数的可变参数表之前的参数，通过第一个参数初始化va_list中的相应数据，因此要使用stdarg.h中的宏，你的可变参数表的函数必须至少有一个具名参数。va_arg返回下一个类型为type的参数，va_end结束可变参数表的使用。还是以上文的addAll为例，这次写出它的使用标准宏的版本： int addAll(int i,...) { va_list vl; //定义一个va_list结构 va_start(vl,i); //用省略号之前的参数初始化vl if(i=0)return 0; //如果第一个参数就是0，返回 int sum=i; //将第一个参数加入sum for(;;){ i=va_arg(vl,int); //取得下一个参数，类型是sum if(i==0)break; //如果参数是0，跳出循环 sum+=i; } va_end(vl); return sum; } 可以看出，如果参数类型一致，使用标准库要多些几行代码。不过如果参数类型不一致或者未知(printf的情况)，使用标准库就要方便很多，因为我们很难猜出编译器处置边界对齐(align)等汇编代码的细节。使用标准库的代码是可以移植的，而使用上文所述的其它方法操纵可变参数表都是不可移植的，仅限于在I386平台上使用。 纵使可变参数表有使用上的便利性，它的缺陷也有很多，不可移植性和平台依赖性只是其一，最大的问题在于它的类型不安全性。使用可变参数表就意味着编译器不对参数作任何类型检查，这在C中算是一言难尽的历史遗留问题，在C++中就意味着恶魔reinterpret_cast被你唤醒。C的可变参数表是C++代码错误频发的根源之一，以至于C++标准将可变参数表列为即将被废除的C语言遗留特性。C++语法中的许多新特性，比如重载函数、默认参数值、模板，都可以一定程度上替代可变参数表，并且比可变参数表更加安全。 可变参数表在C++中惟一值得嘉奖的贡献，是在模板元编程(TMP)的SFINAE技术中利用可变参数表制作最差匹配重载。根据C++标准中有关函数重载决议的规则，具有可变参数表的函数总是最差匹配，编译器在被逼无奈走头无路时才会选择可变参数表。利用这一点，我们可以精心制作重载函数来提取类型信息。比如，要判断一个通过模板传递来的类型是不是int： long isIntImp(int); char isIntImp(...); template<typename T> struct isInt { enum{value=sizeof(isIntImp(T()))==sizeof(long);} } 然后，在一个具有模板参数T的函数中，我们就可以写 if(isInt<T>::value)//... 在这个(不怎么精致的)例子中，如果T是int，那么isIntImp的第一个重载版本就会被选中，返回值类型就是long，这样value就为1。否则，编译器只能选中第二个具有可变参数表的重载版本，返回值类型成为char，这样value就为0。把它说得再明白一些，上文的代码所表达的意思是：如果类型T是int，那它就是int，否则它就不是int，呵呵简单吧。这种通过重载决议规则来提取类型信息的技术，在模板元编程中被称作SFINAE，它和其它模板元编程技术被广泛运用于STL、Boost等模板库的开发实现之中。 值得注意的是，在上文SFINAE的运用中，isIntImp并没有出现定义而只提供了声明，因为我们并没有实际调用isIntImp函数，而只是让它参与重载决议并用sizeof判断其返回值类型。这是C++的一个设计准则的完美体现：不需要的东西可以不出现。由于这一准则，我们避免了在C++中调用具有可变参数表的函数这一危险举动，而仅仅利用了可变参数表在语法分析过程中的特殊地位，这种对于危险语言特性的巧妙利用是善意而无害的。","tags":"import","url":"//farseerfc.me/zhs/c-tricks-2-6-i386-variable-arguments.html"},{"title":"C++ Tricks 2.7 I386平台的其它函数调用模型","text":"从 farseerfc.wordpress.com 导入 2.7 I386平台的其它函数调用模型 上文介绍的只是I386平台上C函数调用的标准模型，被称作__cdecl。事实上，Microsoft Visual C++编译器还支持其它一些函数调用模型，所有调用模型名称皆以双下划线开头，下面列出所有函数调用模型的异同： 1 __cdecl 参数压栈顺序：逆序(从右至左) 参数堆栈恢复者：主调函数(caller) __cdecl明确地指出函数使用C函数调用模型，这是默认的调用模型。 2 __stdcall 参数压栈顺序：逆序(从右至左) 参数堆栈恢复者：被调函数(callee) __stdcall是微软所谓的标准调用模型。可惜的是它与__cdecl不兼容。几乎所有的Win32API函数使用这种函数调用模型，希望在DLL之间，或者在程序和WinNT操作系统之间传递函数指针的函数也应该使用这种模型。与__cdecl模型的不同之处在于，__stdcall模型下由被调函数恢复堆栈。主调函数在call语句之后，不需要再加上add语句。而被调函数的ret语句则被添加一个参数，代表函数参数堆栈的长度。因此，被调函数需要明确的知晓函数参数的数量和类型，所以在__stdcall模型下不支持可变参数表，所有参数必须写明。 3 __thiscall 参数压栈顺序：逆序(从右至左)，this用ecx传递。 参数堆栈恢复者：被调函数(callee) __thiscall是VC编译器中类的非静态成员函数(non-static member functon)的默认调用模型。但是如果此成员函数有可变参数表，VC编译器会使用__cdecl。和__stdcall一样，__thiscall由被调函数恢复堆栈。比较独特的是__thiscall会通过ecx寄存器传递成员函数的this指针，而__cdecl下this指针是通过在参数表最前面增加一个函数参数来传递的。__thiscall是VC编译器对this指针的使用的一种优化，大大提高了面向对象程序的效率。在VC2003及之前的编译器上__thiscall不是一个关键字，不能被显式指定。但可以给成员函数显式指定__cdecl来避免使用__thiscall。 4 __fastcall 参数压栈顺序：逆序(从右至左)，前两个32位函数参数放入ecx和edx中 参数堆栈恢复者：被调函数(callee) 快速函数调用模型，将前两个32位函数参数放入ecx和edx中，其余参数再逆序压栈。使用的是和__thiscall类似的优化技术，加快函数调用，适合运用在小型inline函数上。同样使用__stdcall形式的被调函数恢复堆栈，所以不支持可变参数表。 5 __pascal 参数压栈顺序：正序(从左至右) 参数堆栈恢复者：被调函数(callee) 过程式编程语言Pascal所使用的函数调用模型，由此得名。也是16位版本的Windows使用的API模型，过时的模型，现在已经废弃且禁止使用。你会看到有些书本仍会不时提到它，所以需要注意。__pascal是正序压栈，这与大部分I386函数模型都不相同。与__stdcall一样，由被调者恢复堆栈，不支持可变参数表。历史上曾有过的别名PASCAL、pascal、_pascal(单下划线)，现在都改成了__stdcall的别名，与__pascal(双下划线)不同。 6 其它函数调用模型，以及模型别名。 __syscall：操作系统内部使用的函数调用模型，由用户模式向核心模式跳转时使用的模型。由于用户模式和核心模式使用不同的栈，所以没办法使用栈来传递参数，所有参数通过寄存器传递，这限制了参数的数量。用户模式编程中不允许使用。 __fortran：数学运算语言fortran使用的函数模型，由此得名。在C中调用由fortran编译的函数时使用。 __clrcall：微软.Net框架使用的函数模型，托管(Managed)C++默认使用，也可以从非托管代码调用托管函数时使用。参数在托管栈上正序(从左至右)压栈，不使用普通栈。 CALLBACK、PASCAL、WINAPI、APIENTRY、APIPRIVATE：I386平台上是__stdcall的别名 WINAPIV：I386平台上是__cdecl的别名 7 函数调用模型的指定 函数调用模型的指定方式和inline关键字的指定方式相同，事实上，inline可以被看作是C++语言内建的一种函数调用模型。唯一不同的是，声明函数指针时，也要指明函数调用模型，而inline的指针是不能指明的，根本不存在指向inline函数的指针。比如： int CALLBACK GetVersion(); int (CALLBACK * pf)()=GetVersion;","tags":"import","url":"//farseerfc.me/zhs/c-tricks-2-7-i386-calling-conventions.html"},{"title":"C++ Tricks 2.1 X86概述","text":"从 farseerfc.wordpress.com 导入 2.1 X86概述 所谓X86体系结构，是指以Intel 8086芯片为首的芯片所沿袭的CPU结构，一些文档中又被称作IA32体系结构。包括的芯片有但不限于:Intel 8086至 80486，奔腾(Pentium)系列处理器1至4，赛扬系列处理器，酷睿系列处理器，以及AMD的相应型号产品。X86体系结构在早期属于16位处理器，自80386之后扩展为32位处理器，所以一些文档中又把80386之后的32位处理器体系称作I386。自Pentium4后期，AMD的Athlon64开始，I386被进一步扩充为64位处理器，含有64位寻址能力的X86体系结构被称作X86-64或IA32-64。总之，市售的个人电脑用CPU，除苹果的Macintosh之外，全部采用X86体系结构芯片。 在X86早期，16位的寻址能力只支持64KB(2&#94;16=64K)内存，这显然是不够的。Intel采用分段寻址的方法，用4位段位+16位偏移量，提供了总共1MB(2&#94;20=1M)的寻址能力。所以在X86的16位编程中，有两种指针类型：长指针(lp,long pointer)和短指针(sp,short pointer)，长指针(20位)提供整个内存空间寻址能力，短指针(16位)仅支持同一段中的寻址。在\"古代\"DOS及Win3.x编程过程中，两种类型的指针，以及总共1MB的内存大小，常常把程序员们折腾得焦头烂额。 自I386之后，CPU才开始提供32位的寻址能力。有了整整4GB(2&#94;32=4G)的寻址空间，所有指针统一为长指针(32位)。时至今日，我们仍可以看到微软文档中指针变量的lp前缀。由于内存管理的需要，分段机制被保留下来，但这一次不是因为地址空间太小，而是因为地址空间远大于实际内存容量，从而采用了虚拟内存机制。 在从16位结构向32位结构转变的过程中，由于向下兼容的历史原因，曾一度长时间出现硬件32位(I386)、软件16位(Win3.x)的情况。同样也是为了兼容16位软件，Win9x操作系统(Win95、Win98、WinME)保留了16位代码和32位代码。混合代码的设计使得Win9x及其混乱和不稳定。直到完全32位内核的操作系统WinNT(以及构建于其上的Win2000，WinXP，Win2003)的出现，X86平台上内存布局混乱的局面才得以改善。有了从16位至32位移植的经验和准备，现今的从32位到64位的操作系统移植显得平稳顺利很多。WinXP和WinVista系统都同时发布了32位版本和64位版本，并且其x86-64系统都实现了对32位软件的无缝衔接支持。","tags":"import","url":"//farseerfc.me/zhs/c-tricks-2-1-x86-architecture.html"},{"title":"C++ Tricks 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱","text":"从 farseerfc.wordpress.com 导入 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱 很多人甚至不知道逗号(,)也是个C++运算符。与语法上要求出现的逗号(比如分隔函数参数的逗号)不同的是，出现在表达式中的逗号运算符在语义上表示多个表达式操作的连续执行，类似于分隔多语句的分号。比如： for ( int i=0,j=9;i<10;++i , --j)std::cout<<i<<\"+\"<<j<<\"=9\\n\"; 在这句语句中，出现了两个逗号，其中前者是语法上用来分隔声明的变量的，并非逗号运算符，而后者则是一个逗号运算符。根据C++标准，逗号运算符的执行顺序为从左到右依次执行，返回最后一个子表达式的结果。由于只有最后一个表达式返回结果，所以对于一个语义正常的逗号表达式而言，前几个子表达式必须具有副作用。同时，从语言的定义中也可以看出，逗号表达式对求值的顺序有严格要求。 对求值顺序有要求的，除了逗号表达式和条件表达式(参见1.1)，在C++中还有逻辑运算符(&&和||)。逻辑运算相较于数学运算和位运算而言，有个显著的不同点：逻辑运算在计算到一半时，就有可能已经得到结果，这样继续运算另一半就不是必需的。对于A&&B，如果A=false，那么无论B为何值，整个的结果都是false；同样的A||B，如果A=true，那么不考虑B，结果一定是true。 C++标准规定，如果逻辑运算到一半(算出A)时，就已经可以确定运算的结果，那么就不运算剩下的另一半(B)。这种执行语义被称作\"短路\"。在其它一些编程语言中，短路语义是可以选择的：在Ada里非短路的逻辑运算符为and和or，短路的逻辑运算符为and_then和or_else。但是在C++中，逻辑运算符的短路语义是语法上强制的，我们没有非短路版本的运算符。如果确实需要非短路语义，我们总是可以通过增加一个bool中间变量加以解决。有时，短路对于保证正确执行是必须的，比如： char *p=getString(); if (p && *p)std::cout<<p; 这段代码在得到了一个字符串后，在字符串不为空时输出它。在C++中判断一个字符串不为空需要两个步骤：判断指针是否为0，以及指针不为0时判断指针指向的内容是否为''。就像条件表达式中讨论到的(参见1.1)，在p为空时提领p是个极其危险的操作。逻辑运算符的短路语义则避免了这种危险。 以上对逗号运算符与逻辑运算符的讨论，仅限于C++标准所定义的运算符语义。为什么这样说呢？这是因为在C++中，运算符的语义是可以由程序员自行定义的，这种机制叫做运算符重载(operator overload)。运算符重载可以将人们熟悉的运算符表达式转换成函数调用，使编程灵活而直观，是个方便的语言特性。不过有时运算符重载也会使人困扰，那就是当运算符重载遇到求值顺序问题时。 C++中，并不是所有合法运算符都可以被合法地重载。条件运算符虽然对求值顺序有要求，但它并不在可重载运算符之列，所以运算符重载机制对它没有影响。问题在于，逗号运算符和逻辑运算符都可以被合法地重载： class BadThing{/* Some Bad and Stupid Thing*/}; BadThing& operator ,(BadThing&, BadThing&);//重载了逗号运算符 bool operator &&(BadThing&, BadThing&);//重载了&& BadThing b1,b2; if (b1&&b2)b1,b2;//被替换成如下形式： if ( operator &&(b1,b2)) operator ,(b1,b2); 可以看到，重载了运算符之后，对运算符的使用被替换为相应的函数调用形式。因此，旧有的运算符的执行顺序不再适用，取而代之的是函数参数的压栈顺序。 根据C++标准规定，任何参数必须在进入函数之前压栈，所以在进入 operator &&之前，b1、b2就会被求值，这里不再有短路规则，任何依赖于短路语义的不知不觉间操作BadThing的代码(可能通过模板)都会混乱。 短路语义只是一个方面，更重要的在于压栈顺序。鉴于执行效率和旧代码兼容性等细节问题，C++标准在压栈顺序上给编译器的开发者留有很大自主性。标准的说辞是，编译器可能以任何它觉得方便的顺序将参数压栈，从左到右，从右到左，甚至从中间到两边，在这一点上我们不能安全地做任何假设。在上面的例子中，编译器生成的代码可能先计算b1再计算b2，也可能是相反的顺序。再看看编译器的实际情况，在我试过的所有基于X86体系结构的编译器中，参数都是以逆向压栈，即从右到左，有悖于大多数人的阅读习惯和直觉(别说你是来自伊斯兰的……)。 在C时代使用函数调用时，压栈顺序并不是什么大问题，毕竟大多数人会在函数调用的边界稍稍小心一些。但是到了C++中，事情变得有些复杂，因为简单如a+b的使用，就有可能被运算符重载机制替换为函数调用。更何况有模板参与之后，我们写代码时不能确定对象的真实类型，也就无法预知一个运算符是否真的被重载过，唯一稳妥的方法是，假定任何有可能被重载的运算符的使用都是函数调用。 <p style=\"margin:0;\"> 回到上文的示例中，由于,和&&都被替换为函数调用，程序的执行顺序将成为压栈顺序，在X86上很有可能是从右到左，与标准定义的运算符的顺序正好相反。逗号运算符原本就含有\"先…后…\"的语义，这种颠倒的执行顺序势必造成程序和程序员的混乱。以我的经验而言，含有 operator ,的类，完全没有办法和STL或者iostream相互协作，反而会导致巨量的错误报告(什么叫巨量的错误报告有概念么？如果没有，那说明你还没玩过范式编程(GP, Generic Programming)。去玩玩GP吧，看看你的编译器对巨量的定义。在我手头，针对3.5KB的代码文件倾泻出3.8 MB 的错误信息的编译器不在少数……)。有鉴于此，我的结论是，除非你有充足的依据支持你这么做(比如你的粗暴上司的键盘上只剩下逗号能用)，并且你清楚的了解这么做的后果的严重性(比如至少要看过此文)，否则我奉劝你，永远不要碰 operator ,、 operator &&以及 operator ||！","tags":"import","url":"//farseerfc.me/zhs/c-tricks-1-2-trap-in-comma-logical-operator.html"},{"title":"C++ Tricks 1.1  条件运算符(?:)","text":"从 farseerfc.wordpress.com 导入 1.1 条件运算符(?:) 条件运算符(?:)是C++中唯一的三目运算符(trinary operator)，用于在表达式中作条件判断，通常可以替换if语句，与Visual Basic中的iif函数、Excel中的if函数有同样的作用。语法形式如下： condition ? true_value : false_value 其中 condition *条件是任何可以转换为bool类型的表达式，包括但不仅限于**bool* 、 int 、指针。与 if 和 while 的条件部分稍显不同的是，这里不能定义变量，否则会导致语法错误。 另外，条件语句会切实地控制执行流程，而不仅仅是控制返回值。也就是说，两个返回值表达式中永远只有一个会被求值，在表达式的执行顺序很重要时，这点尤为值得注意。比如： int *pi=getInt(); int i=pi ? *pi : 0; 这里，只有当pi的值不为0时，它才会被提领(dereference)。这种语义保证了程序的正确性，因为提领一个空指针将导致致命的运行期错误(通常是非法操作的警告)。同时，正因为条件运算符控制运算流程的特点，使得它不能用类似iif的普通函数来模拟： int iif( int con, int t, int f){ if (c) return t; return f;}//试图模拟?: …//in some function int *pi=getInt(); int i=iif(pi,*pi,0);//Error! 这段代码会导致上文提到的致命运行期错误。C/C++标准规定，参数在被传递给函数之前求值，因此无论pi为何值，都会被提领。又因为函数传回一个空指针的情况比较少见，所以这样的错误在调试时很难被发现，一旦发生又势必造成重大灾难。这样的代码在实践中应尽量避免。 有时，条件运算符控制流程的特点会不知不觉影响我们的代码。在C时代，最大值MAX通常用宏实现： #define MAX(a,b) ((a)>(b) ? (a) : (b)) 需要用额外的括号将宏参数和宏本体保护起来，以免运算符优先级扰乱逻辑，这是宏丑陋的特点之一，这里暂且不提。矛盾在于，用具有副作用的表达式调用宏时，会出现问题： int i=5,j=6;//… int a=MAX(++i,++j); 代码的作者原意显然是想先将i,j分别递增，再将其中较大的一个赋给a。执行这段代码，当i=5,j=6时，a=8，知道为什么吗？通过宏展开，赋值语句成这样： int a=(++i)>(++j) ? (++i) : (++j);//删除了多余括号 在判断之前，i、j被分别自增一次，然后舍弃:之前的部分，j又被自增一次。执行之后，i=6,j=8。 MAX的更正确更安全的实现，是利用模板将类型参数化。STL标准算法中就有一个这样的工具级模版函数std::max。 条件运算符是表达式而不是语句，这使得它可以出现在任何需要表达式的地方，这扩大了它的适用范围。在那些语法上只能出现表达式而不能出现语句的地方（比如变量初始化），条件运算符有着不可替代的作用。 条件运算符优于 if 语句的另一个场合是\"模板元编程\"(TMP, Template MetaProgramming)。在TMP这个古怪奇异的编译期运算编程技术中，一切旧有的技术和法则被全线击破，我们所能仰仗的工具，只有模板特化(Specialization)、 typedef s、函数声明(无法调用它们)、以及编译期常量运算。已经有人很深入地论证过，仅有以上这些，就已经形成了一个\"图灵完善\"的计算机语言。我们可以用模板特化技术，来模拟条件分支，循环迭代等一系列复杂的语言结构。由于可以参与编译期常量运算，条件运算符在TMP世界中很自然地扮演起重要角色。 比如，给与类型T的一个变量t，我们想声明一个缓冲区存放t和一个int，缓冲区的大小不小于sizeof(T)也不小于sizeif(int)，我们可以这样写： char buffer[sizeof(T)>sizeof(int)? sizeof(T): sizeof(int)]; 我们不能用一个if语句替换这个运算： int i; if(sizeof(T)>sizeof(int))i=sizeof(T); else i=sizeof(int); char buffer[i];//语法错误! 原因在于数组声明中的下标必须是一个编译期常量，而不是一个运行期的值，条件表达式的运算可以在编译期进行，if语句就只能在执行期执行。","tags":"import","url":"//farseerfc.me/zhs/c-tricks-1-1-conditional-operator.html"},{"title":"填补信仰、唤醒良知","text":"从 farseerfc.wordpress.com 导入 填补信仰、唤醒良知 我们听尽了呼吁与号召，对于良知，我不必谴责丧失它的国人，不必盛赞良知的美好。我只想讨论，丧失了良知的原因——空缺的信仰。 一、空缺信仰丧失良知 现代的国人缺少信仰，以至于丧失良知。曾几何时，中华民族由良好的信仰凝聚而成。三皇五帝时，族民们以炎黄为信仰；春秋战国时，士大夫之族以周制礼乐为信仰；汉代以后，百姓延习孔孟之说、老聃之道，以儒家学说为信仰；自大唐起，以佛教为首的现代宗教纷纷传入中原，人民开始以它们作为信仰。 直至鸦片战争、五四运动，西方文化入侵中华，国人开始抛弃国学，转而去研究科学；文化大革命，十年文化浩劫，人们批判旧的信仰，却没有合适的新的信仰前来填补。从此，国人的信仰出现空缺，国人的良知也被一块块蚕食殆尽。 二、信仰、科学、迷信 在许多国人的心目中，信仰就等于迷信。从小到大的教育告诉我们，信奉宗教是愚昧而又无知的表现，科学与信仰是矛盾的。是么？ 我们无法保证社会上的每一个人都接受过良好的教育，我们无法确信最前沿的科学素养能在民众中普及。在科普与教育力不从心的社会死角，在科学技术尚不能及的文化盲区，我们依旧需要信仰的规范与限制，我们的良知需要信仰！ 信仰不等于迷信。信仰本身无所谓谜与不迷，迷信是持有信仰的人误解了信仰，盲目遵从的结果。以为烧过香就可以免遭祸患，以为捐了钱就可以升入天堂，以为引火自焚就可以功德圆满，这便是迷信了。希特勒曾经的人类完善计划，依照遗传学的原理，将科学家与运动员强行结为夫妇孕育生命，希望得到最优秀的人类种族，这便是对科学这种信仰的迷信！ 由此可见，科学与信仰并不是矛盾的硬币的两面，从某种意义而言科学本身也是信仰的一种。虽然历史上宗教往往作为科学发展的阻碍，可信奉真理的信念一直是推动科学发展的动力。牛顿就曾说过，对自然规律的探询是为了更接近上帝。由此可见，信仰与真理，与良知毫无矛盾。 三、信仰唤醒良知 很少有人仔细思考过，良知的缺失是由信仰的缺失造成的。信仰是人思想的寄托与依靠，是人行动处世的准则。没有了信仰的人，思想行为就缺少了约束的标准，人就更容易因为一时不成熟的冲动，背叛良知、铸成错误。 泰国人以佛教为信仰，泰国的寺庙每天都会有成千上万人顶礼膜拜。寺庙有一个人尽皆知的不成文规定：不得穿鞋进入。于是在寺庙之外，游客们可以看到千百双各式的鞋子有序的摆放在门口。国人每每看到此景，总会诧异地问：没有人会偷鞋么？得到的答案极为简单：庙前偷鞋会遭报应。由于拥有信仰，泰国人作了坏事会受到良知的谴责，泰国商人售出假货会彻夜难眠。二战期间，无数犹太难民被天主教会收留藏匿从而侥幸逃生，这同样是出于，天主教徒们被自己信奉的教义\"众生生来平等\"，所唤醒的良知。 天下无贼的世界，不能仅靠科普说教来营造。如果脱离了信仰，纵使是教育也无法培养良知。我问过许多修化学的同学，学习化学的意义，结论竟是为了考试。如果没有对科学的信仰，我们可以牢记公式定理，却质疑它们是真理；如果没有对社会公德的信仰，我们可以熟背交通规则，却正大光明地闯红灯；如果没有对医疗道德的信仰，医生可以放任伤口发炎，从而留住病人继续治疗…… 国人需要信仰的约束，需要填补信仰的空白，从而唤醒那深埋于每个国人内心深处的良知！","tags":"import","url":"//farseerfc.me/zhs/filling-believings-calling-conscience.html"}]}