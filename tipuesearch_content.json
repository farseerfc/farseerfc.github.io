{"pages":[{"url":"//farseerfc.me/about.html","text":"關於這個Blog 我會儘量用中文(Chinese, zh)，日語(Japanese, jp)，英語(English, en)這 三門語言同時寫這個blog，在有意義的情況下。中文有繁體(zh)與簡體(zhs) 之分，我以繁體撰寫，再以 OpenCC 將繁體轉化爲對應的簡體。 近況 我叫 楊嘉晨 1989年6月生 目前就讀於 大阪大學大學院 情報科學研究科 計算機科學專攻 博士2年級 ( http://sdl.ist.osaka-u.ac.jp/ ) 本科畢業於 上海交通大學 軟件學院 軟件工程專業 F0703701班 ( http://se.sjtu.edu.cn/ ) 聯繫方式 生活中你可以通過這些方式找到我： 手機（softbank）: 080-3853-2770 手機郵箱: jc-yang@softbank.ne.jp 網絡上你可以通過這些方式找到我： Skype: farseerfc GMail: farseerfc@gmail.com twitter: http://twitter.com/farseerfc Github: https://github.com/farseerfc weibo(微博): http://weibo.com/farseerfc facebook: http://www.facebook.com/farseerfc telegram: http://telegram.me/farseerfc tox: https://toxme.se/u/farseerfc 關於現在用的頭像 這個頭像來自 HUG 大大 繪製的 十六夜 ( いざよい ) 咲夜 ( さくや ) ， pixiv id=41143207 因爲實在太喜歡了所以就擅自拿來作爲頭像了。十六夜是東方系列正傳 妖々夢 ( ようようむ ) 、 永夜抄 ( えいやしょう ) 和格鬥類 緋想天 ( ひそうてん ) 、 非想天則 ( ひそうてんそく ) 等作裏用得最順手的角色。","tags":"pages","title":"About"},{"url":"//farseerfc.me/links.html","text":"友情鏈接 以下列出我在網上認識的好 朋友 ( jī yǒu ) 們，排名不分先後。歡迎申請友鏈。 lilydjwg 依雲 百合仙子 #archlinuxcn 社區管理者之一。 felixonmars 火星貓大大 archlinux官方打包者， #archlinuxcn 社區管理者之一。 phoenixlzx 鳳凰菊苣 #archlinuxcn 社區管理者之一， #nyaacat MC喵窩 管理員之一。 fixme 水源技站，本科同窗。 LQYMGT ID是irc上的中文社區鎮社之寶的可愛學弟。 quininer 純JavaScript的帥氣博客。 acgtyrant 御宅暴君，維護着他個人的和Arch的兩個博客。 przhu OS X 骨灰用戶，Haskell大牛，好像什麼都知道。 mazk 我的完整博客模板的第一個用戶，似乎還是高中生，前途無量呀。","tags":"pages","title":"Links"},{"url":"//farseerfc.me/compositor-in-X-and-compositext.html","text":"在上篇文章 「桌面系統的混成器簡史」 中我介紹了其它桌面系統中的混成器的發展史和工作原理， 話題回到我們的正題 Linux 系統上，來說說目前 X 中混成器是如何工作的。 這篇文章將比上一篇深入更多技術細節，不想看太多細節的可以直接跳過看 結論 。 原始的 X 的繪圖模型 首先，沒有混成器的時候 X 是這樣畫圖的： X 的應用程序沒有統一的繪圖 API 。GTK+ 在 3.0 之後統一用 Cairo 繪圖， 而 Cairo 則是基於 PDF 1.4 的繪圖模型構建的， GTK 的 2.0 和之前的版本中也有很大一部分的繪圖是用 Cairo 進行， 其餘則通過 xlib 或者 xcb 調用 X 核心協議提供的繪圖原語繪圖。 QT 的情況也是類似，基本上用 QPaint 子系統繪製成位圖然後交給 X 的顯示服務器。 顯示服務器拿到這些繪製請求之後，再在屏幕上的相應位置繪製整個屏幕。 當然還有很多老舊的不用 GTK 或者 QT 的程序，他們則直接調用 X 核心協議提供的繪圖原語。 值得注意一點是 X 上除了沒有統一的繪圖模型，也沒有統一的矢量圖格式。 X 核心協議的繪圖原語提供的是像素單位的繪圖操作，沒有類似 GDI+ 或者 Quartz 提供的 設備無關 ( Device Independence ) 的「點」的抽象。所以只用 X 的繪圖原語的話，我們可以把 (1,1) 這個像素點塗黑，但是不能把 (0.5, 0.5) 這個點塗黑，這一設計缺陷在 Unix Hater's Handbook 中已經被吐槽過了。因爲這個缺陷，所以直接用 X 繪圖原語繪製的圖像不能像 矢量圖那樣進行無損縮放。同樣的缺陷導致 X 繪圖原語繪製的字符不能做到 子像素級 ( subpixel-level ) 抗鋸齒 ( anti-aliasing ) （這解釋了默認配置下的 xterm 和 urxvt 中的字體渲染爲什麼難看 ）。相比之下 GDI 有對應的 WMF 矢量圖格式， Quartz 有對應的 PDF 矢量圖格式， 而 X 中沒有這樣的格式對應。因爲沒有統一的矢量圖格式，所以無論是 Cairo 、QPaint 還是沒有用這些繪圖庫但是同樣在意字體和曲線渲染效果的程序（比如 Firefox 和 Chromium）都需要首先渲染到內部的 XPixMap 位圖格式，做好子像素渲染和矢量縮放，然後再把渲染好的位圖轉交給 X 圖形服務器。 通過 Composite 擴展重定向窗口輸出 2004年發佈的 X11R6.8 版本的 Xorg 引入了 Composite 擴展 。這個擴展背後的動機以及前因後果在一篇文章 The (Re)Architecture of the X Window System 中有詳細的表述。Composite 擴展允許某個 X 程序做這幾件事情： 通過 RedirectSubwindows 調用將一個窗口樹中的所有窗口渲染重定向到 內部存儲 ( off-screen storage ) 。重定向的時候可以指定讓 X 自動更新窗口的內容到屏幕上或者由混成器手動更新。 通過 NameWindowPixmap 取得某個窗口的內部存儲。 通過 GetOverlayWindow 獲得一個特殊的用於繪圖的窗口， 在這個窗口上繪製的圖像將覆蓋在屏幕的最上面。 通過 CreateRegionFromBorderClip 取得某個窗口的邊界剪裁區域（不一定是矩形）。 有了 Composite 擴展，一個 X 程序就可以調用這些 API 實現混成器。 這裏有篇 教學解釋如何使用 Composite 擴展 。開啓了混成的 X 是這樣繪圖的： 整個 X 的混成器模型與 Mac OS X 的混成器模型相比，有如下幾點顯著的區別： 混成的部分是交由外部的程序完成的，對混成的繪製方式和繪製普通窗口一樣。 出於效率考慮，絕大多數 X 上的混成器額外使用了 XRender 擴展或者 OpenGL/EGL 來加速繪製貼圖。不過即使如此，還是不能避免同樣的位圖（內容不一定完全一致， 比如 X 可以在窗口交給它的位圖上加上邊框然後再返還給混成器） 在不同的三個程序之間來回傳遞 。 RedirectSubwindows 調用針對的是一個窗口樹，換句話說是一個窗口 及其全部子窗口，不同於 Mac OS X 中混成器會拿到全部窗口的輸出。 這個特點其實並不算是限制，因爲 X 中每個虛擬桌面都有一個根窗口，只要指定這個根窗口 就可以拿到整個虛擬桌面上的全部可見窗口輸出了。 反而這個設計提供了一定的自由度，比如我們可以用這個調用實現一個截圖程序， 拿到某個特定窗口的輸出，而不用在意別的窗口。 爲了讓窗口有輸出，窗口必須顯示在當前桌面上，不能處於最小化 狀態或者顯示在別的虛擬桌面，用 X 的術語說就是窗口必須處於 被映射 ( mapped ) 的狀態。因此直接用上述方法 不能得到沒有顯示的窗口的輸出 ，比如不能對最小化的窗口 直接實現 Windows 7 中的 Aero Peak 之類的效果。這個限制可以想辦法繞開， 比如在需要窗口輸出的時候臨時把窗口映射到桌面上，拿到輸出之後再隱藏起來， 不過要實現這一點需要混成器和窗口管理器相互配合。 不像 Mac OS X 的基於 OpenGL Surface 的繪圖模型是 設備無關 ( device independent ) 的，這裏 X 的繪圖模型是 設備相關 ( device dependent ) 的。 這既是優點也是缺點。從缺點方面而言，顯示到 X 的位圖輸出因爲設備相關性， 所以嚴格對應顯示器的點陣，並不適合作爲文檔格式打印出來。當然無論是 Cairo 還是 QPaint 都提供了到 PostScript 或者 PDF 後端的輸出，所以實用層面這個並不構成問題。 設備相關這一點的優點在於，繪製到 XPM 位圖的時候，程序和繪圖庫是能拿到輸出設備（顯示器） 的特殊屬性的，從而繪圖庫能考慮不同的色彩、分辨率、 DPI 或者 子像素佈局 ( subpixel layout ) 這些屬性以提供最好的渲染效果。 Mac OS X 10.4 在設計的時候也曾考慮過提供無極縮放的支持，而這種支持到了 Mac OS X 10.5 中就縮水變成了 Retina 的固定 2 倍縮放。這種局面在 X 上沒有發生正是因爲 X 的繪圖模型的這種設備相關性，而 Mac OS X 的混成器採用的 OpenGL Surface 則無視了這些設備相關的屬性。 輸入事件的重定向，這可能做到麼？ 通過上述 Composite 擴展提供的 API ，混成器可以把窗口的 輸出 重定向到自己的窗口上。 但是僅僅重定向輸出，整個 X 還不處於可用狀態，因爲 沒有重定向輸入 。 考慮一下用戶試圖用鼠標點擊某個按鈕或者文本框，這時鼠標處於的位置是在 OverlayWindow 上繪製的位置，這個鼠標事件會交給 OverlayWindow ，而用戶期待這個事件被發送給他看到的按鈕上。 需要重定向的事件主要有鍵盤和鼠標事件兩大類（暫時先不考慮觸摸屏之類的額外輸入）。 由於 Composite 擴展並沒有直接提供這方面的重定向 API ，這使得輸入事件處理起來都比較麻煩， 假設要重定向鍵盤事件，混成器需要效仿輸入法框架（fcitx, ibus, scim） 那樣處理一部分按鍵事件並把其餘事件轉給具有輸入焦點的程序。 看看現有的輸入法框架和諸多程序間的問題，我們就能知道這裏的坑有多深。 於是 大部分 X 的混成器都不處理鍵盤事件重定向 。再來看重定向鼠標事件，這邊的坑比重定向鍵盤事件的坑更多， 因爲不像重定向窗口輸出那樣只需要考慮 頂層 ( top-level ) 窗口， 重定向鼠標輸入的時候要考慮所有子窗口（它們有獨立的事件隊列）， 以及要準確記錄輸入事件事件發生時的鍵盤組合鍵狀態，還要正確實現 ICCCM/EWMH 中描述的轉交窗口焦點的複雜規則，所有這些都已經在 X 中實現過的事情需要重新實現一遍。 由於坑太多難以實現，所以所有 X 下的混成器的實現方式都是直接忽略這個繁重的任務， 不重定向輸入事件 而把它交給 X 處理。具體的實現方式就是通過 XFixes 擴展提供的 SetWindowShapeRegion API 將 OverlayWindow 的 輸入區域 ShapeInput 設爲空區域，從而忽略對這個 OverlayWindow 的一切鼠標鍵盤事件。 這樣一來對 OverlayWindow 的點擊會透過 OverlayWindow 直接作用到底下的窗口上。 因爲選擇了不重定向輸入事件， X 下的混成器通常會處於以下兩種狀態： 選擇狀態下可以縮放窗口的大小，扭曲窗口的形狀，並且可以把窗口繪製在任意想要繪製的位置上 （並不是移動窗口的位置）， 但是不能讓用戶與窗口的內容交互 。 正常狀態下可以讓用戶與窗口的內容交互，但是 繪製的窗口位置、大小和形狀必須嚴格地和 X 記錄的窗口的位置、大小和形狀保持一致 。持續時間短暫的動畫效果可以允許位置和形狀稍有偏差，但是在動畫的過程中如果用戶點擊了 變形縮放過的窗口，那麼鼠標事件將發往錯誤的（ X 記錄中的而非顯示出的）窗口元素上。 可以發現這兩種狀態就直接對應了 Gnome 3 的普通狀態和縮略圖狀態（點擊 活動 ( Activity ) 或者戳畫面左上角之後顯示的狀態），這也解釋了爲什麼儘管 Gnome 3 的窗口有碩大的關閉按鈕，但是在縮略圖狀態下 Gnome 3 仍然需要給窗口加上額外的關閉按鈕： 因爲處於縮略狀態下的窗口只是一張畫而不能點 。 Composite 擴展的這些限制使得 X 下的混成器目前只能實現 Mac OS X 那樣的 Exposé 效果，而不能實現 LG3D 那樣直接在 3D 空間中操縱窗口內容。 解決重定向問題曾經的一縷曙光是 昇陽公司 ( Sun Microsystems ) 在開發 LG3D 的過程中同時提議過另一個 X 擴展叫做 Event Interception 或者簡稱 XEvIE ，這個擴展的設計目的就是提供 API 讓某個程序接收並操縱全部的鍵盤和鼠標事件。可惜這個擴展隨着昇陽公司本身的隕落而 處於無人維護的狀態，這一點也在它的官方網頁上說明了： It has been suggested that this extension should not be used because it is broken and maintainerless. Composite 擴展的不足 通過上面的介紹，我們就已經可以看到 Composite 擴展的不足之處了。 總結起來說，主要有兩大不足： 繪圖效率低。因爲同樣的位圖從應用程序傳到 Xorg ，再從 Xorg 傳到混成器， 最後從混成器再繪製到屏幕上，繞了一個大彎。這就是爲什麼 Wayland 的開發者在他的slide the real story behind Wayland and X 裏這麼說： and what's the X server? really bad IPC 那麼 X 服務器到底做了什麼呢？ 非常糟糕的進程間通訊 沒有重定向輸入事件。如果我們要在 X 的混成器裏做這個事情， 基本上我們要全部重寫一遍 X 已經寫好的窗口事件分發邏輯。 既然同樣要重寫，爲什麼不直接重寫一遍 X 呢，扔掉那些歷史負擔，扔掉那些無用的 API ，重新設計可擴展的 API ，做好快速安全的 IPC —— 嗯，重寫 X 就是 Wayland 的目的。 不過這麼重寫了的 Wayland 還是我們熟悉可愛的 X 麼？它有哪些地方變樣了？ 這將是我下一篇文章的內容。 附錄：擴展閱讀 我自己沒有寫過窗口管理器，沒有寫過混成器，沒有寫過 Wayland 程序，以上說的都是我從互聯網上看到的整理出來的內容。寫下本文的過程中我參考了這些文章： The (Re)Architecture of the X Window System 這篇2004年寫的文章描述了 Composite 擴展出現的動機和歷史，介紹了繪圖庫的實現情況，涉及了上面所說的那些 X 擴展被用到的情況和可能。 同時這篇文章還展望了很多現在的 X 已然實現了的功能，比如 OpenGL 和 X 的結合方面我們有了 GLX 和 AIGLX ，比如內核的顯卡支持方面我們有了 DRI 和 KMS 。總之這是一篇描述 Linux 桌面未來的發展軌跡的非常有閱讀價值的歷史文獻。 so you want to build a compositor 這是一篇 2008 年寫的博文，介紹如何用 Clutter 實現一個最簡單的混成器。 Composite tutorial 這是另一篇介紹如何實現一個簡單的混成器的博文，用 Qt 實現，但是同樣很底層。 unagi 這是一個可用的（但是已經長期沒有開發的）類似 xcompmgr 的混成器。這個項目貌似 是一位研究生的碩士畢業設計，同時他公開了碩士學位的畢業論文 Master thesis: Writing an X compositing manager 其中也對實現一個簡單的混成器做了詳盡描述，包括介紹了相關的 X 擴展和調用。","tags":"tech","title":"X 中的混成器與 Composite 擴展"},{"url":"//farseerfc.me/brief-history-of-compositors-in-desktop-os.html","text":"（原本是想寫篇關於 Wayland 的文章，後來越寫越長感覺能形成一個系列， 於是就先把這篇背景介紹性質的部分發出來了。） Linux 系統上要迎來 Wayland 了，或許大家能從各種渠道打聽到 Wayland 是一個混成器，替代 X 作爲顯示服務器。 那麼 混成器 是個什麼東西，桌面系統爲什麼需要它呢？ 要理解爲什麼桌面系統需要 混成器 （或者它的另一個叫法， 混成窗口管理器 ( Compositing Window Manager ) ），在這篇文章中我想回顧一下歷史， 瞭解一下混成器出現的前因後果。 首先介紹一下混成器出現前主要的一類窗口管理器，也就是 棧式窗口管理器 ( Stacking Window Manager ) 的實現方式。 本文中所有桌面截圖來自維基百科，不具有著作權保護。 早期的棧式窗口管理器 棧式窗口管理器的例子，Windows 3.11 的桌面 我們知道最初圖形界面的應用程序是全屏的，獨佔整個顯示器（現在很多遊戲機和手持設備的實現仍舊如此）。 所有程序都全屏並且任何時刻只能看到一個程序的輸出，這個限制顯然不能滿足人們使用計算機的需求， 於是就有了 窗口 的概念，有了 桌面隱喻 。 在 桌面隱喻 ( Desktop Metaphor ) 中每個窗口只佔用顯示面積的一小部分， 有其顯示的位置和大小，可以互相遮蓋。於是棧式窗口管理器就是在圖形界面中實現桌面隱喻的核心功能， 其實現方式大體就是：給每個窗口一個相對的\"高度\"或者說\"遠近\"，比較高的窗口顯得距離用戶比較近， 會覆蓋其下比較低的窗口。繪圖的時候窗口管理器會從把窗口按高低排序，按照從低到高的順序使用 畫家算法 繪製整個屏幕。 這裏還要補充一點說明，在當時圖形界面的概念剛剛普及的時候，繪圖操作是非常\"昂貴\"的。 可以想象一下 800x600 像素的顯示器輸出下，每幀 真彩色 位圖就要佔掉 \\(800 \\times 600 \\times 3 \\approx 1.4 \\text{MiB}\\) 的內存大小，30Hz 的刷新率（也就是30FPS）下每秒從 CPU 傳往繪圖設備的數據單單位圖就需要 \\(1.4 \\times 30 = 41 \\text{MiB}\\) 的帶寬。對比一下當時的 VESA 接口 總的數據傳輸能力也就是 \\(25 \\text{MHz} \\times 32 \\text{bits} = 100 \\text{MiB/s}\\) 左右， 而 Windows 3.1 的最低內存需求是 1MB，對當時的硬件而言無論是顯示設備、內存或是CPU， 這無疑都是一個龐大的負擔。 於是在當時的硬件條件下採用棧式窗口管理器有一個巨大 優勢 ：如果正確地採用畫家算法， 並且合理地控制重繪時 只繪製沒有被別的窗口覆蓋的部分 ，那麼無論有多少窗口互相 遮蓋，都可以保證每次繪製屏幕的最大面積不會超過整個顯示器的面積。 同樣因爲實現方式棧式窗口管理器也有一些難以迴避的 限制 ： 窗口必須是矩形的，不能支持不規則形狀的窗口。 不支持透明或者半透明的顏色。 爲了優化效率，在縮放窗口和移動窗口的過程中，窗口的內容不會得到重繪請求， 必須等到縮放或者移動命令結束之後窗口纔會重繪。 以上這些限制在早期的 X11 窗口管理器比如 twm 以及 XP 之前經典主題的 Windows 或者經典的 Mac OS 上都能看到。 在這些早期的窗口環境中，如果你拖動或者縮放一個窗口，那麼將顯示變化後的窗口邊界， 這些用來預覽的邊界用快速的位圖反轉方式繪製。當你放開鼠標的時候纔會觸發窗口的 重繪事件。 雖然有很多方法或者說技巧能繞過這些限制，比如 Windows XP 上就支持了實時的 重繪事件和不規則形狀的窗口剪裁，不過這些技巧都是一連串的 hack ，難以擴展。 NeXTSTEP 與 Mac OS X 中混成器的發展 NeXTSTEP 桌面 轉眼進入了千禧年， Windows 稱霸了 PC 產業，蘋果爲重振 Macintosh 請回了 Jobs 基於 NeXTSTEP 開發 Mac OSX 。 NeXTSTEP 在當時提供的 GUI 界面技術相比較於同年代的 X 和 Windows 有一個很特別的地方： 拖動滾動條或者移動窗口的時候，窗口的內容是 實時更新 的，這比只顯示一個縮放大小的框框來說被認爲更直觀。 而實現這個特性的基礎是在 NeXTSTEP 中運用了 Display PostScript (DPS) 技術，簡單地說，就是每個窗口並非直接輸出到顯示設備，而是把內容輸出到 (Display) PostScript 格式交給窗口管理器，然後窗口管理器再在需要的時候把 PostScript 用軟件解釋器解釋成位圖顯示在屏幕上。 比起讓窗口直接繪製，這種方案在滾動和移動窗口的時候不需要重新渲染保存好的 DPS ， 所以能實現實時渲染。到了實現 Mac OS X 的時候，爲了同時兼容老的 Mac 程序 API (carbon) 以及更快的渲染速度，以及考慮到 Adobe 對蘋果收取的高昂的 Display PostScript 授權費， Mac OS X 的 Quartz 技術在矢量圖的 PDF 描述模型和最終渲染之間又插入了一層抽象： Mission Control 也就是說在 Mac OS X 中無論窗口用何種方式繪圖，都會繪製輸出成一副內存中的位圖交給混成器， 而後者再在需要的時候將位圖混成在屏幕上。這種設計使得 2001年3月發佈的 Mac OS X v10.0 成爲了第一個廣泛使用的具有軟件混成器的操作系統。 到了 Mac OS X v10.2 的時候，蘋果又引入了 Quartz Extreme 讓最後的混成渲染這一步發生在 顯卡上。然後在 2003年1月公開亮相的 Mac OS X v10.3 中，他們公佈了 Exposé (後來改名爲 Mission Control) 功能，把窗口的縮略圖（而不是事先繪製的圖標）並排顯示在桌面上， 方便用戶挑選打開的窗口。 由於有了混成器的這種實現方式，使得可能把窗口渲染的圖像做進一步加工，添加陰影、三維和動畫效果。 這使得 Mac OS X 有了美輪美奐的動畫效果和 Exposé 這樣的方便易用的功能。 或許對於喬布斯而言，更重要的是因爲有了混成器，窗口的形狀終於能顯示爲他 夢寐以求 的 圓角矩形 了！ 插曲：曇花一現的 Project Looking Glass 3D 在蘋果那邊剛剛開始使用混成器渲染窗口的 2003 年，昔日的 昇陽公司 ( Sun Microsystems ) 則在 Linux 和 Solaris 上用 Java3D 作出了另一個炫酷到沒有朋友的東西，被他們命名爲 Project Looking Glass 3D （縮寫LG3D，別和 Google 的 Project Glass 混淆呀）。這個項目的炫酷實在難以用言語描述， 好在還能找到兩段視頻展示它的效果。 Youtube Youku Youtube Youku LG3D 如視頻中展示的那樣， LG3D 完全突破了傳統的棧式窗口管理方式， 在三維空間中操縱二維的窗口平面，不僅像傳統的窗口管理器那樣可以縮放和移動窗口， 還能夠旋轉角度甚至翻轉到背面去。從視頻中難以體會到的一點是， LG3D 在實現方式上與 Mac OS X 中的混成器有一個本質上的不同，那就是處於（靜止或動畫中）縮放或旋轉狀態 下的窗口是 可以接受輸入事件 的。這一重要區別在後面 Wayland 的說明中還會提到。 LG3D 項目展示了窗口管理器將如何突破傳統的棧式管理的框架，可以說代表了窗口管理器的未來發展趨勢。 LG3D 雖然以 GPL 放出了實現的源代碼，不過整個項目已經停滯開發許久了。 官方曾經放出過一個 預覽版的 LiveCD 。可惜時隔久遠（12年前了）在我的 VirtualBox 上已經不能跑起來這個 LiveCD 了…… 更爲可惜的是，就在這個項目剛剛公開展示出來的時候，喬布斯就致電昇陽， 說如果繼續商業化這個產品，昇陽公司將涉嫌侵犯蘋果的知識產權 （時間順序上來看，蘋果最初展示 Exposé 是在 2003年6月23日的 Apple Worldwide Developers Conference ，而昇陽最初展示 LG3D 是在 2003年8月5日的 LinuxWorld Expo）。 雖然和喬布斯的指控無關，昇陽公司本身的業務也着重於服務器端的業務， 後來隨着昇陽的財政困難，這個項目也就停止開發並不了了之了。 Windows 中的混成器 Longhorn 中的 Wobbly 效果 Youtube Youku 上面說到， Windows 系列中到 XP 爲止都還沒有使用混成器繪製窗口。 看着 Mac OS X 上有了美輪美奐的動畫效果， Windows 這邊自然不甘示弱。 於是同樣在 2003 年展示的 Project Longhorn 中就演示了 wobbly 效果的窗口， 並且跳票推遲多年之後的 Windows Vista 中實現了完整的混成器 Desktop Window Manager (DWM) 。整個 DWM 的架構和 Mac OS X 上看到的很像： 和 Mac OS X 的情況類似， Windows Vista 之後的應用程序有兩套主要的繪圖庫，一套是從早期 Win32API 就沿用至今的 GDI（以及GDI+），另一套是隨着 Longhorn 計劃開發出的 WPF 。 WPF 的所有用戶界面控件都繪製在 DirectX 貼圖上，所以使用了 WPF 的程序也可以看作是 DirectX 程序。而對老舊的 GDI 程序而言，它們並不是直接繪製到 DirectX 貼圖的。首先每一個 GDI 的繪圖操作都對應一條 Windows Metafile (WMF) 記錄，所以 WMF 就可以看作是 Mac OS X 的 Quartz 內部用的 PDF 或者 NeXTSTEP 內部用的 DPS，它們都是矢量圖描述。隨後，這些 WMF 繪圖操作被通過一個 Canonical Display Driver (cdd.dll) 的內部組建轉換到 DirectX 平面，並且保存起來交給 DWM。最後， DWM 拿到來自 CDD 或者 DirectX 的平面，把它們混合起來繪製在屏幕上。 值得注意的細節是，WPF 底層的繪圖庫幾乎肯定有 C/C++ 綁定對應， Windows 自帶的不少應用程序 和 Office 2007 用了 Ribbon 之後的版本都採用這套繪圖引擎，不過微軟沒有公開這套繪圖庫的 C/C++ 實現的底層細節，而只能通過 .Net 框架的 WPF 訪問它。這一點和 OS X 上只能通過 Objective-C 下的 Cocoa API 調用 Quartz 的情況類似。 另外需要注意的細節是 DirectX 的單窗口限制在 Windows Vista 之後被放開了，或者嚴格的說是 基於 WDDM 規範下的顯卡驅動支持了多個 DirectX 繪圖平面。 在早期的 Windows 包括 XP 上，整個桌面上同一時刻只能有一個程序的窗口處於 DirectX 的 直接繪製 模式，而別的窗口如果想用 DirectX 的話，要麼必須改用軟件渲染要麼就不能工作。 這種現象可以通過打開多個播放器或者窗口化的遊戲界面觀察到。 而在 WDDM 規範的 Vista 中，所有窗口最終都繪製到 DirectX 平面上，換句話說每個窗口都是 DirectX 窗口。又或者我們可以認爲，整個界面上只有一個真正的窗口也就是 DWM 繪製的全屏窗口， 只有 DWM 處於 DirectX 的直接渲染模式下，而別的窗口都輸出到 DirectX 平面裏（可能通過了硬件加速）。 由 DWM 的這種實現方式，可以解釋爲什麼 窗口模式下的遊戲總是顯得比較慢 ，原因是整個桌面有很多不同的窗口都需要 DWM 最後混成，而如果在全屏模式下，只有遊戲 處於 DirectX 的直接渲染方式，從而不會浪費對遊戲而言寶貴的 GPU 資源。 由於 DWM 實現了混成器，使得 Vista 和隨後的 Windows 7 有了 Aero Glass 的界面風格， 有了 Flip 3D 、Aero Peek 等等的這些輔助功能和動畫效果。 這套渲染方式延續到 Windows 8 之後，雖然 Windows 8 還提出了 Modern UI 不過傳統桌面上的渲染仍舊是依靠混成器來做的。 這就結束了？ Linux 桌面呢？ 別急，我寫這些文章的目的是想聊聊 Linux 中的混成器，尤其是 X 下現有的混成器和 Wayland ，這篇文章只是個背景介紹。關於 X 中混成器的實現方式和限制，且聽我下回分解。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdnjscn.b0.upaiyun.com/libs/mathjax/2.4.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","title":"桌面系統的混成器簡史"},{"url":"//farseerfc.me/stop-write-simply.html","text":"我的 RSS 訂閱着一個博客叫 The Old New Thing ，作者是Windows開發者之一的 Raymond Chen ，記錄 Windows 中的很多有趣的技術細節。 這個博客中的一些精彩內容還被他寫成了一本書，中文名叫《Windows編程啓示錄》 (ISBN: 978-7-111-21919-4 ) 而英文書名就叫 :cite:`The Old New Thing — Practical Development Throughout the Evolution of Windows` (ISBN: 978-0-321-44030-3 )。 System Message: ERROR/3 ( /home/travis/build/farseerfc/farseerfc/content/life/stop-write-simply.zh.rst , line 9); backlink Unknown interpreted text role \"cite\". 今天看到這個博客的一篇文章說 你用「簡單地」次數越多我越懷疑你不懂這個詞的意思 ， 描述他看到某個博客上指導讀者打開命令行、執行某條魔法命令、從命令輸出抽取參數、 改寫配置文件、用魔法命令重啓服務，並把這些工作描述爲「簡單地」。 的確正如 Raymond 指出，一個人覺得簡單的事情對別人並不一定是簡單的。 搜了一下我自己寫的東西，的確很多地方寫了「簡單」二字，這的確對讀者不友好。 從今往後避免用「簡單」來描述。","tags":"life","title":"避免在博文中寫「簡單地」"},{"url":"//farseerfc.me/travis-push-to-github-pages-blog.html","text":"2015年2月21日更新 上次介紹過 這個博客改換了主題 ， 本以爲這個話題可以告一段落了，沒想到還能繼續寫呢。 寄宿在 Github Pages 上的靜態博客通常有兩種方案，其一是使用 Jekyll 方式撰寫，這可以利用 Github Pages 原本就有的 Jekyll支持 生成靜態網站。另一種是在 本地 也就是自己的電腦上生成好，然後把生成的 HTML 網站 push 到 Github Pages ，這種情況下 Github Pages 就完全只是一個靜態頁面宿主環境。 我用 Pelican 生成博客，當然就只能選擇後一種方式了。這帶來一些不便，比如本地配置 pelican 還是有一點點複雜的，所以不能隨便找臺電腦就開始寫博客。有的時候只是想修正一兩個錯別字， 這時候必須打開某臺特定的電腦纔能編輯博客就顯得不太方便了。再比如 pelican 本身雖然是 python 寫的所以跨平臺，但是具體到博客的配置方面， Windows 環境和 Linux/OSX/Unix-like 環境下還是有 些許出入 的。還有就是沒有像 wordpress 那樣的基於 web 的編輯環境，在手機上就不能隨便寫一篇博客發表出來（不知道有沒有勇士嘗試過在 Android 的 SL4A 環境下的 python 中跑 pelican ，還要配合一個 Android 上的 git 客戶端 ）。 當然並不是因此就束手無策了，感謝 Travis-CI 提供了免費的 持续整合 ( Continuous integration ) 虛擬機環境， 通過它全自動生成靜態博客成爲了可能。 關於 Travis-CI 持续整合 原本是 敏捷開發 ( Agile Development ) 或者 極限編程 ( Extreme Programming ) 中提到的概念，大意就是說在開發的過程中， 一旦有微小的變更，就全自動地 持續 合併到主線中， 整合 變更的內容到發佈版本裏。 這裏的 整合 實際上可以理解爲 全自動測試 加上 生成最終產品 。 可以看到 持續整合 實際強調 全自動 ，於是需要有一個服務器不斷地監聽主線開發的變更內容， 一旦有任何變更（可以理解爲 git commit ）就自動調用測試和部署腳本。 於是要用持續整合就需要一個整合服務器，幸而 Travis-CI 對 github 上的公開 repo 提供了免費的整合服務器虛擬機服務，和 github 的整合非常自然。所以我們就可以用它提供的虛擬機 爲博客生成靜態網站。 啓用 Travis-CI 自動編譯 這一步很簡單，訪問 https://travis-ci.org/ 並用你的 Github 賬戶登錄， 授權它訪問你的賬戶信息就可以了。然後在 https://travis-ci.org/repositories 裏開啓 需要編譯的 repo ，這樣 Travis-CI 就會監視對這個 repo 的所有 push 操作，並且對 每個 push 調用測試了。 在 Travis-CI 中開啓對 Github Repo 的持續整合 然後在 repo 的根目錄放一個 .travis.yml 文件描述編譯的步驟。 暫時 測試的目的下我寫的 .travis.yml 大概是下面這樣。 language : python python : - \"2.7\" before_install : - sudo apt-add-repository ppa:chris-lea/node.js -y - sudo apt-get update - sudo apt-get install nodejs ditaa doxygen parallel install : - sudo pip install pelican - sudo pip install jinja2 - sudo pip install babel - sudo pip install beautifulsoup4 - sudo pip install markdown - sudo npm install -g less - wget \"http://downloads.sourceforge.net/project/plantuml/plantuml.jar?r=&ts=1424308684&use_mirror=jaist\" -O plantuml.jar - sudo mkdir -p /opt/plantuml - sudo cp plantuml.jar /opt/plantuml - echo \"#! /bin/sh\" > plantuml - echo 'exec java -jar /opt/plantuml/plantuml.jar \"$@\"' >> plantuml - sudo install -m 755 -D plantuml /usr/bin/plantuml - wget https://bintray.com/artifact/download/byvoid/opencc/opencc-1.0.2.tar.gz - tar xf opencc-1.0.2.tar.gz - cd opencc-1.0.2 && make && sudo make install && cd .. - sudo locale-gen zh_CN.UTF-8 - sudo locale-gen zh_HK.UTF-8 - sudo locale-gen en_US.UTF-8 - sudo locale-gen ja_JP.UTF-8 script : - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - mkdir output - env SITEURL=\"farseerfc.me\" make publish Travis-CI 提供的虛擬機是比較標準的 Ubuntu 12.04 LTS ，打上了最新的補丁，並且根據你指定的 語言選項會把相應的解釋器和編譯器升級到最新版（或者指定的版本）。這裏用 python 語言的配置， 所以 python 是 2.7 的最新版並且有 pip 可以直接用。 配置中的 before_install 和 install 的區別其實不大，其中任何一個失敗的話算作 build errored 而不是 build fail ，而如果在 script 裏失敗的話算作 build fail 。 爲了編譯我的模板，還需要比較新的 less.js ，所以添加了 ppa 裝了個最新的 nodejs 並用它裝上了 less 。 還從源碼編譯安裝上了最新版的 opencc 1.0.2 ，因爲 Ubuntu 源裏的 opencc 的版本比較老(0.4)， 然後 doxygen 作爲 opencc 的編譯依賴也裝上了。 其它安裝的東西麼，除了 pelican 之外都是插件們需要的。以及我還需要生成 4 個語言的 locale 所以調用了 4 次 locale-gen 。由於是比較標準的 Ubuntu 環境，所以基本上編譯的步驟和在本地 Linux 環境中是一樣的，同樣的這套配置應該可以直接用於本地 Ubuntu 下編譯我的博客。 寫好 .travis.yml 之後把它 push 到 github ，然後 travis 這邊就會自動 clone 下來開始編譯。 travis 上能看到編譯的完整過程和輸出，一切正常的話編譯結束之後 build 的狀態就會變成 passing ，比如 我的這次的build 。 從 Travis-CI 推往 Github 上面的測試編譯通過了之後，下一步就是讓 travis-ci 編譯的結果自動推到 Github Pages 並發佈出來。要推往 Github 自然需要設置 Github 用戶的身份，在本地設置的時候是把 ssh key 添加到 github 賬戶就可以了，在編譯細節都通過 github repo 公開了的 travis 上 當然不能放推送用的私有 key ，所以我們需要另外一種方案傳遞密碼。 Github 上創建 Personal Access Token 好在 Github 支持通過 Personal Access Token 的方式驗證，這個和 App Token 一樣可以隨時吊銷，同時完全是個人創建的。另一方面 Travis-CI 支持加密一些私密數據，通過環境變量的方式傳遞給編譯腳本，避免公開密碼這樣的關鍵數據。 首先創建一個 Personal Access Token ，這裏需要勾選一些給這個 Token 的權限，我只給予了最小的 public_repo 權限，如側邊裏的圖。 生成之後會得到一長串 Token 的散列碼。 如果你不能使用 travis 命令 2015年2月21日更新 使用 travis encrypt 命令來加密重要數據最方便，不過如果有任何原因， 比如 ruby 版本太低或者安裝不方便之類的，那麼不用擔心，我們直接通過 travis api 也能加密數據。 第一步用這個命令得到你的repo的 pubkey ： curl -H \"Accept: application/vnd.travis-ci.2+json\" https://api.travis-ci.org/repos/<github-id/repo>/key | python2 -m json.tool | grep key | sed 's/.*\"key\": \"\\(.*\\)\"/\\1/' | xargs -0 echo -en | sed 's/ RSA//' > travis.pem 其中的 <github-id/repo> 替換成 github 上的 用戶名/repo名， 比如我的是 farseerfc/farseer 。travis api 獲得的結果是一個 json ，所以還用 python 的 json 模塊處理了一下，然後把其中包含 key 的行用 grep 提取出來，用 sed 匹配出 key 的字符串本身，然後 xargs -0 echo -en 解釋掉轉義字符，然後刪掉其中的 \"<空格>RSA\" 幾個字（否則 openssl 不能讀）， 最後保存在名爲 travis.pem 的文件裏。 有了 pubkey 之後用 openssl 加密我們需要加密的東西並用 base64 編碼： echo -n 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' | openssl rsautl -encrypt -pubin -inkey travis.pem | base64 -w0 替換了相應的身份信息和token之後，這行得到的結果就是 secure 裏要寫的加密過的內容。 然後我們需要 travis 命令來加密這個 token ， archlinux 用戶可以安裝 aur/ruby-travis ，其它用戶可以用 gems 安裝： $ gem install travis 裝好之後，在設定了 Travis-CI 的 repo 的目錄中執行一下 travis status ， 命令會指導你登錄 Travis-CI 並驗證 repo 。正常的話會顯示最新的 build 狀態。 然後同樣在這個 repo 目錄下執行： $ travis encrypt 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' 當然上面一行裏的相應信息替換爲個人的信息，作爲這個命令的執行結果會得到另一長串散列碼， 把這串散列寫入剛纔的 .travis.yml 文件： env : - secure : \"long secure base64 string\" 有了這段聲明之後， Travis-CI 就會在每次編譯之前，設置上面加密的環境變量。 然後在編譯腳本中利用這些環境變量來生成博客： script : - git config --global user.email \"$GIT_EMAIL\" - git config --global user.name \"$GIT_NAME\" - git config --global push.default simple - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - git clone --depth 1 https://$GH_TOKEN@github.com/farseerfc/farseerfc.github.io output - env SITEURL=\"farseerfc.me\" make publish after_success : - cd output - git add -A . - git commit -m \"update from travis\" - git push --quiet 這裏要注意最後 git push 的時候一定要加上 --quiet ，因爲默認不加的時候會把 代入了 $GH_TOKEN 的 URL 顯示出來，從而上面的加密工作就前功盡棄了…… 根據 travis 的文檔 ， after_success 裏寫的步驟只有在 script 裏的全都完全無錯執行完之後纔會執行，這正是我們 push 的條件。目前 after_success 的成功與否不會影響到 build 的狀態。 具體我用的配置見 這裏的最新版 。 在我的 make github 中 調用了 git push 命令，從而執行了 make github 之後就會自動部署到 github 上。 用 Web 編輯並發佈靜態博客 經過以上設置之後，一切正常的話，每次對主 repo 推送更新的同時， Travis-CI 就會自動 拉來更新然後編譯並發佈了。可以放置這樣的圖標 在項目的 Readme.md 中顯示編譯狀態。 這樣設置之後的另一個好處就在於可以利用 Github 的 Web 界面編輯文章內容。在 Github 裏 編輯和保存之後會自動作爲一個 commit 提交，所以也會觸發 Travis-CI 的自動編譯。 在 Github 的 Web 界面中直接編輯文章內容 以及雖然目前還沒有好用的 Github 的手機客戶端，不過直接用 Android/iPhone 的瀏覽器登錄 github 並編輯文章的可用性也還不錯，所以同樣的方式也可以直接在手機上發佈博文了。 That is all, happy blogging ~","tags":"tech","title":"用 Travis-CI 生成 Github Pages 博客"},{"url":"//farseerfc.me/weather-forcast-academic-in-japan.html","text":"最近 mazk 說我 life 分類裏的文章太少 ，所以想了想寫了這篇。 很多人問過我爲什麼要來日本留學，嘛原因之一是我英語太差了，相對而言日語比較好。 另一方面，我比較喜歡日本的學術氛圍。這個當然是主觀體會，而不是客觀的評價，只是我 覺得相對於 歐美喜歡研究基礎架構技術 ， 日本則偏向實用層面 。 說個具體一點例子，最近看到這篇新聞說 卢布贬值影响中央气象台预报准确率？ ，其中提到： 因为卢布贬值，天气预报的准确率会有所降低 也說道： 不过经我多年的观察，中国中央气象台的预报准确率实在是不怎么样，具体到我生活的地区， 实际天气状况和中国中央气象台预报的出入较大…… 相信不少人也有類似的體會。 天氣預報是事關人們生活的重要信息，其準確度對生產生活當然有很大影響。 說到增加天氣預報的準確度，人們自然會想到高性能的超級計算機比如 天河二號 ，想到環繞在地球高空的 氣象衛星 ，想到遍佈世界各地的氣象站觀測臺。想想這麼多耗資不菲的高尖端項目被國家投入， 用來改善天氣預報的準確程度，看起來這的確是一個困難的科研課題。 話說回來，準確預測氣溫、氣壓、溼度、降水概率等等這些事情對於生產生活固然重要， 不過對一般民衆而言，天氣預報最重要的作用就只是回答 明天我該穿多厚的衣服，出門是否需要打傘 這種問題。一年四季換衣服的時機其實並不那麼頻繁，氣溫提升五度或者降低兩度這種程度下人們估計也 不能感覺得到，大體上只要根據「昨天穿什麼衣服，昨天覺得冷不冷」就能作出判斷。另一方面， 出門是否需要打傘 這樣的問題的確只能依靠天氣預報來回答。 那麼解決 出門是否需要打傘 這個問題需要那麼高尖端的技術麼？ 我所在的大阪大學情報科學研究科有個已經畢業的學長 今城 健太郎 ( いまじょう けんたろう ) 就對此作出了解答。他的專業不是氣象預測，而是圖像分析處理，純粹的計算機科學學科。 而他的本科畢業設計就着眼於「僅僅分析氣象雲圖，能否高精度預測降水概率」， 其研究成果，就是一個叫 ないんたん 的降水概率預測系統 。 這個系統有數個會賣萌的Twitter機器人 @ninetan ，每時每刻對 其預測地區的降水情況做播報，同時也有詳細的降水概率曲線圖對 大阪 ( @ninetan_osaka )， 京都 ( @ninetan_kyoto )， 東京 ( @ninetan_tokyo )， 兵庫 ( @ninetan_hyogo )， 和歌山 ( @ninetan_wakayam ) 的各個大學所在校區 兩個半小時內做精確的降水概率預測。比如今天晚上大阪大學三個校區的降水概率圖如下： 今天晚上大阪大學三個校區的降水概率圖 從上面的圖可以看出這個系統的預測精度是以 分爲單位 的，可以看到 兩個半小時內各地的降水量的大小。比如我可以根據這張圖看出，我所在的吹田校區 將在 21時35分 開始有微弱的概率下起 0.1mm/h~1mm/h 的毛毛雨，到 22時05分 左右這個降水概率 爬升到最高大約45%，從而作出判斷： 我最好在晚上九點左右離開學校回家，避免淋雨。 自從研究室的前輩給我介紹這個天氣預報系統開始，我用了它兩三年了，直觀感覺是 這個系統的預測精度驚人得準確，基本上能接近 《魔法的禁書目錄》中的「樹形圖設計者」 能做的天氣預報的程度， 它說何時會下雨就一定下雨，它說何時雨停就一定雨停。同學們出門和回家的時候一般都會 看一眼這個天氣預報然後決定是否出門。「啊今天晚上9點開始下雨所以早點回家」 或者「啊還有30分鐘雨就停了，再在研究室裏留一會兒」。 這只是一個本科生的畢業設計，所以覆蓋面小（只有5所大學的十幾個校區，只能預測 未來兩個多小時的降水概率），不過僅此而已能做到如此的精度以至於實用，實在讓我 驚訝。系統的測試之初就有人說： 最近ないんたん予報あたりすぎてないんたんが雨降らせてるんじゃないかという疑惑 — すみのネコ歩き (@sumi_eee) 2011 7月 6日 最近ないんたん預告實在太準了，甚至讓人懷疑是不是ないんたん把雨招來的。 不過最近身邊的日本人似乎已經把這個系統的準確當作習以爲常了，就像日本的電車 掐着秒錶準點到站一樣，理所當然。 把天氣預報這種高尖端的技術做到如此實用的地步，這基本上可以代表我對 日本學術界研究方式和研究目的的總體印象了。 嗯今天就寫這麼多，9點到了，我要按照天氣預報的預測，準時回家了。 ——寫於2015羊年除夕夜，9點。","tags":"life","title":"從天氣預報談談日本的學術氛圍"},{"url":"//farseerfc.me/arch-chrome-remote-desktop.html","text":"透明計算 具體是什麼，因爲他們沒有公開技術細節所以我並不知道，只是看 公開出來的演示視頻 ，感覺似乎只要能從手機上遠程登錄系統桌面，就能算是透明計算了。 如果透明計算真是這個意思，那麼我似乎已經用着這個技術很多年了嘛。 Xorg 上常用的遠程桌面工具有很多，基於 VNC 協議的、基於NX的和基於 RDP 協議的都能找到， 直接 ssh X forwarding 效果也不錯。只是這些方案的一個 不太易用 的地方在於，需要 通過 ip 訪問到遠程的電腦，所以在跨越 NAT 之類的情況下不太容易使用。 於是今天介紹一個使用方便設置也簡單的方法： 通過 chrome-remote-desktop 在 archlinux 上使用遠程桌面。這個方案的優勢在於，藉助 Google 的雲端服務器（內部貌似是XMPP協議下的握手） 方便地實現了 NAT 穿透，無論什麼網絡環境基本都能使用。當然，要支持遠程登錄， 位於遠端的登錄的計算機必須一直開着 Chrome Remote Desktop 的後臺服務。 Chrome Remote Desktop 插件 Chrome Remote Desktop 的客戶端 雖然可能有很多人不知道，不過 Chrome 內包括遠程桌面的功能很久了。只是這個功能的界面默認 沒有提供界面，要使用它需要安裝 Google 官方出品的 remote-desktop 插件 。 裝好之後遠程桌面的客戶端就準備好，可以用來遠程訪問別的計算機桌面了（無論是 Windows/OS X 還是 Linux 都支持）。並且不光可以自己遠程訪問自己賬戶的桌面，還可以遠程協助朋友的桌面。 Archlinux 上設置遠程登錄的服務器 有了客戶端之後還要設置一下纔能讓桌面作爲遠程登錄的服務器。Windows 和 OS X 上 Chrome 會自動下載需要的安裝包，無腦下一步就能裝好了。Linux上由於發行版衆多，桌面配置各異， 所以需要一點手動配置。官方的設置步驟記載在 這裏 其中給出了 debian 用的二進制包和 Ubuntu 12.10 上的設置方式，以下設置是參考官方步驟。 首先要安裝 chrome-remote-desktop 這個包，這個包實際上對應了 Windows/OS X 上用安裝程序 安裝的 Remote Desktop Host Controller。 archlinux 上開啓了 [archlinuxcn] 倉庫的話，可以直接安裝打好的包。或者可以從 AUR 裝。 $ pacman -Ss chrome-remote-desktop archlinuxcn/ chrome-remote-desktop 40.0.2214.44-1 Allows you to securely access your computer over the Internet through Chrome. 裝好之後從會說這麼一段話： groupadd：无效的组 ID \"chrome-remote-desktop\" Please create ~/.config/chrome-remote-desktop folder manually, if it doesn't exist, or else you can't use CRD. The needed files are created by the Chrome app, inside the chrome-remote-desktop folder, after Enabling Remote Connections. To {enable,start} the service use systemctl --user {enable,start} chrome-remote-desktop You may need to create a ~/.chrome-remote-desktop-session file with commands to start your session Go to https://support.google.com/chrome/answer/1649523 for more information. 那句報錯是 AUR 裏打的包還沒跟上上游 Google 的更改導致的錯誤， 首先我們需要把遠程登錄的用戶添加入 chrome-remote-desktop 這個用戶組裏。 新版本的 chrome remote desktop 提供了一個命令做這個事情，所以執行以下命令就可以了： $ /opt/google/chrome-remote-desktop/chrome-remote-desktop --add-user 然後我們需要手動創建 ~/.config/chrome-remote-desktop 這個文件夾，內容是空的 就好了，隨後 chrome 會往這裏面放 host#.json 文件用於身份驗證。 $ mkdir ~/.config/chrome-remote-desktop 然後我們要創建一個 shell 腳本 ~/.chrome-remote-desktop-session ，這是遠程 登錄時的 .xinitrc ，內容麼就是啓動你想在遠程登錄時用的桌面環境。 這裏可以指定一個和你正在登錄的 WM/DE 不同的桌面，比如我啓動 xfce4： $ cat ~/.chrome-remote-desktop-session # !/bin/bash startxfce4 $ chmod 755 .chrome-remote-desktop-session 接下來需要從 Chrome 的插件裏啓用遠程桌面。打開 Chrome 的 Remote Desktop 插件，這時 應該可以看到一個「啓用遠程鏈接」的按鈕。 Chrome Remote Desktop 插件中「啓用遠程鏈接」的按鈕 在撰寫本文的時候， Archlinux 官方源裏的 chromium 的版本和 aur/google-chrome 的版本尚且還是 40.0.2214.111 ，而 Chrome Web Store 中提供的 Chrome Remote Desktop 的插件的版本是 41.0.2272.41 。雖然通常並不要求兩者版本一致，不過貌似最近 Chrome 內部的 Remoting 功能更改了 API 導致可能出問題。如果你找不到 「啓用遠程鏈接」的按鈕，請嘗試一下新版本的 Chrome 比如 google-chrome-dev 。 在這一步啓用之後，老版本的 chrome 應該也就能使用遠程桌面了。 在32位的 Linux 版本上，最近更新的 Chrome Remote Desktop 插件可能無法正確識別 Host 的版本，具體 參考這個 bug 。 點擊「啓用遠程鏈接」，設定一個 PIN 密碼（不需要很複雜，這裏首先有 Google 帳號驗證保證只有 你纔能訪問），然後就能看到這套電腦的 hostname 出現在「我的電腦」列表裏。 啓用遠程鏈接之後的樣子 同時，啓用了遠程鏈接之後，可以在剛剛創建的 ~/.config/chrome-remote-desktop 文件夾中找到記錄了驗證信息的文件。 $ ls .config/chrome-remote-desktop chrome-profile host#8cfe7ecfd6bb17955c1ea22f77d0d800.json pulseaudio#8cfe7ecfd6 然後就可以啓動對應的 systemd 用戶服務了，如果想自動啓動服務要記得 systemctl --user enable ： $ systemctl --user start chrome-remote-desktop.service 如果上面的設置一切正常，就可以看到 chrome-remote-desktop 啓動了另外一個 Xorg 執行你 剛剛指定的桌面環境： htop 中看到的 chrome-remote-desktop 啓動的另外一個 Xorg 然後就可以試着通過 Remote Desktop 插件登錄到這個新開的 Xorg 了： 「遠程」登錄到新的 XFCE4 Linux 版本的 Chrome遠程桌面 和 Windows/ OS X 上的區別 通過上面的設置步驟也可以看出，Linux版本的遠程桌面會在後臺開一個獨立的 X 會話，而不能 復用現在已有的 X 會話。對遠程登錄的用法而言這還能接受，對遠程協助的功能而言有點問題， 因爲正在使用的人不能觀察協助者做了什麼，協助者也不能繼續請求協助的人的操作。 當然目前 Chrome 遠程桌面的 Linux Host Controller 還只是 beta 版本，官方只測試支持 Ubuntu 12.04 和 12.10 （14.04之後似乎有 Bug ），所以不能要求太多。希望以後能改善吧。 Bonus： 手機遠程登錄 手機上的 Chrome 遠程桌面 App 通過上面的設置就可以從任何一個 Chrome 遠程桌面客戶端登錄剛剛設置的這臺電腦了。 因爲 Chrome 在三大桌面系統 Windows / OS X / Linux 上都有，所以應該能覆蓋大多數桌面 系統了。 除了桌面的 Chrome 之外還有一個客戶端是 Android 上的 Chrome 遠程桌面 App 經過上面的設置之後，從這個 App 也能看到並登錄： 手機遠程登錄 好啦，開始享受國家自然科學一等獎的透明計算技術吧！","tags":"tech","title":"archlinux 上用 chrome 實現 透明計算 遠程登錄"},{"url":"//farseerfc.me/switch-to-farseerfc-dot-me-domain.html","text":"上個月就在 狗爹 ( godaddy ) 上買了個自己的域名 farseerfc.me 準備用在這個 博客上，當時試着轉到過這個域名，發現 自定義域名 ( custom domain ) 只支持 http 不支持 https ，想着還要買自己的證書，於是就扔在了一旁。不用自定義域名的話， 放在 github.io 上是可以用 HTTPS 的。 今天在 #archlinux-cn 上受大牛 quininer 和 lilydjwg 點播， 發現 cloudflare 有提供 免費的支持 SSL 的 CDN 服務 趕快去申請了一個，感覺非常讚，於是就換過來了。 設置的方法按照 這篇博文 說的一步步做下來，如它所述，用 CloudFlare 的優點如下： CDN 加速 SSL (HTTPS) 加密 支持 SPDY 協議 支持 IPv6 然後 免費賬戶 的一些缺點有： CloudFlare 和 github.io 之間的數據不是加密的，因爲 github 自定義域名 ( custom domain ) 還不支持使用自己的證書。這也是一開始我沒用 自定義域名的原因嘛，這沒有辦法…… CloudFlare 給免費賬戶簽名的 SSL 證書比較新，不支持一些老的設備和瀏覽器，比如不支持 老的 XP 系統的 IE 或者 2.x 的 Android。這種情況下沒辦法只能用沒有加密的 HTTP 了。 不支持 HSTS 頭 ，所以不能從服務器這邊強制瀏覽器用 HTTPS。當然可以放個 javascript 跳轉， 也可以用 HTTPSEverywhere 這種方案。 設置步驟 基本按照默認的選項下一步就可以了。 和那個博主一樣我把 安全級別 ( Security profile ) 降到了 Low ，即使是可疑流量也 不會要求輸入 CAPTCHA 。 把 SSL 方式開在 Flexible SSL，訪客到 CloudFlare 是加密的，而 CloudFlare 到 github.io 是不加密的。 把 CDN 開到了 CDT+Full Optimization ，可以對訪問加速。由於是完全靜態的博客，沒有 動態變化的內容，所以應該比較安全。 服務器設置的一步需要將 域名解析服務器 ( DNS nameservers ) 從狗爹的服務器改到 CloudFlare 的，如下圖： 更改狗爹的域名服務器 申請好之後就由 CloudFlare 接管域名解析了，接下來在 CloudFlare 的 DNS 設置添加一條 A 類規則指向 github pages 的 IP 。 更改CloudFlare的DNS規則 等一切都反映到 DNS 服務器上就設置完成了，接下來給 farseerfc.github.io push 一個 CNAME 文件 寫上我的域名就可以了。我用 Makefile 配合我的 pelican 配置做這個： publish : rmdrafts cc clean theme [ ! -d $( OUTPUTDIR ) ] || find $( OUTPUTDIR ) -mindepth 1 -not -wholename \"*/.git*\" -delete rm -rf cache echo $( SITEURL ) > content/static/CNAME $( PELICAN ) $( INPUTDIR ) -o $( OUTPUTDIR ) -s $( PUBLISHCONF ) $( PELICANOPTS ) $( MAKE ) rsthtml github : ( cd $( OUTPUTDIR ) && git checkout master ) env SITEURL = \"farseerfc.me\" $( MAKE ) publish ( cd $( OUTPUTDIR ) && git add . && git commit -m \"update\" && git push ) SITEURL = '//' + getenv ( \"SITEURL\" , default = 'localhost:8000' ) STATIC_PATHS = [ 'static' , 'images' , 'uml' , 'images/favicon.ico' , 'static/CNAME' ] EXTRA_PATH_METADATA = { 'images/favicon.ico' : { 'path' : 'favicon.ico' }, 'static/CNAME' : { 'path' : 'CNAME' } } 然後把生成的靜態網站 push 到 github 之後可以從項目設置裏看到域名的變化： Github 配置好自定義域名之後的變化 最後把Disqus的評論也遷移到新的域名，disqus有方便的遷移嚮導，一直下一步就可以了。 這樣就一切都設置妥當了。 致謝 最後要感謝提供消息的 quininer 和 lilydjwg ，感謝撰寫設置步驟的 Jonathan J Hunt ， 感謝 CloudFlare 提供免費 SSL CDN 服務，感謝 Github 提供 方便免費的 Pages 託管。","tags":"tech","title":"換到 farseerfc.me 域名"},{"url":"//farseerfc.me/redesign-pelican-theme.html","text":"2015年2月14日更新 前言: 新天新地，將一切都更新了 [1] 不知不覺間放任這邊長草很久了，從上次 折騰主題 到現在都快三年了， 而從上次 寫了篇告白信 到現在也有快兩年了。 這期間曾經把主題配色從 Bootstrap 2 默認的 白底黑字改成了讓眼睛更舒適的黑底白字，也不過是用 drop-in 的配色方案而已，沒有本質上的改進。 洞中一日世上千載，兩年裏 Bootstrap 已經升上 v3.3 , 而 Pelican 則已經升到 3.5 了。 早就眼饞 Bootstrap 和 Pelican 中的諸多新功能新設計，不過無奈於時間有限只能飽飽眼福。 近日想寫的東西越積越多，終於下定決心花了前前後後 兩個月 的時間重新設計了一遍 Pelican 的主題，配合一些我覺得有用的插件。於是本博客就變成你們現在看到的樣子了。 （以及本篇博文也用了兩個月的時間寫完，其間還發了幾篇別的短文，算是恢復寫博客的嘗試吧。） 在邁阿密參加 ICSR 2015 的時候 拍到的街邊一家叫 Pelican 的旅館 Bootstrap 3 的新設計 全新的 優先移動設備 ( mobile-first ) 響應式 ( responsive ) 設計。 原本Bootstrap 2雖然有響應式設計， 不過諸多細節不能符合我的需求，最終還是得手工 hack @media 查詢去微調。 現在的 優先移動設備 ( mobile-first ) 響應式 ( responsive ) 柵格系統 ( grid system ) 則相對顯得科學很多了，也終於能在手持 設備上看起來舒服一些。諸位可以嘗試改變窗口寬度，或者在不同的手持設備上打開這個 blog ，體驗一下這個頁面在不同顯示器大小中的效果。如果仍有問題歡迎 發 Issue 給我 。 科學的 導航欄 ( Navbar ) 。 比 Bootstrap 2 那個科學很多了。無論是 保持 ( sticky ) 在上端還是跟着浮動， 或者像這邊這樣 自動隱藏 都很簡單。 更多細節參考 Bootstrap 3 主頁 。 Pelican 3.5 的新功能 Python 2 和 Python 3 統一代碼： 再沒有惱人的 unicode 相關的問題了。這對 blog 系統來說相當重要啊。 而且還能方便切換 pypy 等不同的解釋器。 全新的插件系統：非常多功能強大的 插件 等着你。 增強了導入系統：嗯總算可以導入我的中文的 wordpress 博客了。（雖然那邊長草更久了……） 站內鏈接 ：不用 硬編碼 ( hard code ) 目標頁面的鏈接了，可以直接寫源文件的位置然後讓 pelican 處理，這樣能簡化各種 插件 ( plugin ) 和 主題 ( theme ) 的實現。 更多細節參考 Pelican 文檔 。 新的文件夾佈局 Pelican 的新文件夾佈局 . ├── cache 生成頁面的 pickle 緩存 ├── content 讀取的全部內容 │ ├── <categories> 按分類存放的文章 │ ├── pages 像 About 這樣的固定頁面 │ └── static 文章內用到的靜態內容 ├── drafts 文章的草稿箱 ├── Makefile 生成用的 makefile ├── pelicanconf.py 測試時用的快速 Pelican 配置 ├── publishconf.py 部署時用的耗時 Pelican 配置 ├── output -> ../farseerfc.github.io ├── plugins -> ../pelican-plugins └── theme -> ../pelican-bootstrap3 之前的博客 仍然留在 github 上，其中的內容完全搬過來了。開始寫老博客的時候 Pelican 版本較早，沒有形成好的 文件夾佈局，導致生成的文章、使用的模板和撰寫的內容全都混在一起，非常難以管理， 於是趁改版之際用了新的文件夾佈局方式，並分爲 4 個 git repo 分別管理歷史。 首先是存放 總的博客內容的 repo ， 其佈局是如圖那樣的。這樣將生成的靜態網站和生成網站用的配置啦內容啦分開之後，頓時清晰了很多。 然後這個內容 repo 中的三個符號鏈接分別指向三個子 repo（沒用 git submodule 管理純粹是因爲偷懶）。 theme 指向 pelican-bootstrap3 ，是我修改過的 pelican 主題。 plugins 指向 pelican-plugins ，由於 plugins 的質量有些參差不齊，其中不少 plugin 都按我的需要做了些許修改，一些是功能改進，另一些則是修bug（比如不少plugin只支持 python 2）。 最後 output 指向 farseerfc.github.io 也就是發佈的靜態網站啦。 接下來從 主題 和 插件 兩個方面介紹一下改版的細節。 主題： Material Design 風格的 Bootstrap 3 上篇 博文 就總結了我爲了這個博客尋找了一堆 CSS 框架，並且最終決定用 bootstrap-material-design , DandyDev/pelican-bootstrap3 和 Bootstrap 3 這三個項目結合的方式實現這個模板的主題。 這三個項目都或多或少經過了我的修改，修改後的項目以 pelican-bootstrap3 爲基礎放在 這裏 ，包括 Bootstrap3 樣式 和 Material 樣式 。 對 Bootstrap 3 的定製 由於架構完善，修改 Bootstrap 3 感覺非常簡單。另一方面我在 Web 前端技術上的技能點也不多， 所以修改的地方非常有限，只能按我自己的需求定製而已。 響應式設備的大小 修改了 Bootstrap 3 響應式設備的大小 @screen-xs : 320px ; @screen-sm : 598px ; /* 768px; */ @screen-md : 952px ; /* 992px; */ @screen-lg : 1350px ; /* 1200px; */ @screen-xl : 2030px ; @container-sm : 582px ; /* 750px; */ @container-md : 930px ; /* 970px; */ @container-lg : 1320px ; /* 1170px; */ @container-xl : 1990px ; 首先把 Bootstrap 3 默認適配的幾個 響應式設備的大小 改成了我需要的大小。 xs 和 sm 的大小分別按照我的手機屏幕 豎屏 和 橫屏 時候的瀏覽器頁面寬度來算， md 是想兼容 Nexus 7 橫屏 960 的寬度以及 一個常見上網本 1024 的寬度。 lg 的大小則按照常見的筆記本 1366 寬的屏幕來適配。 這裏 Bootstrap 3 支持的設備大小的一個問題是，它最多考慮到 1200 像素寬的顯示器，而更寬的 比如 1600、 2048 甚至 2560 像素寬的顯示器現在也並不少見，其結果就是頁面中左右兩側 有很大的空間被浪費掉了。作爲深受這一問題困擾的用戶之一，我用 這裏介紹的方法 給 bootstrap 增加了一類「 比大更大 ( bigger than bigger ) 」的 xl 響應式設備尺寸，寬度設爲支持 2048 像素寬的顯示器，具體的修改反映在 variables.less 文件裏。 根據寬度自動分欄和瀑布式佈局 接下來目標是讓主頁的文章列表像 Google+ 主頁那樣根據顯示器寬度自動調整分欄，使得寬度不同的 顯示器上每個分欄的寬度接近。想要達到的效果是，根據上面定義的屏幕寬度尺寸： xs 用單欄 流動 ( fluid ) 佈局 sm 用上方單欄文章列表、下方雙欄 側邊欄 ( sidebar ) 固定佈局 md 用單欄文章列表、單欄 側邊欄 固定佈局 導航欄 ( Navbar ) 文章 側邊欄 底欄 導航欄 文章 側邊欄 1 側邊欄 2 底欄 ( footer ) 導航欄 文章 1 側邊欄 1 文章 2 側邊欄 2 底欄 ( footer ) lg 用雙欄文章列表、單欄 側邊欄 固定佈局 xl 用三欄文章列表、雙欄 側邊欄 固定佈局 導航欄 文章 1 文章 3 側邊欄 1 文章 2 文章 4 側邊欄 2 底欄 ( footer ) 導航欄 文章 1 文章 3 文章 5 側邊欄 1 文章 2 文章 4 文章 6 側邊欄 2 底欄 ( footer ) 一開始純粹用 Bootstrap3 的響應式柵格實現這個分欄佈局，結果發現效果不太理想， 因爲文章列表和側邊欄的高度是變化的，會導致柵格間留下大片空白。後來改用 這裏示範的純CSS瀑布式佈局 實現文章和側邊欄的佈局，具體的實現代碼在 waterfall.less ，總算達到了想要的佈局了。 正文的樣式 最最重要的是文章正文的樣式。這裏我想要達到的效果是，在大屏幕上用更大的字號，讓讀者 看起來更舒適，同時在小屏幕上用比較小的字號，最終保證基本上「一行」的文字數接近。這個修改 主要針對 .jumbotron ， 用了 不太科學的方式 代碼太長就不貼全了。 一些細微的定製 把主題配色改成了現在這樣的淡紫色 @brand-primary: darken(#6B5594, 6.5%); ，配合我的頭像風格， 這個修改只需要一行。 接着刪掉了 .btn 的 white-space: nowrap; 讓按鈕的文字可以換行， 這也只是一行修改。 2015年1月29日更新 另外我也不太喜歡 Bootstrap 3 默認在手機上的 摺疊導航欄 ( collapsed navbar ) ， 摺疊之後的操作不夠直觀方便而且依賴 javascript 所以有 bug …… 於是我把它關掉了， 具體方式是在 variables.less 把 @grid-float-breakpoint 和 @grid-float-breakpoint-max 都設爲0就可以了。 對 bootstrap-material-design 的定製 這裏定製的地方不多。原樣式中一個不太科學的做法是所有 .btn 都強制加上了陰影 效果，這在已經有陰影的環境裏用的話非常礙眼，像是 Win9x 風格的厚重睫毛膏。既然可以單獨 給每個樣式加陰影，於是就把 .btn 強制的陰影去掉了，只保留鼠標懸停之後強調的陰影。 其它定製的細節麼就是統一配色風格，修補漏洞錯誤，微調響應式效果而已，這裏不細說。 將以上兩者整合在 pelican-bootstrap3 裏 Pelican 實現顯示源代碼按鈕 顯示源代碼按鈕借用了 Pelican 配置中自帶的 OUTPUT_SOURCES 選項將源文件複製到輸出文件夾： OUTPUT_SOURCES = True OUTPUT_SOURCES_EXTENSION = '.rst' 然後在 Makefile 裏用 pygmentize 把所有源代碼文件着色： find -iname \"*.rst\" | parallel -I@ pygmentize -f html -o @.html @ 最後在按鈕按下的時候用 jQuery 載入源代碼： <a onclick= \"$.get('{{SITEURL}}/{{article.slug}}.rst.html', function(data){$('#source-code').html(data)});$('#article-content').toggle();$('#source-content').toggle();\" > 雖然難看的 hack 比較多，但是能用！ 雖說 pelican-bootstrap3 是我 fork 出來的，不過由於我修改的地方實在太多，代碼看來基本上 接近重寫了一份。好在之前有給 pelican 寫 bootstrap 2 主題的經驗，這次修改算得上駕輕就熟。 可以對比一下 上游作者的博客 和這裏的樣子體會一下感覺。 具體修改過的地方包括： 套用 bootstrap-material-design 的各個元素樣式。 在文章列表模板應用上面提到的 Bootstrap 3 的柵格佈局和瀑布式佈局。 翻譯到多個語言，這裏在後面的 i18n-subsite 插件裏詳述。 套用後面會介紹到的各種插件。 統一側邊欄的樣式到一個模板裏。 添加 Atom 訂閱按鈕和 breadcrumb 條。 對正文中出現的插圖，添加點擊放大的功能，通過 Bootstrap 的 modal 實現。 上面提到的用 這個bootstrap插件 讓導航欄自動隱藏。 顯示源代碼按鈕 ，也就是每篇文章信息欄中的 按鈕。 插件: 發揮 Pelican 和 reStructuredText 的優勢 先列舉一下我目前用到的所有插件： PLUGINS = [ \"i18n_subsites\" , \"plantuml\" , \"youku\" , \"youtube\" , 'tipue_search' , 'neighbors' , 'series' , 'bootstrapify' , 'twitter_bootstrap_rst_directives' , \"render_math\" , 'extract_toc' , 'summary' ] 嗯其實不算多。接下來逐一介紹一下這些各具特色的插件。 i18n-subsites 這個插件的目的是創建 國際化 ( internationalization ) 子站 ( subsite ) 。 之前介紹 Pelican 配置的時候就提到過， 原本的 Pelican 就支持一篇文章用多種語言書寫，有 lang 屬性註明這篇文章使用的 語言，以及 slug 屬性註明多語言的翻譯之間的關聯，換句話說同一篇文章的多個語言 版本應該有相同的 slug 和不同的 lang 。然後原本 Pelican 裏對多語言的 實現方式是，首先有一個 主語言 是模板和大部分文章採用的語言，文章列表中會優先列出 用 主語言 撰寫的文章，然後從 主語言 的文章鏈接到別的翻譯版本。 很多博客系統和CMS對多語言的支持都是這樣的，這種處理方式的缺點也顯而易見：作爲 主語言 的語言必須足夠通用，纔能讓進來的人找到合適的翻譯版本，所以通常 主語言 都是英語。 而這個插件做的事情描述起來很簡單：將文章按語言屬性分到多個子站，每個子站獨立放在各自的文件夾。 比如主站是 https://farseerfc.github.io/ 的話，那麼英語的子站就可以是 https://farseerfc.github.io/en/ 。 然後分別對多個子站生成靜態頁面。具體的實現方式是對 pelican 的頁面生成步驟做了拆分： pelican 按正常情況讀入文章，生成元信息。 i18n-subsites 針對每個語言，覆蓋掉 pelican 的一些選項設置比如路徑和 URL ， 分別調用 pelican 的頁面生成器按模板生成文章。 對共用的靜態內容比如模板的 js 和 css 文件，只在主站中生成，子站中的相應鏈接全部鏈回主站。 雖然描述起來簡單，但是這個插件可以說最大化利用了 Pelican 的插件系統，實現細節相對比較 複雜，大概是我用的這些插件裏面最複雜的了。不誇張的說 Pelican 3.4 支持的新插件 API 和 站內鏈接功能基本上就是爲了配合這個插件的。至於具體它會覆蓋哪些 Pelican 的配置，請參閱它的 README.md文件 。 按內容拆分多語言子站的做法只解決了問題的一半，還留下另一半的問題，也即對模板的翻譯。 對這個問題， i18n-subsites 提供了兩套方案供選擇： 用覆蓋配置路徑的方式讓每個子站套用不同的模板。這配置起來簡單，但是對模板維護起來有點困難。 用 jinja2 的 i18n 插件，配合 Python 的 gettext 庫實現內容翻譯。這個方案 配置起來比較複雜 ，但是配置好之後用起來就很方便了。 只是要記得每次修改了模板都要更新翻譯，處理 *.po 和 *.mo 文件等等瑣碎事宜。 這裏我用 jinja2 的 i18n 插件的方式實現了模板的翻譯， 各個語言的翻譯在這裏 ， 然後用 這裏的 SCons 腳本 根據內容是否變化自動更新 po 和 mo 文件。 配置好這一套方案之後，還要注意在模板和文章中處理好鏈接。用 Pelican 3.4 之後推薦的 新的文章間鏈接的寫法以及將 SITEURL 設置爲實際 URL 並且關閉 RELATIVE_URLS 之後，應該就不會出沒什麼問題了（可能還要考慮使用的模板和插件的兼容性，大部分都是寫死了 URL 的問題）。 plantuml 嵌入 PlantUML 的示例 PlantUML 是一個Java實現的， 用接近文字描述的語言繪製 UML 圖或者 GUI 界面圖的工具，非常適合嵌入在 Markdown、 reStructuredText、 AsciiDoc 等這種輕量級標記語言裏。 然後麼這個 plantuml 插件就是定義了一個新的 reStructuredText 指示符 ( directive ) .. uml:: ，把嵌入的內容提取出來調用 plantuml 命令處理 成圖像然後再插入到文章中。 比如示例裏的這個 UML 圖就是用這樣一段簡單的文字描述生成的： .. uml :: Object <|-- ArrayList Object : equals() ArrayList : Object[] elementData ArrayList : size() 實際用起來這個插件實現上稍微有點小問題：首先它只支持 python2，所以我把它改寫成了 python 2 和 3 都通用的語法；其次它原本輸出的文件夾似乎會被 pelican 刪掉，所以把它改了個位置； 然後它輸出的 URL 也和 i18n-subsites 插件間有不兼容的問題，也順帶修掉了。 修改之後的代碼在這裏 。 2015年1月30日更新 嵌入 Ditaa 的示例 plantuml 是繪製UML的，除此之外還有一個類似的工具是繪製一般的 流程圖 ( diagram ) 的，叫 ditaa ，和 plantuml 非常像，也比較像 reStructuredText 的表格。 於是我也照貓畫虎實現了一個 ditaa 的 指示符 ( directive ) ，用起來類似這樣： .. ditaa :: +-------------+ | ditaa |-------+ | Diagram | | +-------------+ | PNG out &#94; | | ditaa in | | v +--------+ +--------+----+ /----------------\\ | | --+ Pelican +--> | | | Text | +-------------+ | Beautiful Blog | |Document| | !magic! | | | | {d}| | | | | +---+----+ +-------------+ \\----------------/ : &#94; | Lots of work | +-----------------------------------+ render-math 嵌入公式的示例 示範行內公式 \\(A_\\text{c} = (\\pi/4) d&#94;2\\) . 整行公式 \\begin{equation*} \\alpha{}_t(i) = P(O_1, O_2, \\ldots O_t, q_t = S_i \\lambda{}) \\end{equation*} 這個插件提供在 reStructuredText 中用 LaTeX 語法插入數學公式的能力，定義了 :math: 行內角色 ( role ) 和 .. math:: 指示符 ( directive ) 。 實際工作的渲染庫當然是大名鼎鼎的 MathJax ，這個插件 會用 MathJax 的 CDN 載入，所以也沒有額外的依賴文件。（只是不知道是否會被國內牆掉， 如果公式顯示不正常請 務必 告訴我。） youtube 和 youku 顧名思義，這兩個插件分別實現嵌入 youtube 和 youku 視頻。其中 youtube 是原本就有的插件， youku 是我照貓畫虎抄的。 之前寫了一篇 KDE5 Plasma 之跳動賣萌的活動按鈕 用到了這兩個插件。 tipue_search Tipue search 是一個非常有意思也很強大的搜索工具， 通過 jQuery 實現靜態博客的站內搜索功能。實現方式是，它需要你寫一個 json 文件，包含 整個網站的 全部 文章的標題和文字內容，然後在搜索的時候讀入這個 json 做搜索（是不是有點耍賴）。 雖然聽起來會有性能問題，但是應用在小型的靜態博客上效果意外很不錯，比如本站的所有文章內容 放在一起的 json 也只有 300KiB 左右。 這個插件就是自動在 pelican 輸出完全部靜態網頁之後，調用 beautifulsoup4 從所有網頁中抽取出 純文本，產生這個 json 給 Tipue 用。 neighbors 和 series 這兩個插件比較類似也都比較簡單， neighbors 提供一篇文章的前後文章信息， 在主題模板裏可以用來製作 上一篇 和 下一篇 按鈕。 series 提供將多篇文章歸類爲一個 系列 的支持，當然也需要在 主題模板中定義顯示「文章系列」的列表。這兩個插件的效果都能在本文末尾，評論區上方的部分看到。 bootstrapify 和 twitter_bootstrap_rst_directives 這兩個插件讓文章的 正文 套用上 Bootstrap 的樣式。 bootstrapify 這個插件實現得比較簡單，用 beautifulsoup4 在靜態網頁的結果裏面過濾元素， 對 table , img , embed , iframe , video , object 這幾個標籤套用上 響應式嵌入對象的類 讓他們更美觀。 twitter_bootstrap_rst_directives 這個插件則是增加了幾個 reStructuredText 的 行內角色 ( role ) 和 指示符 ( directive ) 。 它實現的 行內角色 ( role ) 包括： 用 :kbd: 實現如 Ctrl+C 這樣的鍵盤快捷鍵， 用 :code: 嵌入代碼片段，用 :glyph: 嵌入字符圖標。 它實現的 指示符 ( directive ) 包括： labels 行內標籤 ， alerts 提示段落 ， panels 嵌入面板 ， 以及還有一個 media 混排圖標 。 對其中的 panel 我改寫了它在文章正文中的樣式，在 lg 或者 xl 的屏幕寬度下，分別用 \\(\\frac{1}{2}\\) 和 \\(\\frac{1}{3}\\) 大小的嵌入面板， 簡單實現和正文文字的圖文混排。 除此以外我還在 twitter_bootstrap_rst_directives 這個插件裏套用它的框架實現了兩個額外 的 行內角色 ( role ) ， 分別是 :ruby: ：通過 html5 的 <ruby> 標籤實現文字上方的注音（firefox下 不支持 ，會使用文字後的括號顯示）， 以及 :html: ：在 行內插入 裸 ( raw ) html 標籤（這屬於 Markdown 的基本功能，在 reStructuredText 這邊由於要考慮多種輸出格式於是就比較麻煩了）。這兩個 行內角色 ( role ) 的 實現代碼在這裏 。 2015年2月3日更新 今天又在 twitter_bootstrap_rst_directives 裏增加了兩個 行內角色 ( role ) 。 一個是 :twi: 用來寫 twitter 用戶的鏈接，比如 @farseerfc ，另一個是 :irc: 用來指向 freenode 的 channel ，比如 #yssyd3 。 2015年2月14日更新 今天增加了 .. friend:: 用來寫好友鏈接，以及 fref 用來引用好友， 比如 LQYMGT 這樣。 extract_toc 和 summary 最後是這兩個有點「名不副實」的插件。 reStructuredText 原本就有自動生成 目錄 ( toc ) 的功能，用起來也非常簡單，只需要在想要插入目錄的地方寫一行 .. contents:: ，剩下的都由 docutils 自動生成了。 只是當然這樣生成的目錄肯定會插入在文章的正文裏，而 extract_toc 這個插件的作用就是簡單地 把這個目錄抽取出來，讓模板能在別的地方放置這個目錄。比如我這裏就把目錄放在了一個 panel 裏。 然後 Pelican 也原本就有從文章中抽取 總結 ( summary ) 顯示在文章列表的功能。 Pelican 原始的實現似乎是按照文字數抽取前半段，不總是適合作爲總結。 於是這個 summary 插件的作用其實是允許在正文中以特殊的註釋的方式標註哪些部分應該被抽出來作爲總結。 summary 這個插件原本的實現只允許抽取一段文字，我又對它的實現做了少許擴充，允許標註多段 文字合併起來作爲總結。 2015年1月29日更新 今天在 extract_toc 插件的幫助下，在側邊欄裏放了一個 Bootstrap affix 的目錄， 它保持在頁面的右側位置不變，方便導航到文章的各個地方。具體實現方法除了 Bootstrap 3 的 Affix 文檔 ，還參考了 這篇更詳細的說明 。 結語 這個博客的配置都可以在 github 上找到 ，包括用來 自動生成整個博客的 Makefile ，由於比較長，這裏就不再貼了。 折騰這個主題前後歷時兩個月，期間學會了不少東西，也算是不錯的收穫吧。 現在既然基礎打好了，接下來就要開始多寫博客了。（希望拖延症不會再犯……） 最近發現除了我的博客之外還有一個網站 Kansas Linux Fest fork 了我的主題，不過他們用了我修改的早期版本，還是原本的 Bootstrap 3 和 bootstrap-material-design 樣式。自己草草修改的東西被別人用到果然還是有點小激動呢， 以及接下來不能馬馬虎虎地寫 commit 消息了。 [1] 賽65:17「看哪！我造新天新地」啟21:5「我將一切都更新了。」 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdnjscn.b0.upaiyun.com/libs/mathjax/2.4.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","title":"重新設計了 Pelican 的主題與插件"},{"url":"//farseerfc.me/summarize-material-design-css-framework.html","text":"現在這裏的界面風格要從 Google 在 I/O 2014 大會 上公佈Android L 也即 後來的 Lollipop 說起。 他們在談論界面設計的時候公佈了他們的 設計準則： Material Design ( 中文非官方翻譯 )。 當然這只是一些準則，總結並描述了之前在 Web 設計和移動端 App 界面設計方面的一些規範， 並且用材料的類比來形象化的比喻這個準則。關於 Material Design 的更多中文資料可 參考這裏 。 看到 Material Design 之後就覺得這個設計風格非常符合直覺，於是想在這邊也用上 Material Design。 但是我在 Web 前端科技樹上沒點多少技能點，所以想找找別人實現好的模板 或者框架直接套用上。在網絡上搜索數日找到了這幾個： Polymer Paper Elements Polymer Polymer logo Google 官方提供的參考實現應該是 Polymer 中的 Paper Elements 。 由於是 官方參考實現 ，這個框架的確非常忠實地實現了 Material Design 的設計，但是同時 由於它基於 HTML5 Web Components 構建，相關技術我還 不太懂，瀏覽器兼容性和其餘 HTML 技術的兼容性也還不太完善的樣子…… 並且對於我這個 Web 開發的半吊子來說，Polymer 只是提供了一組設計組建，沒有完善的 響應式 (responsive) 佈局支持，也沒有 Navbar 這種常見的框架組建，真的要用起來的話還 需要手工實現不少東西。於是口水了半天之後只好放棄……以後可能真的會換用這個，只是目前需要學 的東西太多了。 Angular Material Design AngularJS AngularJS 是 Google 對 Web Components 技術的另一個 嘗試。而這額 Angular Material Design 項目 就是基於 AngularJS 構建的Material Design 庫啦，同樣是 Google 出品所以應該算得上半個 官方實現吧。 相比於 Polymer, AngularJS 算是實用了很多，提供了基於 CSS Flexbox 的佈局。有人對這兩者的評價是， 如果說 Polymer 代表了 未來趨勢 ，那麼 AngularJS 就是 眼下可用 的 Web Components 實現了。 只不過同樣是因爲它是 Components 的框架，對 WebApp 的支持很豐富，大量採用 Ajax 等 JavaScript 技術， 對於我這個靜態博客來說仍然稍顯高級了……非常擔心還不支持 HTML5 的瀏覽器 比如 w3m 甚至 cURL 對它的支持程度。 於是最終也沒有使用它。 Materialize Materialize Materialize 這是一批(自稱?)熟悉 Android 上 Material Design 的設計師們新近出爐的框架，試圖提供一個接近 Bootstrap 的方案。 最早是在 Reddit 上看到對它的討論的，立刻覺得這個想法不錯。 體驗一下官網的設計就可以看出，他們的動畫效果非常接近 Polymer 的感覺，響應式設計的佈局 也還不錯。 只是同樣體驗一下他們現在的官網就可以看出，他們目前的 bug 還比較多 ，甚至一些 bug 在他們自己的主頁上也有顯現。 雖然不想給這個新出爐的項目潑涼水，不過看來要達到他們聲稱的接近 Bootstrap 的易用度還任重而道遠…… bootstrap-material-design + bootstrap3 這是我最終選擇的方案。這個方案將三個項目組合在了一起，分別是 bootstrap-material-design , pelican-bootstrap3 和 Bootstrap 3 。 Bootstrap 3 想必不用再介紹了，很多網站都在使用這套框架，定製性很高。 bootstrap-material-design 是在 Bootstrap 3 的基礎上套用 Material Design 風格 製作的一套 CSS 庫，當然也不是很完善並且在不斷改進中，一些細節其實並不是很符合我的要求。 最後 pelican-bootstrap3 是用 Bootstrap 3 做的 pelican 模板。 這三個項目或多或少都有點不合我的口味，於是嘛就把 pelican-bootstrap3 fork了一套放在 這裏 ，其中還包括我自己改 過的 Bootstrap3 樣式 和 Material 樣式 ，需要的可以自取。 至於細節上我定製了哪些地方，敬請聽下回分解……","tags":"tech","title":"總結一下 Material Design 的 CSS 框架"},{"url":"//farseerfc.me/from-unbuffered-stdin-to-history-of-linux-tty.html","text":"這篇也是源自於水源C板上板友的一個問題，涉及Linux上的控制檯的實現方式和歷史原因。因爲內容比較長，所以在這裏再排版一下發出來。 原帖在這裏 。 可以設置不帶緩衝的標準輸入流嗎？ WaterElement(UnChanged) 於 2014年12月09日23:29:51 星期二 問到： 請問對於標準輸入流可以設置不帶緩衝嗎？比如以下程序 #include <stdio.h> #include <unistd.h> int main ( int argc , char * argv []) { FILE * fp = fdopen ( STDIN_FILENO , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 似乎還是需要在命令行輸入後按回車纔會讓 fgets 返回，不帶緩衝究竟體現在哪裏？ 這和緩存無關，是控制檯的實現方式的問題。 再講細節一點，這裏有很多個程序和設備。以下按 linux 的情況講： 終端模擬器窗口（比如xterm）收到鍵盤事件 終端模擬器(xterm)把鍵盤事件發給虛擬終端 pty1 pty1 檢查目前的輸入狀態，把鍵盤事件轉換成 stdin 的輸入，發給你的程序 你的程序的 c 庫從 stdin 讀入一個輸入，處理 標準庫說的輸入緩存是在 4 的這一步進行的。而行輸入是在 3 的這一步被緩存起來的。 終端pty有多種狀態，一般控制檯程序所在的狀態叫「回顯行緩存」狀態，這個狀態的意思是: 所有普通字符的按鍵，會回顯到屏幕上，同時記錄在行緩存區裏。 處理退格( BackSpace )，刪除( Delete )按鍵爲刪掉字符，左右按鍵移動光標。 收到回車的時候把整個一行的內容發給stdin。 參考： http://en.wikipedia.org/wiki/Cooked_mode 同時在Linux/Unix下可以發特殊控制符號給pty讓它進入「raw」狀態，這種狀態下按鍵 不會被回顯，顯示什麼內容都靠你程序自己控制。 如果你想得到每一個按鍵事件需要用raw狀態，這需要自己控制回顯自己處理緩衝， 簡單點的方法是用 readline 這樣的庫（基本就是「回顯行緩存」的高級擴展，支持了 Home/End，支持歷史）或者 ncurses 這樣的庫（在raw狀態下實現了一個簡單的窗口/ 事件處理框架）。 參考： http://en.wikipedia.org/wiki/POSIX_terminal_interface#History 除此之外， Ctrl-C 轉換到 SIGINT ， Ctrl-D 轉換到 EOF 這種也是在 3 這一步做的。 以及，有些終端模擬器提供的 Ctrl-Shift-C 表示複製這種是在 2 這一步做的。 以上是 Linux/unix 的方式。 Windows的情況大體類似，只是細節上有很多地方不一樣： 窗口事件的接收者是創建 cmd 窗口的 Win32 子系統。 Win32子系統接收到事件之後，傳遞給位於 命令行子系統 的 cmd 程序 cmd 程序再傳遞給你的程序。 Windows上同樣有類似行緩存模式和raw模式的區別，只不過實現細節不太一樣。 strace查看了下 WaterElement(UnChanged) 於 2014年12月10日21:53:54 星期三 回復： 感謝FC的詳盡解答。 用strace查看了下，設置標準輸入沒有緩存的話讀每個字符都會調用一次 read 系統調用， 比如輸入abc： read(0, abc \"a\", 1) = 1 read(0, \"b\", 1) = 1 read(0, \"c\", 1) = 1 read(0, \"\\n\", 1) = 1 如果有緩存的話就只調用一次了 read 系統調用了： read(0, abc \"abc\\n\", 1024) = 4 如果想感受一下 raw mode 沒錯，這個是你的進程內C庫做的緩存，tty屬於字符設備所以是一個一個字符塞給你的 程序的。 如果想感受一下 raw mode 可以試試下面這段程序（沒有檢測錯誤返回值） #include <stdio.h> #include <unistd.h> #include <termios.h> static int ttyfd = STDIN_FILENO ; static struct termios orig_termios ; /* reset tty - useful also for restoring the terminal when this process wishes to temporarily relinquish the tty */ int tty_reset ( void ){ /* flush and reset */ if ( tcsetattr ( ttyfd , TCSAFLUSH , & orig_termios ) < 0 ) return - 1 ; return 0 ; } /* put terminal in raw mode - see termio(7I) for modes */ void tty_raw ( void ) { struct termios raw ; raw = orig_termios ; /* copy original and then modify below */ /* input modes - clear indicated ones giving: no break, no CR to NL, no parity check, no strip char, no start/stop output (sic) control */ raw . c_iflag &= ~ ( BRKINT | ICRNL | INPCK | ISTRIP | IXON ); /* output modes - clear giving: no post processing such as NL to CR+NL */ raw . c_oflag &= ~ ( OPOST ); /* control modes - set 8 bit chars */ raw . c_cflag |= ( CS8 ); /* local modes - clear giving: echoing off, canonical off (no erase with backspace, &#94;U,...), no extended functions, no signal chars (&#94;Z,&#94;C) */ raw . c_lflag &= ~ ( ECHO | ICANON | IEXTEN | ISIG ); /* control chars - set return condition: min number of bytes and timer */ raw . c_cc [ VMIN ] = 5 ; raw . c_cc [ VTIME ] = 8 ; /* after 5 bytes or .8 seconds after first byte seen */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 0 ; /* immediate - anything */ raw . c_cc [ VMIN ] = 2 ; raw . c_cc [ VTIME ] = 0 ; /* after two bytes, no timer */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 8 ; /* after a byte or .8 seconds */ /* put terminal in raw mode after flushing */ tcsetattr ( ttyfd , TCSAFLUSH , & raw ); } int main ( int argc , char * argv []) { atexit ( tty_reset ); tty_raw (); FILE * fp = fdopen ( ttyfd , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 終端上的字符編程 vander(大青蛙) 於 2014年12月12日08:52:20 星期五 問到： 學習了！ 進一步想請教一下fc大神。如果我在Linux上做終端上的字符編程，是否除了用ncurses庫 之外，也可以不用該庫而直接與終端打交道，就是你所說的直接在raw模式？ 另外，終端類型vt100和linux的差別在哪裏？爲什麼Kevin Boone的KBox配置手冊裏面說必 須把終端類型設成linux，而且要加上terminfo文件，才能讓終端上的vim正常工作？term info文件又是幹什麼的？ Linux控制檯的歷史 嗯理論上可以不用 ncurses 庫直接在 raw 模式操縱終端。 這裏稍微聊一下terminfo/termcap的歷史，詳細的歷史和吐槽參考 Unix hater's Handbook 第6章 Terminal Insanity。 首先一個真正意義上的終端就是一個輸入設備（通常是鍵盤）加上一個輸出設備（打印 機或者顯示器）。很顯然不同的終端的能力不同，比如如果輸出設備是打印機的話，顯 示出來的字符就不能刪掉了（但是能覆蓋），而且輸出了一行之後就不能回到那一行了 。再比如顯示器終端有的支持粗體和下劃線，有的支持顏色，而有的什麼都不支持。 早期Unix工作在電傳打字機（TeleTYpe）終端上，後來Unix被port到越來越多的機器上 ，然後越來越多類型的終端會被連到Unix上，很可能同一臺Unix主機連了多個不同類型 的終端。由於是不同廠商提供的不同的終端，能力各有不同，自然控制他們工作的方式 也是不一樣的。所有終端都支持回顯行編輯模式，所以一般的面向行的程序還比較好寫 ，但是那時候要撰寫支持所有終端的「全屏」程序就非常痛苦，這種情況就像現在瀏覽 器沒有統一標準下寫HTML要測試各種瀏覽器兼容性一樣。 通常的做法是 使用最小功能子集 假設終端是某個特殊設備，不管別的設備。 水源的代碼源頭 Firebird2000 就是那樣的一個程序，只支持固定大小的vt102終端。 這時有一個劃時代意義的程序出現了，就是 vi，試圖要做到「全屏可視化編輯」。這在 現在看起來很簡單，但是在當時基本是天方夜譚。 vi 的做法是提出一層抽象，記錄它所需要的所有終端操作，然後有一個終端類型數據庫 ，把那些操作映射到終端類型的具體指令上。當然並不是所有操作在所有終端類型上都 支持，所以會有一堆 fallback，比如要「強調」某段文字，在彩色終端上可能 fallback 到紅色，在黑白終端上可能 fallback 到粗體。 vi 一出現大家都覺得好頂讚，然後想要寫更多類似 vi 這樣的全屏程序。然後 vi 的作 者就把終端抽象的這部分數據庫放出來形成一個單獨的項目，叫 termcap （Terminal Capibility），對應的描述終端的數據庫就是 termcap 格式。然後 termcap 只是一個 數據庫（所以無狀態）還不夠方便易用，所以後來又有人用 termcap 實現了 curses 。 再後來大家用 curses/termcap 的時候漸漸發現這個數據庫有一點不足：它是爲 vi 設 計的，所以只實現了 vi 需要的那部分終端能力。然後對它改進的努力就形成了新的 terminfo 數據庫和 pcurses 和後來的 ncurses 。 然後 VIM 出現了自然也用 terminfo 實現這部分終端操作。 然後麼就是 X 出現了， xterm 出現了，大家都用顯示器了，然後 xterm 爲了兼容各種 老程序加入了各種老終端的模擬模式。不過因爲最普及的終端是 vt100 所以 xterm 默 認是工作在兼容 vt100 的模式下。然後接下來各種新程序（偷懶不用*curses的那些） 都以 xterm/vt100 的方式寫。 嗯到此爲止是 Unix 世界的黑歷史。 知道這段歷史的話就可以明白爲什麼需要 TERM 變量配合 terminfo 數據庫纔能用一些 Unix 下的全屏程序了。類比一下的話這就是現代瀏覽器的 user-agent。 然後話題回到 Linux 。 大家知道 Linux 早期代碼不是一個 OS， 而是 Linus 大神想 在他的嶄新蹭亮的 386-PC 上遠程登錄他學校的 Unix 主機，接收郵件和逛水源（咳咳 ）。於是 Linux 最早的那部分代碼並不是一個通用 OS 而只是一個 bootloader 加一個 終端模擬器。所以現在 Linux 內核裏還留有他當年實現的終端模擬器的部分代碼，而這 個終端模擬器的終端類型就是 linux 啦。然後他當時是爲了逛水源嘛所以 linux 終端 基本上是 vt102 的一個接近完整子集。 說到這裏脈絡大概應該清晰了， xterm終端類型基本模擬 vt100，linux終端類型基本模 擬 vt102。這兩個的區別其實很細微，都是同一個廠商的兩代產品嘛。有差別的地方差 不多就是 Home / End / PageUp / PageDown / Delete 這些不在 ASCII 控制字符表裏的按鍵的映射關係不同。 嗯這也就解釋了爲什麼在linux環境的圖形界面的終端裏 telnet 上水源的話，上面這些 按鍵會錯亂…… 如果設置終端類型是 linux/vt102 的話就不會亂了。在 linux 的 TTY 裏 telnet 也不會亂的樣子。 寫到這裏纔發現貌似有點長…… 總之可以參考 Unix hater's Handbook 裏的相關歷史評論和吐槽，那一段非常有意思。","tags":"tech","title":"從非緩衝輸入流到 Linux 控制檯的歷史"},{"url":"//farseerfc.me/jumping-kde5-plasma-activities-button.html","text":"今天嘗試 KDE5 Plasma 的活動的時候無意間發現這個現象。 只要把活動按鈕拖出桌面，它就會在桌面邊緣來回跳動。 視頻如下： Youtube Youku 當然你可以把它再拖回來，所以這個問題還無傷大雅，只是賣萌。 比比之前 Gnome3 那個跳動的界面真是好太多了： Youtube Youku 順便，今天還看到一個賣萌的 KDE5 Plasma 靜音圖標的翻譯： KDE5のミュート画面の中国語翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","title":"KDE5 Plasma 之跳動賣萌的活動按鈕"},{"url":"//farseerfc.me/marry-me.html","text":"渲染的樣子 可以玩的是下面這個： * 用 WASD←→ 移動，需要 WebGL 支持","tags":"life","title":"嫁給我好麼"},{"url":"//farseerfc.me/icse2012.html","text":"June 6 Keynote 1 沒怎麼聽懂，只記得講到了finance is not money但是沒聽懂這個和軟件有什麼關係。 Cost Estimation for Distributed Software Project 講到他們試圖改善現有的模型去更精確地評估軟件開發的開銷。 他們會給PM建議之前的項目的歷史數據，然後對於新項目，他們建議歷史上已有 的項目的數據，從而幫助PM得到更精確的評估。他們試圖儘量減少項目評估對PM 的經驗的需求，從而幫助即使經驗很少的PM也能準確評估項目的開銷。 他們的觀點： Context-specfic solutions needed! 我們需要更上下文相關的解決方案！ Early user paticipation is key! 早期用戶的參與是關鍵 Characterizing Logging Practices in Open-Source Software Common mistakes in logging messages 在日誌記錄中容易犯的錯誤 他們學習了歷史上的log記錄，然後試圖找到重複修改的輸出log的語句，確定log 中存在的問題。他們首先確定修改是事後修改。 通常的修改的比例（9027個修改） 45% 靜態文本 27% 打印出的變量 26% 調試等級verbosity 2% 日誌輸出的位置 他們發現有調試等級的變化，是因爲安全漏洞之類的原因，或者在開銷和數據 之間的權衡。 大多數對log的變量的修改都是爲了增加一個參數。他們之前的LogEnhancer是爲了 解決這個問題而提出的，通過靜態檢查，提醒程序員是否忘記了某個參數 對text的修改是因爲要改掉過時的代碼信息，避免誤導用戶。 他們的實驗是採用了基於code clone 的技術，找到所有log語句，然後找不一致 的clone，然後自動提出建議。 Combine Functional and Imperative Pgrm for Multicore Sw: Scala & Java 趨勢：到處都是多核，但是併發程序呢？ 他們研究的對象是Scala和Java，因爲可以編譯後確認JVM字節碼的語義。 Java: 共享內存 顯示創建的線程 手動同步 Wait/Notify機制 Scala: 高階函數 Actors, 消息傳遞 lists, filters, iterators while 共享狀態, OO import java.* 能從java導入任何庫 auto type inferance 自動類型推導 實驗的參與者都經過4周的訓練，實驗項目是工業等級的開發項目 結果： scala 的項目平均比java多花38%的時間，主要都是花在Test和debug上的時間。 程序員的經驗和總體時間相關，但是對test和debug沒有顯著影響。 scala的爲了讓編程更有效率的設計，導致debug更困難。比如類型推導，debug 的時候需要手動推導，來理解正在發生什麼。 scala的程序比java小，中位數2.6%，平均15.2% 性能比較： 單核：scala的線性程序的性能比java好 4核： scala 7s @ 4 threads java 4si @ 8 threads median 83s scala 98s java 32core: best scala 34s @ 64 threads 結論 java有更好的scalability scala類型推導 45%說對攜帶碼有幫助 85%說導致程序錯誤 調試 23%認爲scala簡單 77%認爲java簡單 multi-paradigram are better Sound Empirical Evidence in Software Testing Test data generation 測試數據自動生成 Large Empirical Studies - not always possible For open source software - big enough Identifing Linux Bug Fixing Patch current practice: manual Current research: keywords in commits link bug reports in bugzilla Try to solve classification problem issue pre-identified post-identified data from commit log feature extraction text pre-process stemmed non-stop words model learning research questions Active Refinement of Clone Anomaly Reports motivating code clones, clone groups clone used to detect bugs anomaly : inconsistent clone group many anomaly clone are note bug, high false positive approach reorder by sorted bug reports June7 Keynotes 2: Sustainability with Software - An Industrial Perspective Sustainability Classic View: Idenpendent view with overlap Social Environment Economic Nested viw Environment Social Economic Triple bottom line economic -global business, networks , global econ env natural res, climate change, population grow social awareness, connectivity, accountability Green IT reduce IT energy more than 50% cooling - doing nothing mini e-waste: not properly recycled 80% in EU 75% in US foster dematerialization In-Memory Technology: Expected Sustainable Benefits What can we do? consider all software lifecycle phases in your design avoid energy expensive behavior in your codes design lean architectures Green by IT 2% green IT 98% green IT On How Often code is cloned across repositories Line based hashing code clone detection never do anything harder than sorting hashing a window of 5 lines of normalized (tokenized) code, dropping 3/4 of the hashing 把ccfinder一個月的工作縮短到了3, 4天。沒有比較presion和recall。 14% type1 16% type2 17% type3 (not really type2) Graph-based analysis and prediction for sw evolution graph are everywhere internet topology social net chemistry biology in sw - func call graph - module dependency graph developer interaction graph - commit logs - bug reports experiment 11 oss, 27~171 release, > 9 years predictors NodeRank similar to pagerank of google measure relative importance of each node func call graph with noderank compare rank with severity scale on bugzilla correlation between noderank and BugSeverity func level 0.48 ~ 0.86 varies among projects. model level > func level ModularityRatio cohesion/coupling ratio: IntraDep(M)/InterDep(M) forecast mantencance effort use for identify modules that need redesign or refactoring EditDistance bug-based developer collaboration graphs ED(G1,G2)=|V1|+|V2|-2|V1交V2|+|E1|+|E2|-2|E1交E2| use for release planning resource allocation graph metrics graph diameter average node degree indicates reuse clustering coefficient assortativity num of cycles Conclusion \"Actionable intelligence\" from graph evolution studie 11 large long-live projs predictors identify pivotal moments in evolution What make long term contributors: willingness and opportunity in OSS OSS don't work without contributors form community mozilla (2000-2008) 10&#94;2.2 LTC <- 2 order -> 10&#94;4.2 new contributors <- 3.5 order -> 10&#94;7.7 users gnome (1999-2007) 10&#94;2.5 LTC <- 1.5 order -> 10&#94;4.0 new contributors <- 3.5 order -> 10&#94;6.5 users approach read issues of 20 LTC and 20 non-LTC suvery 56 (36 non-LTC and 20 LTC) extract practices published on project web sites summeray Ability/Willingness distinguishes LTCs Environment macro-climate popularity micro-climate attention bumber of peers performance of peers regression model newcomers to LTC conversion drops actions in first month predicts LTCs 24% recall 37% precision develop of auxiliary functions: should you be agile? a empirial assessment of pair programming and test-first programming can agile help auxiliary functions? experiment pair vs solo test-first vs test-last students vs professors research questions r1: can pair help obtain more correct impl r2: can test-first r3: dst test1 encourage the impl or more test cases? r4: does test1 course more coverage result test-first higher coverage non change with correctness pair improve on correctness longer total programming time Static Detection of Resource Contention Problems in Server-side script Addressed the race condition of accessing database or filesystem of PHP Amplifying Tests to Validate Exception Handling Code 異常處理的代碼不但難寫，而且難以驗證。各種組合情況難以估計，尤其是手機 系統上。 A tactic-centric approach automating traceability of quality concerns tactic traceability information models","tags":"life","title":"ICSE 2012"},{"url":"//farseerfc.me/msr2012.html","text":"Mining Software Repository 2012 @ ICSE 參加了今年的MSR，會場在University of Zurich。一大早來到大學，註冊有點 小插曲，顯然瑞士人搞不清楚中國人的名字，3個楊（Yang）姓的中國人的名牌 被搞錯了。然後堀田學長的所屬被寫作了\"Japan, Japan\"，成爲了全日本的代表。 MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) 首先是來自微軟亞洲研究院（MicroSoft Research @ Asia, MSR Asia）的Keynots， 於是就變成了MSR在MSR的演講。MSR的張冬梅（Dongmei Zhang）女士的演講 分爲關於Software Analysis和XIAO的兩部分。XIAO是MSRA開發的Code Clone Detector，似乎我要給井上研做的就是這個。想更多瞭解Xiao的細節，不過張女士 演講結束的時候的鼓掌導致了話筒的小故障。 Towards Improving BTS with Game Mechanisms 感覺這篇的內容基本上就是關於 http://www.joelonsoftware.com/items/2008/09/15.html 這裏寫到的東西，然後說同樣的理論是否可以用於Issue Tracking之類的事情上。 個人感覺這個意義不大，stackoverflow之所以成功是因爲它把開源社區本身就 具有的名譽體系具現化了，本着大家都喜歡被別人奉爲大牛的心態，就如同 wikipedia一樣。同樣的理論如果用於公司內部的Issue Tracking系統上，會得到 完全不同的東西吧。就像MSDN的組織方式雖然和wikipedia是一樣的，但是在MSDN 裏找信息的感覺和在wikipedia完全不一樣。個人不太看好這個方向。 GHTorrent 這篇的slide在這裏可以看到： http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Github的主要數據，代碼，已經可以通過git接口 獲得了，wiki是git的形式保存的。所以這個項目的目的就是暴露別的數據，主要 是issue tracking，code comments，這種。代碼訪問github api，然後用分佈式 實現以克服api的限制，然後提供torrents形式的history下載。github api獲得 的json數據以bson的形式保存在MongoDB裏，解析過的有了Schema之後的數據保存 在MySQL裏並可以導出SQL。 個人的想法，覺得數據如果能夠更統一，全部存在Git裏或許更好，像Wiki一樣。 同樣是要暴露全部歷史記錄的目的，用Torrent自己實現的歷史遠不如用Git的 接口實現的歷史記錄方便吧，git blame之類的也更方便追蹤code comment之類的 作者信息。當然對git的raw date直接讀寫，需要對git的內部原理有足夠的理解， 或許只有github的人有這種能力了。 Topic Mining 用得兩個參數， DE 和 AIC，完全不能理解，過後研究。實驗針對了Firefox, Mylyn, Eclipse三個軟件。試圖從Repo中分析源代碼的identifier和comments， 找到topic和bug之間的關係，比如怎樣的topic更容易導致bug。得出的結論似乎 也很曖昧，只是說核心功能被報告的bug更多，但是不知道原因。這只能表示核心 功能受到更多關注和更多測試吧，並不能說明核心功能就容易產生bug。 不過這個的Slide做得很漂亮，很容易理解。 SeCold A linked data platform for mining software repositories 沒聽懂這個項目的目的。 The evolution of software 第二天的Keynotes，關於將Social Media和Software Development相結合的想法。 或許就是Github賴以成功的基礎。講到代碼中的comment, Tags, uBlog, blog之類 的social的特性和IDE的融合的趨勢。 Do Faster Releases Imporve Software Quality? 使用Firefox作爲例子。 結論是快速發佈導致bug更多，更容易crash，但是bug更快得到修復，並且用戶 更快轉向新的發佈。 Security vs Performance Bugs in Firefox Performance bugs are regression, blocks release. 一些感想 基於自然語義分析的commit分割 經常工具（比如git）的使用者並沒有按照工具設計者的意圖使用工具，這給MSR 帶來很多困難。舉個例子，git有非常完美的branch系統，通常期望git的使用者 能夠在一次commit裏commit一個功能，比如一個bug的修復，或者一個feature的 添加，但是事實上經常有很多邏輯上的commit被合併在一個裏面了。 或許這不是使用者的錯，而是工具仍然不夠人性的表現。或許我們可以自動把 一次的commit按照語義分割成多個。 分割之後，可以更容易地把issue和commit關聯，也更容易組織更多的研究。 關於這次發表中大家用的slides系統 題目爲``Incorporating Version Histories in Information Retrieval Based Bug Localization''的人用的slide是beamer的。公式很多，overlay很多，列表 很多，圖片很少，典型的beamer做出的slide。思維導圖用得很不錯。今天一天 有至少3個slide是用beamer做的。 題目爲``Towards Improving Bug Tracking Systems with Game Mechanisms'' 的人用了prezi，圖片很多，過度很多。但是比如沒有頁號沒有頁眉頁腳，正式 會議的場合不太方便。 至少有六個以上用了Apple Keynotes，Keynotes做出來的東西真的和Powerpoint 做出來的很難區別，其中兩個人用了初始的主題所以才看出來。 剩下的自然是PPT。MSRA的張女士做的雖然是PPT，倒是有很多beamer的感覺， 比如頁眉頁腳和overlay的用法。這些如果都是PPT做出來的，會多很多額外的 人力吧。 值得一提的是有一個題目爲``Green Mining: A Methodology of Relating Software Change to Power Consumption''的人的slide全是``劣質''的手繪漫畫， 效果意外地好，很低碳很環保很綠色很可愛。具體效果可以參考下面的動畫，雖然 現場看到的不是一個版本： http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv 微軟是個腹黑娘！ 嘛雖然這也不是什麼新聞了。MSR2012的Mining Challenge的贊助商是微軟，管理 組織者來自微軟研究院，獎品是Xbox和Kinect。然後今年的題目是： Mining Android Bug 我看到了微軟滿滿的怨氣……","tags":"life","title":"MSR 2012 @ ICSE"},{"url":"//farseerfc.me/pyssy.html","text":"簡介 Pyssy 是用於 上海交通大學 飲水思源站 的一系列 Python 腳本和工具。 Pyssy 被有意設計爲既可以託管寄宿在 SAE [1] 上，也可以在單機上獨立使用。 項目地址： http://pyssy.sinaapp.com/ Github上的源代碼地址： https://github.com/yssy-d3/pyssy [1] Sina App Engine ，新浪雲平臺，類似 Google App Engine 的東西。 依賴關係 Pyssy 使用 Flask 作爲網頁服務器， 並且使用 Memcached 或者 Redis 作爲抓取 水源Web 的緩存。 SAE Python 環境下請開啓 Memcached 支持。 本地環境下請安裝 Redis-py 並運行 redis-server 服務器程序。","tags":"tech","title":"Pyssy 項目"},{"url":"//farseerfc.me/mix-ruby.html","text":"今天在GitHub上閒逛的時候看到一個叫做 PyRuby 的項目。項目的Readme說得很好： PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } 甚至 PyPI 上還有這個項目的包。 一開始我還以爲這又是一個野心勃勃的基於PyPy的Ruby實現，或者某種trick在Python裏面直接調用Ruby解釋器。 然後我想看看這個的源代碼 只有一個ruby.py文件，內容是： # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) 是的……的確……這種嘗試把Python和Ruby放在一起的想法絕對是瘋了……","tags":"tech","title":"PyRuby"},{"url":"//farseerfc.me/discuss-cpp-template-downcast.html","text":"這兩天在飲水思源的C板，關於C++模板的類型轉換的一個討論，後面是我的解答。 討論地址 http://bbs.sjtu.edu.cn/bbstcon,board,C,reid,1330078933,file,M.1330078933.A.html 原問題 今天在書上看到模板演繹的時候可以允許cast-down，於是我寫了個東西： template < bool _Test , class _Type = void > struct enable_if { }; template < class _Type > struct enable_if < true , _Type > { typedef _Type type ; }; class A { }; class B : A { }; template < typename T > struct traits { static int const value = false ; }; template <> struct traits < A > { static int const value = true ; }; template < typename T > void f ( T , typename enable_if < traits < T >:: value >:: type * = 0 ) { } template <> void f < A > ( A , enable_if < traits < A >:: value >:: type * ) { } template < typename T > class BB {}; template < typename T > class DD : public BB < T > {}; template < typename T > void ff ( BB < T > ) {}; int main ( int argc , char * argv []) { A a ; B b ; DD < long > dd ; //f(b); ff ( dd ); } 奇怪的是重載決議的時候， f 的情況下它就不讓我特化的 f<A> 進來。 但是在 ff 的情況下， ff<BB<long>> 卻進來了。 在VC10和GCC3.4下測試 我的解答 我們來設身處地地作爲編譯器，看一遍到底發生了什麼。 約定符號 # : A#B 是把 B 帶入 A<T> 的參數 T 之後實例化得到的結果。 首先看ff的情況。 DD < long > dd ; 處理到這句的時候，編譯器看到了 DD<long> 的實例化，於是去實例化 DD#long ，繼而實例 化了 BB#long 。 ff ( dd ); 這句，首先計算重載函數集合。 第一步，需要從參數 DD#long -> BB<T> 推斷 ff<T> 的 T 。根據函數模板參數推斷規則： :code:`class_template_name<T>` 類型的參數，可以用於推斷 :code:`T` 。 於是編譯器推斷 T 爲 long 。這裏就算不是 BB 而是完全無關的 CC 都可以推斷成功，只要 CC 也 是一個 CC<T> 形式的模板。 第二步，模板特化匹配。因爲只有一個模板，所以匹配了最泛化的 ff<T> 。 第三步，模板實例化。 推斷了 long -> T 之後，編譯器實例化 ff#long 。 重載函數集合： {ff#long} 然後重載抉擇找到唯一的可匹配的實例 ff#long ，檢查實際參數 DD#long 可以隱式轉換到 形式參數 BB#long ，從而生成了這次函數調用。 再來看f的情況。 f ( b ); 計算候選重載函數集合。 第一步，對所有 f 模板推斷實參。根據函數模板參數推斷規則： 帶有 :code:`T` 類型的參數，可以用於推斷 :code:`T` 。 於是 B -> T 被推斷出來了。 第二步，模板特化匹配。 這裏 B 不是 A ，所以不能用 f<A> 特化，只能用 f<T> 模板。 第三步，模板實例化。 B 帶入 f<T> 實例化成 f#B 的過程中，實例化 traits#B 。 由於沒有針對 B 的特化，所以用 traits<T> 模板， traits#B::value=false ，進而 enable_if#false 沒有 type ，出錯。 唯一的模板匹配出錯，重載函數集合爲空，SFINAE原則不能找到合適的匹配，於是報錯。","tags":"tech","title":"關於C++模板的類型轉換的討論"},{"url":"//farseerfc.me/try-pelican.html","text":"似乎一夜之間所有的 極客們 都 有了 自己 的 Github主頁 和 Octopress 博客。就像所有人在他們的博客中指出的，靜態博客的確比傳統的WordPress方式具有更多優勢。 自從看到這些 我就一直在想着自己搭一個 Octopress 。 但是似乎 Octopress 不適合我 一上手就被 Octopress的搭建步驟 煩到了。 RVM 是什麼？ rbenv 又是什麼？ 看來 Ruby 社區的快節奏發展已經超過了我的想象，他們似乎需要一套發行版管理器來調和不同版本之間的 Ruby 的兼容性問題。 雖然同樣的兼容性問題在 Python 社區也有 [1] ，不過總覺得 Python 至少還沒到需要一個發行版管理器的程度 [2] 。 真正的問題是我手上還沒有一個可以讓我隨便玩的 Linux 環境（真的想要……）。 而無論是 RVM 還是 rbenv 似乎都只支持 Unix/Linux/MacOSX 。 身爲極客就註定不能用 Windows 麼？（或許是的……）。 剩下的問題就是 Ruby 和 Python 兩大陣營的對立問題了。我不熟悉 Markdown ， 相對來說比較喜歡 ReST 。 似乎無論哪邊都要 依賴 Pygments 作爲代碼着色器，那麼其實 Rubyist 也至少需要安裝 Python 。 我傾向於不依賴任何 Ruby 組件，最好沒有 C 擴展 的純 Python 實現。 於是我開始在 Github 上找 Python 的靜態博客引擎。 Flask 的作者 mitsuhiko 寫的 rstblog 看起來不錯，不過似乎沒有多少人在用。 Hyde 似乎很完善，不過默認的標記語言是 MarkDown ， 又依賴於幾個 Ruby 組建，而且官方網站的設計實在太前衛。 最終我看到了 Pelican 。 [1] 比如 Python 2.x 與 3.x 之間看似難以跨越的鴻溝，以及 PyPy 、 CPython 、 Stackless 、 Cython 等各個實現之間的微妙差別。 [2] 是的，我們有 easy_install ，我們有 pip ， 不過這些都是包管理器，都是裝好特定的Python實現之後的事情。 Python實現本身還不需要包管理器來管理。 Python 的版本問題基本上也只需要 2to3.py 和 3to2.py 這樣的輕量級轉換器就可以了，你不需要爲了安裝多個軟件而在硬盤裏留下多個不同版本的 Python 。 如果爲了引用的穩定性，你可以用 virtualenv ，不過這又是另一回事情了。 那麼就 Pelican 吧 對我而言， Pelican 相比於 Octopress 有幾個好處： 純 Python 實現。 這意味着我可以換用任何 Python 解釋器而不必擔心兼容性問題。比如我就換成了 PyPy 。 多語言支持。因爲 Pelican 的作者似乎是個法國人。不過這個似乎大部分人不需要…… 我是想儘量把一篇博客寫成三種語言作爲鍛鍊吧。 ReST 。這樣我就可以用 Leo 的 @auto-rst 直接寫 ReST了。簡單方便快捷有效。 不過似乎 Pelican 的關注度不如 Octopress 那麼高，現在一些部分還有細微的問題： pelican-import 從 WordPress 導入的時候對中文、日文的支持似乎很成問題。 日期格式、時區、字符集、和多語言功能的結合度還不夠。 我在嘗試改善它。 模板還不夠豐富。 插件也不夠多…… 希望這麼優秀的工具能夠受到更多關注，以上這些問題都是增加關注度之後很快就能解決的問題。 我的設置 settings.py 安裝 Pelican 很容易，一句話就夠了： $ pip install pelican 然後把文章寫成ReST的格式，放在`pages`文件夾裏面。(重新)生成只要： $ pelican -s settings.py 上傳到 Github: $ git commit -am \"Commit message\" $ git push 就這麼簡單。附上我的配置文件： # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , '%a, %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a' ), 'jp' :( 'jpn' , '%Y/%m/ %d (%a)' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","title":"嘗試一下 Pelican"},{"url":"//farseerfc.me/about-my-blogs.html","text":"從 farseerfc.wordpress.com 導入 很久沒有寫過blog或者之類的東西了。這邊一直荒廢着。 由於國內被牆的原因，另一個wordpress： http://fchome.sinaapp.com/ 應該會同步更新這裏的內容。 抽空寫點什麼吧。","tags":"import","title":"關於我的Blogs"},{"url":"//farseerfc.me/if-we-do-this-work.html","text":"導入自 renren From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf 如果這就是我至今在Xen4.0上得不到ACPI 3.0的完善支持的原因，那麼我詛咒Bill Gates！","tags":"import","title":"\"…if we do this work … \" --Bill Gates"},{"url":"//farseerfc.me/zz-introducing-scholarzhang.html","text":"從 farseerfc.wordpress.com 導入 好神奇的想法，先存着，以後慢慢研究 原文： http://blog.youxu.info/2010/03/14/west- chamber/ 待月西廂下，迎風戶半開。隔牆花影動，疑是玉人來。 最近推上最流行的一個關鍵詞是\"西廂計劃\", 這個計劃名字取得很浪漫，客戶端叫做張生，對，就是西廂記裏面那個翻牆去見崔鶯鶯小姐的張生；顯然，服務器端必然叫做崔鶯鶯。客戶端的張生是最重要的部件，可以不依賴於服務端工作。因爲西廂計劃的作者只是簡要的介紹了一下原理，其他報道又語焉不詳，我當時就覺得很好奇，花了昨天一個晚上詳細讀了一下源代碼，終於知道怎麼回事了，覺得原理非常漂亮，所以寫篇文章介紹總結一下。 先說大方向。大家都知道，連接被重置的本質，是因爲收到了破壞連接的一個 TCP Reset 包。以前劍橋大學有人實驗過，客戶端和服務器都忽略 Reset, 則通信可以不受影響。但是這個方法其實只有理論價值，因爲絕大多數服務器都不可能忽略 Reset 的 (比如 Linux, 需要 root 權限配置iptables, 而且這本身也把正常的 Reset 給忽略了)。只要服務器不忽略 Reset, 客戶端再怎麼弄都沒用，因爲服務器會停止發送數據，Reset 這條連接。所以，很多報道說西廂計劃是忽略 Reset, 我從源代碼來看應該不是這樣。在我看來，西廂計劃是利用了牆的一個可能的弱點–牆只在連接發起的時候把一個 TCP 連接加入監聽序列，如果牆認爲這個連接終止了，就會從監聽序列中去掉這條記錄，這樣，這條連接上後續的包就不會被監聽。西廂計劃就是讓牆\"認爲\"這個連接終止的一個絕妙的方法。只要牆認爲這個連接兩端都是死老虎，牆就不會觸發關鍵詞檢測，其後所有的數據，都不存在連接被重置的問題了。 如何讓一個連接置之死地而後生，就是西廂計劃那幫黑客神奇的地方了。這也不是一日之功。 首先，這幫牛人發現，牆的是一個入侵檢測系統，把含有關鍵字的包當成一種\"入侵\"來對待。採取這種設計有很多好處，但缺點是入侵檢測系統可能具有的問題，牆都可能有。西廂計劃主頁上那篇著名的論文就是講這些七七八八的漏洞的。可以說處理這些七七八八的漏洞是非常困難的，迫使牆的設計者\"拆東牆，補西牆\"。這樣補來補去，外表看起來好像很牛逼的牆，其實有很多本質上無法簡單修補的漏洞，其中有一個致命的，就是 TCP 連接狀態的判定問題。 出於入侵檢測系統這種設計的侷限，牆沒有，也沒辦法準確判定一條 TCP 連接的狀態，而只是根據兩邊收到的數據來\"推測\"連接的狀態。而所有的關鍵詞檢測功能，都是基於\"連接還活着\"的這個推測的結果的。因爲牆的規則是在連接發起的時候開始對這條連接的檢測，在連接終止的時候停止對這條連接的檢測，所以，一旦對連接的狀態推測錯誤，把還活着的連接當成已經關閉的連接，牆就會放棄對這條連接上隨後所有的包的檢測，他們都會都透明的穿過牆的入侵檢測。 上面只是想法，具體到 TCP 協議實現這一層，就要只迷惑牆，還不能觸及我要通信的服務器。最理想的情況下，在任何有效通信之前，就能讓牆出現錯誤判斷，這些，就需要對 TCP 協議有深刻理解了。西廂計劃的那幫黑客，居然真的去讀 TCP 幾百頁的 RFC，還居然就發現了方法（這裏我假設讀者都知道 TCP 的三次握手過程和序列號每次加一的規則）。 我們都知道，三次握手的時候，在收到服務器的 SYN/ACK 的時候，客戶端如果發送 ACK 並且序列號+1 就算建立連接了，但是客戶端如果發送一個序列號沒 +1 的 FIN （表示連接終止，但是服務器知道，這時候連接還沒建立呢， FIN 這個包狀態是錯的，加上序列號也是錯的，服務器自己一判斷，就知道這個包是壞包，按照標準協議，服務器隨手丟棄了這個包）, 但這個包，過牆的時候，在牆看來，是表示連接終止的(牆是 ma de in china, 是比較山寨的，不維護連接狀態，並且，牆並沒有記下剛纔服務器出去的 SYN/ACK 的序列號，所以牆不知道序列號錯了）。所以，牆很高興的理解爲連接終止，舒了一口氣去重置其他連接了， 而這個連接，就成了殭屍，牆不管你客戶端了，而這時候，好戲纔剛剛開始。 事實上，牆是雙向檢測的（或者說對每個包都檢測的），因此，對服務器和客戶端實現相同的對待方法，所以，牆不管客戶端還不行，假如服務端有關鍵詞傳給客戶端，牆還是有可能要發飆的（這裏說有可能，因爲我也不知道）。所以，最好的辦法就是，讓服務端也給牆一個終止連接的標誌就好了。可是這個說起來簡單，做起來難，怎麼能讓不受自己控制的服務器發一個自己想要的包呢？ 西廂計劃的那幫黑客，再次去讀幾百頁的 RFC, 令人驚訝的發現，他們居然在 RFC 上發現了一個可以用的特性。我們上面說了，三次握手的時候，在收到 SYN/ACK 後，客戶端要給服務器發送一個序列號+1 的ACK，可是，假如我不+1呢，直接發 ACK 包給服務器。 牆已經認爲你客戶端是死老虎了，不理你了，不知道你搞什麼飛機，讓這個 ACK 過了。可是服務器一看，不對啊，你給我的不是我期待的那個序列號， RFC 上說了，TCP 包如果序列號錯了的話，就回復一個 Reset. 所以，服務器就回復了一個 Reset。這個 Reset 過牆的時候，牆一看樂了，服務器也終止連接了，好吧，兩邊都是死老虎了，我就不監聽這條連接了。而至於客戶端，這個服務器過來的 Reset 非常好識別，忽略就是。隨後，客戶端開始正確的發送 ACK, 至此，三次握手成功，真正的好戲開始，而牆則認爲客戶端和服務器都是死老虎，直接放過。所以，張生就這樣透明的過了牆。 至於過牆以後所有的事情，《西廂記》裏面都有記載，各位讀者自行買書學習。 現在的西廂計劃客戶端，即\"張生\"模塊的防連接重置的原理就是這樣，服務器端，即鶯鶯模塊的實現也是類似的。防DNS那個，不懂 DNS 協議，所以看不懂。我猜想，因爲開發人員都是黑客，所以自然喜歡用最經得起折騰和高度定製的 Linux 開發。 現在看西廂計劃的實現，因爲依賴於 Linux 內核模塊 netfilter, 在 Linux 上如魚得水，但往其他平臺的移植可能是個亟待解決的問題。 我覺得，在其他平臺上，可以通過 libpcap 和 libnet ，在用戶態實現相同的功能，就是有點麻煩而已，有興趣的懂網絡的可以照西廂計劃原理，在家自行做出此功能；當然，全中國人民都用 Linux 最好 :) PS 1: 據說是西廂計劃一個作者畫的原理圖： http://img.ly/DIi PS 2: 我對 TCP 的理解僅限於課本，如果上面的對技術的理解有錯，請大家指出。 PS 3: 有些漏洞，可能是設計上本質缺陷，不是那麼容易修復的。 PS 4: 除了最後一個圖，本文沒有其他相關鏈接，如需相關資料，自行Google。","tags":"import","title":"[zz]\"西廂計劃\"原理小解"},{"url":"//farseerfc.me/sine-cpu.html","text":"導入自 renren 據說是一道微軟的面試題。如題，寫程序，讓Windows的任務管理器中的性能監視器呈現正弦曲線。 潛心鑽研良久，得代碼：（java） public class sincpu { private static final int cycle = 1024 , tick = 256 ; public static void main ( String [] args ) throws InterruptedException { for ( int i = 0 ;; i ++){ work ( calcNextSleep ( i % cycle )); sleep ( tick - calcNextSleep ( i % cycle )); } } private static long calcNextSleep ( long i ){ return ( int )( Math . sin (( double ) i * 2 * Math . PI / cycle ) * tick + tick ) / 2 ; } private static void sleep ( long sleepTime ) throws InterruptedException { if ( sleepTime < 2 ) Thread . yield (); else Thread . sleep ( sleepTime ); } private static void work ( long period ) { long start = System . currentTimeMillis (); for (;;){ Math . sin ( 1 ); if ( System . currentTimeMillis () - start >= period ) break ; } } } 多核CPU上測試時要注意關掉一個CPU：","tags":"import","title":"寫程序讓CPU佔用率保持正弦函數"},{"url":"//farseerfc.me/some-thought-on-creationism.html","text":"導入自 renren 看到陳驫同學很有感想的一篇神創論與命運日誌，覺得近日很久沒有看到這樣的評論了。想說幾句自己的觀點。 首先我認爲，神創論與宿命論沒有多少關聯，甚至進化論者相較於神創論者更容易接受宿命論的觀點。因爲神創論主張意志的存在，人所具有的個體意志與神的意志，因此在神創論者的眼中事件的結果是可以通過意志來改變的，亦即如果我從物理樓11樓跳下，那麼我就可以改變自己死亡時間的宿命。上帝的意志同樣可以左右事件的結果，也就是所謂的宿命不復存在。而進化論者不承認意志獨立於物質世界的存在，你我的思考、行爲，都受到物理學法則諸如量子力學的約束，這就引出了北大物理系教授的那句\"宇宙中的一切都是可以計算的\"，亦即宿命論。如我我選擇現在從物理樓上跳下，我這一行爲並不是處於個人的獨立意志，乃是想證明這一點，亦即我跳樓這一舉動是有其背後的動機與原因的，就如同計算機的輸入必然導致了輸出，宿命的必然終結於此。 其次，關於事件的複雜度所導致的隨機化，在大量混沌隨機中也存在着如統計學和隨機分形學這樣的規律，並不是否認宿命的充分理由。 關於神創論的合理性問題。我認爲是否相信神的存在只是一個boolean二值問題，它爲true爲false本身並不重要，重要的是確定它的取值之後得到的推論與結果。如果否認神的存在，如現代數學這樣的完美又何以存在，進化論者的解釋是事物最終會向着更好更高級的方向發展，產生現代數學乃至現代科學是發展的必然。而這種論調顯然有悖於物理中以熱力學第二定律爲首的，預言事物會隨時間推演愈發混亂的論斷。更進一步，甚至整個人類、整個生物系統的存在都是有悖於熱力學推論的現象，是某種理論只能以\"小概率事件\"解釋的現象。 神創論的核心觀點之一，是神的唯一存在性，按照鄒恆明的比喻，這就如同數學中集閤中元素的的唯一性一般至關重要。數學乃至近代科學的發展，其起源在於這種對神性的探求，而不僅僅是好奇心就可以解釋的。反觀東方文化中數學的發展，開始時領先於西方科學千餘每年，但是始終作爲一種craft-oriented的實用主義學科。可以說沒有了神的唯一性支持，人們就不能確信自己能找到這樣一種完美高效的學科，只能在實用的基礎上發展其基礎算數。可以想象，沒有神的完美與唯一性，數學必將發展成現代化學或者微軟軟件這樣，龐大而充滿特例，到處都是修補與查表，怎麼會像現在的完美、簡潔與和諧。 神創論者並不是將難題推與\"神\"然後放任不管，他們相信神是最爲理智的存在，創人時人同樣得到了神的智慧和理智，也就是神可以用人的理智來理解。 引用牛頓《自然哲學的數學原理》中終章的話\"太陽、恆星、行星的這個極精緻的結構不可能存在，除非通過一個有理智的和有權能的存在的設計和主宰……他不是作爲宇宙的靈魂，而是作爲一切的主宰而統治所有……\" 以上…… (發現最近的哲理思維果然慢了不少，寫作思緒也一片混亂&#94;_&#94;)","tags":"import","title":"關於神創論的一些見解"},{"url":"//farseerfc.me/9-thoughts-about-oop-from-wrongly-insert-memory-stick.html","text":"從 farseerfc.wordpress.com 導入 故障描述: MMC Memory Stick Duo記憶棒未經Adapter適配器，直接插入SD Reader，致使MMC卡入SD Reader中。 棧展開： 某日下午，無課。 忙於數分作業，想查詢用手機拍攝的板書照片。 取出手機中的MMC。 未經裝配Adapter，直接插入SD Reader。 (A runtime exception was thrown.) 嘗試翻轉筆記本機身，倒出MMC，未果。(rethrow) 嘗試用手指甲取出，未果。(rethrow) 考慮到有\"推入反彈\"機制，嘗試將MMC推入更深，反彈機制由於類型不匹配而失效，未果。(rethrow) (The exception spread across the border of the model.) 電腦維修技師接手(catch) 技師未能發現問題所在，由我解說原委。 (Because the exception lose the information, RTTI was asked to recall the information) 技師發現問題，嘗試用鑷子鑷出MMC，未果。 技師開解機箱(expose the data structure) 技師製作鉤子，勾出MMC(hooker link to the structure) 取出MMC，故障解除 故障總結 1.接收到沒有完全瞭解、或沒有適當工具解決的exception時，不要嘗試用不成熟的技術解決，應儘快尋求能解決它的代碼。否則，被反覆rethrow的exception，尤其是通過模塊邊界的exception，有可能由subclass退化爲superclass，並因此而喪失一些信息。儘量不要讓exception丟失信息，必要時，通過RTTI機制尋回信息。 2.超負荷運轉，多線程執行，這種種複雜性都有可能導致錯誤，應避免。無論你有多麼信任你的代碼或能力。 3.在設計class的interface時，相匹配的interface應該滿足is-a的關係。因此，任何能插入SD Reader的object，即任何實現了SD interface的object，都應該is-a SD card。這次故障中，interface接受了MMC，但MMC不是SD。即使這種情況下throw an exception，都不能使事態緩和。能提供compile-time error時，儘量讓錯誤以compile-time error的形式展現，並在事先解決。類型匹配問題是應該能在事先解決的問題。 4.Design patterns中的Adapter pattern應該只是迫不得已情況之下的解決方案。只有當你無權改變現狀時，才能使用Adapter。如果能改變現狀，應該改變設計以符合interface。 5.因爲上條，所有相似功能的對象應具有相同的interface，不同的interface是本次故障的根源所在。 6.特殊情況下，破壞封裝機制並expose the data structure是必要的，應該有方法支持這種做法。C的指針和C#的Reflection技術都以不同的方式支持這種做法。其他的一些語言機制，比如serializing(序列化)或streaming(流化)，也可以以某種方式間接支持這一做法。當然，機制還應避免這種做法被濫用。 7.相反功能具有相同操作的設計，容易造成使用的混亂，應適當避免。比如SD Reader的推入反彈設計，即插入和彈出使用同一個向裏推的操作的設計。同樣的設計還包括，C++中的setNewHandle使用同一個函數，同時設置和返回handle。以及有些書中提倡的，使用同名函數重載的方式，實現setter/getter的設計。 8.特殊工具(hooker)對於解決特定問題，通常比手工解決有效。不要嫌麻煩而不願意構造特殊工具。 9.棧語義，即FILO順序，總在不知不覺中影響我們。違反了FILO順序的操作極易造成混亂。本故障發生時正確的處理順序爲： 裝配Adapter 插入SD Reader 讀取數據 停用設備 拔出SD Reader 拆解Adapter 本次故障的原因就是違反了FILO順序，違反了棧語義。","tags":"import","title":"由記憶棒誤差故障引發的關於面向對象設計的九點思考"},{"url":"//farseerfc.me/program-development-in-java-preface.html","text":"從 farseerfc.wordpress.com 導入 程序開發原理 ——抽象、規格與面向對象設計 Barbara Liskov 、John Guttag 著 楊嘉晨 等譯 關於翻譯風格： 多年來閱讀計算機類的著作及譯作，感覺總體的困難在於一大堆沒有標準譯名的技術術語。由於通行於工業界和學術界的還是英文原名和術語，我決定保留大量的英文術語。這樣的翻譯風格借鑑於臺灣著名的譯者和作者侯捷先生。對於譯與不譯的權衡，主要考慮閱讀的流暢，以及讀者的理解能力，或許難免帶有一些主觀色彩。 前言 Preface 構建產品級質量的程序——可以在很長一段時間內使用的程序——衆所周知是極其困難的。本書的目標就是改善程序員解決這項任務的效率。我希望讀者在閱讀本書之後成爲一名好程序員。我相信本書的成功在於改善編程技巧，因爲我的學生告訴我這已經發生在他們身上。 怎麼纔算是一名好程序員？是產生整個程序產品的效率。關鍵是要在每一階段減少浪費掉的努力。解決的方法包括：在開始編寫代碼之前就仔細考慮你的實現方案，通過未雨綢繆的方法來編寫代碼，使用嚴格的測試在早期發現錯誤，以及仔細注意模塊化編程，這樣當錯誤出現時，只需要改動極少數代碼就可以修正整個程序。本書涉及所有這些領域的技術。 模塊化編程(Modularity)是編寫好程序的關鍵。把程序分解成許多小模塊，每一個模塊通過良好定義的狹窄接口和別的模塊交互作用(interact)。有了模塊化，可以修正一部分程序中的錯誤而不考慮程序的其他部分，而且可以僅僅理解一部分程序而不必理解整個程序。沒有模塊化，程序是一大堆有着錯綜複雜的相互關係的部分的拼湊。很難去領悟和修改這樣一個程序，同樣也很難讓它正常工作。 因此本書的重點在於創建模塊化的程序：怎樣把程序組織成一系列精心挑選的模塊。本書認爲模塊化就是抽象(abstraction)。每一個模塊意味着一個抽象，比如說指引一系列文檔中的關鍵字的目錄，或者在文檔中使用目錄來查找匹配某個問題的文檔的過程。着重強調面向對象編程思想——在程序中使用數據抽象和對象的思想。 這本書使用Java作爲它的編程示例的語言。我們沒有假定讀者已經熟悉Java。儘管可能沒什麼價值，但是本書中的思想是語言無關的，並且可以在任何語言的編程中使用。 怎樣使用這本書？ How Can the Book Be Used 本書《程序開發原理》有兩種使用方法。其一是作爲課本教材，講述如何用面向對象的方法來設計和實現複雜系統；其二是編程專家使用，幫助他們改善編程技能，增進他們的關於模塊化和Object-Oriented(面向對象)設計的知識。 作爲教材使用時，本書一般作爲第二或第三門程序設計課程。我們已經在MIT使用本書很多年，給大一大二的本科生教授第二門編程課。在這一階段，學生們已經知道怎樣編寫小程序。課程在兩方面利用這一點：讓學生更仔細地思考小程序，以及教他們如何利用小程序作爲組件構建大型程序。這本書也可以在專業（如軟件工程）後期教學中使用。 建立在本書基礎上的課程適合於所有計算機科學專業。儘管許多學生可能永遠不會成爲真正的大型程序的設計師，他們可以在開發部門工作，在那兒他們負責設計和實現能與整個結構耦合的子系統。模塊化設計的子系統是這種任務中心，這對那些從事大型程序設計任務的人來說也同樣重要。 這本書講什麼？What Is This Book About 通觀全篇三分之二的書致力於討論在構建獨立的程序模塊時產生的問題，剩下的部分討論怎樣運用這些模塊構建大型程序。 程序模塊Program Modules 這一部分的書集中討論抽象機制(abstraction mechanism)。它討論procedure(子程序)和exception(異常)，數據抽象，遍歷(iteration)抽象，數據抽象系列(family)以及多態(polymorphic)抽象。 在對抽象的討論中，三個步驟是重要的。首先是決定被抽象的東西到底是什麼：它提供給它的用戶哪些行爲。創造抽象是設計的關鍵，因此本書討論如何在衆多選擇中挑選，以及怎樣才能創造出好的抽象。 第二步是通過爲一個抽象制定一個規格(specification)來獲取它的意義。如果沒有一些描述，一個抽象就會含糊不清，而變得沒有使用價值。specification則提供了需要的描述。本書定義了一種specification的格式，討論了一份好的specification應有的屬性，並且提供了許多示例。 第三步是實現抽象。本書討論怎樣設計一份實現，以及在簡潔性和執行性能之間怎樣權衡利弊。書中強調封裝(encapsulation)的重要性以及在一份實現中履行規格中定義的行爲的重要性。書中同樣提供一些技術——尤其是不變式斷言(representation invariant)和抽象函數(abstraction function)——來幫助讀者理解代碼和它的原因。不變式斷言和抽象函數都實現到儘可能的程度，這對於除錯和調試很有用。 關於類型層次(type hierarchy)的材料注重討論使用它作爲抽象的技術——一種把相關聯的一組數據抽象歸入同一系列的技術。這裏很重要的一點是，是否應當將一個類型作爲另一個類型的子類。本書定義了替換原則——通過比較子類和父類的specification，來決定是否建立子類關係的方法 [1] 。 本書同樣涉及除錯和調試。書中討論怎樣得到足夠數量的測試情況，來準備通過黑箱和白箱測試，它同樣強調了複查(regression)測試的重要性。 編寫大型程序 Programming in the Large 本書的其後部分講解怎樣用模塊化的方法設計和實現大型程序。它建立在前文有關abstraction和specification的材料的基礎之上。 編寫大型程序涵蓋四個主要議題。首先講解需求分析——怎樣才能領悟程序中需要什麼。本書討論怎樣實施需求分析，也討論書寫產生的需求規格的方式，通過使用一種描述程序的抽象階段的數據模型。使用這種模型將產生一份更爲正式的specification，同時它也使需求檢查更加嚴格，這樣可以更好的領悟需求。 編寫大型程序的第二項議題是程序設計，這通常是一個循序漸進的過程。設計過程圍繞構建有用的抽象來組織，這些抽象作爲整個程序之中理想的構建組建。這些抽象在設計時被仔細的編寫規格，這樣當程序實現時，那些實現抽象的模塊可以獨立地開發。這種設計使用設計筆記編寫文檔，包括描述整個程序結構的模塊間依賴性的圖示。 第三項議題是實現和測試。本書討論了前置設計分析對於實現的必要性，以及怎樣進行設計複審。它同樣討論了設計和實現的順序。這一部分比較了自頂而下與自底而上的組織方式，討論如何使用驅動程序和佔位程序 [2] (stub)，並且強調了制定一個事先的順序策略的必要性，以滿足開發組織和客戶的需求。 本書以一章設計模式(design pattern)結束。一些模式在前面的章節介紹過，比如遍歷抽象是算法的主要組建。最後的章節討論前文中沒有涉及到的模式。希望它作爲這一教材的介紹。有興趣的讀者可以繼續閱讀其它書中更完善的討論 [3] 。 [1] 譯註：如果子類的specification包括了所有父類的specification，就是說父類的要求也是子類的要求，或者子類的要求更爲嚴格，那麼可以建立父子關係。而替換原則的說法是，對於具有父子關係的類，任何需要一個父類對象的地方，都可以替換爲一個子類對象。 [2] 譯註：在測試某一組建時，由於其餘組建還未實現，這一組建與其餘組建的接口銜接部分無法工作。此時可以針對這一組建編寫其餘組建的佔位程序(stub)，預留出接口的銜接代碼。佔位代碼通常不做任何有價值的事情，只報告組建的銜接部位工作正常。 [3] 譯註：作者指的是設計模式的開山之作——《Design Patterns—Elements of Reusable Object-Oriented Software》,作者爲設計模式界著名的\"四人幫\"GoF(Gang of Four)。此書詳盡討論了三大類共23個廣泛使用的設計模式的適用範圍、依存關係、實現細節以及已有的應用領域等問題。書中以C++和Smalltalk爲示例語言，不過書中所涉及的模式適用於所有面向對象的語言。","tags":"import","title":"Program Development in Java Preface"},{"url":"//farseerfc.me/c-tricks-3-2-label-goto-and-implementation-of-switch.html","text":"從 farseerfc.wordpress.com 導入 3.2 標號、goto，以及switch的實現 goto語句及標號(label)是最古老的C語言特性，也是最早被人們拋棄的語言特性之一。像彙編語言中的jmp指令一樣，goto語句可以跳轉到同一函數體中任何標號位置： void f() {int i=0; Loop: //A label ++i; if(i<10)goto Loop; //Jump to the label } 在原始而和諧的早期Fortran和Basic時代，我們沒有if then else，沒有for和while，甚至沒有函數的概念，一切控制結構都靠goto(帶條件的或無條件的)構件。軟件工程師將這樣的代碼稱作\"意大利麪條\"代碼。實踐證明這樣的代碼極容易造成混亂。 自從證明了結構化的程序可以做意大利麪條做到的任何事情，人們就開始不遺餘力地推廣結構化設計思想，將goto像猛獸一般囚禁在牢籠，標號也因此消失。 標號唯一散發餘熱的地方，是在switch中控制分支流程。 很多人不甚瞭解switch存在的意義，認爲它只是大型嵌套if then else結構的縮略形式，並且比if語句多了很多\"不合理\"的限制。如果你瞭解到switch在編譯器內部的實現機制，就不難理解強加在switch之上的諸多限制，比如case後只能跟一個編譯期整型常量，比如用break結束每一個case。首先看一個switch實例： switch (shape.getAngle()) { case 3: cout<<\"Triangle\";break; case 4: cout<<\"Square\";break; case 0:case1: cout<<\"Not a sharp!\";break; default: cout<<\"Polygon\"; } 任何程序員都可以寫出與之對應的if結構： int i= getAngle(shape); if (i==3) cout<<\"Triangle\"; else if(i==4) cout<<\"Square\"; else if(i==0||i==1) cout<<\"Not a sharp!\"; else cout<<\"Polygon\"; 看起來這兩段代碼在語義上是完全一樣的，不是麼？ 不！或許代碼的執行結果完全一樣，但是就執行效率而言，switch版本的更快！ 要了解爲什麼switch的更快，我們需要知道編譯器是怎樣生成switch的實現代碼的： 首先，保留switch之後由{}括起來的語具體，僅將其中case、default和break替換爲真正的標號： switch (getAngle(shape)) { _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 隨後，對於所有出現在case之後的常量，列出一張只有goto的跳轉表，其順序按case後的常量排列： goto _case_0; goto _case_1; goto _case_3; goto _case_4; 然後，計算case之後的常量與跳轉表地址之間的關係，如有需要，在跳轉表中插入空缺的項目： 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; //因爲沒有case 2，所以插入此項以條轉到default 100120: goto _case_3; 100125: goto _case_4; 假設一個goto語句佔用5個字節，那麼在本例中，goto的地址=case後的常量*5+100105 之後，生成跳轉代碼，在其餘條件下跳轉至default，在已知範圍內按照公式跳轉，全部的實現如下： { int i= getAngle(shape); if (i<0||i>=5)goto _default; i=i*5+100105; //按照得出的公式算出跳轉地址 goto i; //僞代碼，C中不允許跳轉到整數，但是彙編允許 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; 100120: goto _case_3; 100125: goto _case_4; _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 經過這樣處理整個switch結構，使得無論switch後的變量爲何值，都可以通過最多兩次跳轉到達目標代碼。相比之下if版本的代碼則採用線性的比較和跳轉，在case語句很多的情況下效率極低。 由此,我們也可以知道,爲什麼case後跟的一定是編譯期整型常數，因爲編譯器需要根據這個值製作跳轉表。我們可以明白爲什麼case與case之間應該用break分隔，因爲編譯器不改變switch語句體的結構，case其本身只是一個具有語義的標號而已，要想跳出switch，就必須用break語句。","tags":"import","title":"C++ Tricks 3.2 標號、goto，以及switch的實現"},{"url":"//farseerfc.me/c-tricks-3-1-lvalue-rvalue-constant.html","text":"從 farseerfc.wordpress.com 導入 3.1 左值右值與常量性(lvalue，rvalue & constant) 首先要搞清楚的是，什麼是左值，什麼是右值。這裏給出左值右值的定義： 1、左值是可以出現在等號(=)左邊的值，右值是隻能出現在等號右邊的值。 2、左值是可讀可寫的值，右值是隻讀的值。 3、左值有地址，右值沒有地址。 根據左值右值的第二定義，值的左右性就是值的常量性——常量是右值，非常量是左值。比如： 1=1;//Error 這個複製操作在C++中是語法錯誤，MSVC給出的錯誤提示爲\"error C2106: '=' : left operand must be l-value\"，就是說'='的左操作數必須是一個左值，而字面常數1是一個右值。可見，嚴格的區分左值右值可以從語法分析的角度找出程序的邏輯錯誤。 根據第二定義，一個左值也是一個右值，因爲左值也可讀，而一個右值不是一個左值，因爲右值不可寫。 通常情況下，聲明的變量是一個左值，除非你指定const將它變成一個右值： int lv=1; const int rv=lv; 由於右值的值在程序執行期間不能改變，所以必須用另一個右值初始化它。 一個普通變量只能用右值初始化，如果你想傳遞左值，必須聲明一個引用或一個指針： int & ref=lv;//用引用傳遞左值 int * plv=&lv;//傳遞指針以間接傳遞左值 必須用左值初始化引用，然而，可以用右值初始化常量引用： int & r1=1; //Error! const int & r2=1; //OK 這實際上相當於： int _r2=1; const int & r2=_r2; 這樣的寫法在函數體內沒什麼作用，但是在傳遞函數參數時，它可以避免潛在的(傳遞左值時的)複製操作，同時又可以接受右值。 通常情況下，函數的參數和返回值都只傳回右值，除非你明確的通過引用傳遞左值。 明確了左值與右值的區別，有助於我們寫函數時確定什麼時候應該有const，什麼時候不該有。比如，我們寫了一個代表數學中複數的類Complex： class Complex; 然後，我們寫針對Complex的運算符重載：operator+和operator=。問題在於，參數和返回值應該是什麼類型，可選類型有四種： Complex、const Complex、Complex&、const Complex&。 對於operator+，我們不會改變參數的值，所以可以通過const Complex&傳遞參數。至於返回值類型，由於int類型的加法返回右值，所以根據Do as the ints do的原則，返回值類型爲const Complex： const Complex operator+(const Complex&,const Complex&); 對於operator=，同樣要思考這些問題。我們寫入第一個參數，所以第一個參數爲Complex&，我們只讀取第二個參數，所以第二個參數爲const Complex&。至於返回值，還是Do as the ints do。int的賦值返回左值，不信你可以試一試： int i; (i=1)=2; 雖然比較傻，先將i賦爲1，再將其改爲2，但是這是被C++語法支持的做法，我們就理應遵守。所以返回第一個參數的左值： Complex& operator=(Complex&,const Complex&); const是C++引入的語言特性，也被ANSI C99借鑑，在經典版本的C語言中是沒有的。關於const的歷史，有幾點值得玩味。最初Bjarne Stroustrup引入const時，可寫性是和可讀性分開的。那時使用關鍵字readonly和writeonly。這個特點被首先提交到C的ANSI標準化委員會(當時還沒有C++標準化的計劃)，但是ANSI C標準只接受了readonly的概念，並將其命名爲const。隨後，有人發現在多線程同步的環境下，有些變量的值會在編譯器的預料之外改變，爲了防止過度優化破壞這些變量，C++又引入關鍵字violate。從語義特點來看，violate是const的反義詞，因爲const表示不會變的量，而violate表示會不按照預期自行變化的量。從語法特點而言，violate與const是極爲相似的，適用於const的一切語法規則同樣適用於violate。 值的常量性可以被劃分爲兩種：編譯期常量和運行期常量。C++語法並沒有嚴格區分這兩種常量，導致了少許混亂： const int i=5;const int * pi=&i; const_cast<int&>i=1;//對於運行期常量，在需要時可以去除它的常量性 int a[i];//對於編譯期常量，可以用它來指定數組大小 cout<<i<<sizeof(a)/sizeof(a[0])<<*pi; 這種將編譯期與運行期常量的特性混用的方法，勢必導致語義的混亂。數組a的大小最終是5，因爲採用了i的編譯期值，而不管i在運行期是否被改變了值。最後一句代碼將（有可能）輸出551，第一個i的值作爲一種優化在編譯期綁定，第二個值標明瞭a的大小，第三個值通過指針顯示地輸出i的運行期真實值。 在C++的近親C#的語法中，這兩種常量被嚴格地區分開：編譯期常量由const指定，只能是內建類型變量；運行期常量由readonly指定，可以是任何類型。永遠不會改變的常量，如圓周率pi的值，應該用const聲明；而其它有可能改變的常量，皆由readonly聲明。 C++中的const的特點更傾向於C#中的readonly，雖然語法上允許使用const的編譯期常量性，但正如上文所展示的，這容易造成混亂。爲了得到C#中const的語義，在C++中，我們不必迴歸惡魔#define的懷抱，可以使用所謂\"匿名enum技巧\"。當匿名聲明一個enum類型時，其中的枚舉值就是一個int類型的編譯期常量，比如： enum{Size=5;}; int a[Size]; 這種使用匿名enum來聲明編譯期常量的做法，被廣泛應用於STL、boost等模板庫的實現代碼中。","tags":"import","title":"C++ Tricks 3.1 左值右值與常量性(lvalue，rvalue & constant)"},{"url":"//farseerfc.me/c-tricks-2-2-i386-memory-layout.html","text":"從 farseerfc.wordpress.com 導入 2.2 I386平臺的內存佈局 衆所周知，I386是32位體系結構。因此對於絕大多數I386平臺的C++編譯器而言，sizeof(int)=sizeof(long)=sizeof(void*)=4。當然C++標準對此沒有任何保證，我們也不應該試圖編寫依賴於此的代碼。 32位指針的可尋址空間爲4GB。爲充分利用這麼大的尋址空間，也是爲了支持其它更先進的技術比如多任務技術或者動態鏈接庫技術，WinNT使用虛擬內存技術，給與每個應用程序全部4GB的內存空間。4GB的地址被一分爲二，前2GB供應用程序自己使用，後2GB由系統內核分配和管理。這2GB的內存地址，通常被劃分成3種內存區使用： 1 代碼及靜態數據區 由代碼加載器從動態鏈接庫鏡像(通常是exe或dll文件)加載，通常定位到鏡像文件中指定的基址開始的內存區。如果基址所在內存已被佔用，動態連接器會將代碼或數據重定向到其它可用地址。 在C++中，靜態數據包括：名字空間(namespace)和全局(global)對象、函數的static對象、類的static數據成員。這些靜態數據由編譯器分配地址(但可能被重定向)，由靜態連接器寫入代碼文件(通常是exe或dll)的靜態數據區段。所以標準說，這些靜態數據在編譯期就已經具有地址。 2 棧(Stack) 棧是最常用的動態數據存儲區，所有函數的non-static對象和函數參數都在程序運行期在棧上分配內存。在數據結構中，術語\"棧(Stack)\"意指先進後出(FILO，First In Last Out)，與\"隊列(Queue)\"所指的FIFO相對。相對於基於堆的對象分配技術，默認使用棧的對象分配有兩點優勢： 一、棧的FILO與人的思維方式相同 現實生活中有許多事例都使用FILO的方式，比如人們必須先提起話筒再撥打號碼，而後掛斷電話之後再放下話筒。使用FILO的棧，可以保證事物的銷燬順序以其誕生順序相反的順序進行，不會產生在掛斷電話之前就放下話筒的尷尬。 二、棧的分配管理僅需要兩個額外指針：棧頂(esp)和棧底(ebp)指針 從實現的技術層面而言，棧的管理比其它動態分配技術要簡單很多。I386平臺上的動態棧管理，僅需要棧頂和棧底兩個指針。這兩個指針的存儲顯然不能放置於棧中，置於靜態數據區又有損效率。I386平臺爲管理動態棧專門預留了兩個通用寄存器變量esp與ebp，分別代表棧頂(esp,Extended Stack Pointer)與棧底(Extended Bottom Pointer)指針。其中的extended代表它們是32位指針，以區分16位的sp和bp寄存器。 棧是動態存儲區的特點，表明它的內存佔用將隨着程序的運行而變化。I386平臺上WinNT將應用程序的棧置於程序空間，向下增長。程序初始化時，由操作系統將esp指向系統分配的棧空間的頂部。當程序需要在棧上分配變量時，就將esp減去變量所需字節數，這被稱作\"壓棧(Push)\"；隨後又要銷燬變量時，就將esp加上變量所需字節數，這被稱作\"彈出(Pop)\"。esp與ebp兩者之間所夾的空間，就是當前函數正在使用的棧空間。由於棧向下增長，esp(棧頂)的值總是小於ebp(棧底)的值，新分配的變量地址總是小於舊變量的地址。 3 堆(Heap)和自由存儲區 棧中的變量對於分配與釋放的順序有特定要求，這在一定程度上限制了棧的適用範圍。面向對象(OO，Object Oriented)的程序設計思想也要求能自由地控制變量的分配與銷燬。由此，現代操作系統都提供了被稱作\"堆(Heap)\"的自由存儲區，以允許由程序員控制的對象創建和銷燬過程。C標準庫函數malloc和free則是對操作系統提供的堆操作的封裝。C++提供的自由存儲區運算符new和delete則通常是malloc和free的又一層封裝。 操作系統經由malloc和free控制對堆的訪問。堆的存儲管理技術各不相同，簡單的使用雙鏈表管理，複雜的可以比擬一個完整的文件系統。 由於額外的管理需求，使用系統提供的通用分配器在堆上分配和銷燬變量的代價，無論從空間角度還是效率角度而言，都比在棧上分配對象要高昂很多。對於sizeof上百的大型對象，這樣的高昂代價還是可以接受的，但是對於sizeof只有個位數的小對象，這樣的代價通常是一個數量級的差距。正因爲這個原因，STL不使用new和delete，轉而使用分配子(alllocor)分配對象。","tags":"import","title":"C++ Tricks 2.2 I386平臺的內存佈局"},{"url":"//farseerfc.me/c-tricks.html","text":"從 farseerfc.wordpress.com 導入 C++ Tricks By FarseerFc 從今天起，我再將在 Live Space 和 QQZone 同時發表一系列文章，暫定名爲\"C++Tricks\"。 本文旨在記錄和闡述一些本人學習C++時所得的心得、技巧。總體來看，本文涉及的內容是每一個C++程序員都應該知道的，但是很少見諸C++教材。希望對各位同仁學習C++有所幫助。 也可以通過QQ或MSN向我索要此文的DOC版或PDF版，會比網頁上的更新的快一點。 1 詞法問題(Lexical Problems) 1.1 條件運算符(?:) 1.2 逗號運算符(,)、邏輯運算符(&&,||)與運算符重載的陷阱 2 X86體系結構 2.1 X86概述 2.2 I386平臺的內存佈局 2.3 I386平臺C函數內部的棧分配 2.4 I386平臺C函數調用邊界的棧分配 2.5 I386平臺的邊界對齊(Align) 2.6 I386平臺C函數的可變參數表(Variable Arguments) 2.7 I386平臺的其它函數調用模型 3 過程式編程 3.1 左值右值與常量性(lvalue，rvalue & constant) 3.2 標號、goto，以及switch的實現","tags":"import","title":"C++ Tricks"},{"url":"//farseerfc.me/c-tricks-2-3-i386-stack-allocation-in-c-functions.html","text":"從 farseerfc.wordpress.com 導入 2.3 I386平臺C函數內部的棧分配 函數使用棧來保存局部變量，傳遞函數參數。進入函數時，函數在棧上爲函數中的變量統一預留棧空間，將esp減去相應字節數。當函數執行流程途徑變量聲明語句時，如有需要就調用相應構造函數將變量初始化。當執行流程即將離開聲明所在代碼塊時，以初始化的順序的相反順序逐一調用析構函數。當執行流程離開函數體時，將esp加上相應字節數，歸還棧空間。 爲了訪問函數變量，必須有方法定位每一個變量。變量相對於棧頂esp的位置在進入函數體時就已確定，但是由於esp會在函數執行期變動，所以將esp的值保存在ebp中，並事先將ebp的值壓棧。隨後，在函數體中通過ebp減去偏移量來訪問變量。以一個最簡單的函數爲例： void f() { int a=0; //a的地址被分配爲ebp-4 char c=1; //c的地址被分配爲ebp-8 } 產生的彙編代碼爲： push ebp ;將ebp壓棧 mov ebp,esp ;ebp=esp 用棧底備份棧頂指針 sub esp,8 ;esp-=8，爲a和c預留空間，包括邊界對齊 mov dword ptr[ebp-4],0 ;a=0 mov byte ptr[ebp-8],1 ;c=1 add esp,8 ;esp+=8，歸還a和c的空間 mov esp,ebp ;esp=ebp 從棧底恢復棧頂指針 pop ebp ;恢復ebp ret ;返回 相應的內存佈局是這樣： 09992:c=1 <-esp 09996:a=0 10000:舊ebp <-ebp 10004:…… 注:彙編中的pop、push、call、ret語句是棧操作指令，其功能可以用普通指令替換 push ebp相當於: add esp,4 mov dword ptr[esp],ebp pop ebp相當於： mov ebp,dword ptr[esp] sub esp,4 call fun_address相當於： push eip jmp fun_address ret相當於 add esp,4 jmp dword ptr[esp-4] 帶參數的ret ret 8相當於 add esp,12 jmp dword ptr[esp-4] 所有局部變量都在棧中由函數統一分配，形成了類似逆序數組的結構，可以通過指針逐一訪問。這一特點具有很多有趣性質，比如，考慮如下函數，找出其中的錯誤及其造成的結果： void f() { int i,a[10]; for(i=0;i<=10;++i)a[i]=0;/An error occurs here! } 這個函數中包含的錯誤，即使是C++新手也很容易發現，這是老生常談的越界訪問問題。但是這個錯誤造成的結果，是很多人沒有想到的。這次的越界訪問，並不會像很多新手預料的那樣造成一個\"非法操作\"消息，也不會像很多老手估計的那樣會默不作聲，而是導致一個，呃，死循環！ 錯誤的本質顯而易見，我們訪問了a[10]，但是a[10]並不存在。C++標準對於越界訪問只是說\"未定義操作\"。我們知道，a[10]是數組a所在位置之後的一個位置，但問題是，是誰在這個位置上。是i! 根據前面的討論，i在數組a之前被聲明，所以在a之前分配在棧上。但是，I386上棧是向下增長的，所以，a的地址低於i的地址。其結果是在循環的最後，a[i]引用到了i自己！接下來的事情就不難預見了，a[i]，也就是i，被重置爲0，然後繼續循環的條件仍然成立……這個循環會一直繼續下去，直到在你的帳單上產生高額電費，直到耗光地球電能，直到太陽停止燃燒……呵呵，或者直到聰明的你把程序Kill了……","tags":"import","title":"C++ Tricks 2.3 I386平臺C函數內部的棧分配"},{"url":"//farseerfc.me/c-tricks-2-4-i386-stack-allocation-accross-function-invocation.html","text":"從 farseerfc.wordpress.com 導入 2.4 I386平臺C函數調用邊界的棧分配 當調用一個函數時，主調函數將參數以聲明中相反的順序壓棧，然後將當前的代碼執行指針(eip)壓棧，然後跳轉到被調函數的入口點。在被調函數中，通過將ebp加上一個偏移量來訪問函數參數，以聲明中的順序(即壓棧的相反順序)來確定參數偏移量。被調函數返回時，彈出主調函數壓在棧中的代碼執行指針，跳回主調函數。再由主調函數恢復到調用前的棧。 函數的返回值不同於函數參數，通過寄存器傳遞。如果返回值類型可以放入32位變量，比如int、short、char、指針等類型，通過eax寄存器傳遞。如果返回值類型是64位變量，如_int64，同過edx+eax傳遞，edx存儲高32位，eax存儲低32位。如果返回值是浮點類型，如float和double，通過專用的浮點數寄存器棧的棧頂返回。如果返回值類型是用戶自定義結構，或C++類類型，通過修改函數簽名，以引用型參數的形式傳回。 同樣以最簡單的函數爲例： void f(){ int i=g(1,2); } int g(int a,int b){ int c=a+b； return c; } 產生的彙編代碼如下： f: push ebp ;備份ebp mov ebp,esp ;建立棧底 sub esp,4 ;爲i分配空間 mov eax,2 ;準備參數b的值2 push eax ;將b壓棧 mov eax,1 ;準備參數a的值1 push eax ;將a壓棧 call g ;調用g add esp,8 ;將a和b一起彈出，恢復調用前的棧 mov dword ptr[ebp-4],eax ;將返回值保存進變量i mov esp,ebp ;恢復棧頂 pop ebp ;恢復棧底 g: push ebp ;備份ebp mov ebp,esp ;建立棧底 sub esp,4 ;爲局部變量c在棧中分配內存 mov eax,dword ptr[ebp+8] ;通過ebp間接讀取參數a的值 mov ebx,dword ptr[ebp+12] ;通過ebp間接讀取參數b的值 add eax,ebx ;將a和b的值相加，之和存在eax中 mov dword ptr[ebp-4],eax ;將和存入變量c mov eax,dword ptr[ebp-4] ;將c作爲返回值，代碼優化後會刪除此句 add esp,4 ;銷燬c的內存 mov esp,ebp ;恢復棧頂 pop ebp ;恢復棧底 ret ;返回函數f 棧的內存佈局如下： 100076:c <- g的esp 100080:f的ebp=100100 <- g的ebp 100084:f的eip 100088:a=1 100092:b=2 100096:i 100100:舊ebp <-f的ebp 100104:…… 注意在函數g的彙編代碼中，訪問函數的局部變量和訪問函數參數的區別。局部變量總是通過將ebp減去偏移量來訪問，函數參數總是通過將ebp加上偏移量來訪問。對於32位變量而言，第一個局部變量位於ebp-4，第二個位於ebp-8，以此類推，32位局部變量在棧中形成一個逆序數組；第一個函數參數位於ebp+8，第二個位於ebp+12，以此類推，32位函數參數在棧中形成一個正序數組。 由於函數返回值通過寄存器返回，不需要空間分配等操作，所以返回值的代價很低。基於這個原因，舊的C語法約定，不寫明返回值類型的函數，返回值類型爲int。這一規則與現行的C++語法相違背，因爲C++中，不寫明返回值類型的函數返回值類型爲void，表示不返回值。這種語法不兼容性是爲了加強C++的類型安全，但同時也帶來了一些問題。","tags":"import","title":"C++ Tricks 2.4 I386平臺C函數調用邊界的棧分配"},{"url":"//farseerfc.me/c-tricks-2-5-address-alignment.html","text":"從 farseerfc.wordpress.com 導入 2.5 I386平臺的邊界對齊(Align) 首先提問，既然I386上sizeof(int)==4、sizeof(char)==1，那麼如下結構(struct)A的sizeof是多少？ struct A{int i;char c;}; 答案是sizeof(A)==8……1+5=8？ 呵呵，這就是I386上的邊界對齊問題。我們知道，I386上有整整4GB的地址空間，不過並不是每一個字節上都可以放置任何東西的。由於內存總線帶寬等等的技術原因，很多體系結構都要求內存中的變量被放置於某一個邊界的地址上。如果違反這個要求，重則導致停機出錯，輕則減慢運行速度。對於I386平臺而言，類型爲T的變量必須放置在sizeof(T)的整數倍的地址上，char可以隨便放置，short必須放在2的整數倍的地址上，int必須放在4的整數倍的地址上，double必須放在8的整數倍的地址上。如果違反邊界對齊要求，從內存中讀取數據必須進行兩次，然後將獨到的兩半數據拼接起來，這會嚴重影響效率。 由於邊界對齊問題的要求，在計算struct的sizeof的時候，編譯器必須算入額外的字節填充，以保證每一個變量都能自然對齊。比如如下聲明的struct: struct WASTE { char c1; int i; char c2; } 實際上相當於聲明瞭這樣一個結構： struct WASTE { char c1; char _filling1 [3];//三個字節填充，保證下一個int的對齊 int i; char c2； char _filling2 [3];//又三個字節填充 } 值得注意的是尾部的3個字節填充，這是爲了可以在一個數組中聲明WASTE變量，並且每一個都自然對齊。因爲有了這些填充，所以sizeof(WASTE)==12。這是一種浪費，因爲只要我們重新安排變量的聲明，就可以減少sizeof： struct WASTE { int i; char c1,c2; } 像這樣的安排，sizeof就減少到8，只有2個字節的額外填充。爲了與彙編代碼相兼容，C語言語法規定，編譯器無權擅自安排結構體內變量的佈局順序，必須從左向右逐一排列。所以，妥當安排成員順序以避免內存空間的浪費，就成了我們程序員的責任之一。一般的，總是將結構體的成員按照其sizeof從大到小排列，double在最前，char在最後，這樣總可以將結構的字節填充降至最小。 C++繼承了C語言關於結構體佈局的規定，所以以上的佈局準則也適用於C++的class的成員變量。C++進一步擴展了佈局規定，同一訪問區段(private、public、protected)中的變量，編譯器無權重新排列，不過編譯器有權排列訪問區段的前後順序。基於這個規則，C++中有的程序員建議給每一個成員變量放在單獨區段，在每一個成員聲明之前都加上private:、public:、protected:標誌，這可以最大限度的利用編譯器的決策優勢。 在棧中按順序分配的變量，其邊界也受到對齊要求的限制。與在結構中不同的是，棧中的變量還必須保證其後續變量無論是何種類型都可以自由對齊，所以在棧中的變量通常都有平臺相關的對齊最小值。在MSVC編譯器上，這個最小值可以由宏_INTSIZEOF(T)查詢： #define _INTSIZEOF(T) ( (sizeof(T) + sizeof(int) - 1) & ~(sizeof(int) - 1) ) _INTSIZEOF(T)會將sizeof(T)進位到sizeof(int)的整數倍。 由於在棧中分配變量使用_INTSIZEOF而不是sizeof，在棧上連續分配多個小變量(sizeof小於int的變量)會造成內存浪費，不如使用結構(struct)或數組。也就是說： char c1,c2,c3,c4;//使用16字節 char c[4];//使用4字節 當然，使用數組的方法在訪問數組變量(比如c[1])時有一次額外的指針運算和提領(dereference)操作，這會有執行效率的損失。這又是一種空間(內存佔用)vs時間(執行效率)的折中，需要程序員自己根據情況權衡利弊。 sizeof的大小可能比我們預期的大，也可能比我們預期的小。對於空類： class Empty {}; 在通常情況下，sizeof(Empty)至少爲1。這是因爲C++語法規定，對於任何實體類型的兩個變量，都必須具有不同的地址。爲了符合語法要求，編譯器會給Empty加入1字節的填充。所以sizeof()的值不可能出現0的情況。可是對於以下的類聲明： class A:public Empty{vitual ~A(){}}; sizeof(A)有可能是6，也有可能是5，也有可能是4！必不可少的四個字節是一個指向虛函數表的指針。一個可能有的字節是Empty的大小，這是是因爲編譯器在特定情況下會將Empty視作一個\"空基類\"，從而實施\"空基類優化\"，省掉那毫無作用的一字節填充。另一個字節是A的一字節填充，因爲從語法上講，A沒有成員聲明，理應有1字節填充，而從語義上講，編譯器給A的聲明加入了一個指向虛函數表的指針，從而A就不再是一個\"空類\"，是否實施這個優化，要看編譯器作者對語法措詞的理解。也就是說，sizeof也會出現4+1+1=4的情況。具體要看編譯器有沒有實施\"空基類優化\"和\"含虛函數表的空類優化\"。 結構和類的空間中可能有填充的字節，這意味着填充字節中可能有數值，雖然這數值並不影響結構的邏輯狀態，但是它也可能不知不覺中影響到你。比如說，你手頭正好有一組依賴於底層硬件(比如多處理器)的函數，他們在操縱連續字節時比手動編碼要快很多，而你想充分利用這種硬件優勢： bool BitCompare(void* begin,void* end,void* another); 這個函數將區間[begin,end)之間的字節與another開始的字節相比較，如果有一位不同就返回false，否則返回true。 比如你想將這個函數用於你自己的類的operator==中，這樣可以利用硬件加快速度。不過你在動手前要充分考慮，你的class是否真的要比較每一位。如果在類的成員中存在編譯器填充的字節數，那麼應用以上的函數就是不正確的，因爲填充的字節中可以有不同的值。爲了保證你可以用Bitwise Compare，你必須確保填充的字節中的值也是相同的。這不僅要求你在類的構造函數中初始化類的每一bit而不是每一個成員，也要求你在複製初始化和複製賦值函數中也同時保證bitwise copy語義，而不是編譯器默認產生的memberwise語義。當然，你可能通過與BitCompare一同提供的BitCopy來完成這個艱鉅的任務。","tags":"import","title":"C++ Tricks 2.5 I386平臺的邊界對齊(Align)"},{"url":"//farseerfc.me/c-tricks-2-6-i386-variable-arguments.html","text":"從 farseerfc.wordpress.com 導入 2.6 I386平臺C函數的可變參數表(Variable Arguments) 基於前文(2.4節)分析，我們可以不通過函數簽名，直接通過指針運算，來得到函數的參數。由於參數的壓棧和彈出操作都由主調函數進行，所以被調函數對於參數的真實數量不需要知曉。因此，函數簽名中的變量聲明不是必需的。爲了支持這種參數使用形式，C語言提供可變參數表。可變參數表的語法形式是在參數表末尾添加三個句點形成的省略號\"...\"： void g(int a,char* c,...); 省略號之前的逗號是可選的，並不影響詞法語法分析。上面的函數g可以接受2個或2個以上的參數，前兩個參數的類型固定，其後的參數類型未知，參數的個數也未知。爲了知道參數個數，我們必須通過其他方法，比如通過第一個參數傳遞： g(3,\"Hello\",2,4,5);//調用g並傳遞5個參數，其中後3個爲可變參數。 在函數的實現代碼中，可以通過2.4節敘述的，參數在棧中的排列順序，來訪問位於可變參數表的參數。比如: void g(int a,char* c...){ void *pc=&c;int* pi=static_cast<int*>(pc)+1;//將pi指向首個可變參數 for(int i=0;i<a;i++)std::cout<<pi[i]<<\" \"； std::cout<<c<<std::endl; } 我們甚至可以讓一個函數的所有參數都是可變參數，只要有辦法獲知參數的數量即可。比如，我們約定，在傳遞給addAll的參數都是int，並且最後一個以0結束： int addAll(...); int a=f(1,4,2,5,7,0); 那麼addAll可以這樣實現： int addAll(...){ int sum=0;int *p=&sum; //p指向第一個局部變量 p+=3; //跳過sum，ebp，eip，現在p指向第一個參數 for(;*p;++p) //如果p不指向0就繼續循環 sum+=*p; return sum; } 可變參數表的最廣泛應用是C的標準庫函數中的格式化輸入輸出：printf和scanf。 void printf(char *c,...); void scanf(char *c,...); 兩者都通過它的首個參數指出後續參數表中的參數類型和參數數量。 如果可變參數表中的參數類型不一樣，那麼操縱可變參數表就需要複雜的指針運算，並且還要時刻注意邊界對齊(align)問題，非常令人頭痛。好在C標準庫提供了用於操縱可變參數表的宏(macro)和結構(struct)，他們被定義在庫文件stdarg.h中: typedef struct {char *p;int offset;} va_list; #define va_start(valist,arg) #define va_arg(valist,type) #define va_end(valist) 其中結構va_list用於指示參數在棧中的位置，宏va_start接受一個va_list和函數的可變參數表之前的參數，通過第一個參數初始化va_list中的相應數據，因此要使用stdarg.h中的宏，你的可變參數表的函數必須至少有一個具名參數。va_arg返回下一個類型爲type的參數，va_end結束可變參數表的使用。還是以上文的addAll爲例，這次寫出它的使用標準宏的版本： int addAll(int i,...) { va_list vl; //定義一個va_list結構 va_start(vl,i); //用省略號之前的參數初始化vl if(i=0)return 0; //如果第一個參數就是0，返回 int sum=i; //將第一個參數加入sum for(;;){ i=va_arg(vl,int); //取得下一個參數，類型是sum if(i==0)break; //如果參數是0，跳出循環 sum+=i; } va_end(vl); return sum; } 可以看出，如果參數類型一致，使用標準庫要多些幾行代碼。不過如果參數類型不一致或者未知(printf的情況)，使用標準庫就要方便很多，因爲我們很難猜出編譯器處置邊界對齊(align)等彙編代碼的細節。使用標準庫的代碼是可以移植的，而使用上文所述的其它方法操縱可變參數表都是不可移植的，僅限於在I386平臺上使用。 縱使可變參數表有使用上的便利性，它的缺陷也有很多，不可移植性和平臺依賴性只是其一，最大的問題在於它的類型不安全性。使用可變參數表就意味着編譯器不對參數作任何類型檢查，這在C中算是一言難盡的歷史遺留問題，在C++中就意味着惡魔reinterpret_cast被你喚醒。C的可變參數表是C++代碼錯誤頻發的根源之一，以至於C++標準將可變參數表列爲即將被廢除的C語言遺留特性。C++語法中的許多新特性，比如重載函數、默認參數值、模板，都可以一定程度上替代可變參數表，並且比可變參數表更加安全。 可變參數表在C++中惟一值得嘉獎的貢獻，是在模板元編程(TMP)的SFINAE技術中利用可變參數表製作最差匹配重載。根據C++標準中有關函數重載決議的規則，具有可變參數表的函數總是最差匹配，編譯器在被逼無奈走頭無路時纔會選擇可變參數表。利用這一點，我們可以精心製作重載函數來提取類型信息。比如，要判斷一個通過模板傳遞來的類型是不是int： long isIntImp(int); char isIntImp(...); template<typename T> struct isInt { enum{value=sizeof(isIntImp(T()))==sizeof(long);} } 然後，在一個具有模板參數T的函數中，我們就可以寫 if(isInt<T>::value)//... 在這個(不怎麼精緻的)例子中，如果T是int，那麼isIntImp的第一個重載版本就會被選中，返回值類型就是long，這樣value就爲1。否則，編譯器只能選中第二個具有可變參數表的重載版本，返回值類型成爲char，這樣value就爲0。把它說得再明白一些，上文的代碼所表達的意思是：如果類型T是int，那它就是int，否則它就不是int，呵呵簡單吧。這種通過重載決議規則來提取類型信息的技術，在模板元編程中被稱作SFINAE，它和其它模板元編程技術被廣泛運用於STL、Boost等模板庫的開發實現之中。 值得注意的是，在上文SFINAE的運用中，isIntImp並沒有出現定義而只提供了聲明，因爲我們並沒有實際調用isIntImp函數，而只是讓它參與重載決議並用sizeof判斷其返回值類型。這是C++的一個設計準則的完美體現：不需要的東西可以不出現。由於這一準則，我們避免了在C++中調用具有可變參數表的函數這一危險舉動，而僅僅利用了可變參數表在語法分析過程中的特殊地位，這種對於危險語言特性的巧妙利用是善意而無害的。","tags":"import","title":"C++ Tricks 2.6 I386平臺C函數的可變參數表(Variable Arguments)"},{"url":"//farseerfc.me/c-tricks-2-7-i386-calling-conventions.html","text":"從 farseerfc.wordpress.com 導入 2.7 I386平臺的其它函數調用模型 上文介紹的只是I386平臺上C函數調用的標準模型，被稱作__cdecl。事實上，Microsoft Visual C++編譯器還支持其它一些函數調用模型，所有調用模型名稱皆以雙下劃線開頭，下面列出所有函數調用模型的異同： 1 __cdecl 參數壓棧順序：逆序(從右至左) 參數堆棧恢復者：主調函數(caller) __cdecl明確地指出函數使用C函數調用模型，這是默認的調用模型。 2 __stdcall 參數壓棧順序：逆序(從右至左) 參數堆棧恢復者：被調函數(callee) __stdcall是微軟所謂的標準調用模型。可惜的是它與__cdecl不兼容。幾乎所有的Win32API函數使用這種函數調用模型，希望在DLL之間，或者在程序和WinNT操作系統之間傳遞函數指針的函數也應該使用這種模型。與__cdecl模型的不同之處在於，__stdcall模型下由被調函數恢復堆棧。主調函數在call語句之後，不需要再加上add語句。而被調函數的ret語句則被添加一個參數，代表函數參數堆棧的長度。因此，被調函數需要明確的知曉函數參數的數量和類型，所以在__stdcall模型下不支持可變參數表，所有參數必須寫明。 3 __thiscall 參數壓棧順序：逆序(從右至左)，this用ecx傳遞。 參數堆棧恢復者：被調函數(callee) __thiscall是VC編譯器中類的非靜態成員函數(non-static member functon)的默認調用模型。但是如果此成員函數有可變參數表，VC編譯器會使用__cdecl。和__stdcall一樣，__thiscall由被調函數恢復堆棧。比較獨特的是__thiscall會通過ecx寄存器傳遞成員函數的this指針，而__cdecl下this指針是通過在參數表最前面增加一個函數參數來傳遞的。__thiscall是VC編譯器對this指針的使用的一種優化，大大提高了面向對象程序的效率。在VC2003及之前的編譯器上__thiscall不是一個關鍵字，不能被顯式指定。但可以給成員函數顯式指定__cdecl來避免使用__thiscall。 4 __fastcall 參數壓棧順序：逆序(從右至左)，前兩個32位函數參數放入ecx和edx中 參數堆棧恢復者：被調函數(callee) 快速函數調用模型，將前兩個32位函數參數放入ecx和edx中，其餘參數再逆序壓棧。使用的是和__thiscall類似的優化技術，加快函數調用，適合運用在小型inline函數上。同樣使用__stdcall形式的被調函數恢復堆棧，所以不支持可變參數表。 5 __pascal 參數壓棧順序：正序(從左至右) 參數堆棧恢復者：被調函數(callee) 過程式編程語言Pascal所使用的函數調用模型，由此得名。也是16位版本的Windows使用的API模型，過時的模型，現在已經廢棄且禁止使用。你會看到有些書本仍會不時提到它，所以需要注意。__pascal是正序壓棧，這與大部分I386函數模型都不相同。與__stdcall一樣，由被調者恢復堆棧，不支持可變參數表。歷史上曾有過的別名PASCAL、pascal、_pascal(單下劃線)，現在都改成了__stdcall的別名，與__pascal(雙下劃線)不同。 6 其它函數調用模型，以及模型別名。 __syscall：操作系統內部使用的函數調用模型，由用戶模式向核心模式跳轉時使用的模型。由於用戶模式和核心模式使用不同的棧，所以沒辦法使用棧來傳遞參數，所有參數通過寄存器傳遞，這限制了參數的數量。用戶模式編程中不允許使用。 __fortran：數學運算語言fortran使用的函數模型，由此得名。在C中調用由fortran編譯的函數時使用。 __clrcall：微軟.Net框架使用的函數模型，託管(Managed)C++默認使用，也可以從非託管代碼調用託管函數時使用。參數在託管棧上正序(從左至右)壓棧，不使用普通棧。 CALLBACK、PASCAL、WINAPI、APIENTRY、APIPRIVATE：I386平臺上是__stdcall的別名 WINAPIV：I386平臺上是__cdecl的別名 7 函數調用模型的指定 函數調用模型的指定方式和inline關鍵字的指定方式相同，事實上，inline可以被看作是C++語言內建的一種函數調用模型。唯一不同的是，聲明函數指針時，也要指明函數調用模型，而inline的指針是不能指明的，根本不存在指向inline函數的指針。比如： int CALLBACK GetVersion(); int (CALLBACK * pf)()=GetVersion;","tags":"import","title":"C++ Tricks 2.7 I386平臺的其它函數調用模型"},{"url":"//farseerfc.me/c-tricks-2-1-x86-architecture.html","text":"從 farseerfc.wordpress.com 導入 2.1 X86概述 所謂X86體系結構，是指以Intel 8086芯片爲首的芯片所沿襲的CPU結構，一些文檔中又被稱作IA32體系結構。包括的芯片有但不限於:Intel 8086至 80486，奔騰(Pentium)系列處理器1至4，賽揚系列處理器，酷睿系列處理器，以及AMD的相應型號產品。X86體系結構在早期屬於16位處理器，自80386之後擴展爲32位處理器，所以一些文檔中又把80386之後的32位處理器體系稱作I386。自Pentium4後期，AMD的Athlon64開始，I386被進一步擴充爲64位處理器，含有64位尋址能力的X86體系結構被稱作X86-64或IA32-64。總之，市售的個人電腦用CPU，除蘋果的Macintosh之外，全部採用X86體系結構芯片。 在X86早期，16位的尋址能力只支持64KB(2&#94;16=64K)內存，這顯然是不夠的。Intel採用分段尋址的方法，用4位段位+16位偏移量，提供了總共1MB(2&#94;20=1M)的尋址能力。所以在X86的16位編程中，有兩種指針類型：長指針(lp,long pointer)和短指針(sp,short pointer)，長指針(20位)提供整個內存空間尋址能力，短指針(16位)僅支持同一段中的尋址。在\"古代\"DOS及Win3.x編程過程中，兩種類型的指針，以及總共1MB的內存大小，常常把程序員們折騰得焦頭爛額。 自I386之後，CPU纔開始提供32位的尋址能力。有了整整4GB(2&#94;32=4G)的尋址空間，所有指針統一爲長指針(32位)。時至今日，我們仍可以看到微軟文檔中指針變量的lp前綴。由於內存管理的需要，分段機制被保留下來，但這一次不是因爲地址空間太小，而是因爲地址空間遠大於實際內存容量，從而採用了虛擬內存機制。 在從16位結構向32位結構轉變的過程中，由於向下兼容的歷史原因，曾一度長時間出現硬件32位(I386)、軟件16位(Win3.x)的情況。同樣也是爲了兼容16位軟件，Win9x操作系統(Win95、Win98、WinME)保留了16位代碼和32位代碼。混合代碼的設計使得Win9x及其混亂和不穩定。直到完全32位內核的操作系統WinNT(以及構建於其上的Win2000，WinXP，Win2003)的出現，X86平臺上內存佈局混亂的局面才得以改善。有了從16位至32位移植的經驗和準備，現今的從32位到64位的操作系統移植顯得平穩順利很多。WinXP和WinVista系統都同時發佈了32位版本和64位版本，並且其x86-64系統都實現了對32位軟件的無縫銜接支持。","tags":"import","title":"C++ Tricks 2.1 X86概述"},{"url":"//farseerfc.me/c-tricks-1-2-trap-in-comma-logical-operator.html","text":"從 farseerfc.wordpress.com 導入 1.2 逗號運算符(,)、邏輯運算符(&&,||)與運算符重載的陷阱 很多人甚至不知道逗號(,)也是個C++運算符。與語法上要求出現的逗號(比如分隔函數參數的逗號)不同的是，出現在表達式中的逗號運算符在語義上表示多個表達式操作的連續執行，類似於分隔多語句的分號。比如： for ( int i=0,j=9;i<10;++i , --j)std::cout<<i<<\"+\"<<j<<\"=9\\n\"; 在這句語句中，出現了兩個逗號，其中前者是語法上用來分隔聲明的變量的，並非逗號運算符，而後者則是一個逗號運算符。根據C++標準，逗號運算符的執行順序爲從左到右依次執行，返回最後一個子表達式的結果。由於只有最後一個表達式返回結果，所以對於一個語義正常的逗號表達式而言，前幾個子表達式必須具有副作用。同時，從語言的定義中也可以看出，逗號表達式對求值的順序有嚴格要求。 對求值順序有要求的，除了逗號表達式和條件表達式(參見1.1)，在C++中還有邏輯運算符(&&和||)。邏輯運算相較於數學運算和位運算而言，有個顯著的不同點：邏輯運算在計算到一半時，就有可能已經得到結果，這樣繼續運算另一半就不是必需的。對於A&&B，如果A=false，那麼無論B爲何值，整個的結果都是false；同樣的A||B，如果A=true，那麼不考慮B，結果一定是true。 C++標準規定，如果邏輯運算到一半(算出A)時，就已經可以確定運算的結果，那麼就不運算剩下的另一半(B)。這種執行語義被稱作\"短路\"。在其它一些編程語言中，短路語義是可以選擇的：在Ada裏非短路的邏輯運算符爲and和or，短路的邏輯運算符爲and_then和or_else。但是在C++中，邏輯運算符的短路語義是語法上強制的，我們沒有非短路版本的運算符。如果確實需要非短路語義，我們總是可以通過增加一個bool中間變量加以解決。有時，短路對於保證正確執行是必須的，比如： char *p=getString(); if (p && *p)std::cout<<p; 這段代碼在得到了一個字符串後，在字符串不爲空時輸出它。在C++中判斷一個字符串不爲空需要兩個步驟：判斷指針是否爲0，以及指針不爲0時判斷指針指向的內容是否爲''。就像條件表達式中討論到的(參見1.1)，在p爲空時提領p是個極其危險的操作。邏輯運算符的短路語義則避免了這種危險。 以上對逗號運算符與邏輯運算符的討論，僅限於C++標準所定義的運算符語義。爲什麼這樣說呢？這是因爲在C++中，運算符的語義是可以由程序員自行定義的，這種機制叫做運算符重載(operator overload)。運算符重載可以將人們熟悉的運算符表達式轉換成函數調用，使編程靈活而直觀，是個方便的語言特性。不過有時運算符重載也會使人困擾，那就是當運算符重載遇到求值順序問題時。 C++中，並不是所有合法運算符都可以被合法地重載。條件運算符雖然對求值順序有要求，但它並不在可重載運算符之列，所以運算符重載機制對它沒有影響。問題在於，逗號運算符和邏輯運算符都可以被合法地重載： class BadThing{/* Some Bad and Stupid Thing*/}; BadThing& operator ,(BadThing&, BadThing&);//重載了逗號運算符 bool operator &&(BadThing&, BadThing&);//重載了&& BadThing b1,b2; if (b1&&b2)b1,b2;//被替換成如下形式： if ( operator &&(b1,b2)) operator ,(b1,b2); 可以看到，重載了運算符之後，對運算符的使用被替換爲相應的函數調用形式。因此，舊有的運算符的執行順序不再適用，取而代之的是函數參數的壓棧順序。 根據C++標準規定，任何參數必須在進入函數之前壓棧，所以在進入 operator &&之前，b1、b2就會被求值，這裏不再有短路規則，任何依賴於短路語義的不知不覺間操作BadThing的代碼(可能通過模板)都會混亂。 短路語義只是一個方面，更重要的在於壓棧順序。鑑於執行效率和舊代碼兼容性等細節問題，C++標準在壓棧順序上給編譯器的開發者留有很大自主性。標準的說辭是，編譯器可能以任何它覺得方便的順序將參數壓棧，從左到右，從右到左，甚至從中間到兩邊，在這一點上我們不能安全地做任何假設。在上面的例子中，編譯器生成的代碼可能先計算b1再計算b2，也可能是相反的順序。再看看編譯器的實際情況，在我試過的所有基於X86體系結構的編譯器中，參數都是以逆向壓棧，即從右到左，有悖於大多數人的閱讀習慣和直覺(別說你是來自伊斯蘭的……)。 在C時代使用函數調用時，壓棧順序並不是什麼大問題，畢竟大多數人會在函數調用的邊界稍稍小心一些。但是到了C++中，事情變得有些複雜，因爲簡單如a+b的使用，就有可能被運算符重載機制替換爲函數調用。更何況有模板參與之後，我們寫代碼時不能確定對象的真實類型，也就無法預知一個運算符是否真的被重載過，唯一穩妥的方法是，假定任何有可能被重載的運算符的使用都是函數調用。 <p style=\"margin:0;\"> 回到上文的示例中，由於,和&&都被替換爲函數調用，程序的執行順序將成爲壓棧順序，在X86上很有可能是從右到左，與標準定義的運算符的順序正好相反。逗號運算符原本就含有\"先…後…\"的語義，這種顛倒的執行順序勢必造成程序和程序員的混亂。以我的經驗而言，含有 operator ,的類，完全沒有辦法和STL或者iostream相互協作，反而會導致巨量的錯誤報告(什麼叫巨量的錯誤報告有概念麼？如果沒有，那說明你還沒玩過範式編程(GP, Generic Programming)。去玩玩GP吧，看看你的編譯器對巨量的定義。在我手頭，針對3.5KB的代碼文件傾瀉出3.8 MB 的錯誤信息的編譯器不在少數……)。有鑑於此，我的結論是，除非你有充足的依據支持你這麼做(比如你的粗暴上司的鍵盤上只剩下逗號能用)，並且你清楚的瞭解這麼做的後果的嚴重性(比如至少要看過此文)，否則我奉勸你，永遠不要碰 operator ,、 operator &&以及 operator ||！","tags":"import","title":"C++ Tricks 1.2 逗號運算符(,)、邏輯運算符(&&,||)與運算符重載的陷阱"},{"url":"//farseerfc.me/c-tricks-1-1-conditional-operator.html","text":"從 farseerfc.wordpress.com 導入 1.1 條件運算符(?:) 條件運算符(?:)是C++中唯一的三目運算符(trinary operator)，用於在表達式中作條件判斷，通常可以替換if語句，與Visual Basic中的iif函數、Excel中的if函數有同樣的作用。語法形式如下： condition ? true_value : false_value 其中 condition *條件是任何可以轉換爲bool類型的表達式，包括但不僅限於**bool* 、 int 、指針。與 if 和 while 的條件部分稍顯不同的是，這裏不能定義變量，否則會導致語法錯誤。 另外，條件語句會切實地控制執行流程，而不僅僅是控制返回值。也就是說，兩個返回值表達式中永遠只有一個會被求值，在表達式的執行順序很重要時，這點尤爲值得注意。比如： int *pi=getInt(); int i=pi ? *pi : 0; 這裏，只有當pi的值不爲0時，它纔會被提領(dereference)。這種語義保證了程序的正確性，因爲提領一個空指針將導致致命的運行期錯誤(通常是非法操作的警告)。同時，正因爲條件運算符控制運算流程的特點，使得它不能用類似iif的普通函數來模擬： int iif( int con, int t, int f){ if (c) return t; return f;}//試圖模擬?: …//in some function int *pi=getInt(); int i=iif(pi,*pi,0);//Error! 這段代碼會導致上文提到的致命運行期錯誤。C/C++標準規定，參數在被傳遞給函數之前求值，因此無論pi爲何值，都會被提領。又因爲函數傳回一個空指針的情況比較少見，所以這樣的錯誤在調試時很難被發現，一旦發生又勢必造成重大災難。這樣的代碼在實踐中應儘量避免。 有時，條件運算符控制流程的特點會不知不覺影響我們的代碼。在C時代，最大值MAX通常用宏實現： #define MAX(a,b) ((a)>(b) ? (a) : (b)) 需要用額外的括號將宏參數和宏本體保護起來，以免運算符優先級擾亂邏輯，這是宏醜陋的特點之一，這裏暫且不提。矛盾在於，用具有副作用的表達式調用宏時，會出現問題： int i=5,j=6;//… int a=MAX(++i,++j); 代碼的作者原意顯然是想先將i,j分別遞增，再將其中較大的一個賦給a。執行這段代碼，當i=5,j=6時，a=8，知道爲什麼嗎？通過宏展開，賦值語句成這樣： int a=(++i)>(++j) ? (++i) : (++j);//刪除了多餘括號 在判斷之前，i、j被分別自增一次，然後捨棄:之前的部分，j又被自增一次。執行之後，i=6,j=8。 MAX的更正確更安全的實現，是利用模板將類型參數化。STL標準算法中就有一個這樣的工具級模版函數std::max。 條件運算符是表達式而不是語句，這使得它可以出現在任何需要表達式的地方，這擴大了它的適用範圍。在那些語法上只能出現表達式而不能出現語句的地方（比如變量初始化），條件運算符有着不可替代的作用。 條件運算符優於 if 語句的另一個場合是\"模板元編程\"(TMP, Template MetaProgramming)。在TMP這個古怪奇異的編譯期運算編程技術中，一切舊有的技術和法則被全線擊破，我們所能仰仗的工具，只有模板特化(Specialization)、 typedef s、函數聲明(無法調用它們)、以及編譯期常量運算。已經有人很深入地論證過，僅有以上這些，就已經形成了一個\"圖靈完善\"的計算機語言。我們可以用模板特化技術，來模擬條件分支，循環迭代等一系列複雜的語言結構。由於可以參與編譯期常量運算，條件運算符在TMP世界中很自然地扮演起重要角色。 比如，給與類型T的一個變量t，我們想聲明一個緩衝區存放t和一個int，緩衝區的大小不小於sizeof(T)也不小於sizeif(int)，我們可以這樣寫： char buffer[sizeof(T)>sizeof(int)? sizeof(T): sizeof(int)]; 我們不能用一個if語句替換這個運算： int i; if(sizeof(T)>sizeof(int))i=sizeof(T); else i=sizeof(int); char buffer[i];//語法錯誤! 原因在於數組聲明中的下標必須是一個編譯期常量，而不是一個運行期的值，條件表達式的運算可以在編譯期進行，if語句就只能在執行期執行。","tags":"import","title":"C++ Tricks 1.1  條件運算符(?:)"},{"url":"//farseerfc.me/filling-believings-calling-conscience.html","text":"從 farseerfc.wordpress.com 導入 填補信仰、喚醒良知 我們聽盡了呼籲與號召，對於良知，我不必譴責喪失它的國人，不必盛讚良知的美好。我只想討論，喪失了良知的原因——空缺的信仰。 一、空缺信仰喪失良知 現代的國人缺少信仰，以至於喪失良知。曾幾何時，中華民族由良好的信仰凝聚而成。三皇五帝時，族民們以炎黃爲信仰；春秋戰國時，士大夫之族以周制禮樂爲信仰；漢代以後，百姓延習孔孟之說、老聃之道，以儒家學說爲信仰；自大唐起，以佛教爲首的現代宗教紛紛傳入中原，人民開始以它們作爲信仰。 直至鴉片戰爭、五四運動，西方文化入侵中華，國人開始拋棄國學，轉而去研究科學；文化大革命，十年文化浩劫，人們批判舊的信仰，卻沒有合適的新的信仰前來填補。從此，國人的信仰出現空缺，國人的良知也被一塊塊蠶食殆盡。 二、信仰、科學、迷信 在許多國人的心目中，信仰就等於迷信。從小到大的教育告訴我們，信奉宗教是愚昧而又無知的表現，科學與信仰是矛盾的。是麼？ 我們無法保證社會上的每一個人都接受過良好的教育，我們無法確信最前沿的科學素養能在民衆中普及。在科普與教育力不從心的社會死角，在科學技術尚不能及的文化盲區，我們依舊需要信仰的規範與限制，我們的良知需要信仰！ 信仰不等於迷信。信仰本身無所謂謎與不迷，迷信是持有信仰的人誤解了信仰，盲目遵從的結果。以爲燒過香就可以免遭禍患，以爲捐了錢就可以升入天堂，以爲引火自焚就可以功德圓滿，這便是迷信了。希特勒曾經的人類完善計劃，依照遺傳學的原理，將科學家與運動員強行結爲夫婦孕育生命，希望得到最優秀的人類種族，這便是對科學這種信仰的迷信！ 由此可見，科學與信仰並不是矛盾的硬幣的兩面，從某種意義而言科學本身也是信仰的一種。雖然歷史上宗教往往作爲科學發展的阻礙，可信奉真理的信念一直是推動科學發展的動力。牛頓就曾說過，對自然規律的探詢是爲了更接近上帝。由此可見，信仰與真理，與良知毫無矛盾。 三、信仰喚醒良知 很少有人仔細思考過，良知的缺失是由信仰的缺失造成的。信仰是人思想的寄託與依靠，是人行動處世的準則。沒有了信仰的人，思想行爲就缺少了約束的標準，人就更容易因爲一時不成熟的衝動，背叛良知、鑄成錯誤。 泰國人以佛教爲信仰，泰國的寺廟每天都會有成千上萬人頂禮膜拜。寺廟有一個人盡皆知的不成文規定：不得穿鞋進入。於是在寺廟之外，遊客們可以看到千百雙各式的鞋子有序的擺放在門口。國人每每看到此景，總會詫異地問：沒有人會偷鞋麼？得到的答案極爲簡單：廟前偷鞋會遭報應。由於擁有信仰，泰國人作了壞事會受到良知的譴責，泰國商人售出假貨會徹夜難眠。二戰期間，無數猶太難民被天主教會收留藏匿從而僥倖逃生，這同樣是出於，天主教徒們被自己信奉的教義\"衆生生來平等\"，所喚醒的良知。 天下無賊的世界，不能僅靠科普說教來營造。如果脫離了信仰，縱使是教育也無法培養良知。我問過許多修化學的同學，學習化學的意義，結論竟是爲了考試。如果沒有對科學的信仰，我們可以牢記公式定理，卻質疑它們是真理；如果沒有對社會公德的信仰，我們可以熟背交通規則，卻正大光明地闖紅燈；如果沒有對醫療道德的信仰，醫生可以放任傷口發炎，從而留住病人繼續治療…… 國人需要信仰的約束，需要填補信仰的空白，從而喚醒那深埋於每個國人內心深處的良知！","tags":"import","title":"填補信仰、喚醒良知"},{"url":"//farseerfc.me/zhs/compositor-in-X-and-compositext.html","text":"在上篇文章 「桌面系统的混成器简史」 中我介绍了其它桌面系统中的混成器的发展史和工作原理， 话题回到我们的正题 Linux 系统上，来说说目前 X 中混成器是如何工作的。 这篇文章将比上一篇深入更多技术细节，不想看太多细节的可以直接跳过看 结论 。 原始的 X 的绘图模型 首先，没有混成器的时候 X 是这样画图的： X 的应用程序没有统一的绘图 API 。GTK+ 在 3.0 之后统一用 Cairo 绘图， 而 Cairo 则是基于 PDF 1.4 的绘图模型构建的， GTK 的 2.0 和之前的版本中也有很大一部分的绘图是用 Cairo 进行， 其余则通过 xlib 或者 xcb 调用 X 核心协议提供的绘图原语绘图。 QT 的情况也是类似，基本上用 QPaint 子系统绘制成位图然后交给 X 的显示服务器。 显示服务器拿到这些绘制请求之后，再在屏幕上的相应位置绘制整个屏幕。 当然还有很多老旧的不用 GTK 或者 QT 的程序，他们则直接调用 X 核心协议提供的绘图原语。 值得注意一点是 X 上除了没有统一的绘图模型，也没有统一的矢量图格式。 X 核心协议的绘图原语提供的是像素单位的绘图操作，没有类似 GDI+ 或者 Quartz 提供的 设备无关 ( Device Independence ) 的「点」的抽象。所以只用 X 的绘图原语的话，我们可以把 (1,1) 这个像素点涂黑，但是不能把 (0.5, 0.5) 这个点涂黑，这一设计缺陷在 Unix Hater's Handbook 中已经被吐槽过了。因为这个缺陷，所以直接用 X 绘图原语绘制的图像不能像 矢量图那样进行无损缩放。同样的缺陷导致 X 绘图原语绘制的字符不能做到 子像素级 ( subpixel-level ) 抗锯齿 ( anti-aliasing ) （这解释了默认配置下的 xterm 和 urxvt 中的字体渲染为什么难看 ）。相比之下 GDI 有对应的 WMF 矢量图格式， Quartz 有对应的 PDF 矢量图格式， 而 X 中没有这样的格式对应。因为没有统一的矢量图格式，所以无论是 Cairo 、QPaint 还是没有用这些绘图库但是同样在意字体和曲线渲染效果的程序（比如 Firefox 和 Chromium）都需要首先渲染到内部的 XPixMap 位图格式，做好子像素渲染和矢量缩放，然后再把渲染好的位图转交给 X 图形服务器。 通过 Composite 扩展重定向窗口输出 2004年发布的 X11R6.8 版本的 Xorg 引入了 Composite 扩展 。这个扩展背后的动机以及前因后果在一篇文章 The (Re)Architecture of the X Window System 中有详细的表述。Composite 扩展允许某个 X 程序做这几件事情： 通过 RedirectSubwindows 调用将一个窗口树中的所有窗口渲染重定向到 内部存储 ( off-screen storage ) 。重定向的时候可以指定让 X 自动更新窗口的内容到屏幕上或者由混成器手动更新。 通过 NameWindowPixmap 取得某个窗口的内部存储。 通过 GetOverlayWindow 获得一个特殊的用于绘图的窗口， 在这个窗口上绘制的图像将覆盖在屏幕的最上面。 通过 CreateRegionFromBorderClip 取得某个窗口的边界剪裁区域（不一定是矩形）。 有了 Composite 扩展，一个 X 程序就可以调用这些 API 实现混成器。 这里有篇 教学解释如何使用 Composite 扩展 。开启了混成的 X 是这样绘图的： 整个 X 的混成器模型与 Mac OS X 的混成器模型相比，有如下几点显著的区别： 混成的部分是交由外部的程序完成的，对混成的绘制方式和绘制普通窗口一样。 出于效率考虑，绝大多数 X 上的混成器额外使用了 XRender 扩展或者 OpenGL/EGL 来加速绘制贴图。不过即使如此，还是不能避免同样的位图（内容不一定完全一致， 比如 X 可以在窗口交给它的位图上加上边框然后再返还给混成器） 在不同的三个程序之间来回传递 。 RedirectSubwindows 调用针对的是一个窗口树，换句话说是一个窗口 及其全部子窗口，不同于 Mac OS X 中混成器会拿到全部窗口的输出。 这个特点其实并不算是限制，因为 X 中每个虚拟桌面都有一个根窗口，只要指定这个根窗口 就可以拿到整个虚拟桌面上的全部可见窗口输出了。 反而这个设计提供了一定的自由度，比如我们可以用这个调用实现一个截图程序， 拿到某个特定窗口的输出，而不用在意别的窗口。 为了让窗口有输出，窗口必须显示在当前桌面上，不能处于最小化 状态或者显示在别的虚拟桌面，用 X 的术语说就是窗口必须处于 被映射 ( mapped ) 的状态。因此直接用上述方法 不能得到没有显示的窗口的输出 ，比如不能对最小化的窗口 直接实现 Windows 7 中的 Aero Peak 之类的效果。这个限制可以想办法绕开， 比如在需要窗口输出的时候临时把窗口映射到桌面上，拿到输出之后再隐藏起来， 不过要实现这一点需要混成器和窗口管理器相互配合。 不像 Mac OS X 的基于 OpenGL Surface 的绘图模型是 设备无关 ( device independent ) 的，这里 X 的绘图模型是 设备相关 ( device dependent ) 的。 这既是优点也是缺点。从缺点方面而言，显示到 X 的位图输出因为设备相关性， 所以严格对应显示器的点阵，并不适合作为文档格式打印出来。当然无论是 Cairo 还是 QPaint 都提供了到 PostScript 或者 PDF 后端的输出，所以实用层面这个并不构成问题。 设备相关这一点的优点在于，绘制到 XPM 位图的时候，程序和绘图库是能拿到输出设备（显示器） 的特殊属性的，从而绘图库能考虑不同的色彩、分辨率、 DPI 或者 子像素布局 ( subpixel layout ) 这些属性以提供最好的渲染效果。 Mac OS X 10.4 在设计的时候也曾考虑过提供无极缩放的支持，而这种支持到了 Mac OS X 10.5 中就缩水变成了 Retina 的固定 2 倍缩放。这种局面在 X 上没有发生正是因为 X 的绘图模型的这种设备相关性，而 Mac OS X 的混成器采用的 OpenGL Surface 则无视了这些设备相关的属性。 输入事件的重定向，这可能做到么？ 通过上述 Composite 扩展提供的 API ，混成器可以把窗口的 输出 重定向到自己的窗口上。 但是仅仅重定向输出，整个 X 还不处于可用状态，因为 没有重定向输入 。 考虑一下用户试图用鼠标点击某个按钮或者文本框，这时鼠标处于的位置是在 OverlayWindow 上绘制的位置，这个鼠标事件会交给 OverlayWindow ，而用户期待这个事件被发送给他看到的按钮上。 需要重定向的事件主要有键盘和鼠标事件两大类（暂时先不考虑触摸屏之类的额外输入）。 由于 Composite 扩展并没有直接提供这方面的重定向 API ，这使得输入事件处理起来都比较麻烦， 假设要重定向键盘事件，混成器需要效仿输入法框架（fcitx, ibus, scim） 那样处理一部分按键事件并把其余事件转给具有输入焦点的程序。 看看现有的输入法框架和诸多程序间的问题，我们就能知道这里的坑有多深。 于是 大部分 X 的混成器都不处理键盘事件重定向 。再来看重定向鼠标事件，这边的坑比重定向键盘事件的坑更多， 因为不像重定向窗口输出那样只需要考虑 顶层 ( top-level ) 窗口， 重定向鼠标输入的时候要考虑所有子窗口（它们有独立的事件队列）， 以及要准确记录输入事件事件发生时的键盘组合键状态，还要正确实现 ICCCM/EWMH 中描述的转交窗口焦点的复杂规则，所有这些都已经在 X 中实现过的事情需要重新实现一遍。 由于坑太多难以实现，所以所有 X 下的混成器的实现方式都是直接忽略这个繁重的任务， 不重定向输入事件 而把它交给 X 处理。具体的实现方式就是通过 XFixes 扩展提供的 SetWindowShapeRegion API 将 OverlayWindow 的 输入区域 ShapeInput 设为空区域，从而忽略对这个 OverlayWindow 的一切鼠标键盘事件。 这样一来对 OverlayWindow 的点击会透过 OverlayWindow 直接作用到底下的窗口上。 因为选择了不重定向输入事件， X 下的混成器通常会处于以下两种状态： 选择状态下可以缩放窗口的大小，扭曲窗口的形状，并且可以把窗口绘制在任意想要绘制的位置上 （并不是移动窗口的位置）， 但是不能让用户与窗口的内容交互 。 正常状态下可以让用户与窗口的内容交互，但是 绘制的窗口位置、大小和形状必须严格地和 X 记录的窗口的位置、大小和形状保持一致 。持续时间短暂的动画效果可以允许位置和形状稍有偏差，但是在动画的过程中如果用户点击了 变形缩放过的窗口，那么鼠标事件将发往错误的（ X 记录中的而非显示出的）窗口元素上。 可以发现这两种状态就直接对应了 Gnome 3 的普通状态和缩略图状态（点击 活动 ( Activity ) 或者戳画面左上角之后显示的状态），这也解释了为什么尽管 Gnome 3 的窗口有硕大的关闭按钮，但是在缩略图状态下 Gnome 3 仍然需要给窗口加上额外的关闭按钮： 因为处于缩略状态下的窗口只是一张画而不能点 。 Composite 扩展的这些限制使得 X 下的混成器目前只能实现 Mac OS X 那样的 Exposé 效果，而不能实现 LG3D 那样直接在 3D 空间中操纵窗口内容。 解决重定向问题曾经的一缕曙光是 升阳公司 ( Sun Microsystems ) 在开发 LG3D 的过程中同时提议过另一个 X 扩展叫做 Event Interception 或者简称 XEvIE ，这个扩展的设计目的就是提供 API 让某个程序接收并操纵全部的键盘和鼠标事件。可惜这个扩展随着升阳公司本身的陨落而 处于无人维护的状态，这一点也在它的官方网页上说明了： It has been suggested that this extension should not be used because it is broken and maintainerless. Composite 扩展的不足 通过上面的介绍，我们就已经可以看到 Composite 扩展的不足之处了。 总结起来说，主要有两大不足： 绘图效率低。因为同样的位图从应用程序传到 Xorg ，再从 Xorg 传到混成器， 最后从混成器再绘制到屏幕上，绕了一个大弯。这就是为什么 Wayland 的开发者在他的slide the real story behind Wayland and X 里这么说： and what's the X server? really bad IPC 那么 X 服务器到底做了什么呢？ 非常糟糕的进程间通讯 没有重定向输入事件。如果我们要在 X 的混成器里做这个事情， 基本上我们要全部重写一遍 X 已经写好的窗口事件分发逻辑。 既然同样要重写，为什么不直接重写一遍 X 呢，扔掉那些历史负担，扔掉那些无用的 API ，重新设计可扩展的 API ，做好快速安全的 IPC —— 嗯，重写 X 就是 Wayland 的目的。 不过这么重写了的 Wayland 还是我们熟悉可爱的 X 么？它有哪些地方变样了？ 这将是我下一篇文章的内容。 附录：扩展阅读 我自己没有写过窗口管理器，没有写过混成器，没有写过 Wayland 程序，以上说的都是我从互联网上看到的整理出来的内容。写下本文的过程中我参考了这些文章： The (Re)Architecture of the X Window System 这篇2004年写的文章描述了 Composite 扩展出现的动机和历史，介绍了绘图库的实现情况，涉及了上面所说的那些 X 扩展被用到的情况和可能。 同时这篇文章还展望了很多现在的 X 已然实现了的功能，比如 OpenGL 和 X 的结合方面我们有了 GLX 和 AIGLX ，比如内核的显卡支持方面我们有了 DRI 和 KMS 。总之这是一篇描述 Linux 桌面未来的发展轨迹的非常有阅读价值的历史文献。 so you want to build a compositor 这是一篇 2008 年写的博文，介绍如何用 Clutter 实现一个最简单的混成器。 Composite tutorial 这是另一篇介绍如何实现一个简单的混成器的博文，用 Qt 实现，但是同样很底层。 unagi 这是一个可用的（但是已经长期没有开发的）类似 xcompmgr 的混成器。这个项目貌似 是一位研究生的硕士毕业设计，同时他公开了硕士学位的毕业论文 Master thesis: Writing an X compositing manager 其中也对实现一个简单的混成器做了详尽描述，包括介绍了相关的 X 扩展和调用。","tags":"tech","title":"X 中的混成器与 Composite 扩展"},{"url":"//farseerfc.me/zhs/brief-history-of-compositors-in-desktop-os.html","text":"（原本是想写篇关于 Wayland 的文章，后来越写越长感觉能形成一个系列， 于是就先把这篇背景介绍性质的部分发出来了。） Linux 系统上要迎来 Wayland 了，或许大家能从各种渠道打听到 Wayland 是一个混成器，替代 X 作为显示服务器。 那么 混成器 是个什么东西，桌面系统为什么需要它呢？ 要理解为什么桌面系统需要 混成器 （或者它的另一个叫法， 混成窗口管理器 ( Compositing Window Manager ) ），在这篇文章中我想回顾一下历史， 了解一下混成器出现的前因后果。 首先介绍一下混成器出现前主要的一类窗口管理器，也就是 栈式窗口管理器 ( Stacking Window Manager ) 的实现方式。 本文中所有桌面截图来自维基百科，不具有著作权保护。 早期的栈式窗口管理器 栈式窗口管理器的例子，Windows 3.11 的桌面 我们知道最初图形界面的应用程序是全屏的，独占整个显示器（现在很多游戏机和手持设备的实现仍旧如此）。 所有程序都全屏并且任何时刻只能看到一个程序的输出，这个限制显然不能满足人们使用计算机的需求， 于是就有了 窗口 的概念，有了 桌面隐喻 。 在 桌面隐喻 ( Desktop Metaphor ) 中每个窗口只占用显示面积的一小部分， 有其显示的位置和大小，可以互相遮盖。于是栈式窗口管理器就是在图形界面中实现桌面隐喻的核心功能， 其实现方式大体就是：给每个窗口一个相对的\"高度\"或者说\"远近\"，比较高的窗口显得距离用户比较近， 会覆盖其下比较低的窗口。绘图的时候窗口管理器会从把窗口按高低排序，按照从低到高的顺序使用 画家算法 绘制整个屏幕。 这里还要补充一点说明，在当时图形界面的概念刚刚普及的时候，绘图操作是非常\"昂贵\"的。 可以想象一下 800x600 像素的显示器输出下，每帧 真彩色 位图就要占掉 \\(800 \\times 600 \\times 3 \\approx 1.4 \\text{MiB}\\) 的内存大小，30Hz 的刷新率（也就是30FPS）下每秒从 CPU 传往绘图设备的数据单单位图就需要 \\(1.4 \\times 30 = 41 \\text{MiB}\\) 的带宽。对比一下当时的 VESA 接口 总的数据传输能力也就是 \\(25 \\text{MHz} \\times 32 \\text{bits} = 100 \\text{MiB/s}\\) 左右， 而 Windows 3.1 的最低内存需求是 1MB，对当时的硬件而言无论是显示设备、内存或是CPU， 这无疑都是一个庞大的负担。 于是在当时的硬件条件下采用栈式窗口管理器有一个巨大 优势 ：如果正确地采用画家算法， 并且合理地控制重绘时 只绘制没有被别的窗口覆盖的部分 ，那么无论有多少窗口互相 遮盖，都可以保证每次绘制屏幕的最大面积不会超过整个显示器的面积。 同样因为实现方式栈式窗口管理器也有一些难以回避的 限制 ： 窗口必须是矩形的，不能支持不规则形状的窗口。 不支持透明或者半透明的颜色。 为了优化效率，在缩放窗口和移动窗口的过程中，窗口的内容不会得到重绘请求， 必须等到缩放或者移动命令结束之后窗口才会重绘。 以上这些限制在早期的 X11 窗口管理器比如 twm 以及 XP 之前经典主题的 Windows 或者经典的 Mac OS 上都能看到。 在这些早期的窗口环境中，如果你拖动或者缩放一个窗口，那么将显示变化后的窗口边界， 这些用来预览的边界用快速的位图反转方式绘制。当你放开鼠标的时候才会触发窗口的 重绘事件。 虽然有很多方法或者说技巧能绕过这些限制，比如 Windows XP 上就支持了实时的 重绘事件和不规则形状的窗口剪裁，不过这些技巧都是一连串的 hack ，难以扩展。 NeXTSTEP 与 Mac OS X 中混成器的发展 NeXTSTEP 桌面 转眼进入了千禧年， Windows 称霸了 PC 产业，苹果为重振 Macintosh 请回了 Jobs 基于 NeXTSTEP 开发 Mac OSX 。 NeXTSTEP 在当时提供的 GUI 界面技术相比较于同年代的 X 和 Windows 有一个很特别的地方： 拖动滚动条或者移动窗口的时候，窗口的内容是 实时更新 的，这比只显示一个缩放大小的框框来说被认为更直观。 而实现这个特性的基础是在 NeXTSTEP 中运用了 Display PostScript (DPS) 技术，简单地说，就是每个窗口并非直接输出到显示设备，而是把内容输出到 (Display) PostScript 格式交给窗口管理器，然后窗口管理器再在需要的时候把 PostScript 用软件解释器解释成位图显示在屏幕上。 比起让窗口直接绘制，这种方案在滚动和移动窗口的时候不需要重新渲染保存好的 DPS ， 所以能实现实时渲染。到了实现 Mac OS X 的时候，为了同时兼容老的 Mac 程序 API (carbon) 以及更快的渲染速度，以及考虑到 Adobe 对苹果收取的高昂的 Display PostScript 授权费， Mac OS X 的 Quartz 技术在矢量图的 PDF 描述模型和最终渲染之间又插入了一层抽象： Mission Control 也就是说在 Mac OS X 中无论窗口用何种方式绘图，都会绘制输出成一副内存中的位图交给混成器， 而后者再在需要的时候将位图混成在屏幕上。这种设计使得 2001年3月发布的 Mac OS X v10.0 成为了第一个广泛使用的具有软件混成器的操作系统。 到了 Mac OS X v10.2 的时候，苹果又引入了 Quartz Extreme 让最后的混成渲染这一步发生在 显卡上。然后在 2003年1月公开亮相的 Mac OS X v10.3 中，他们公布了 Exposé (后来改名为 Mission Control) 功能，把窗口的缩略图（而不是事先绘制的图标）并排显示在桌面上， 方便用户挑选打开的窗口。 由于有了混成器的这种实现方式，使得可能把窗口渲染的图像做进一步加工，添加阴影、三维和动画效果。 这使得 Mac OS X 有了美轮美奂的动画效果和 Exposé 这样的方便易用的功能。 或许对于乔布斯而言，更重要的是因为有了混成器，窗口的形状终于能显示为他 梦寐以求 的 圆角矩形 了！ 插曲：昙花一现的 Project Looking Glass 3D 在苹果那边刚刚开始使用混成器渲染窗口的 2003 年，昔日的 升阳公司 ( Sun Microsystems ) 则在 Linux 和 Solaris 上用 Java3D 作出了另一个炫酷到没有朋友的东西，被他们命名为 Project Looking Glass 3D （缩写LG3D，别和 Google 的 Project Glass 混淆呀）。这个项目的炫酷实在难以用言语描述， 好在还能找到两段视频展示它的效果。 Youtube Youku Youtube Youku LG3D 如视频中展示的那样， LG3D 完全突破了传统的栈式窗口管理方式， 在三维空间中操纵二维的窗口平面，不仅像传统的窗口管理器那样可以缩放和移动窗口， 还能够旋转角度甚至翻转到背面去。从视频中难以体会到的一点是， LG3D 在实现方式上与 Mac OS X 中的混成器有一个本质上的不同，那就是处于（静止或动画中）缩放或旋转状态 下的窗口是 可以接受输入事件 的。这一重要区别在后面 Wayland 的说明中还会提到。 LG3D 项目展示了窗口管理器将如何突破传统的栈式管理的框架，可以说代表了窗口管理器的未来发展趋势。 LG3D 虽然以 GPL 放出了实现的源代码，不过整个项目已经停滞开发许久了。 官方曾经放出过一个 预览版的 LiveCD 。可惜时隔久远（12年前了）在我的 VirtualBox 上已经不能跑起来这个 LiveCD 了…… 更为可惜的是，就在这个项目刚刚公开展示出来的时候，乔布斯就致电升阳， 说如果继续商业化这个产品，升阳公司将涉嫌侵犯苹果的知识产权 （时间顺序上来看，苹果最初展示 Exposé 是在 2003年6月23日的 Apple Worldwide Developers Conference ，而升阳最初展示 LG3D 是在 2003年8月5日的 LinuxWorld Expo）。 虽然和乔布斯的指控无关，升阳公司本身的业务也着重于服务器端的业务， 后来随着升阳的财政困难，这个项目也就停止开发并不了了之了。 Windows 中的混成器 Longhorn 中的 Wobbly 效果 Youtube Youku 上面说到， Windows 系列中到 XP 为止都还没有使用混成器绘制窗口。 看着 Mac OS X 上有了美轮美奂的动画效果， Windows 这边自然不甘示弱。 于是同样在 2003 年展示的 Project Longhorn 中就演示了 wobbly 效果的窗口， 并且跳票推迟多年之后的 Windows Vista 中实现了完整的混成器 Desktop Window Manager (DWM) 。整个 DWM 的架构和 Mac OS X 上看到的很像： 和 Mac OS X 的情况类似， Windows Vista 之后的应用程序有两套主要的绘图库，一套是从早期 Win32API 就沿用至今的 GDI（以及GDI+），另一套是随着 Longhorn 计划开发出的 WPF 。 WPF 的所有用户界面控件都绘制在 DirectX 贴图上，所以使用了 WPF 的程序也可以看作是 DirectX 程序。而对老旧的 GDI 程序而言，它们并不是直接绘制到 DirectX 贴图的。首先每一个 GDI 的绘图操作都对应一条 Windows Metafile (WMF) 记录，所以 WMF 就可以看作是 Mac OS X 的 Quartz 内部用的 PDF 或者 NeXTSTEP 内部用的 DPS，它们都是矢量图描述。随后，这些 WMF 绘图操作被通过一个 Canonical Display Driver (cdd.dll) 的内部组建转换到 DirectX 平面，并且保存起来交给 DWM。最后， DWM 拿到来自 CDD 或者 DirectX 的平面，把它们混合起来绘制在屏幕上。 值得注意的细节是，WPF 底层的绘图库几乎肯定有 C/C++ 绑定对应， Windows 自带的不少应用程序 和 Office 2007 用了 Ribbon 之后的版本都采用这套绘图引擎，不过微软没有公开这套绘图库的 C/C++ 实现的底层细节，而只能通过 .Net 框架的 WPF 访问它。这一点和 OS X 上只能通过 Objective-C 下的 Cocoa API 调用 Quartz 的情况类似。 另外需要注意的细节是 DirectX 的单窗口限制在 Windows Vista 之后被放开了，或者严格的说是 基于 WDDM 规范下的显卡驱动支持了多个 DirectX 绘图平面。 在早期的 Windows 包括 XP 上，整个桌面上同一时刻只能有一个程序的窗口处于 DirectX 的 直接绘制 模式，而别的窗口如果想用 DirectX 的话，要么必须改用软件渲染要么就不能工作。 这种现象可以通过打开多个播放器或者窗口化的游戏界面观察到。 而在 WDDM 规范的 Vista 中，所有窗口最终都绘制到 DirectX 平面上，换句话说每个窗口都是 DirectX 窗口。又或者我们可以认为，整个界面上只有一个真正的窗口也就是 DWM 绘制的全屏窗口， 只有 DWM 处于 DirectX 的直接渲染模式下，而别的窗口都输出到 DirectX 平面里（可能通过了硬件加速）。 由 DWM 的这种实现方式，可以解释为什么 窗口模式下的游戏总是显得比较慢 ，原因是整个桌面有很多不同的窗口都需要 DWM 最后混成，而如果在全屏模式下，只有游戏 处于 DirectX 的直接渲染方式，从而不会浪费对游戏而言宝贵的 GPU 资源。 由于 DWM 实现了混成器，使得 Vista 和随后的 Windows 7 有了 Aero Glass 的界面风格， 有了 Flip 3D 、Aero Peek 等等的这些辅助功能和动画效果。 这套渲染方式延续到 Windows 8 之后，虽然 Windows 8 还提出了 Modern UI 不过传统桌面上的渲染仍旧是依靠混成器来做的。 这就结束了？ Linux 桌面呢？ 别急，我写这些文章的目的是想聊聊 Linux 中的混成器，尤其是 X 下现有的混成器和 Wayland ，这篇文章只是个背景介绍。关于 X 中混成器的实现方式和限制，且听我下回分解。","tags":"tech","title":"桌面系统的混成器简史"},{"url":"//farseerfc.me/zhs/stop-write-simply.html","text":"我的 RSS 订阅着一个博客叫 The Old New Thing ，作者是Windows开发者之一的 Raymond Chen ，记录 Windows 中的很多有趣的技术细节。 这个博客中的一些精彩内容还被他写成了一本书，中文名叫《Windows编程启示录》 (ISBN: 978-7-111-21919-4 ) 而英文书名就叫 :cite:`The Old New Thing — Practical Development Throughout the Evolution of Windows` (ISBN: 978-0-321-44030-3 )。 System Message: ERROR/3 ( /home/travis/build/farseerfc/farseerfc/content/life/stop-write-simply.zhs.rst , line 9); backlink Unknown interpreted text role \"cite\". 今天看到这个博客的一篇文章说 你用「简单地」次数越多我越怀疑你不懂这个词的意思 ， 描述他看到某个博客上指导读者打开命令行、执行某条魔法命令、从命令输出抽取参数、 改写配置文件、用魔法命令重启服务，并把这些工作描述为「简单地」。 的确正如 Raymond 指出，一个人觉得简单的事情对别人并不一定是简单的。 搜了一下我自己写的东西，的确很多地方写了「简单」二字，这的确对读者不友好。 从今往后避免用「简单」来描述。","tags":"life","title":"避免在博文中写「简单地」"},{"url":"//farseerfc.me/zhs/travis-push-to-github-pages-blog.html","text":"2015年2月21日更新 上次介绍过 这个博客改换了主题 ， 本以为这个话题可以告一段落了，没想到还能继续写呢。 寄宿在 Github Pages 上的静态博客通常有两种方案，其一是使用 Jekyll 方式撰写，这可以利用 Github Pages 原本就有的 Jekyll支持 生成静态网站。另一种是在 本地 也就是自己的电脑上生成好，然后把生成的 HTML 网站 push 到 Github Pages ，这种情况下 Github Pages 就完全只是一个静态页面宿主环境。 我用 Pelican 生成博客，当然就只能选择后一种方式了。这带来一些不便，比如本地配置 pelican 还是有一点点复杂的，所以不能随便找台电脑就开始写博客。有的时候只是想修正一两个错别字， 这时候必须打开某台特定的电脑才能编辑博客就显得不太方便了。再比如 pelican 本身虽然是 python 写的所以跨平台，但是具体到博客的配置方面， Windows 环境和 Linux/OSX/Unix-like 环境下还是有 些许出入 的。还有就是没有像 wordpress 那样的基于 web 的编辑环境，在手机上就不能随便写一篇博客发表出来（不知道有没有勇士尝试过在 Android 的 SL4A 环境下的 python 中跑 pelican ，还要配合一个 Android 上的 git 客户端 ）。 当然并不是因此就束手无策了，感谢 Travis-CI 提供了免费的 持续整合 ( Continuous integration ) 虚拟机环境， 通过它全自动生成静态博客成为了可能。 关于 Travis-CI 持续整合 原本是 敏捷开发 ( Agile Development ) 或者 极限编程 ( Extreme Programming ) 中提到的概念，大意就是说在开发的过程中， 一旦有微小的变更，就全自动地 持续 合并到主线中， 整合 变更的内容到发布版本里。 这里的 整合 实际上可以理解为 全自动测试 加上 生成最终产品 。 可以看到 持续整合 实际强调 全自动 ，于是需要有一个服务器不断地监听主线开发的变更内容， 一旦有任何变更（可以理解为 git commit ）就自动调用测试和部署脚本。 于是要用持续整合就需要一个整合服务器，幸而 Travis-CI 对 github 上的公开 repo 提供了免费的整合服务器虚拟机服务，和 github 的整合非常自然。所以我们就可以用它提供的虚拟机 为博客生成静态网站。 启用 Travis-CI 自动编译 这一步很简单，访问 https://travis-ci.org/ 并用你的 Github 账户登录， 授权它访问你的账户信息就可以了。然后在 https://travis-ci.org/repositories 里开启 需要编译的 repo ，这样 Travis-CI 就会监视对这个 repo 的所有 push 操作，并且对 每个 push 调用测试了。 在 Travis-CI 中开启对 Github Repo 的持续整合 然后在 repo 的根目录放一个 .travis.yml 文件描述编译的步骤。 暂时 测试的目的下我写的 .travis.yml 大概是下面这样。 language : python python : - \"2.7\" before_install : - sudo apt-add-repository ppa:chris-lea/node.js -y - sudo apt-get update - sudo apt-get install nodejs ditaa doxygen parallel install : - sudo pip install pelican - sudo pip install jinja2 - sudo pip install babel - sudo pip install beautifulsoup4 - sudo pip install markdown - sudo npm install -g less - wget \"http://downloads.sourceforge.net/project/plantuml/plantuml.jar?r=&ts=1424308684&use_mirror=jaist\" -O plantuml.jar - sudo mkdir -p /opt/plantuml - sudo cp plantuml.jar /opt/plantuml - echo \"#! /bin/sh\" > plantuml - echo 'exec java -jar /opt/plantuml/plantuml.jar \"$@\"' >> plantuml - sudo install -m 755 -D plantuml /usr/bin/plantuml - wget https://bintray.com/artifact/download/byvoid/opencc/opencc-1.0.2.tar.gz - tar xf opencc-1.0.2.tar.gz - cd opencc-1.0.2 && make && sudo make install && cd .. - sudo locale-gen zh_CN.UTF-8 - sudo locale-gen zh_HK.UTF-8 - sudo locale-gen en_US.UTF-8 - sudo locale-gen ja_JP.UTF-8 script : - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - mkdir output - env SITEURL=\"farseerfc.me\" make publish Travis-CI 提供的虚拟机是比较标准的 Ubuntu 12.04 LTS ，打上了最新的补丁，并且根据你指定的 语言选项会把相应的解释器和编译器升级到最新版（或者指定的版本）。这里用 python 语言的配置， 所以 python 是 2.7 的最新版并且有 pip 可以直接用。 配置中的 before_install 和 install 的区别其实不大，其中任何一个失败的话算作 build errored 而不是 build fail ，而如果在 script 里失败的话算作 build fail 。 为了编译我的模板，还需要比较新的 less.js ，所以添加了 ppa 装了个最新的 nodejs 并用它装上了 less 。 还从源码编译安装上了最新版的 opencc 1.0.2 ，因为 Ubuntu 源里的 opencc 的版本比较老(0.4)， 然后 doxygen 作为 opencc 的编译依赖也装上了。 其它安装的东西么，除了 pelican 之外都是插件们需要的。以及我还需要生成 4 个语言的 locale 所以调用了 4 次 locale-gen 。由于是比较标准的 Ubuntu 环境，所以基本上编译的步骤和在本地 Linux 环境中是一样的，同样的这套配置应该可以直接用于本地 Ubuntu 下编译我的博客。 写好 .travis.yml 之后把它 push 到 github ，然后 travis 这边就会自动 clone 下来开始编译。 travis 上能看到编译的完整过程和输出，一切正常的话编译结束之后 build 的状态就会变成 passing ，比如 我的这次的build 。 从 Travis-CI 推往 Github 上面的测试编译通过了之后，下一步就是让 travis-ci 编译的结果自动推到 Github Pages 并发布出来。要推往 Github 自然需要设置 Github 用户的身份，在本地设置的时候是把 ssh key 添加到 github 账户就可以了，在编译细节都通过 github repo 公开了的 travis 上 当然不能放推送用的私有 key ，所以我们需要另外一种方案传递密码。 Github 上创建 Personal Access Token 好在 Github 支持通过 Personal Access Token 的方式验证，这个和 App Token 一样可以随时吊销，同时完全是个人创建的。另一方面 Travis-CI 支持加密一些私密数据，通过环境变量的方式传递给编译脚本，避免公开密码这样的关键数据。 首先创建一个 Personal Access Token ，这里需要勾选一些给这个 Token 的权限，我只给予了最小的 public_repo 权限，如侧边里的图。 生成之后会得到一长串 Token 的散列码。 如果你不能使用 travis 命令 2015年2月21日更新 使用 travis encrypt 命令来加密重要数据最方便，不过如果有任何原因， 比如 ruby 版本太低或者安装不方便之类的，那么不用担心，我们直接通过 travis api 也能加密数据。 第一步用这个命令得到你的repo的 pubkey ： curl -H \"Accept: application/vnd.travis-ci.2+json\" https://api.travis-ci.org/repos/<github-id/repo>/key | python2 -m json.tool | grep key | sed 's/.*\"key\": \"\\(.*\\)\"/\\1/' | xargs -0 echo -en | sed 's/ RSA//' > travis.pem 其中的 <github-id/repo> 替换成 github 上的 用户名/repo名， 比如我的是 farseerfc/farseer 。travis api 获得的结果是一个 json ，所以还用 python 的 json 模块处理了一下，然后把其中包含 key 的行用 grep 提取出来，用 sed 匹配出 key 的字符串本身，然后 xargs -0 echo -en 解释掉转义字符，然后删掉其中的 \"<空格>RSA\" 几个字（否则 openssl 不能读）， 最后保存在名为 travis.pem 的文件里。 有了 pubkey 之后用 openssl 加密我们需要加密的东西并用 base64 编码： echo -n 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' | openssl rsautl -encrypt -pubin -inkey travis.pem | base64 -w0 替换了相应的身份信息和token之后，这行得到的结果就是 secure 里要写的加密过的内容。 然后我们需要 travis 命令来加密这个 token ， archlinux 用户可以安装 aur/ruby-travis ，其它用户可以用 gems 安装： $ gem install travis 装好之后，在设定了 Travis-CI 的 repo 的目录中执行一下 travis status ， 命令会指导你登录 Travis-CI 并验证 repo 。正常的话会显示最新的 build 状态。 然后同样在这个 repo 目录下执行： $ travis encrypt 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' 当然上面一行里的相应信息替换为个人的信息，作为这个命令的执行结果会得到另一长串散列码， 把这串散列写入刚才的 .travis.yml 文件： env : - secure : \"long secure base64 string\" 有了这段声明之后， Travis-CI 就会在每次编译之前，设置上面加密的环境变量。 然后在编译脚本中利用这些环境变量来生成博客： script : - git config --global user.email \"$GIT_EMAIL\" - git config --global user.name \"$GIT_NAME\" - git config --global push.default simple - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - git clone --depth 1 https://$GH_TOKEN@github.com/farseerfc/farseerfc.github.io output - env SITEURL=\"farseerfc.me\" make publish after_success : - cd output - git add -A . - git commit -m \"update from travis\" - git push --quiet 这里要注意最后 git push 的时候一定要加上 --quiet ，因为默认不加的时候会把 代入了 $GH_TOKEN 的 URL 显示出来，从而上面的加密工作就前功尽弃了…… 根据 travis 的文档 ， after_success 里写的步骤只有在 script 里的全都完全无错执行完之后才会执行，这正是我们 push 的条件。目前 after_success 的成功与否不会影响到 build 的状态。 具体我用的配置见 这里的最新版 。 在我的 make github 中 调用了 git push 命令，从而执行了 make github 之后就会自动部署到 github 上。 用 Web 编辑并发布静态博客 经过以上设置之后，一切正常的话，每次对主 repo 推送更新的同时， Travis-CI 就会自动 拉来更新然后编译并发布了。可以放置这样的图标 在项目的 Readme.md 中显示编译状态。 这样设置之后的另一个好处就在于可以利用 Github 的 Web 界面编辑文章内容。在 Github 里 编辑和保存之后会自动作为一个 commit 提交，所以也会触发 Travis-CI 的自动编译。 在 Github 的 Web 界面中直接编辑文章内容 以及虽然目前还没有好用的 Github 的手机客户端，不过直接用 Android/iPhone 的浏览器登录 github 并编辑文章的可用性也还不错，所以同样的方式也可以直接在手机上发布博文了。 That is all, happy blogging ~","tags":"tech","title":"用 Travis-CI 生成 Github Pages 博客"},{"url":"//farseerfc.me/zhs/weather-forcast-academic-in-japan.html","text":"最近 mazk 说我 life 分类里的文章太少 ，所以想了想写了这篇。 很多人问过我为什么要来日本留学，嘛原因之一是我英语太差了，相对而言日语比较好。 另一方面，我比较喜欢日本的学术氛围。这个当然是主观体会，而不是客观的评价，只是我 觉得相对于 欧美喜欢研究基础架构技术 ， 日本则偏向实用层面 。 说个具体一点例子，最近看到这篇新闻说 卢布贬值影响中央气象台预报准确率？ ，其中提到： 因为卢布贬值，天气预报的准确率会有所降低 也说道： 不过经我多年的观察，中国中央气象台的预报准确率实在是不怎么样，具体到我生活的地区， 实际天气状况和中国中央气象台预报的出入较大…… 相信不少人也有类似的体会。 天气预报是事关人们生活的重要信息，其准确度对生产生活当然有很大影响。 说到增加天气预报的准确度，人们自然会想到高性能的超级计算机比如 天河二号 ，想到环绕在地球高空的 气象卫星 ，想到遍布世界各地的气象站观测台。想想这么多耗资不菲的高尖端项目被国家投入， 用来改善天气预报的准确程度，看起来这的确是一个困难的科研课题。 话说回来，准确预测气温、气压、湿度、降水概率等等这些事情对于生产生活固然重要， 不过对一般民众而言，天气预报最重要的作用就只是回答 明天我该穿多厚的衣服，出门是否需要打伞 这种问题。一年四季换衣服的时机其实并不那么频繁，气温提升五度或者降低两度这种程度下人们估计也 不能感觉得到，大体上只要根据「昨天穿什么衣服，昨天觉得冷不冷」就能作出判断。另一方面， 出门是否需要打伞 这样的问题的确只能依靠天气预报来回答。 那么解决 出门是否需要打伞 这个问题需要那么高尖端的技术么？ 我所在的大阪大学情报科学研究科有个已经毕业的学长 今城 健太郎 ( いまじょう けんたろう ) 就对此作出了解答。他的专业不是气象预测，而是图像分析处理，纯粹的计算机科学学科。 而他的本科毕业设计就着眼于「仅仅分析气象云图，能否高精度预测降水概率」， 其研究成果，就是一个叫 ないんたん 的降水概率预测系统 。 这个系统有数个会卖萌的Twitter机器人 @ninetan ，每时每刻对 其预测地区的降水情况做播报，同时也有详细的降水概率曲线图对 大阪 ( @ninetan_osaka )， 京都 ( @ninetan_kyoto )， 东京 ( @ninetan_tokyo )， 兵库 ( @ninetan_hyogo )， 和歌山 ( @ninetan_wakayam ) 的各个大学所在校区 两个半小时内做精确的降水概率预测。比如今天晚上大阪大学三个校区的降水概率图如下： 今天晚上大阪大学三个校区的降水概率图 从上面的图可以看出这个系统的预测精度是以 分为单位 的，可以看到 两个半小时内各地的降水量的大小。比如我可以根据这张图看出，我所在的吹田校区 将在 21时35分 开始有微弱的概率下起 0.1mm/h~1mm/h 的毛毛雨，到 22时05分 左右这个降水概率 爬升到最高大约45%，从而作出判断： 我最好在晚上九点左右离开学校回家，避免淋雨。 自从研究室的前辈给我介绍这个天气预报系统开始，我用了它两三年了，直观感觉是 这个系统的预测精度惊人得准确，基本上能接近 《魔法的禁书目录》中的「树形图设计者」 能做的天气预报的程度， 它说何时会下雨就一定下雨，它说何时雨停就一定雨停。同学们出门和回家的时候一般都会 看一眼这个天气预报然后决定是否出门。「啊今天晚上9点开始下雨所以早点回家」 或者「啊还有30分钟雨就停了，再在研究室里留一会儿」。 这只是一个本科生的毕业设计，所以覆盖面小（只有5所大学的十几个校区，只能预测 未来两个多小时的降水概率），不过仅此而已能做到如此的精度以至于实用，实在让我 惊讶。系统的测试之初就有人说： 最近ないんたん予报あたりすぎてないんたんが雨降らせてるんじゃないかという疑惑 — すみのネコ歩き (@sumi_eee) 2011 7月 6日 最近ないんたん预告实在太准了，甚至让人怀疑是不是ないんたん把雨招来的。 不过最近身边的日本人似乎已经把这个系统的准确当作习以为常了，就像日本的电车 掐着秒表准点到站一样，理所当然。 把天气预报这种高尖端的技术做到如此实用的地步，这基本上可以代表我对 日本学术界研究方式和研究目的的总体印象了。 嗯今天就写这么多，9点到了，我要按照天气预报的预测，准时回家了。 ——写于2015羊年除夕夜，9点。","tags":"life","title":"从天气预报谈谈日本的学术氛围"},{"url":"//farseerfc.me/zhs/arch-chrome-remote-desktop.html","text":"透明计算 具体是什么，因为他们没有公开技术细节所以我并不知道，只是看 公开出来的演示视频 ，感觉似乎只要能从手机上远程登录系统桌面，就能算是透明计算了。 如果透明计算真是这个意思，那么我似乎已经用着这个技术很多年了嘛。 Xorg 上常用的远程桌面工具有很多，基于 VNC 协议的、基于NX的和基于 RDP 协议的都能找到， 直接 ssh X forwarding 效果也不错。只是这些方案的一个 不太易用 的地方在于，需要 通过 ip 访问到远程的电脑，所以在跨越 NAT 之类的情况下不太容易使用。 于是今天介绍一个使用方便设置也简单的方法： 通过 chrome-remote-desktop 在 archlinux 上使用远程桌面。这个方案的优势在于，借助 Google 的云端服务器（内部貌似是XMPP协议下的握手） 方便地实现了 NAT 穿透，无论什么网络环境基本都能使用。当然，要支持远程登录， 位于远端的登录的计算机必须一直开着 Chrome Remote Desktop 的后台服务。 Chrome Remote Desktop 插件 Chrome Remote Desktop 的客户端 虽然可能有很多人不知道，不过 Chrome 内包括远程桌面的功能很久了。只是这个功能的界面默认 没有提供界面，要使用它需要安装 Google 官方出品的 remote-desktop 插件 。 装好之后远程桌面的客户端就准备好，可以用来远程访问别的计算机桌面了（无论是 Windows/OS X 还是 Linux 都支持）。并且不光可以自己远程访问自己账户的桌面，还可以远程协助朋友的桌面。 Archlinux 上设置远程登录的服务器 有了客户端之后还要设置一下才能让桌面作为远程登录的服务器。Windows 和 OS X 上 Chrome 会自动下载需要的安装包，无脑下一步就能装好了。Linux上由于发行版众多，桌面配置各异， 所以需要一点手动配置。官方的设置步骤记载在 这里 其中给出了 debian 用的二进制包和 Ubuntu 12.10 上的设置方式，以下设置是参考官方步骤。 首先要安装 chrome-remote-desktop 这个包，这个包实际上对应了 Windows/OS X 上用安装程序 安装的 Remote Desktop Host Controller。 archlinux 上开启了 [archlinuxcn] 仓库的话，可以直接安装打好的包。或者可以从 AUR 装。 $ pacman -Ss chrome-remote-desktop archlinuxcn/ chrome-remote-desktop 40.0.2214.44-1 Allows you to securely access your computer over the Internet through Chrome. 装好之后从会说这么一段话： groupadd：无效的组 ID \"chrome-remote-desktop\" Please create ~/.config/chrome-remote-desktop folder manually, if it doesn't exist, or else you can't use CRD. The needed files are created by the Chrome app, inside the chrome-remote-desktop folder, after Enabling Remote Connections. To {enable,start} the service use systemctl --user {enable,start} chrome-remote-desktop You may need to create a ~/.chrome-remote-desktop-session file with commands to start your session Go to https://support.google.com/chrome/answer/1649523 for more information. 那句报错是 AUR 里打的包还没跟上上游 Google 的更改导致的错误， 首先我们需要把远程登录的用户添加入 chrome-remote-desktop 这个用户组里。 新版本的 chrome remote desktop 提供了一个命令做这个事情，所以执行以下命令就可以了： $ /opt/google/chrome-remote-desktop/chrome-remote-desktop --add-user 然后我们需要手动创建 ~/.config/chrome-remote-desktop 这个文件夹，内容是空的 就好了，随后 chrome 会往这里面放 host#.json 文件用于身份验证。 $ mkdir ~/.config/chrome-remote-desktop 然后我们要创建一个 shell 脚本 ~/.chrome-remote-desktop-session ，这是远程 登录时的 .xinitrc ，内容么就是启动你想在远程登录时用的桌面环境。 这里可以指定一个和你正在登录的 WM/DE 不同的桌面，比如我启动 xfce4： $ cat ~/.chrome-remote-desktop-session # !/bin/bash startxfce4 $ chmod 755 .chrome-remote-desktop-session 接下来需要从 Chrome 的插件里启用远程桌面。打开 Chrome 的 Remote Desktop 插件，这时 应该可以看到一个「启用远程链接」的按钮。 Chrome Remote Desktop 插件中「启用远程链接」的按钮 在撰写本文的时候， Archlinux 官方源里的 chromium 的版本和 aur/google-chrome 的版本尚且还是 40.0.2214.111 ，而 Chrome Web Store 中提供的 Chrome Remote Desktop 的插件的版本是 41.0.2272.41 。虽然通常并不要求两者版本一致，不过貌似最近 Chrome 内部的 Remoting 功能更改了 API 导致可能出问题。如果你找不到 「启用远程链接」的按钮，请尝试一下新版本的 Chrome 比如 google-chrome-dev 。 在这一步启用之后，老版本的 chrome 应该也就能使用远程桌面了。 在32位的 Linux 版本上，最近更新的 Chrome Remote Desktop 插件可能无法正确识别 Host 的版本，具体 参考这个 bug 。 点击「启用远程链接」，设定一个 PIN 密码（不需要很复杂，这里首先有 Google 帐号验证保证只有 你才能访问），然后就能看到这套电脑的 hostname 出现在「我的电脑」列表里。 启用远程链接之后的样子 同时，启用了远程链接之后，可以在刚刚创建的 ~/.config/chrome-remote-desktop 文件夹中找到记录了验证信息的文件。 $ ls .config/chrome-remote-desktop chrome-profile host#8cfe7ecfd6bb17955c1ea22f77d0d800.json pulseaudio#8cfe7ecfd6 然后就可以启动对应的 systemd 用户服务了，如果想自动启动服务要记得 systemctl --user enable ： $ systemctl --user start chrome-remote-desktop.service 如果上面的设置一切正常，就可以看到 chrome-remote-desktop 启动了另外一个 Xorg 执行你 刚刚指定的桌面环境： htop 中看到的 chrome-remote-desktop 启动的另外一个 Xorg 然后就可以试着通过 Remote Desktop 插件登录到这个新开的 Xorg 了： 「远程」登录到新的 XFCE4 Linux 版本的 Chrome远程桌面 和 Windows/ OS X 上的区别 通过上面的设置步骤也可以看出，Linux版本的远程桌面会在后台开一个独立的 X 会话，而不能 复用现在已有的 X 会话。对远程登录的用法而言这还能接受，对远程协助的功能而言有点问题， 因为正在使用的人不能观察协助者做了什么，协助者也不能继续请求协助的人的操作。 当然目前 Chrome 远程桌面的 Linux Host Controller 还只是 beta 版本，官方只测试支持 Ubuntu 12.04 和 12.10 （14.04之后似乎有 Bug ），所以不能要求太多。希望以后能改善吧。 Bonus： 手机远程登录 手机上的 Chrome 远程桌面 App 通过上面的设置就可以从任何一个 Chrome 远程桌面客户端登录刚刚设置的这台电脑了。 因为 Chrome 在三大桌面系统 Windows / OS X / Linux 上都有，所以应该能覆盖大多数桌面 系统了。 除了桌面的 Chrome 之外还有一个客户端是 Android 上的 Chrome 远程桌面 App 经过上面的设置之后，从这个 App 也能看到并登录： 手机远程登录 好啦，开始享受国家自然科学一等奖的透明计算技术吧！","tags":"tech","title":"archlinux 上用 chrome 实现 透明计算 远程登录"},{"url":"//farseerfc.me/zhs/switch-to-farseerfc-dot-me-domain.html","text":"上个月就在 狗爹 ( godaddy ) 上买了个自己的域名 farseerfc.me 准备用在这个 博客上，当时试着转到过这个域名，发现 自定义域名 ( custom domain ) 只支持 http 不支持 https ，想着还要买自己的证书，于是就扔在了一旁。不用自定义域名的话， 放在 github.io 上是可以用 HTTPS 的。 今天在 #archlinux-cn 上受大牛 quininer 和 lilydjwg 点播， 发现 cloudflare 有提供 免费的支持 SSL 的 CDN 服务 赶快去申请了一个，感觉非常赞，于是就换过来了。 设置的方法按照 这篇博文 说的一步步做下来，如它所述，用 CloudFlare 的优点如下： CDN 加速 SSL (HTTPS) 加密 支持 SPDY 协议 支持 IPv6 然后 免费账户 的一些缺点有： CloudFlare 和 github.io 之间的数据不是加密的，因为 github 自定义域名 ( custom domain ) 还不支持使用自己的证书。这也是一开始我没用 自定义域名的原因嘛，这没有办法…… CloudFlare 给免费账户签名的 SSL 证书比较新，不支持一些老的设备和浏览器，比如不支持 老的 XP 系统的 IE 或者 2.x 的 Android。这种情况下没办法只能用没有加密的 HTTP 了。 不支持 HSTS 头 ，所以不能从服务器这边强制浏览器用 HTTPS。当然可以放个 javascript 跳转， 也可以用 HTTPSEverywhere 这种方案。 设置步骤 基本按照默认的选项下一步就可以了。 和那个博主一样我把 安全级别 ( Security profile ) 降到了 Low ，即使是可疑流量也 不会要求输入 CAPTCHA 。 把 SSL 方式开在 Flexible SSL，访客到 CloudFlare 是加密的，而 CloudFlare 到 github.io 是不加密的。 把 CDN 开到了 CDT+Full Optimization ，可以对访问加速。由于是完全静态的博客，没有 动态变化的内容，所以应该比较安全。 服务器设置的一步需要将 域名解析服务器 ( DNS nameservers ) 从狗爹的服务器改到 CloudFlare 的，如下图： 更改狗爹的域名服务器 申请好之后就由 CloudFlare 接管域名解析了，接下来在 CloudFlare 的 DNS 设置添加一条 A 类规则指向 github pages 的 IP 。 更改CloudFlare的DNS规则 等一切都反映到 DNS 服务器上就设置完成了，接下来给 farseerfc.github.io push 一个 CNAME 文件 写上我的域名就可以了。我用 Makefile 配合我的 pelican 配置做这个： publish : rmdrafts cc clean theme [ ! -d $( OUTPUTDIR ) ] || find $( OUTPUTDIR ) -mindepth 1 -not -wholename \"*/.git*\" -delete rm -rf cache echo $( SITEURL ) > content/static/CNAME $( PELICAN ) $( INPUTDIR ) -o $( OUTPUTDIR ) -s $( PUBLISHCONF ) $( PELICANOPTS ) $( MAKE ) rsthtml github : ( cd $( OUTPUTDIR ) && git checkout master ) env SITEURL = \"farseerfc.me\" $( MAKE ) publish ( cd $( OUTPUTDIR ) && git add . && git commit -m \"update\" && git push ) SITEURL = '//' + getenv ( \"SITEURL\" , default = 'localhost:8000' ) STATIC_PATHS = [ 'static' , 'images' , 'uml' , 'images/favicon.ico' , 'static/CNAME' ] EXTRA_PATH_METADATA = { 'images/favicon.ico' : { 'path' : 'favicon.ico' }, 'static/CNAME' : { 'path' : 'CNAME' } } 然后把生成的静态网站 push 到 github 之后可以从项目设置里看到域名的变化： Github 配置好自定义域名之后的变化 最后把Disqus的评论也迁移到新的域名，disqus有方便的迁移向导，一直下一步就可以了。 这样就一切都设置妥当了。 致谢 最后要感谢提供消息的 quininer 和 lilydjwg ，感谢撰写设置步骤的 Jonathan J Hunt ， 感谢 CloudFlare 提供免费 SSL CDN 服务，感谢 Github 提供 方便免费的 Pages 托管。","tags":"tech","title":"换到 farseerfc.me 域名"},{"url":"//farseerfc.me/zhs/redesign-pelican-theme.html","text":"2015年2月14日更新 前言: 新天新地，将一切都更新了 [1] 不知不觉间放任这边长草很久了，从上次 折腾主题 到现在都快三年了， 而从上次 写了篇告白信 到现在也有快两年了。 这期间曾经把主题配色从 Bootstrap 2 默认的 白底黑字改成了让眼睛更舒适的黑底白字，也不过是用 drop-in 的配色方案而已，没有本质上的改进。 洞中一日世上千载，两年里 Bootstrap 已经升上 v3.3 , 而 Pelican 则已经升到 3.5 了。 早就眼馋 Bootstrap 和 Pelican 中的诸多新功能新设计，不过无奈于时间有限只能饱饱眼福。 近日想写的东西越积越多，终于下定决心花了前前后后 两个月 的时间重新设计了一遍 Pelican 的主题，配合一些我觉得有用的插件。于是本博客就变成你们现在看到的样子了。 （以及本篇博文也用了两个月的时间写完，其间还发了几篇别的短文，算是恢复写博客的尝试吧。） 在迈阿密参加 ICSR 2015 的时候 拍到的街边一家叫 Pelican 的旅馆 Bootstrap 3 的新设计 全新的 优先移动设备 ( mobile-first ) 响应式 ( responsive ) 设计。 原本Bootstrap 2虽然有响应式设计， 不过诸多细节不能符合我的需求，最终还是得手工 hack @media 查询去微调。 现在的 优先移动设备 ( mobile-first ) 响应式 ( responsive ) 栅格系统 ( grid system ) 则相对显得科学很多了，也终于能在手持 设备上看起来舒服一些。诸位可以尝试改变窗口宽度，或者在不同的手持设备上打开这个 blog ，体验一下这个页面在不同显示器大小中的效果。如果仍有问题欢迎 发 Issue 给我 。 科学的 导航栏 ( Navbar ) 。 比 Bootstrap 2 那个科学很多了。无论是 保持 ( sticky ) 在上端还是跟着浮动， 或者像这边这样 自动隐藏 都很简单。 更多细节参考 Bootstrap 3 主页 。 Pelican 3.5 的新功能 Python 2 和 Python 3 统一代码： 再没有恼人的 unicode 相关的问题了。这对 blog 系统来说相当重要啊。 而且还能方便切换 pypy 等不同的解释器。 全新的插件系统：非常多功能强大的 插件 等着你。 增强了导入系统：嗯总算可以导入我的中文的 wordpress 博客了。（虽然那边长草更久了……） 站内链接 ：不用 硬编码 ( hard code ) 目标页面的链接了，可以直接写源文件的位置然后让 pelican 处理，这样能简化各种 插件 ( plugin ) 和 主题 ( theme ) 的实现。 更多细节参考 Pelican 文档 。 新的文件夹布局 Pelican 的新文件夹布局 . ├── cache 生成页面的 pickle 缓存 ├── content 读取的全部内容 │ ├── <categories> 按分类存放的文章 │ ├── pages 像 About 这样的固定页面 │ └── static 文章内用到的静态内容 ├── drafts 文章的草稿箱 ├── Makefile 生成用的 makefile ├── pelicanconf.py 测试时用的快速 Pelican 配置 ├── publishconf.py 部署时用的耗时 Pelican 配置 ├── output -> ../farseerfc.github.io ├── plugins -> ../pelican-plugins └── theme -> ../pelican-bootstrap3 之前的博客 仍然留在 github 上，其中的内容完全搬过来了。开始写老博客的时候 Pelican 版本较早，没有形成好的 文件夹布局，导致生成的文章、使用的模板和撰写的内容全都混在一起，非常难以管理， 于是趁改版之际用了新的文件夹布局方式，并分为 4 个 git repo 分别管理历史。 首先是存放 总的博客内容的 repo ， 其布局是如图那样的。这样将生成的静态网站和生成网站用的配置啦内容啦分开之后，顿时清晰了很多。 然后这个内容 repo 中的三个符号链接分别指向三个子 repo（没用 git submodule 管理纯粹是因为偷懒）。 theme 指向 pelican-bootstrap3 ，是我修改过的 pelican 主题。 plugins 指向 pelican-plugins ，由于 plugins 的质量有些参差不齐，其中不少 plugin 都按我的需要做了些许修改，一些是功能改进，另一些则是修bug（比如不少plugin只支持 python 2）。 最后 output 指向 farseerfc.github.io 也就是发布的静态网站啦。 接下来从 主题 和 插件 两个方面介绍一下改版的细节。 主题： Material Design 风格的 Bootstrap 3 上篇 博文 就总结了我为了这个博客寻找了一堆 CSS 框架，并且最终决定用 bootstrap-material-design , DandyDev/pelican-bootstrap3 和 Bootstrap 3 这三个项目结合的方式实现这个模板的主题。 这三个项目都或多或少经过了我的修改，修改后的项目以 pelican-bootstrap3 为基础放在 这里 ，包括 Bootstrap3 样式 和 Material 样式 。 对 Bootstrap 3 的定制 由于架构完善，修改 Bootstrap 3 感觉非常简单。另一方面我在 Web 前端技术上的技能点也不多， 所以修改的地方非常有限，只能按我自己的需求定制而已。 响应式设备的大小 修改了 Bootstrap 3 响应式设备的大小 @screen-xs : 320px ; @screen-sm : 598px ; /* 768px; */ @screen-md : 952px ; /* 992px; */ @screen-lg : 1350px ; /* 1200px; */ @screen-xl : 2030px ; @container-sm : 582px ; /* 750px; */ @container-md : 930px ; /* 970px; */ @container-lg : 1320px ; /* 1170px; */ @container-xl : 1990px ; 首先把 Bootstrap 3 默认适配的几个 响应式设备的大小 改成了我需要的大小。 xs 和 sm 的大小分别按照我的手机屏幕 竖屏 和 横屏 时候的浏览器页面宽度来算， md 是想兼容 Nexus 7 横屏 960 的宽度以及 一个常见上网本 1024 的宽度。 lg 的大小则按照常见的笔记本 1366 宽的屏幕来适配。 这里 Bootstrap 3 支持的设备大小的一个问题是，它最多考虑到 1200 像素宽的显示器，而更宽的 比如 1600、 2048 甚至 2560 像素宽的显示器现在也并不少见，其结果就是页面中左右两侧 有很大的空间被浪费掉了。作为深受这一问题困扰的用户之一，我用 这里介绍的方法 给 bootstrap 增加了一类「 比大更大 ( bigger than bigger ) 」的 xl 响应式设备尺寸，宽度设为支持 2048 像素宽的显示器，具体的修改反映在 variables.less 文件里。 根据宽度自动分栏和瀑布式布局 接下来目标是让主页的文章列表像 Google+ 主页那样根据显示器宽度自动调整分栏，使得宽度不同的 显示器上每个分栏的宽度接近。想要达到的效果是，根据上面定义的屏幕宽度尺寸： xs 用单栏 流动 ( fluid ) 布局 sm 用上方单栏文章列表、下方双栏 侧边栏 ( sidebar ) 固定布局 md 用单栏文章列表、单栏 侧边栏 固定布局 导航栏 ( Navbar ) 文章 侧边栏 底栏 导航栏 文章 侧边栏 1 侧边栏 2 底栏 ( footer ) 导航栏 文章 1 侧边栏 1 文章 2 侧边栏 2 底栏 ( footer ) lg 用双栏文章列表、单栏 侧边栏 固定布局 xl 用三栏文章列表、双栏 侧边栏 固定布局 导航栏 文章 1 文章 3 侧边栏 1 文章 2 文章 4 侧边栏 2 底栏 ( footer ) 导航栏 文章 1 文章 3 文章 5 侧边栏 1 文章 2 文章 4 文章 6 侧边栏 2 底栏 ( footer ) 一开始纯粹用 Bootstrap3 的响应式栅格实现这个分栏布局，结果发现效果不太理想， 因为文章列表和侧边栏的高度是变化的，会导致栅格间留下大片空白。后来改用 这里示范的纯CSS瀑布式布局 实现文章和侧边栏的布局，具体的实现代码在 waterfall.less ，总算达到了想要的布局了。 正文的样式 最最重要的是文章正文的样式。这里我想要达到的效果是，在大屏幕上用更大的字号，让读者 看起来更舒适，同时在小屏幕上用比较小的字号，最终保证基本上「一行」的文字数接近。这个修改 主要针对 .jumbotron ， 用了 不太科学的方式 代码太长就不贴全了。 一些细微的定制 把主题配色改成了现在这样的淡紫色 @brand-primary: darken(#6B5594, 6.5%); ，配合我的头像风格， 这个修改只需要一行。 接着删掉了 .btn 的 white-space: nowrap; 让按钮的文字可以换行， 这也只是一行修改。 2015年1月29日更新 另外我也不太喜欢 Bootstrap 3 默认在手机上的 折叠导航栏 ( collapsed navbar ) ， 折叠之后的操作不够直观方便而且依赖 javascript 所以有 bug …… 于是我把它关掉了， 具体方式是在 variables.less 把 @grid-float-breakpoint 和 @grid-float-breakpoint-max 都设为0就可以了。 对 bootstrap-material-design 的定制 这里定制的地方不多。原样式中一个不太科学的做法是所有 .btn 都强制加上了阴影 效果，这在已经有阴影的环境里用的话非常碍眼，像是 Win9x 风格的厚重睫毛膏。既然可以单独 给每个样式加阴影，于是就把 .btn 强制的阴影去掉了，只保留鼠标悬停之后强调的阴影。 其它定制的细节么就是统一配色风格，修补漏洞错误，微调响应式效果而已，这里不细说。 将以上两者整合在 pelican-bootstrap3 里 Pelican 实现显示源代码按钮 显示源代码按钮借用了 Pelican 配置中自带的 OUTPUT_SOURCES 选项将源文件复制到输出文件夹： OUTPUT_SOURCES = True OUTPUT_SOURCES_EXTENSION = '.rst' 然后在 Makefile 里用 pygmentize 把所有源代码文件着色： find -iname \"*.rst\" | parallel -I@ pygmentize -f html -o @.html @ 最后在按钮按下的时候用 jQuery 载入源代码： <a onclick= \"$.get('{{SITEURL}}/{{article.slug}}.rst.html', function(data){$('#source-code').html(data)});$('#article-content').toggle();$('#source-content').toggle();\" > 虽然难看的 hack 比较多，但是能用！ 虽说 pelican-bootstrap3 是我 fork 出来的，不过由于我修改的地方实在太多，代码看来基本上 接近重写了一份。好在之前有给 pelican 写 bootstrap 2 主题的经验，这次修改算得上驾轻就熟。 可以对比一下 上游作者的博客 和这里的样子体会一下感觉。 具体修改过的地方包括： 套用 bootstrap-material-design 的各个元素样式。 在文章列表模板应用上面提到的 Bootstrap 3 的栅格布局和瀑布式布局。 翻译到多个语言，这里在后面的 i18n-subsite 插件里详述。 套用后面会介绍到的各种插件。 统一侧边栏的样式到一个模板里。 添加 Atom 订阅按钮和 breadcrumb 条。 对正文中出现的插图，添加点击放大的功能，通过 Bootstrap 的 modal 实现。 上面提到的用 这个bootstrap插件 让导航栏自动隐藏。 显示源代码按钮 ，也就是每篇文章信息栏中的 按钮。 插件: 发挥 Pelican 和 reStructuredText 的优势 先列举一下我目前用到的所有插件： PLUGINS = [ \"i18n_subsites\" , \"plantuml\" , \"youku\" , \"youtube\" , 'tipue_search' , 'neighbors' , 'series' , 'bootstrapify' , 'twitter_bootstrap_rst_directives' , \"render_math\" , 'extract_toc' , 'summary' ] 嗯其实不算多。接下来逐一介绍一下这些各具特色的插件。 i18n-subsites 这个插件的目的是创建 国际化 ( internationalization ) 子站 ( subsite ) 。 之前介绍 Pelican 配置的时候就提到过， 原本的 Pelican 就支持一篇文章用多种语言书写，有 lang 属性注明这篇文章使用的 语言，以及 slug 属性注明多语言的翻译之间的关联，换句话说同一篇文章的多个语言 版本应该有相同的 slug 和不同的 lang 。然后原本 Pelican 里对多语言的 实现方式是，首先有一个 主语言 是模板和大部分文章采用的语言，文章列表中会优先列出 用 主语言 撰写的文章，然后从 主语言 的文章链接到别的翻译版本。 很多博客系统和CMS对多语言的支持都是这样的，这种处理方式的缺点也显而易见：作为 主语言 的语言必须足够通用，才能让进来的人找到合适的翻译版本，所以通常 主语言 都是英语。 而这个插件做的事情描述起来很简单：将文章按语言属性分到多个子站，每个子站独立放在各自的文件夹。 比如主站是 https://farseerfc.github.io/ 的话，那么英语的子站就可以是 https://farseerfc.github.io/en/ 。 然后分别对多个子站生成静态页面。具体的实现方式是对 pelican 的页面生成步骤做了拆分： pelican 按正常情况读入文章，生成元信息。 i18n-subsites 针对每个语言，覆盖掉 pelican 的一些选项设置比如路径和 URL ， 分别调用 pelican 的页面生成器按模板生成文章。 对共用的静态内容比如模板的 js 和 css 文件，只在主站中生成，子站中的相应链接全部链回主站。 虽然描述起来简单，但是这个插件可以说最大化利用了 Pelican 的插件系统，实现细节相对比较 复杂，大概是我用的这些插件里面最复杂的了。不夸张的说 Pelican 3.4 支持的新插件 API 和 站内链接功能基本上就是为了配合这个插件的。至于具体它会覆盖哪些 Pelican 的配置，请参阅它的 README.md文件 。 按内容拆分多语言子站的做法只解决了问题的一半，还留下另一半的问题，也即对模板的翻译。 对这个问题， i18n-subsites 提供了两套方案供选择： 用覆盖配置路径的方式让每个子站套用不同的模板。这配置起来简单，但是对模板维护起来有点困难。 用 jinja2 的 i18n 插件，配合 Python 的 gettext 库实现内容翻译。这个方案 配置起来比较复杂 ，但是配置好之后用起来就很方便了。 只是要记得每次修改了模板都要更新翻译，处理 *.po 和 *.mo 文件等等琐碎事宜。 这里我用 jinja2 的 i18n 插件的方式实现了模板的翻译， 各个语言的翻译在这里 ， 然后用 这里的 SCons 脚本 根据内容是否变化自动更新 po 和 mo 文件。 配置好这一套方案之后，还要注意在模板和文章中处理好链接。用 Pelican 3.4 之后推荐的 新的文章间链接的写法以及将 SITEURL 设置为实际 URL 并且关闭 RELATIVE_URLS 之后，应该就不会出没什么问题了（可能还要考虑使用的模板和插件的兼容性，大部分都是写死了 URL 的问题）。 plantuml 嵌入 PlantUML 的示例 PlantUML 是一个Java实现的， 用接近文字描述的语言绘制 UML 图或者 GUI 界面图的工具，非常适合嵌入在 Markdown、 reStructuredText、 AsciiDoc 等这种轻量级标记语言里。 然后么这个 plantuml 插件就是定义了一个新的 reStructuredText 指示符 ( directive ) .. uml:: ，把嵌入的内容提取出来调用 plantuml 命令处理 成图像然后再插入到文章中。 比如示例里的这个 UML 图就是用这样一段简单的文字描述生成的： .. uml :: Object <|-- ArrayList Object : equals() ArrayList : Object[] elementData ArrayList : size() 实际用起来这个插件实现上稍微有点小问题：首先它只支持 python2，所以我把它改写成了 python 2 和 3 都通用的语法；其次它原本输出的文件夹似乎会被 pelican 删掉，所以把它改了个位置； 然后它输出的 URL 也和 i18n-subsites 插件间有不兼容的问题，也顺带修掉了。 修改之后的代码在这里 。 2015年1月30日更新 嵌入 Ditaa 的示例 plantuml 是绘制UML的，除此之外还有一个类似的工具是绘制一般的 流程图 ( diagram ) 的，叫 ditaa ，和 plantuml 非常像，也比较像 reStructuredText 的表格。 于是我也照猫画虎实现了一个 ditaa 的 指示符 ( directive ) ，用起来类似这样： .. ditaa :: +-------------+ | ditaa |-------+ | Diagram | | +-------------+ | PNG out &#94; | | ditaa in | | v +--------+ +--------+----+ /----------------\\ | | --+ Pelican +--> | | | Text | +-------------+ | Beautiful Blog | |Document| | !magic! | | | | {d}| | | | | +---+----+ +-------------+ \\----------------/ : &#94; | Lots of work | +-----------------------------------+ render-math 嵌入公式的示例 示范行内公式 \\(A_\\text{c} = (\\pi/4) d&#94;2\\) . 整行公式 \\begin{equation*} \\alpha{}_t(i) = P(O_1, O_2, \\ldots O_t, q_t = S_i \\lambda{}) \\end{equation*} 这个插件提供在 reStructuredText 中用 LaTeX 语法插入数学公式的能力，定义了 :math: 行内角色 ( role ) 和 .. math:: 指示符 ( directive ) 。 实际工作的渲染库当然是大名鼎鼎的 MathJax ，这个插件 会用 MathJax 的 CDN 载入，所以也没有额外的依赖文件。（只是不知道是否会被国内墙掉， 如果公式显示不正常请 务必 告诉我。） youtube 和 youku 顾名思义，这两个插件分别实现嵌入 youtube 和 youku 视频。其中 youtube 是原本就有的插件， youku 是我照猫画虎抄的。 之前写了一篇 KDE5 Plasma 之跳动卖萌的活动按钮 用到了这两个插件。 tipue_search Tipue search 是一个非常有意思也很强大的搜索工具， 通过 jQuery 实现静态博客的站内搜索功能。实现方式是，它需要你写一个 json 文件，包含 整个网站的 全部 文章的标题和文字内容，然后在搜索的时候读入这个 json 做搜索（是不是有点耍赖）。 虽然听起来会有性能问题，但是应用在小型的静态博客上效果意外很不错，比如本站的所有文章内容 放在一起的 json 也只有 300KiB 左右。 这个插件就是自动在 pelican 输出完全部静态网页之后，调用 beautifulsoup4 从所有网页中抽取出 纯文本，产生这个 json 给 Tipue 用。 neighbors 和 series 这两个插件比较类似也都比较简单， neighbors 提供一篇文章的前后文章信息， 在主题模板里可以用来制作 上一篇 和 下一篇 按钮。 series 提供将多篇文章归类为一个 系列 的支持，当然也需要在 主题模板中定义显示「文章系列」的列表。这两个插件的效果都能在本文末尾，评论区上方的部分看到。 bootstrapify 和 twitter_bootstrap_rst_directives 这两个插件让文章的 正文 套用上 Bootstrap 的样式。 bootstrapify 这个插件实现得比较简单，用 beautifulsoup4 在静态网页的结果里面过滤元素， 对 table , img , embed , iframe , video , object 这几个标签套用上 响应式嵌入对象的类 让他们更美观。 twitter_bootstrap_rst_directives 这个插件则是增加了几个 reStructuredText 的 行内角色 ( role ) 和 指示符 ( directive ) 。 它实现的 行内角色 ( role ) 包括： 用 :kbd: 实现如 Ctrl+C 这样的键盘快捷键， 用 :code: 嵌入代码片段，用 :glyph: 嵌入字符图标。 它实现的 指示符 ( directive ) 包括： labels 行内标签 ， alerts 提示段落 ， panels 嵌入面板 ， 以及还有一个 media 混排图标 。 对其中的 panel 我改写了它在文章正文中的样式，在 lg 或者 xl 的屏幕宽度下，分别用 \\(\\frac{1}{2}\\) 和 \\(\\frac{1}{3}\\) 大小的嵌入面板， 简单实现和正文文字的图文混排。 除此以外我还在 twitter_bootstrap_rst_directives 这个插件里套用它的框架实现了两个额外 的 行内角色 ( role ) ， 分别是 :ruby: ：通过 html5 的 <ruby> 标签实现文字上方的注音（firefox下 不支持 ，会使用文字后的括号显示）， 以及 :html: ：在 行内插入 裸 ( raw ) html 标签（这属于 Markdown 的基本功能，在 reStructuredText 这边由于要考虑多种输出格式于是就比较麻烦了）。这两个 行内角色 ( role ) 的 实现代码在这里 。 2015年2月3日更新 今天又在 twitter_bootstrap_rst_directives 里增加了两个 行内角色 ( role ) 。 一个是 :twi: 用来写 twitter 用户的链接，比如 @farseerfc ，另一个是 :irc: 用来指向 freenode 的 channel ，比如 #yssyd3 。 2015年2月14日更新 今天增加了 .. friend:: 用来写好友链接，以及 fref 用来引用好友， 比如 LQYMGT 这样。 extract_toc 和 summary 最后是这两个有点「名不副实」的插件。 reStructuredText 原本就有自动生成 目录 ( toc ) 的功能，用起来也非常简单，只需要在想要插入目录的地方写一行 .. contents:: ，剩下的都由 docutils 自动生成了。 只是当然这样生成的目录肯定会插入在文章的正文里，而 extract_toc 这个插件的作用就是简单地 把这个目录抽取出来，让模板能在别的地方放置这个目录。比如我这里就把目录放在了一个 panel 里。 然后 Pelican 也原本就有从文章中抽取 总结 ( summary ) 显示在文章列表的功能。 Pelican 原始的实现似乎是按照文字数抽取前半段，不总是适合作为总结。 于是这个 summary 插件的作用其实是允许在正文中以特殊的注释的方式标注哪些部分应该被抽出来作为总结。 summary 这个插件原本的实现只允许抽取一段文字，我又对它的实现做了少许扩充，允许标注多段 文字合并起来作为总结。 2015年1月29日更新 今天在 extract_toc 插件的帮助下，在侧边栏里放了一个 Bootstrap affix 的目录， 它保持在页面的右侧位置不变，方便导航到文章的各个地方。具体实现方法除了 Bootstrap 3 的 Affix 文档 ，还参考了 这篇更详细的说明 。 结语 这个博客的配置都可以在 github 上找到 ，包括用来 自动生成整个博客的 Makefile ，由于比较长，这里就不再贴了。 折腾这个主题前后历时两个月，期间学会了不少东西，也算是不错的收获吧。 现在既然基础打好了，接下来就要开始多写博客了。（希望拖延症不会再犯……） 最近发现除了我的博客之外还有一个网站 Kansas Linux Fest fork 了我的主题，不过他们用了我修改的早期版本，还是原本的 Bootstrap 3 和 bootstrap-material-design 样式。自己草草修改的东西被别人用到果然还是有点小激动呢， 以及接下来不能马马虎虎地写 commit 消息了。 [1] 赛65:17「看哪！我造新天新地」启21:5「我将一切都更新了。」","tags":"tech","title":"重新设计了 Pelican 的主题与插件"},{"url":"//farseerfc.me/zhs/summarize-material-design-css-framework.html","text":"现在这里的界面风格要从 Google 在 I/O 2014 大会 上公布Android L 也即 后来的 Lollipop 说起。 他们在谈论界面设计的时候公布了他们的 设计准则： Material Design ( 中文非官方翻译 )。 当然这只是一些准则，总结并描述了之前在 Web 设计和移动端 App 界面设计方面的一些规范， 并且用材料的类比来形象化的比喻这个准则。关于 Material Design 的更多中文资料可 参考这里 。 看到 Material Design 之后就觉得这个设计风格非常符合直觉，于是想在这边也用上 Material Design。 但是我在 Web 前端科技树上没点多少技能点，所以想找找别人实现好的模板 或者框架直接套用上。在网络上搜索数日找到了这几个： Polymer Paper Elements Polymer Polymer logo Google 官方提供的参考实现应该是 Polymer 中的 Paper Elements 。 由于是 官方参考实现 ，这个框架的确非常忠实地实现了 Material Design 的设计，但是同时 由于它基于 HTML5 Web Components 构建，相关技术我还 不太懂，浏览器兼容性和其余 HTML 技术的兼容性也还不太完善的样子…… 并且对于我这个 Web 开发的半吊子来说，Polymer 只是提供了一组设计组建，没有完善的 响应式 (responsive) 布局支持，也没有 Navbar 这种常见的框架组建，真的要用起来的话还 需要手工实现不少东西。于是口水了半天之后只好放弃……以后可能真的会换用这个，只是目前需要学 的东西太多了。 Angular Material Design AngularJS AngularJS 是 Google 对 Web Components 技术的另一个 尝试。而这额 Angular Material Design 项目 就是基于 AngularJS 构建的Material Design 库啦，同样是 Google 出品所以应该算得上半个 官方实现吧。 相比于 Polymer, AngularJS 算是实用了很多，提供了基于 CSS Flexbox 的布局。有人对这两者的评价是， 如果说 Polymer 代表了 未来趋势 ，那么 AngularJS 就是 眼下可用 的 Web Components 实现了。 只不过同样是因为它是 Components 的框架，对 WebApp 的支持很丰富，大量采用 Ajax 等 JavaScript 技术， 对于我这个静态博客来说仍然稍显高级了……非常担心还不支持 HTML5 的浏览器 比如 w3m 甚至 cURL 对它的支持程度。 于是最终也没有使用它。 Materialize Materialize Materialize 这是一批(自称?)熟悉 Android 上 Material Design 的设计师们新近出炉的框架，试图提供一个接近 Bootstrap 的方案。 最早是在 Reddit 上看到对它的讨论的，立刻觉得这个想法不错。 体验一下官网的设计就可以看出，他们的动画效果非常接近 Polymer 的感觉，响应式设计的布局 也还不错。 只是同样体验一下他们现在的官网就可以看出，他们目前的 bug 还比较多 ，甚至一些 bug 在他们自己的主页上也有显现。 虽然不想给这个新出炉的项目泼凉水，不过看来要达到他们声称的接近 Bootstrap 的易用度还任重而道远…… bootstrap-material-design + bootstrap3 这是我最终选择的方案。这个方案将三个项目组合在了一起，分别是 bootstrap-material-design , pelican-bootstrap3 和 Bootstrap 3 。 Bootstrap 3 想必不用再介绍了，很多网站都在使用这套框架，定制性很高。 bootstrap-material-design 是在 Bootstrap 3 的基础上套用 Material Design 风格 制作的一套 CSS 库，当然也不是很完善并且在不断改进中，一些细节其实并不是很符合我的要求。 最后 pelican-bootstrap3 是用 Bootstrap 3 做的 pelican 模板。 这三个项目或多或少都有点不合我的口味，于是嘛就把 pelican-bootstrap3 fork了一套放在 这里 ，其中还包括我自己改 过的 Bootstrap3 样式 和 Material 样式 ，需要的可以自取。 至于细节上我定制了哪些地方，敬请听下回分解……","tags":"tech","title":"总结一下 Material Design 的 CSS 框架"},{"url":"//farseerfc.me/zhs/from-unbuffered-stdin-to-history-of-linux-tty.html","text":"这篇也是源自于水源C板上板友的一个问题，涉及Linux上的控制台的实现方式和历史原因。因为内容比较长，所以在这里再排版一下发出来。 原帖在这里 。 可以设置不带缓冲的标准输入流吗？ WaterElement(UnChanged) 于 2014年12月09日23:29:51 星期二 问到： 请问对于标准输入流可以设置不带缓冲吗？比如以下程序 #include <stdio.h> #include <unistd.h> int main ( int argc , char * argv []) { FILE * fp = fdopen ( STDIN_FILENO , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 似乎还是需要在命令行输入后按回车才会让 fgets 返回，不带缓冲究竟体现在哪里？ 这和缓存无关，是控制台的实现方式的问题。 再讲细节一点，这里有很多个程序和设备。以下按 linux 的情况讲： 终端模拟器窗口（比如xterm）收到键盘事件 终端模拟器(xterm)把键盘事件发给虚拟终端 pty1 pty1 检查目前的输入状态，把键盘事件转换成 stdin 的输入，发给你的程序 你的程序的 c 库从 stdin 读入一个输入，处理 标准库说的输入缓存是在 4 的这一步进行的。而行输入是在 3 的这一步被缓存起来的。 终端pty有多种状态，一般控制台程序所在的状态叫「回显行缓存」状态，这个状态的意思是: 所有普通字符的按键，会回显到屏幕上，同时记录在行缓存区里。 处理退格( BackSpace )，删除( Delete )按键为删掉字符，左右按键移动光标。 收到回车的时候把整个一行的内容发给stdin。 参考： http://en.wikipedia.org/wiki/Cooked_mode 同时在Linux/Unix下可以发特殊控制符号给pty让它进入「raw」状态，这种状态下按键 不会被回显，显示什么内容都靠你程序自己控制。 如果你想得到每一个按键事件需要用raw状态，这需要自己控制回显自己处理缓冲， 简单点的方法是用 readline 这样的库（基本就是「回显行缓存」的高级扩展，支持了 Home/End，支持历史）或者 ncurses 这样的库（在raw状态下实现了一个简单的窗口/ 事件处理框架）。 参考： http://en.wikipedia.org/wiki/POSIX_terminal_interface#History 除此之外， Ctrl-C 转换到 SIGINT ， Ctrl-D 转换到 EOF 这种也是在 3 这一步做的。 以及，有些终端模拟器提供的 Ctrl-Shift-C 表示复制这种是在 2 这一步做的。 以上是 Linux/unix 的方式。 Windows的情况大体类似，只是细节上有很多地方不一样： 窗口事件的接收者是创建 cmd 窗口的 Win32 子系统。 Win32子系统接收到事件之后，传递给位于 命令行子系统 的 cmd 程序 cmd 程序再传递给你的程序。 Windows上同样有类似行缓存模式和raw模式的区别，只不过实现细节不太一样。 strace查看了下 WaterElement(UnChanged) 于 2014年12月10日21:53:54 星期三 回复： 感谢FC的详尽解答。 用strace查看了下，设置标准输入没有缓存的话读每个字符都会调用一次 read 系统调用， 比如输入abc： read(0, abc \"a\", 1) = 1 read(0, \"b\", 1) = 1 read(0, \"c\", 1) = 1 read(0, \"\\n\", 1) = 1 如果有缓存的话就只调用一次了 read 系统调用了： read(0, abc \"abc\\n\", 1024) = 4 如果想感受一下 raw mode 没错，这个是你的进程内C库做的缓存，tty属于字符设备所以是一个一个字符塞给你的 程序的。 如果想感受一下 raw mode 可以试试下面这段程序（没有检测错误返回值） #include <stdio.h> #include <unistd.h> #include <termios.h> static int ttyfd = STDIN_FILENO ; static struct termios orig_termios ; /* reset tty - useful also for restoring the terminal when this process wishes to temporarily relinquish the tty */ int tty_reset ( void ){ /* flush and reset */ if ( tcsetattr ( ttyfd , TCSAFLUSH , & orig_termios ) < 0 ) return - 1 ; return 0 ; } /* put terminal in raw mode - see termio(7I) for modes */ void tty_raw ( void ) { struct termios raw ; raw = orig_termios ; /* copy original and then modify below */ /* input modes - clear indicated ones giving: no break, no CR to NL, no parity check, no strip char, no start/stop output (sic) control */ raw . c_iflag &= ~ ( BRKINT | ICRNL | INPCK | ISTRIP | IXON ); /* output modes - clear giving: no post processing such as NL to CR+NL */ raw . c_oflag &= ~ ( OPOST ); /* control modes - set 8 bit chars */ raw . c_cflag |= ( CS8 ); /* local modes - clear giving: echoing off, canonical off (no erase with backspace, &#94;U,...), no extended functions, no signal chars (&#94;Z,&#94;C) */ raw . c_lflag &= ~ ( ECHO | ICANON | IEXTEN | ISIG ); /* control chars - set return condition: min number of bytes and timer */ raw . c_cc [ VMIN ] = 5 ; raw . c_cc [ VTIME ] = 8 ; /* after 5 bytes or .8 seconds after first byte seen */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 0 ; /* immediate - anything */ raw . c_cc [ VMIN ] = 2 ; raw . c_cc [ VTIME ] = 0 ; /* after two bytes, no timer */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 8 ; /* after a byte or .8 seconds */ /* put terminal in raw mode after flushing */ tcsetattr ( ttyfd , TCSAFLUSH , & raw ); } int main ( int argc , char * argv []) { atexit ( tty_reset ); tty_raw (); FILE * fp = fdopen ( ttyfd , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 终端上的字符编程 vander(大青蛙) 于 2014年12月12日08:52:20 星期五 问到： 学习了！ 进一步想请教一下fc大神。如果我在Linux上做终端上的字符编程，是否除了用ncurses库 之外，也可以不用该库而直接与终端打交道，就是你所说的直接在raw模式？ 另外，终端类型vt100和linux的差别在哪里？为什么Kevin Boone的KBox配置手册里面说必 须把终端类型设成linux，而且要加上terminfo文件，才能让终端上的vim正常工作？term info文件又是干什么的？ Linux控制台的历史 嗯理论上可以不用 ncurses 库直接在 raw 模式操纵终端。 这里稍微聊一下terminfo/termcap的历史，详细的历史和吐槽参考 Unix hater's Handbook 第6章 Terminal Insanity。 首先一个真正意义上的终端就是一个输入设备（通常是键盘）加上一个输出设备（打印 机或者显示器）。很显然不同的终端的能力不同，比如如果输出设备是打印机的话，显 示出来的字符就不能删掉了（但是能覆盖），而且输出了一行之后就不能回到那一行了 。再比如显示器终端有的支持粗体和下划线，有的支持颜色，而有的什么都不支持。 早期Unix工作在电传打字机（TeleTYpe）终端上，后来Unix被port到越来越多的机器上 ，然后越来越多类型的终端会被连到Unix上，很可能同一台Unix主机连了多个不同类型 的终端。由于是不同厂商提供的不同的终端，能力各有不同，自然控制他们工作的方式 也是不一样的。所有终端都支持回显行编辑模式，所以一般的面向行的程序还比较好写 ，但是那时候要撰写支持所有终端的「全屏」程序就非常痛苦，这种情况就像现在浏览 器没有统一标准下写HTML要测试各种浏览器兼容性一样。 通常的做法是 使用最小功能子集 假设终端是某个特殊设备，不管别的设备。 水源的代码源头 Firebird2000 就是那样的一个程序，只支持固定大小的vt102终端。 这时有一个划时代意义的程序出现了，就是 vi，试图要做到「全屏可视化编辑」。这在 现在看起来很简单，但是在当时基本是天方夜谭。 vi 的做法是提出一层抽象，记录它所需要的所有终端操作，然后有一个终端类型数据库 ，把那些操作映射到终端类型的具体指令上。当然并不是所有操作在所有终端类型上都 支持，所以会有一堆 fallback，比如要「强调」某段文字，在彩色终端上可能 fallback 到红色，在黑白终端上可能 fallback 到粗体。 vi 一出现大家都觉得好顶赞，然后想要写更多类似 vi 这样的全屏程序。然后 vi 的作 者就把终端抽象的这部分数据库放出来形成一个单独的项目，叫 termcap （Terminal Capibility），对应的描述终端的数据库就是 termcap 格式。然后 termcap 只是一个 数据库（所以无状态）还不够方便易用，所以后来又有人用 termcap 实现了 curses 。 再后来大家用 curses/termcap 的时候渐渐发现这个数据库有一点不足：它是为 vi 设 计的，所以只实现了 vi 需要的那部分终端能力。然后对它改进的努力就形成了新的 terminfo 数据库和 pcurses 和后来的 ncurses 。 然后 VIM 出现了自然也用 terminfo 实现这部分终端操作。 然后么就是 X 出现了， xterm 出现了，大家都用显示器了，然后 xterm 为了兼容各种 老程序加入了各种老终端的模拟模式。不过因为最普及的终端是 vt100 所以 xterm 默 认是工作在兼容 vt100 的模式下。然后接下来各种新程序（偷懒不用*curses的那些） 都以 xterm/vt100 的方式写。 嗯到此为止是 Unix 世界的黑历史。 知道这段历史的话就可以明白为什么需要 TERM 变量配合 terminfo 数据库才能用一些 Unix 下的全屏程序了。类比一下的话这就是现代浏览器的 user-agent。 然后话题回到 Linux 。 大家知道 Linux 早期代码不是一个 OS， 而是 Linus 大神想 在他的崭新蹭亮的 386-PC 上远程登录他学校的 Unix 主机，接收邮件和逛水源（咳咳 ）。于是 Linux 最早的那部分代码并不是一个通用 OS 而只是一个 bootloader 加一个 终端模拟器。所以现在 Linux 内核里还留有他当年实现的终端模拟器的部分代码，而这 个终端模拟器的终端类型就是 linux 啦。然后他当时是为了逛水源嘛所以 linux 终端 基本上是 vt102 的一个接近完整子集。 说到这里脉络大概应该清晰了， xterm终端类型基本模拟 vt100，linux终端类型基本模 拟 vt102。这两个的区别其实很细微，都是同一个厂商的两代产品嘛。有差别的地方差 不多就是 Home / End / PageUp / PageDown / Delete 这些不在 ASCII 控制字符表里的按键的映射关系不同。 嗯这也就解释了为什么在linux环境的图形界面的终端里 telnet 上水源的话，上面这些 按键会错乱…… 如果设置终端类型是 linux/vt102 的话就不会乱了。在 linux 的 TTY 里 telnet 也不会乱的样子。 写到这里才发现貌似有点长…… 总之可以参考 Unix hater's Handbook 里的相关历史评论和吐槽，那一段非常有意思。","tags":"tech","title":"从非缓冲输入流到 Linux 控制台的历史"},{"url":"//farseerfc.me/en/jumping-kde5-plasma-activities-button.html","text":"I found this when using activities under KDE5 today. One can drag the activities button out of the edge of the screen, then it will jump back and forth at the edge. Here is a video: Youtube Youku Of course you can drag it back, so it is not a serious problem. It is just so cute that I had to note this. By comparison, the jumping window in Gnome3 is far worse than this: Youtube Youku BTW, I saw another cute translation error of mute screen in KDE5: KDE5のミュート画面の中国語翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","title":"Jumping KDE5 Plasma Activities Button"},{"url":"//farseerfc.me/jp/jumping-kde5-plasma-activities-button.html","text":"今日 KDE5 Plasma の「活動」を切り替えている際に偶々この現象を発見しました。 この活動ボタンを画面の外に持ち出すと、デスクトップの縁で踊り出します。 ビデオはこちらに： Youtube Youku 勿論画面の中に引っ張ってきたら問題はなくなるので、大したバグではない。単なる面白い現象です。 この前に Gnome3 にも画面がおかしくなるバグがありました。それを比べて KDE5 のほうはよぽと増しと思います。 Youtube Youku ちなみにですが、KDE5 Plasma のミュート画面の中国語翻訳もなかなか面白いミスがございます： KDE5のミュート画面の中国語翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","title":"KDE5 Plasma の踊る活動ボタン"},{"url":"//farseerfc.me/zhs/jumping-kde5-plasma-activities-button.html","text":"今天尝试 KDE5 Plasma 的活动的时候无意间发现这个现象。 只要把活动按钮拖出桌面，它就会在桌面边缘来回跳动。 视频如下： Youtube Youku 当然你可以把它再拖回来，所以这个问题还无伤大雅，只是卖萌。 比比之前 Gnome3 那个跳动的界面真是好太多了： Youtube Youku 顺便，今天还看到一个卖萌的 KDE5 Plasma 静音图标的翻译： KDE5のミュート画面の中国语翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","title":"KDE5 Plasma 之跳动卖萌的活动按钮"},{"url":"//farseerfc.me/en/marry-me.html","text":"After rendering Above is a image, the playable version is below: * Use WASD←→ to move，need WebGL support","tags":"life","title":"Will You Marry Me?"},{"url":"//farseerfc.me/jp/marry-me.html","text":"画像はこのように 上のは飾りだけ、遊べるのはこれ： * WASD←→ で移動する，WebGL が必要","tags":"life","title":"嫁になってくれませんか？"},{"url":"//farseerfc.me/zhs/marry-me.html","text":"渲染的样子 可以玩的是下面这个： * 用 WASD←→ 移动，需要 WebGL 支持","tags":"life","title":"嫁给我好么"},{"url":"//farseerfc.me/zhs/icse2012.html","text":"June 6 Keynote 1 没怎么听懂，只记得讲到了finance is not money但是没听懂这个和软件有什么关系。 Cost Estimation for Distributed Software Project 讲到他们试图改善现有的模型去更精确地评估软件开发的开销。 他们会给PM建议之前的项目的历史数据，然后对于新项目，他们建议历史上已有 的项目的数据，从而帮助PM得到更精确的评估。他们试图尽量减少项目评估对PM 的经验的需求，从而帮助即使经验很少的PM也能准确评估项目的开销。 他们的观点： Context-specfic solutions needed! 我们需要更上下文相关的解决方案！ Early user paticipation is key! 早期用户的参与是关键 Characterizing Logging Practices in Open-Source Software Common mistakes in logging messages 在日志记录中容易犯的错误 他们学习了历史上的log记录，然后试图找到重复修改的输出log的语句，确定log 中存在的问题。他们首先确定修改是事后修改。 通常的修改的比例（9027个修改） 45% 静态文本 27% 打印出的变量 26% 调试等级verbosity 2% 日志输出的位置 他们发现有调试等级的变化，是因为安全漏洞之类的原因，或者在开销和数据 之间的权衡。 大多数对log的变量的修改都是为了增加一个参数。他们之前的LogEnhancer是为了 解决这个问题而提出的，通过静态检查，提醒程序员是否忘记了某个参数 对text的修改是因为要改掉过时的代码信息，避免误导用户。 他们的实验是采用了基于code clone 的技术，找到所有log语句，然后找不一致 的clone，然后自动提出建议。 Combine Functional and Imperative Pgrm for Multicore Sw: Scala & Java 趋势：到处都是多核，但是并发程序呢？ 他们研究的对象是Scala和Java，因为可以编译后确认JVM字节码的语义。 Java: 共享内存 显示创建的线程 手动同步 Wait/Notify机制 Scala: 高阶函数 Actors, 消息传递 lists, filters, iterators while 共享状态, OO import java.* 能从java导入任何库 auto type inferance 自动类型推导 实验的参与者都经过4周的训练，实验项目是工业等级的开发项目 结果： scala 的项目平均比java多花38%的时间，主要都是花在Test和debug上的时间。 程序员的经验和总体时间相关，但是对test和debug没有显著影响。 scala的为了让编程更有效率的设计，导致debug更困难。比如类型推导，debug 的时候需要手动推导，来理解正在发生什么。 scala的程序比java小，中位数2.6%，平均15.2% 性能比较： 单核：scala的线性程序的性能比java好 4核： scala 7s @ 4 threads java 4si @ 8 threads median 83s scala 98s java 32core: best scala 34s @ 64 threads 结论 java有更好的scalability scala类型推导 45%说对携带码有帮助 85%说导致程序错误 调试 23%认为scala简单 77%认为java简单 multi-paradigram are better Sound Empirical Evidence in Software Testing Test data generation 测试数据自动生成 Large Empirical Studies - not always possible For open source software - big enough Identifing Linux Bug Fixing Patch current practice: manual Current research: keywords in commits link bug reports in bugzilla Try to solve classification problem issue pre-identified post-identified data from commit log feature extraction text pre-process stemmed non-stop words model learning research questions Active Refinement of Clone Anomaly Reports motivating code clones, clone groups clone used to detect bugs anomaly : inconsistent clone group many anomaly clone are note bug, high false positive approach reorder by sorted bug reports June7 Keynotes 2: Sustainability with Software - An Industrial Perspective Sustainability Classic View: Idenpendent view with overlap Social Environment Economic Nested viw Environment Social Economic Triple bottom line economic -global business, networks , global econ env natural res, climate change, population grow social awareness, connectivity, accountability Green IT reduce IT energy more than 50% cooling - doing nothing mini e-waste: not properly recycled 80% in EU 75% in US foster dematerialization In-Memory Technology: Expected Sustainable Benefits What can we do? consider all software lifecycle phases in your design avoid energy expensive behavior in your codes design lean architectures Green by IT 2% green IT 98% green IT On How Often code is cloned across repositories Line based hashing code clone detection never do anything harder than sorting hashing a window of 5 lines of normalized (tokenized) code, dropping 3/4 of the hashing 把ccfinder一个月的工作缩短到了3, 4天。没有比较presion和recall。 14% type1 16% type2 17% type3 (not really type2) Graph-based analysis and prediction for sw evolution graph are everywhere internet topology social net chemistry biology in sw - func call graph - module dependency graph developer interaction graph - commit logs - bug reports experiment 11 oss, 27~171 release, > 9 years predictors NodeRank similar to pagerank of google measure relative importance of each node func call graph with noderank compare rank with severity scale on bugzilla correlation between noderank and BugSeverity func level 0.48 ~ 0.86 varies among projects. model level > func level ModularityRatio cohesion/coupling ratio: IntraDep(M)/InterDep(M) forecast mantencance effort use for identify modules that need redesign or refactoring EditDistance bug-based developer collaboration graphs ED(G1,G2)=|V1|+|V2|-2|V1交V2|+|E1|+|E2|-2|E1交E2| use for release planning resource allocation graph metrics graph diameter average node degree indicates reuse clustering coefficient assortativity num of cycles Conclusion \"Actionable intelligence\" from graph evolution studie 11 large long-live projs predictors identify pivotal moments in evolution What make long term contributors: willingness and opportunity in OSS OSS don't work without contributors form community mozilla (2000-2008) 10&#94;2.2 LTC <- 2 order -> 10&#94;4.2 new contributors <- 3.5 order -> 10&#94;7.7 users gnome (1999-2007) 10&#94;2.5 LTC <- 1.5 order -> 10&#94;4.0 new contributors <- 3.5 order -> 10&#94;6.5 users approach read issues of 20 LTC and 20 non-LTC suvery 56 (36 non-LTC and 20 LTC) extract practices published on project web sites summeray Ability/Willingness distinguishes LTCs Environment macro-climate popularity micro-climate attention bumber of peers performance of peers regression model newcomers to LTC conversion drops actions in first month predicts LTCs 24% recall 37% precision develop of auxiliary functions: should you be agile? a empirial assessment of pair programming and test-first programming can agile help auxiliary functions? experiment pair vs solo test-first vs test-last students vs professors research questions r1: can pair help obtain more correct impl r2: can test-first r3: dst test1 encourage the impl or more test cases? r4: does test1 course more coverage result test-first higher coverage non change with correctness pair improve on correctness longer total programming time Static Detection of Resource Contention Problems in Server-side script Addressed the race condition of accessing database or filesystem of PHP Amplifying Tests to Validate Exception Handling Code 异常处理的代码不但难写，而且难以验证。各种组合情况难以估计，尤其是手机 系统上。 A tactic-centric approach automating traceability of quality concerns tactic traceability information models","tags":"life","title":"ICSE 2012"},{"url":"//farseerfc.me/en/msr2012.html","text":"Mining Software Repository 2012 @ ICSE I participated MSR of this year. We came to University of Zurich early in the morning. The registration got something wrong when it seems that Swisses cannot tell the difference among Asians so that name cards of 3 Chinese with family name of Yang are misplaced. And also the organization field of Hotta was \"Japan, Japan\", as if he represented the Japan. MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) The first talk was the keynote given by Mrs Zhang from MSR(MicroSoft Research @ Asia), so it turned out to be MSR gave keynote of MSR. The talk was about Software Analysis and their clone detection tool called XIAO. XIAO was a clone detector developed by MSRA which can be used as a plugin for Microsoft Visual Studio. XIAO has two part, or system state: the statics state analysis all the clones which didn't consider the running time, while the dynamic state need real time response. The thing I need to develop for Samsung is something like dynamic mode. I wanted to know more about the internal details about XIAO but the talk was finished there. Towards Improving BTS with Game Mechanisms The contents of this talk is very much like this blog: http://www.joelonsoftware.com/items/2008/09/15.html The talk discussed whether the same game mechanism can be applied to the things like issue tracking or similar. From my point of view, it is useless to use game mechanism in this situation. The reason that stackoverflow can success lies on that they just captured the use of fade system in opensource community, as all hackers like to be approved as great hacker, as what is happening in Wikipedia. Whether the same theory can be applied in issue tracking systems inside a internal company is questionable. Although MSDN has basic the same structure as Wikipedia, the content of MSDN and Wikipedia have different involvement of users. So I myself didn't approve this research. GHTorrent They slide of this talk can be found from here: http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Main part of data of Github, namely the hosted code, are already exposed as git repos, and wiki of repos are stored in git repo. So the aim of this project is to expose other data such as issues, code comments, etc. The project access github api and fetch the needed data as distributed system in order to overcome the limitations of the github api. The project will provide download history as torrents. The json data from github api is stored as bson in MongoDB and the parsed data is stored in MySQL with schema. From my point of view, it will be better if the format of data can be uniformed and all data are stored in the git repo as wiki pages. As the history stored in git repo is more nature, and using git blame to trace author of code comments should also be more useful. Of course it is harder to read and write the raw data of git as we need more understanding of the internal format of git. Maybe only people from github can do this. Topic Mining I can not understand the two parameters, DE, AIC, used in this research, study this later. The experiment target of this research are Firefox, Mylyn and Eclipse. They are trying to analysis the identifiers and comments from source codes in software repos and find the relationship between topics and bugs, like what kind of topics are more likely to contain buggy codes. The result of this research is not so clear. Such as it said that the core functions of Firefox have more bug reports, but it said no reason about this. Maybe this only means that the core features are well tested, rather than that the core features are more buggy. But the slides showed by author are pretty and easy to understand. The evolution of software The keynote talk of the second day. It is about how should we combine the social media with software development. Maybe this is the reason why Github succeeded. In the talk she told about accessing tags, uBlogs, blogs etc. directly from Integrated Development Environments, or should we need cloud IDE such as Cloud9. Do Faster Releases Improve Software Quality? Used Firefox as example. The conclusion is that faster releases will lead to more bugs and more frequent crash, but bugs are get fixed more quickly and user will switch to new released more quickly. Security vs Performance Bugs in Firefox Performance bugs are regression, blocks release. Some of my thoughts Separation of commits based on Semantic analysis The user of some tools (such as git) are not following the design purposes of these tools which brings some difficulty to MSR. For example git has a prefect branch system, so it is desired for users of git to commit per topic. Commit per topic means that user send a commit for a single implementation of a feature or a bug fix, etc. If it is difficult to contain all modifications in a commit, then it should be in a separate branch and merged into master branch. But actually user tends to send very large commits, that contains many logical features, and they can not predict to open a new branch until a few commits. Maybe this is not the fault of the user of tools, this is the tools that are not smart enough. We should separate the commits according to the semantic topics inside a commit. About the slide systems used today The study with title Incorporating Version Histories in Information Retrieval Based Bug Localization used the slides made by beamer. It contains many equations, used many overlays are iterations, with few figures, is a typical beamer slide. It also used mindmap very well. There are at least 3 slides that are made by beamer today. The study with title Towards Improving Bug Tracking Systems with Game Mechanisms presented with prezi. It have many pictures and many transitions. But because of it is made by prezi, there are no headers and footers so no page numbers and section titles etc. This is not so convenient in such a official occasions because people need to refer to the page number in question session. There are at lease 6 presents used Apple Keynote. It is really difficult to tell the difference between slides made by PowerPoint and Keynote. 2 of them used the default theme of keynote. The rest are using PowerPoint. Mrs Zhang from Microsoft used PowerPoint but her slides looks like beamer very much such as the usage of footer and header and overlays. If these are made by PowerPoint that will involve many manually operations. It is worth to mention that the slides of a study with title Green Mining: A Methodology of Relating Software Change to Power Consumption are all badly drawn hand paintings. The effect of these slide are well received, they are green and clean and cute. You can refer to the following animation for the effect but it is not exactly the same version with what we saw : http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv Microsoft is MEANING It is not a news. But Microsoft is the sponsor of Mining Challenge, and the prize of this challenge will be Xbox and Kinect and the topic of this year is: Mining Android Bug I see what you are doing there Microsoft ......","tags":"life","title":"MSR 2012 @ ICSE"},{"url":"//farseerfc.me/jp/msr2012.html","text":"Mining Software Repository 2012 @ ICSE 今年のMSRを参加しました、会場はチューリッヒ大学にあります。朝早く大学に 着いて、登録するときちょっと事情をありました。スイス人は明らかに中国人 の名前をわからないから、３つの中国からの楊（Yang）の名札を間違えた。そ して堀田先輩の名札に\"Japan, Japan\"になって、日本代表になった。 MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) まず一番目のKeynoteはマイクロソフトアジア研究院(MicroSoft Research @ Asia ,MSR Asia)のZhang氏が発表する、こうしてMSRがMSRに発表するになった。 Zhangの発表はSoftware AnalysisとXIAOの２つの紹介です。XIAOはマイクロソフト が開発したCode Clone Detector、ある会社が私達に任せるのもこのようなシステム です。もっと詳しく知りたいが、実装に関わるものは言ってなかった。 Towards Improving BTS with Game Mechanisms これの内容は基本的にこのブロクに書いています： http://www.joelonsoftware.com/items/2008/09/15.html 同じ理論をIssue Trackingとかに応用できるかを言いました。個人的にこれは 意味ない気がします。stackoverflowの成功はOpen Software Communityにもと もとある名誉システムを具現化したですから、それを会社の中に応用するのは 難しい気がする。 GHTorrent この研究のスライドはこちらに： http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Githubの主なデータはコード、それは既にgitから アクセスできます、wikiはgitとして保存しているからそれも含まれている。 ですからこのプロジェクトの目的は他のデータを表せる、つまりissues, commit commentsなど。このプロジェクトはgithub apiを通じて、分布システムとして apiの制限を超える、そしてtorrentの形で歴史をdownloadできます。元のデータ はbsonとしてMongoDBの保存して、Schemaを追加したデータはMySQLに保存する。 わたしの意見では、データをgitのrepoの形で保存するの方がいいかもしれない。 今のwikiのように、そしてgitoliteも全てのデータをgit自身の中に保存している。 The evolution of software 二日目のkeynotes, social mediaをソフトウェア開発に巻き込めるについて 話しました。もしかしてこれはGithubの成功の理論かもしれない。IDEの中に social mediaのアクセスを欲しいと言いました。 Do Faster Releases Imporve Software Quality? Firefoxを例として研究しました。 結論としては、早い発行はbugを多く持たされ、crashがもっと頻繁になるが、 bugの修復も早くなって、そしてユーザー側はもっと早く新しい発行に移動する ことをわかりました。 Security vs Performance Bugs in Firefox 性能に関するbugはregression テストが要る、そして発行を阻止する。 思いつき topicに基づいてcommitの分析と分割 よく使うツール（例えばgit）のユーザーはツールの設計者の意図を従って ツールを使うことはない、設計者が思った用途以外にも使っていることが多い、 それはMiningに対しては色々困難を持たされています。例えばgitには完璧な branch機能がある、通常にgitのユーザーが一つのcommitに一つの機能を実現 してほしい、例としてはbugの修復とか、機能の追加とか。それは難しいなら branchを使って、一連のcommitを一つのbranchになって、一つのbranchに一つ の機能を実現してほしい。それなのに、現状では、沢山の編集を一つのcommit に含まれていて、後の管理とか情報の収集とかが困難になってしまう。 それはユーザーの悪いと思わない、ツールの方がもっと頑張らないとユーザー は正しく使えない。もしcommitの時、自動的にcommitの内容を分析して、 その中にtopicによって分けて、ユーザーに推薦するのをてきたらいいなぁ、 と思っています。このように一つのcommitを多くに分割したら、commitの履歴 をもっと見やすくなって、続いて分析とかも便利になるはずです。 今回に皆使っているslideのシステム タイトルは Incorporating Version Histories in Information Retrieval Based Bug Localization の人が使っているのはbeamerです。数式が多くて、 overlayも多くて，iterateも多い、図だけ少ない、典型的にbeamerに作れそうな スライドです。mindmapの使いもうまい。今日の一日に少なくとも3個のslideは beamerで作られています。 タイトルは Towards Improving Bug Tracking Systems with Game Mechanisms の人はpreziを使いました、図が多くて、transitionも多い。但しスライド としては必要なページ数とかがなくて、このような国際会議の場合にはもっと 工夫をした方がいいかもしれな。 少なくとも六人以上はAppleのKeynoteをつかていまう。Keynoteによる作った スライドはPowerpointのになかなか区別しがたいですが、その中に二人は defaultのthemeを使ったからわかります、他の人はPPTに決してありえない アニメションを使っていますから、多分keynote。 残りは勿論Powerpointです。MSRAの張さんが作ったのはpowerpointなんですけど、 すごくbeamerの感じがします、例えばheaderとfooterの使い方とか、overlay 見たいのものでページのitemを一つずつ展開するとか。それらを全部powerpoint で作るのは相当手間がかかりそうです。 ちなみに言いたいのは一つタイトルは Green Mining: A Methodology of Relating Software Change to Power Consumption のスライドは全部 下手 な手描きの漫画で表せている、火狐のアイコンさえ手描きする、効果は意外に 評判がいい。省エネでグリンで環境にいいで可愛らしい。具体的な効果は下の リンクから見えます、現場で見たのは別のバージョンなんですけど： http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv マイクロソフトは腹黒っ子! まぁ大したニュースではないですけど、MSR2012のMining Challengeのスバンサー はマイクロソフトで、商品はXboxとKinectですけど、今年のチャレンジのテーマは： Mining Android Bug マイクロソフトの殺意を感じしました。","tags":"life","title":"MSR 2012 @ ICSE"},{"url":"//farseerfc.me/zhs/msr2012.html","text":"Mining Software Repository 2012 @ ICSE 参加了今年的MSR，会场在University of Zurich。一大早来到大学，注册有点 小插曲，显然瑞士人搞不清楚中国人的名字，3个杨（Yang）姓的中国人的名牌 被搞错了。然后堀田学长的所属被写作了\"Japan, Japan\"，成为了全日本的代表。 MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) 首先是来自微软亚洲研究院（MicroSoft Research @ Asia, MSR Asia）的Keynots， 于是就变成了MSR在MSR的演讲。MSR的张冬梅（Dongmei Zhang）女士的演讲 分为关于Software Analysis和XIAO的两部分。XIAO是MSRA开发的Code Clone Detector，似乎我要给井上研做的就是这个。想更多了解Xiao的细节，不过张女士 演讲结束的时候的鼓掌导致了话筒的小故障。 Towards Improving BTS with Game Mechanisms 感觉这篇的内容基本上就是关于 http://www.joelonsoftware.com/items/2008/09/15.html 这里写到的东西，然后说同样的理论是否可以用于Issue Tracking之类的事情上。 个人感觉这个意义不大，stackoverflow之所以成功是因为它把开源社区本身就 具有的名誉体系具现化了，本着大家都喜欢被别人奉为大牛的心态，就如同 wikipedia一样。同样的理论如果用于公司内部的Issue Tracking系统上，会得到 完全不同的东西吧。就像MSDN的组织方式虽然和wikipedia是一样的，但是在MSDN 里找信息的感觉和在wikipedia完全不一样。个人不太看好这个方向。 GHTorrent 这篇的slide在这里可以看到： http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Github的主要数据，代码，已经可以通过git接口 获得了，wiki是git的形式保存的。所以这个项目的目的就是暴露别的数据，主要 是issue tracking，code comments，这种。代码访问github api，然后用分布式 实现以克服api的限制，然后提供torrents形式的history下载。github api获得 的json数据以bson的形式保存在MongoDB里，解析过的有了Schema之后的数据保存 在MySQL里并可以导出SQL。 个人的想法，觉得数据如果能够更统一，全部存在Git里或许更好，像Wiki一样。 同样是要暴露全部历史记录的目的，用Torrent自己实现的历史远不如用Git的 接口实现的历史记录方便吧，git blame之类的也更方便追踪code comment之类的 作者信息。当然对git的raw date直接读写，需要对git的内部原理有足够的理解， 或许只有github的人有这种能力了。 Topic Mining 用得两个参数， DE 和 AIC，完全不能理解，过后研究。实验针对了Firefox, Mylyn, Eclipse三个软件。试图从Repo中分析源代码的identifier和comments， 找到topic和bug之间的关系，比如怎样的topic更容易导致bug。得出的结论似乎 也很暧昧，只是说核心功能被报告的bug更多，但是不知道原因。这只能表示核心 功能受到更多关注和更多测试吧，并不能说明核心功能就容易产生bug。 不过这个的Slide做得很漂亮，很容易理解。 SeCold A linked data platform for mining software repositories 没听懂这个项目的目的。 The evolution of software 第二天的Keynotes，关于将Social Media和Software Development相结合的想法。 或许就是Github赖以成功的基础。讲到代码中的comment, Tags, uBlog, blog之类 的social的特性和IDE的融合的趋势。 Do Faster Releases Imporve Software Quality? 使用Firefox作为例子。 结论是快速发布导致bug更多，更容易crash，但是bug更快得到修复，并且用户 更快转向新的发布。 Security vs Performance Bugs in Firefox Performance bugs are regression, blocks release. 一些感想 基于自然语义分析的commit分割 经常工具（比如git）的使用者并没有按照工具设计者的意图使用工具，这给MSR 带来很多困难。举个例子，git有非常完美的branch系统，通常期望git的使用者 能够在一次commit里commit一个功能，比如一个bug的修复，或者一个feature的 添加，但是事实上经常有很多逻辑上的commit被合并在一个里面了。 或许这不是使用者的错，而是工具仍然不够人性的表现。或许我们可以自动把 一次的commit按照语义分割成多个。 分割之后，可以更容易地把issue和commit关联，也更容易组织更多的研究。 关于这次发表中大家用的slides系统 题目为``Incorporating Version Histories in Information Retrieval Based Bug Localization''的人用的slide是beamer的。公式很多，overlay很多，列表 很多，图片很少，典型的beamer做出的slide。思维导图用得很不错。今天一天 有至少3个slide是用beamer做的。 题目为``Towards Improving Bug Tracking Systems with Game Mechanisms'' 的人用了prezi，图片很多，过度很多。但是比如没有页号没有页眉页脚，正式 会议的场合不太方便。 至少有六个以上用了Apple Keynotes，Keynotes做出来的东西真的和Powerpoint 做出来的很难区别，其中两个人用了初始的主题所以才看出来。 剩下的自然是PPT。MSRA的张女士做的虽然是PPT，倒是有很多beamer的感觉， 比如页眉页脚和overlay的用法。这些如果都是PPT做出来的，会多很多额外的 人力吧。 值得一提的是有一个题目为``Green Mining: A Methodology of Relating Software Change to Power Consumption''的人的slide全是``劣质''的手绘漫画， 效果意外地好，很低碳很环保很绿色很可爱。具体效果可以参考下面的动画，虽然 现场看到的不是一个版本： http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv 微软是个腹黑娘！ 嘛虽然这也不是什么新闻了。MSR2012的Mining Challenge的赞助商是微软，管理 组织者来自微软研究院，奖品是Xbox和Kinect。然后今年的题目是： Mining Android Bug 我看到了微软满满的怨气……","tags":"life","title":"MSR 2012 @ ICSE"},{"url":"//farseerfc.me/zhs/pyssy.html","text":"简介 Pyssy 是用于 上海交通大学 饮水思源站 的一系列 Python 脚本和工具。 Pyssy 被有意设计为既可以托管寄宿在 SAE [1] 上，也可以在单机上独立使用。 项目地址： http://pyssy.sinaapp.com/ Github上的源代码地址： https://github.com/yssy-d3/pyssy [1] Sina App Engine ，新浪云平台，类似 Google App Engine 的东西。 依赖关系 Pyssy 使用 Flask 作为网页服务器， 并且使用 Memcached 或者 Redis 作为抓取 水源Web 的缓存。 SAE Python 环境下请开启 Memcached 支持。 本地环境下请安装 Redis-py 并运行 redis-server 服务器程序。","tags":"tech","title":"Pyssy 项目"},{"url":"//farseerfc.me/en/mix-ruby.html","text":"Today I saw a package called PyRuby in Github. The readme says: PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } Even PyPI has listed this as a package. In the beginning I thought this was again a Ruby implementation by PyPy project. Or at least it use some magic trick to write ruby code directly in Python. Then I browse into the source code of it. It contains only one file: ruby.py # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) Yes, indead. The idea of using Ruby in Python is totally mad.","tags":"tech","title":"PyRuby"},{"url":"//farseerfc.me/jp/mix-ruby.html","text":"きょう、Githubに PyRuby というプロジェクトを見ました。それの説明にこう書いています: PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } さらに、 PyPI にそれのパッケージもあった。 最初に、これはもう一つのPyPyで実現したRubyだと思った。少なくとも、本当のRubyをPythonから呼び出すの何かの魔法も可能かもしれない。 それのソースコートはこうなっています。 ruby.py # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) 本当だ、Pythonの中にRubyを呼び出すという考えはアホだ。","tags":"tech","title":"PyRuby"},{"url":"//farseerfc.me/zhs/mix-ruby.html","text":"今天在GitHub上闲逛的时候看到一个叫做 PyRuby 的项目。项目的Readme说得很好： PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } 甚至 PyPI 上还有这个项目的包。 一开始我还以为这又是一个野心勃勃的基于PyPy的Ruby实现，或者某种trick在Python里面直接调用Ruby解释器。 然后我想看看这个的源代码 只有一个ruby.py文件，内容是： # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) 是的……的确……这种尝试把Python和Ruby放在一起的想法绝对是疯了……","tags":"tech","title":"PyRuby"},{"url":"//farseerfc.me/en/discuss-cpp-template-downcast.html","text":"This is a discuss in C board in bbs.sjtu.edu.cn, about type down-cast in C++ template. Original Discuss http://bbs.sjtu.edu.cn/bbstcon,board,C,reid,1330078933,file,M.1330078933.A.html The problem Today I read a book about we can do cast-down in template, so I write this to test: template < bool _Test , class _Type = void > struct enable_if { }; template < class _Type > struct enable_if < true , _Type > { typedef _Type type ; }; class A { }; class B : A { }; template < typename T > struct traits { static int const value = false ; }; template <> struct traits < A > { static int const value = true ; }; template < typename T > void f ( T , typename enable_if < traits < T >:: value >:: type * = 0 ) { } template <> void f < A > ( A , enable_if < traits < A >:: value >:: type * ) { } template < typename T > class BB {}; template < typename T > class DD : public BB < T > {}; template < typename T > void ff ( BB < T > ) {}; int main ( int argc , char * argv []) { A a ; B b ; DD < long > dd ; //f(b); ff ( dd ); } It is strange when f it don't allow my specified f<A>` . But in ff it allowed ff<BB<long>>` . Tested under VC10 and GCC3.4 My answer to the problem Let's think ourself as compiler to see what happened there. Define mark # : A#B is the instantiated result when we put B into the parameter T of A<T> . First we discuss ff DD < long > dd ; After this sentense, the compiler saw the instantiation of DD<long> , so it instantiate DD#long , and also BB#long . ff ( dd ); This sentense required the compiler to calculate set of overloading functions. Step 1 we need to infer T of ff<T> from argument DD#long -> BB<T> . Based on the inference rule: Argument with type :code:`class_template_name<T>` can be use to infer :code:`T``. So compiler inferred T as long . Here if it is not BB but CC which is complete un-related, we can also infer, as long as CC is a template like CC<T> . Step 2 Template Specialization Resolution. There is only one template here so we matched ff<T> . Step 3 Template Instantiation After inferred long -> T , compiler instantiated ff#long . Set of available overloading functions : {ff#long} Then overloading resolution found the only match ff#long` , checked its real parameter DD#long can be down-cast to formal parameter BB#long . Then we discuss f f ( b ); Calculate set of overloading functions. Step 1 infer all template parameters for template f . According to inference rule: Parameter with type T can be used to infer T 。 So B -> T is inferred. Step 2 Template Specialization Resolution. Here B is not A so we can not apply specialization of f<A> , remaining f<T> as the only alternative. Step 3 Template Instantiation. When we put B into f<T> to instantiate as f#B , we need to instantiate traits#B` . There is no specialization for B so we use template traits<T> , traits#B::value=false , so enable_if#false didn't contains a type , an error occurred. The only template is mismatch, available overloading functions is empty set. So we got an error.","tags":"tech","title":"Discuss C++ Template Downcast"},{"url":"//farseerfc.me/zhs/discuss-cpp-template-downcast.html","text":"这两天在饮水思源的C板，关于C++模板的类型转换的一个讨论，后面是我的解答。 讨论地址 http://bbs.sjtu.edu.cn/bbstcon,board,C,reid,1330078933,file,M.1330078933.A.html 原问题 今天在书上看到模板演绎的时候可以允许cast-down，于是我写了个东西： template < bool _Test , class _Type = void > struct enable_if { }; template < class _Type > struct enable_if < true , _Type > { typedef _Type type ; }; class A { }; class B : A { }; template < typename T > struct traits { static int const value = false ; }; template <> struct traits < A > { static int const value = true ; }; template < typename T > void f ( T , typename enable_if < traits < T >:: value >:: type * = 0 ) { } template <> void f < A > ( A , enable_if < traits < A >:: value >:: type * ) { } template < typename T > class BB {}; template < typename T > class DD : public BB < T > {}; template < typename T > void ff ( BB < T > ) {}; int main ( int argc , char * argv []) { A a ; B b ; DD < long > dd ; //f(b); ff ( dd ); } 奇怪的是重载决议的时候， f 的情况下它就不让我特化的 f<A> 进来。 但是在 ff 的情况下， ff<BB<long>> 却进来了。 在VC10和GCC3.4下测试 我的解答 我们来设身处地地作为编译器，看一遍到底发生了什么。 约定符号 # : A#B 是把 B 带入 A<T> 的参数 T 之后实例化得到的结果。 首先看ff的情况。 DD < long > dd ; 处理到这句的时候，编译器看到了 DD<long> 的实例化，于是去实例化 DD#long ，继而实例 化了 BB#long 。 ff ( dd ); 这句，首先计算重载函数集合。 第一步，需要从参数 DD#long -> BB<T> 推断 ff<T> 的 T 。根据函数模板参数推断规则： :code:`class_template_name<T>` 类型的参数，可以用于推断 :code:`T` 。 于是编译器推断 T 为 long 。这里就算不是 BB 而是完全无关的 CC 都可以推断成功，只要 CC 也 是一个 CC<T> 形式的模板。 第二步，模板特化匹配。因为只有一个模板，所以匹配了最泛化的 ff<T> 。 第三步，模板实例化。 推断了 long -> T 之后，编译器实例化 ff#long 。 重载函数集合： {ff#long} 然后重载抉择找到唯一的可匹配的实例 ff#long ，检查实际参数 DD#long 可以隐式转换到 形式参数 BB#long ，从而生成了这次函数调用。 再来看f的情况。 f ( b ); 计算候选重载函数集合。 第一步，对所有 f 模板推断实参。根据函数模板参数推断规则： 带有 :code:`T` 类型的参数，可以用于推断 :code:`T` 。 于是 B -> T 被推断出来了。 第二步，模板特化匹配。 这里 B 不是 A ，所以不能用 f<A> 特化，只能用 f<T> 模板。 第三步，模板实例化。 B 带入 f<T> 实例化成 f#B 的过程中，实例化 traits#B 。 由于没有针对 B 的特化，所以用 traits<T> 模板， traits#B::value=false ，进而 enable_if#false 没有 type ，出错。 唯一的模板匹配出错，重载函数集合为空，SFINAE原则不能找到合适的匹配，于是报错。","tags":"tech","title":"关于C++模板的类型转换的讨论"},{"url":"//farseerfc.me/en/try-pelican.html","text":"It seems in one night all geeks have their own Github User Page and Octopress Blog. Like everyone posted in their blogs, Static Blog is indeed more convenient than traditional Blog systems such as WordPress. I have been wanting my own Octopress since then. But it seems that Octopress isn't for me At first I was confused by Setup Steps of Octopress . What is this RVM thing? And what is that rbenv thing? It seems the high pace of Ruby community has beyond my imagination to a degree that they need a version manager to ensure the compatibility of different versions of Ruby. Althrough the same compatibility issue also troubles Python community [1] , but at least Python don't need a version manager (yet) to control this mass [2] . Real problem for me is that I haven't yet a Linux box that I can play around freely. (I really want one ... ) Both RVM and rbenv needs to run on Unix/Linux/MacOSX. One can not be a geek if he use Windows ? (Maybe it's true...) Remaining problem is the battle between Ruby and Python campaign. I haven't tried Markdown , and I rather like ReST . It seems that both sides depend on Pygments as code block highlighter so Rubyists need Python environment anyway. I simply don't want to depend on any Ruby component. It is better when it is in pure Python, no C extensions so that I can debug into it and make minor modifications. So I started searching for Static Blog Engine in Python on Github. The author of the great framework Flask , mitsuhiko , wrote a rstblog , but it's not well developed. Hyde seems to be complete enough, but it use MarkDown as its default markup language, and the design of its homepage is too fashion to be used as blog. Finally I found Pelican . [1] Such as the difference between Python 2.x and 3.x , and also difference in C-API of implementations of PyPy , CPython , Stackless , Cython . [2] Yes, we have easy_install and pip , but all these are package manager, running in a perticular Python implementation. Python implementation itself don't need a manager. Version issue of Python largely have been solved by lightweight converters such as 2to3.py and 3to2.py , you don't need to store multiple implementations of Python in your disk for different packages. Yes you can use virtualenv if you need to preserve stablility but this is another story. Let it be Pelican For my own use, Pelican offers me some advantages over Octopress : Implemented in pure Python . This means that I can use different implementation of Python other than CPython easily. I use PyPy myself. Translation of multi-languages. The original author of Pelican is a France. This is unnecessory for most people, but I will post my blog mainly in three languages: English, Japanese and Chinese. ReST . So that I can use the @auto-rst feature of Leo . And also I don't need to switch between my blog and documentation of my projects. But it seems that Pelican was less contributed than Octopress . Some minor issues remains in latest version: Support of pelican-import from WordPress for Chinese and Japanese articles are buggy. Datetime format, timezone, and locale support for multi-language blogs are not so natural. I will work on this in these days There are not so many templates compared to Octopress . And less plugins . I hope more people from Python community can contribute to this excellent project, then all these issues will be fixed soon. My settings To install Pelican is simple: $ pip install pelican Write posts in ReST , with rst extensions, and put them in pages folder. (Re)Build all pages is simply: $ pelican -s settings.py Push to Github: $ git commit -am \"Commit message\" $ git push And following is my settings.py : # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , '%a, %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a' ), 'jp' :( 'jpn' , '%Y/%m/ %d (%a)' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","title":"Give a try to Pelican"},{"url":"//farseerfc.me/jp/try-pelican.html","text":"一日の間に全ての ギーク たち が 自分の Githubユーザーページ と Octopress ブログを導入したような気がします。皆がブログに書いた通りに、静的ブログは確かに WordPress などの従来の動的ブログ・エンジンより便利だと思います。これらブログを見ると、私も自分の Octopress ブログを立ちましょう とずっと思っています。 ですが Octopress は私に向いてないかも 初めのところに Octopressの配置手順 に迷わされた。 RVM とはなに？ rbenv とは何のこと？見るところ Ruby コミュニティーの発展するハイペースは既に私の想像に超えましたみたい。 彼らは Ruby の各バージョン間に互換性を持つために、バージョン管理が必要らしいです。同様の互換性問題が Python コミュニティーにもある ですが [1] 、 Python は今のところこのようなバージョン管理の必要がないと思います [2] 。 実際に迷惑したのは、私は今自由に持って遊べる Linux 環境が持っていないということ（ほしいなぁ……）。 ですが RVM それとも rbenv 両方も Unix/Linux/MacOSX しか実行できないらしいです。ギークとしたの皆は絶対に Windows つかっじゃいけないんですか？（本当かも……）。 残りは Ruby と Python の争いです。私は Markdown に詳しくない、比べると ReST のほうが私に向いています。それに、どっちでも Pygments を依存しシンタックス・ハイライトをしているから、 Rubyist 達も少なくとも Python を入れなきゃダメみたいです。 私の好みは一切の Ruby コンポーネントを頼らず、 C 拡張もない純粋な Python の実現がほしいです。 そこから Github に Python で実現した静的ブログ・エンジンを探し始めた。 Flask の作者である mitsuhiko 氏が書いた rstblog が素晴らしいが、あんまり他人に使われていないようです。 Hyde は多く使われているけれと、ホームページにブログの感じがみえないです。最後に Pelican を見かけました。 [1] 例えば Python 2.x と 3.x の間にあまりにも巨大なる差、それと PyPy 、 CPython 、 Stackless 、 Cython など各実現間に微妙な違いがあります。 [2] はい、こっちに easy_install とか pip があります、ですがそれらはパッケージ管理、特定なPython環境を入れた後の話です。Python自身はまだ管理する必要がないです。 Python のバージョン問題も 2to3.py とか 3to2.py のようなツールで変換すればいいです、違うソフトを実行するためたくさんの Python バージョンを残る必要はないです。もしバージョンの違いが気にするなら virtualenv を使うのも構わないが、それも別のことです。 それでは Pelican にしよう 私自身にとって、 Pelican は Octopress よりいいところ： 純粋な Python で実現した。ですから CPython のほかべつの実現を使うのも心配がない。例えばわたしは PyPy を使ています。 多言語。 Pelican の原作者はフランス人らしいです。ほとんどの人はこれの必要がないと思うが……できるだけ、わたしは三つの言語で書く。 ReST 。それなら Leo の @auto-rst を使って直接 ReST をかけます。 でも Pelican は Octopress のほど注目されていないから、一部問題があります。 pelican-import は WordPress から導入する時、日本語や中国語は問題となります。 多言語の機能と日付、タイムゾーンなどにバグがある。 私は改善しています。 テンプレートは少ない。 プラグインも少ない…… こんなに優れたツールにもっと注目されてほしい。 配置 Pelican を入れるのは簡単： $ pip install pelican 文章を ReST で書いて、 posts フォルダーに置きます。ページを生成する： $ pelican -s settings.py Github に送る: $ git commit -am \"Commit message\" $ git push 私の配置ファイル： # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , '%a, %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a' ), 'jp' :( 'jpn' , '%Y年%m月 %d 日(%a)' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","title":"Pelicanを試してみた"},{"url":"//farseerfc.me/zhs/try-pelican.html","text":"似乎一夜之间所有的 极客们 都 有了 自己 的 Github主页 和 Octopress 博客。就像所有人在他们的博客中指出的，静态博客的确比传统的WordPress方式具有更多优势。 自从看到这些 我就一直在想着自己搭一个 Octopress 。 但是似乎 Octopress 不适合我 一上手就被 Octopress的搭建步骤 烦到了。 RVM 是什么？ rbenv 又是什么？ 看来 Ruby 社区的快节奏发展已经超过了我的想象，他们似乎需要一套发行版管理器来调和不同版本之间的 Ruby 的兼容性问题。 虽然同样的兼容性问题在 Python 社区也有 [1] ，不过总觉得 Python 至少还没到需要一个发行版管理器的程度 [2] 。 真正的问题是我手上还没有一个可以让我随便玩的 Linux 环境（真的想要……）。 而无论是 RVM 还是 rbenv 似乎都只支持 Unix/Linux/MacOSX 。 身为极客就注定不能用 Windows 么？（或许是的……）。 剩下的问题就是 Ruby 和 Python 两大阵营的对立问题了。我不熟悉 Markdown ， 相对来说比较喜欢 ReST 。 似乎无论哪边都要 依赖 Pygments 作为代码着色器，那么其实 Rubyist 也至少需要安装 Python 。 我倾向于不依赖任何 Ruby 组件，最好没有 C 扩展 的纯 Python 实现。 于是我开始在 Github 上找 Python 的静态博客引擎。 Flask 的作者 mitsuhiko 写的 rstblog 看起来不错，不过似乎没有多少人在用。 Hyde 似乎很完善，不过默认的标记语言是 MarkDown ， 又依赖于几个 Ruby 组建，而且官方网站的设计实在太前卫。 最终我看到了 Pelican 。 [1] 比如 Python 2.x 与 3.x 之间看似难以跨越的鸿沟，以及 PyPy 、 CPython 、 Stackless 、 Cython 等各个实现之间的微妙差别。 [2] 是的，我们有 easy_install ，我们有 pip ， 不过这些都是包管理器，都是装好特定的Python实现之后的事情。 Python实现本身还不需要包管理器来管理。 Python 的版本问题基本上也只需要 2to3.py 和 3to2.py 这样的轻量级转换器就可以了，你不需要为了安装多个软件而在硬盘里留下多个不同版本的 Python 。 如果为了引用的稳定性，你可以用 virtualenv ，不过这又是另一回事情了。 那么就 Pelican 吧 对我而言， Pelican 相比于 Octopress 有几个好处： 纯 Python 实现。 这意味着我可以换用任何 Python 解释器而不必担心兼容性问题。比如我就换成了 PyPy 。 多语言支持。因为 Pelican 的作者似乎是个法国人。不过这个似乎大部分人不需要…… 我是想尽量把一篇博客写成三种语言作为锻炼吧。 ReST 。这样我就可以用 Leo 的 @auto-rst 直接写 ReST了。简单方便快捷有效。 不过似乎 Pelican 的关注度不如 Octopress 那么高，现在一些部分还有细微的问题： pelican-import 从 WordPress 导入的时候对中文、日文的支持似乎很成问题。 日期格式、时区、字符集、和多语言功能的结合度还不够。 我在尝试改善它。 模板还不够丰富。 插件也不够多…… 希望这么优秀的工具能够受到更多关注，以上这些问题都是增加关注度之后很快就能解决的问题。 我的设置 settings.py 安装 Pelican 很容易，一句话就够了： $ pip install pelican 然后把文章写成ReST的格式，放在`pages`文件夹里面。(重新)生成只要： $ pelican -s settings.py 上传到 Github: $ git commit -am \"Commit message\" $ git push 就这么简单。附上我的配置文件： # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , '%a, %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a' ), 'jp' :( 'jpn' , '%Y/%m/ %d (%a)' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","title":"尝试一下 Pelican"},{"url":"//farseerfc.me/zhs/about-my-blogs.html","text":"从 farseerfc.wordpress.com 导入 很久没有写过blog或者之类的东西了。这边一直荒废着。 由于国内被墙的原因，另一个wordpress： http://fchome.sinaapp.com/ 应该会同步更新这里的内容。 抽空写点什么吧。","tags":"import","title":"关于我的Blogs"},{"url":"//farseerfc.me/en/if-we-do-this-work.html","text":"Imported from renren \"…if we do this work … and the result is that Linux works great …\" --Bill Gates From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf If this is the reason that Xen 4.0 is still not fully support ACPI 3.0, then f*ck you Bill Gates!","tags":"import","title":"\"…if we do this work … \" --Bill Gates"},{"url":"//farseerfc.me/jp/if-we-do-this-work.html","text":"renren から導入した。 From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf もしこれは今更Xen4.0の上にACPI 3.0完全的なサポートが得ない原因、ならBill Gatesを呪います！","tags":"import","title":"\"…if we do this work … \" --Bill Gates"},{"url":"//farseerfc.me/zhs/if-we-do-this-work.html","text":"导入自 renren From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf 如果这就是我至今在Xen4.0上得不到ACPI 3.0的完善支持的原因，那么我诅咒Bill Gates！","tags":"import","title":"\"…if we do this work … \" --Bill Gates"},{"url":"//farseerfc.me/zhs/zz-introducing-scholarzhang.html","text":"从 farseerfc.wordpress.com 导入 好神奇的想法，先存着，以后慢慢研究 原文： http://blog.youxu.info/2010/03/14/west- chamber/ 待月西厢下，迎风户半开。隔墙花影动，疑是玉人来。 最近推上最流行的一个关键词是\"西厢计划\", 这个计划名字取得很浪漫，客户端叫做张生，对，就是西厢记里面那个翻墙去见崔莺莺小姐的张生；显然，服务器端必然叫做崔莺莺。客户端的张生是最重要的部件，可以不依赖于服务端工作。因为西厢计划的作者只是简要的介绍了一下原理，其他报道又语焉不详，我当时就觉得很好奇，花了昨天一个晚上详细读了一下源代码，终于知道怎么回事了，觉得原理非常漂亮，所以写篇文章介绍总结一下。 先说大方向。大家都知道，连接被重置的本质，是因为收到了破坏连接的一个 TCP Reset 包。以前剑桥大学有人实验过，客户端和服务器都忽略 Reset, 则通信可以不受影响。但是这个方法其实只有理论价值，因为绝大多数服务器都不可能忽略 Reset 的 (比如 Linux, 需要 root 权限配置iptables, 而且这本身也把正常的 Reset 给忽略了)。只要服务器不忽略 Reset, 客户端再怎么弄都没用，因为服务器会停止发送数据，Reset 这条连接。所以，很多报道说西厢计划是忽略 Reset, 我从源代码来看应该不是这样。在我看来，西厢计划是利用了墙的一个可能的弱点–墙只在连接发起的时候把一个 TCP 连接加入监听序列，如果墙认为这个连接终止了，就会从监听序列中去掉这条记录，这样，这条连接上后续的包就不会被监听。西厢计划就是让墙\"认为\"这个连接终止的一个绝妙的方法。只要墙认为这个连接两端都是死老虎，墙就不会触发关键词检测，其后所有的数据，都不存在连接被重置的问题了。 如何让一个连接置之死地而后生，就是西厢计划那帮黑客神奇的地方了。这也不是一日之功。 首先，这帮牛人发现，墙的是一个入侵检测系统，把含有关键字的包当成一种\"入侵\"来对待。采取这种设计有很多好处，但缺点是入侵检测系统可能具有的问题，墙都可能有。西厢计划主页上那篇著名的论文就是讲这些七七八八的漏洞的。可以说处理这些七七八八的漏洞是非常困难的，迫使墙的设计者\"拆东墙，补西墙\"。这样补来补去，外表看起来好像很牛逼的墙，其实有很多本质上无法简单修补的漏洞，其中有一个致命的，就是 TCP 连接状态的判定问题。 出于入侵检测系统这种设计的局限，墙没有，也没办法准确判定一条 TCP 连接的状态，而只是根据两边收到的数据来\"推测\"连接的状态。而所有的关键词检测功能，都是基于\"连接还活着\"的这个推测的结果的。因为墙的规则是在连接发起的时候开始对这条连接的检测，在连接终止的时候停止对这条连接的检测，所以，一旦对连接的状态推测错误，把还活着的连接当成已经关闭的连接，墙就会放弃对这条连接上随后所有的包的检测，他们都会都透明的穿过墙的入侵检测。 上面只是想法，具体到 TCP 协议实现这一层，就要只迷惑墙，还不能触及我要通信的服务器。最理想的情况下，在任何有效通信之前，就能让墙出现错误判断，这些，就需要对 TCP 协议有深刻理解了。西厢计划的那帮黑客，居然真的去读 TCP 几百页的 RFC，还居然就发现了方法（这里我假设读者都知道 TCP 的三次握手过程和序列号每次加一的规则）。 我们都知道，三次握手的时候，在收到服务器的 SYN/ACK 的时候，客户端如果发送 ACK 并且序列号+1 就算建立连接了，但是客户端如果发送一个序列号没 +1 的 FIN （表示连接终止，但是服务器知道，这时候连接还没建立呢， FIN 这个包状态是错的，加上序列号也是错的，服务器自己一判断，就知道这个包是坏包，按照标准协议，服务器随手丢弃了这个包）, 但这个包，过墙的时候，在墙看来，是表示连接终止的(墙是 ma de in china, 是比较山寨的，不维护连接状态，并且，墙并没有记下刚才服务器出去的 SYN/ACK 的序列号，所以墙不知道序列号错了）。所以，墙很高兴的理解为连接终止，舒了一口气去重置其他连接了， 而这个连接，就成了僵尸，墙不管你客户端了，而这时候，好戏才刚刚开始。 事实上，墙是双向检测的（或者说对每个包都检测的），因此，对服务器和客户端实现相同的对待方法，所以，墙不管客户端还不行，假如服务端有关键词传给客户端，墙还是有可能要发飙的（这里说有可能，因为我也不知道）。所以，最好的办法就是，让服务端也给墙一个终止连接的标志就好了。可是这个说起来简单，做起来难，怎么能让不受自己控制的服务器发一个自己想要的包呢？ 西厢计划的那帮黑客，再次去读几百页的 RFC, 令人惊讶的发现，他们居然在 RFC 上发现了一个可以用的特性。我们上面说了，三次握手的时候，在收到 SYN/ACK 后，客户端要给服务器发送一个序列号+1 的ACK，可是，假如我不+1呢，直接发 ACK 包给服务器。 墙已经认为你客户端是死老虎了，不理你了，不知道你搞什么飞机，让这个 ACK 过了。可是服务器一看，不对啊，你给我的不是我期待的那个序列号， RFC 上说了，TCP 包如果序列号错了的话，就回复一个 Reset. 所以，服务器就回复了一个 Reset。这个 Reset 过墙的时候，墙一看乐了，服务器也终止连接了，好吧，两边都是死老虎了，我就不监听这条连接了。而至于客户端，这个服务器过来的 Reset 非常好识别，忽略就是。随后，客户端开始正确的发送 ACK, 至此，三次握手成功，真正的好戏开始，而墙则认为客户端和服务器都是死老虎，直接放过。所以，张生就这样透明的过了墙。 至于过墙以后所有的事情，《西厢记》里面都有记载，各位读者自行买书学习。 现在的西厢计划客户端，即\"张生\"模块的防连接重置的原理就是这样，服务器端，即莺莺模块的实现也是类似的。防DNS那个，不懂 DNS 协议，所以看不懂。我猜想，因为开发人员都是黑客，所以自然喜欢用最经得起折腾和高度定制的 Linux 开发。 现在看西厢计划的实现，因为依赖于 Linux 内核模块 netfilter, 在 Linux 上如鱼得水，但往其他平台的移植可能是个亟待解决的问题。 我觉得，在其他平台上，可以通过 libpcap 和 libnet ，在用户态实现相同的功能，就是有点麻烦而已，有兴趣的懂网络的可以照西厢计划原理，在家自行做出此功能；当然，全中国人民都用 Linux 最好 :) PS 1: 据说是西厢计划一个作者画的原理图： http://img.ly/DIi PS 2: 我对 TCP 的理解仅限于课本，如果上面的对技术的理解有错，请大家指出。 PS 3: 有些漏洞，可能是设计上本质缺陷，不是那么容易修复的。 PS 4: 除了最后一个图，本文没有其他相关链接，如需相关资料，自行Google。","tags":"import","title":"[zz]\"西厢计划\"原理小解"},{"url":"//farseerfc.me/en/sine-cpu.html","text":"Imported from: renren . It is said that this is a problem from interview of Microsoft. Write a program, which makes the CPU usage curve in Windows Task Manager shows a Sin function. The program below is written in java: public class sincpu { private static final int cycle = 1024 , tick = 256 ; public static void main ( String [] args ) throws InterruptedException { for ( int i = 0 ;; i ++){ work ( calcNextSleep ( i % cycle )); sleep ( tick - calcNextSleep ( i % cycle )); } } private static long calcNextSleep ( long i ){ return ( int )( Math . sin (( double ) i * 2 * Math . PI / cycle ) * tick + tick ) / 2 ; } private static void sleep ( long sleepTime ) throws InterruptedException { if ( sleepTime < 2 ) Thread . yield (); else Thread . sleep ( sleepTime ); } private static void work ( long period ) { long start = System . currentTimeMillis (); for (;;){ Math . sin ( 1 ); if ( System . currentTimeMillis () - start >= period ) break ; } } } Be careful you need to turn off other cores if you have multi-core CPU.","tags":"import","title":"Write a program to keep CPU usage as sin funcion"},{"url":"//farseerfc.me/zhs/sine-cpu.html","text":"导入自 renren 据说是一道微软的面试题。如题，写程序，让Windows的任务管理器中的性能监视器呈现正弦曲线。 潜心钻研良久，得代码：（java） public class sincpu { private static final int cycle = 1024 , tick = 256 ; public static void main ( String [] args ) throws InterruptedException { for ( int i = 0 ;; i ++){ work ( calcNextSleep ( i % cycle )); sleep ( tick - calcNextSleep ( i % cycle )); } } private static long calcNextSleep ( long i ){ return ( int )( Math . sin (( double ) i * 2 * Math . PI / cycle ) * tick + tick ) / 2 ; } private static void sleep ( long sleepTime ) throws InterruptedException { if ( sleepTime < 2 ) Thread . yield (); else Thread . sleep ( sleepTime ); } private static void work ( long period ) { long start = System . currentTimeMillis (); for (;;){ Math . sin ( 1 ); if ( System . currentTimeMillis () - start >= period ) break ; } } } 多核CPU上测试时要注意关掉一个CPU：","tags":"import","title":"写程序让CPU占用率保持正弦函数"},{"url":"//farseerfc.me/zhs/some-thought-on-creationism.html","text":"导入自 renren 看到陈骉同学很有感想的一篇神创论与命运日志，觉得近日很久没有看到这样的评论了。想说几句自己的观点。 首先我认为，神创论与宿命论没有多少关联，甚至进化论者相较于神创论者更容易接受宿命论的观点。因为神创论主张意志的存在，人所具有的个体意志与神的意志，因此在神创论者的眼中事件的结果是可以通过意志来改变的，亦即如果我从物理楼11楼跳下，那么我就可以改变自己死亡时间的宿命。上帝的意志同样可以左右事件的结果，也就是所谓的宿命不复存在。而进化论者不承认意志独立于物质世界的存在，你我的思考、行为，都受到物理学法则诸如量子力学的约束，这就引出了北大物理系教授的那句\"宇宙中的一切都是可以计算的\"，亦即宿命论。如我我选择现在从物理楼上跳下，我这一行为并不是处于个人的独立意志，乃是想证明这一点，亦即我跳楼这一举动是有其背后的动机与原因的，就如同计算机的输入必然导致了输出，宿命的必然终结于此。 其次，关于事件的复杂度所导致的随机化，在大量混沌随机中也存在着如统计学和随机分形学这样的规律，并不是否认宿命的充分理由。 关于神创论的合理性问题。我认为是否相信神的存在只是一个boolean二值问题，它为true为false本身并不重要，重要的是确定它的取值之后得到的推论与结果。如果否认神的存在，如现代数学这样的完美又何以存在，进化论者的解释是事物最终会向着更好更高级的方向发展，产生现代数学乃至现代科学是发展的必然。而这种论调显然有悖于物理中以热力学第二定律为首的，预言事物会随时间推演愈发混乱的论断。更进一步，甚至整个人类、整个生物系统的存在都是有悖于热力学推论的现象，是某种理论只能以\"小概率事件\"解释的现象。 神创论的核心观点之一，是神的唯一存在性，按照邹恒明的比喻，这就如同数学中集合中元素的的唯一性一般至关重要。数学乃至近代科学的发展，其起源在于这种对神性的探求，而不仅仅是好奇心就可以解释的。反观东方文化中数学的发展，开始时领先于西方科学千余每年，但是始终作为一种craft-oriented的实用主义学科。可以说没有了神的唯一性支持，人们就不能确信自己能找到这样一种完美高效的学科，只能在实用的基础上发展其基础算数。可以想象，没有神的完美与唯一性，数学必将发展成现代化学或者微软软件这样，庞大而充满特例，到处都是修补与查表，怎么会像现在的完美、简洁与和谐。 神创论者并不是将难题推与\"神\"然后放任不管，他们相信神是最为理智的存在，创人时人同样得到了神的智慧和理智，也就是神可以用人的理智来理解。 引用牛顿《自然哲学的数学原理》中终章的话\"太阳、恒星、行星的这个极精致的结构不可能存在，除非通过一个有理智的和有权能的存在的设计和主宰……他不是作为宇宙的灵魂，而是作为一切的主宰而统治所有……\" 以上…… (发现最近的哲理思维果然慢了不少，写作思绪也一片混乱&#94;_&#94;)","tags":"import","title":"关于神创论的一些见解"},{"url":"//farseerfc.me/zhs/9-thoughts-about-oop-from-wrongly-insert-memory-stick.html","text":"从 farseerfc.wordpress.com 导入 故障描述: MMC Memory Stick Duo记忆棒未经Adapter适配器，直接插入SD Reader，致使MMC卡入SD Reader中。 栈展开： 某日下午，无课。 忙于数分作业，想查询用手机拍摄的板书照片。 取出手机中的MMC。 未经装配Adapter，直接插入SD Reader。 (A runtime exception was thrown.) 尝试翻转笔记本机身，倒出MMC，未果。(rethrow) 尝试用手指甲取出，未果。(rethrow) 考虑到有\"推入反弹\"机制，尝试将MMC推入更深，反弹机制由于类型不匹配而失效，未果。(rethrow) (The exception spread across the border of the model.) 电脑维修技师接手(catch) 技师未能发现问题所在，由我解说原委。 (Because the exception lose the information, RTTI was asked to recall the information) 技师发现问题，尝试用镊子镊出MMC，未果。 技师开解机箱(expose the data structure) 技师制作钩子，勾出MMC(hooker link to the structure) 取出MMC，故障解除 故障总结 1.接收到没有完全了解、或没有适当工具解决的exception时，不要尝试用不成熟的技术解决，应尽快寻求能解决它的代码。否则，被反复rethrow的exception，尤其是通过模块边界的exception，有可能由subclass退化为superclass，并因此而丧失一些信息。尽量不要让exception丢失信息，必要时，通过RTTI机制寻回信息。 2.超负荷运转，多线程执行，这种种复杂性都有可能导致错误，应避免。无论你有多么信任你的代码或能力。 3.在设计class的interface时，相匹配的interface应该满足is-a的关系。因此，任何能插入SD Reader的object，即任何实现了SD interface的object，都应该is-a SD card。这次故障中，interface接受了MMC，但MMC不是SD。即使这种情况下throw an exception，都不能使事态缓和。能提供compile-time error时，尽量让错误以compile-time error的形式展现，并在事先解决。类型匹配问题是应该能在事先解决的问题。 4.Design patterns中的Adapter pattern应该只是迫不得已情况之下的解决方案。只有当你无权改变现状时，才能使用Adapter。如果能改变现状，应该改变设计以符合interface。 5.因为上条，所有相似功能的对象应具有相同的interface，不同的interface是本次故障的根源所在。 6.特殊情况下，破坏封装机制并expose the data structure是必要的，应该有方法支持这种做法。C的指针和C#的Reflection技术都以不同的方式支持这种做法。其他的一些语言机制，比如serializing(序列化)或streaming(流化)，也可以以某种方式间接支持这一做法。当然，机制还应避免这种做法被滥用。 7.相反功能具有相同操作的设计，容易造成使用的混乱，应适当避免。比如SD Reader的推入反弹设计，即插入和弹出使用同一个向里推的操作的设计。同样的设计还包括，C++中的setNewHandle使用同一个函数，同时设置和返回handle。以及有些书中提倡的，使用同名函数重载的方式，实现setter/getter的设计。 8.特殊工具(hooker)对于解决特定问题，通常比手工解决有效。不要嫌麻烦而不愿意构造特殊工具。 9.栈语义，即FILO顺序，总在不知不觉中影响我们。违反了FILO顺序的操作极易造成混乱。本故障发生时正确的处理顺序为： 装配Adapter 插入SD Reader 读取数据 停用设备 拔出SD Reader 拆解Adapter 本次故障的原因就是违反了FILO顺序，违反了栈语义。","tags":"import","title":"由记忆棒误差故障引发的关于面向对象设计的九点思考"},{"url":"//farseerfc.me/zhs/program-development-in-java-preface.html","text":"从 farseerfc.wordpress.com 导入 程序开发原理 ——抽象、规格与面向对象设计 Barbara Liskov 、John Guttag 著 杨嘉晨 等译 关于翻译风格： 多年来阅读计算机类的著作及译作，感觉总体的困难在于一大堆没有标准译名的技术术语。由于通行于工业界和学术界的还是英文原名和术语，我决定保留大量的英文术语。这样的翻译风格借鉴于台湾著名的译者和作者侯捷先生。对于译与不译的权衡，主要考虑阅读的流畅，以及读者的理解能力，或许难免带有一些主观色彩。 前言 Preface 构建产品级质量的程序——可以在很长一段时间内使用的程序——众所周知是极其困难的。本书的目标就是改善程序员解决这项任务的效率。我希望读者在阅读本书之后成为一名好程序员。我相信本书的成功在于改善编程技巧，因为我的学生告诉我这已经发生在他们身上。 怎么才算是一名好程序员？是产生整个程序产品的效率。关键是要在每一阶段减少浪费掉的努力。解决的方法包括：在开始编写代码之前就仔细考虑你的实现方案，通过未雨绸缪的方法来编写代码，使用严格的测试在早期发现错误，以及仔细注意模块化编程，这样当错误出现时，只需要改动极少数代码就可以修正整个程序。本书涉及所有这些领域的技术。 模块化编程(Modularity)是编写好程序的关键。把程序分解成许多小模块，每一个模块通过良好定义的狭窄接口和别的模块交互作用(interact)。有了模块化，可以修正一部分程序中的错误而不考虑程序的其他部分，而且可以仅仅理解一部分程序而不必理解整个程序。没有模块化，程序是一大堆有着错综复杂的相互关系的部分的拼凑。很难去领悟和修改这样一个程序，同样也很难让它正常工作。 因此本书的重点在于创建模块化的程序：怎样把程序组织成一系列精心挑选的模块。本书认为模块化就是抽象(abstraction)。每一个模块意味着一个抽象，比如说指引一系列文档中的关键字的目录，或者在文档中使用目录来查找匹配某个问题的文档的过程。着重强调面向对象编程思想——在程序中使用数据抽象和对象的思想。 这本书使用Java作为它的编程示例的语言。我们没有假定读者已经熟悉Java。尽管可能没什么价值，但是本书中的思想是语言无关的，并且可以在任何语言的编程中使用。 怎样使用这本书？ How Can the Book Be Used 本书《程序开发原理》有两种使用方法。其一是作为课本教材，讲述如何用面向对象的方法来设计和实现复杂系统；其二是编程专家使用，帮助他们改善编程技能，增进他们的关于模块化和Object-Oriented(面向对象)设计的知识。 作为教材使用时，本书一般作为第二或第三门程序设计课程。我们已经在MIT使用本书很多年，给大一大二的本科生教授第二门编程课。在这一阶段，学生们已经知道怎样编写小程序。课程在两方面利用这一点：让学生更仔细地思考小程序，以及教他们如何利用小程序作为组件构建大型程序。这本书也可以在专业（如软件工程）后期教学中使用。 建立在本书基础上的课程适合于所有计算机科学专业。尽管许多学生可能永远不会成为真正的大型程序的设计师，他们可以在开发部门工作，在那儿他们负责设计和实现能与整个结构耦合的子系统。模块化设计的子系统是这种任务中心，这对那些从事大型程序设计任务的人来说也同样重要。 这本书讲什么？What Is This Book About 通观全篇三分之二的书致力于讨论在构建独立的程序模块时产生的问题，剩下的部分讨论怎样运用这些模块构建大型程序。 程序模块Program Modules 这一部分的书集中讨论抽象机制(abstraction mechanism)。它讨论procedure(子程序)和exception(异常)，数据抽象，遍历(iteration)抽象，数据抽象系列(family)以及多态(polymorphic)抽象。 在对抽象的讨论中，三个步骤是重要的。首先是决定被抽象的东西到底是什么：它提供给它的用户哪些行为。创造抽象是设计的关键，因此本书讨论如何在众多选择中挑选，以及怎样才能创造出好的抽象。 第二步是通过为一个抽象制定一个规格(specification)来获取它的意义。如果没有一些描述，一个抽象就会含糊不清，而变得没有使用价值。specification则提供了需要的描述。本书定义了一种specification的格式，讨论了一份好的specification应有的属性，并且提供了许多示例。 第三步是实现抽象。本书讨论怎样设计一份实现，以及在简洁性和执行性能之间怎样权衡利弊。书中强调封装(encapsulation)的重要性以及在一份实现中履行规格中定义的行为的重要性。书中同样提供一些技术——尤其是不变式断言(representation invariant)和抽象函数(abstraction function)——来帮助读者理解代码和它的原因。不变式断言和抽象函数都实现到尽可能的程度，这对于除错和调试很有用。 关于类型层次(type hierarchy)的材料注重讨论使用它作为抽象的技术——一种把相关联的一组数据抽象归入同一系列的技术。这里很重要的一点是，是否应当将一个类型作为另一个类型的子类。本书定义了替换原则——通过比较子类和父类的specification，来决定是否建立子类关系的方法 [1] 。 本书同样涉及除错和调试。书中讨论怎样得到足够数量的测试情况，来准备通过黑箱和白箱测试，它同样强调了复查(regression)测试的重要性。 编写大型程序 Programming in the Large 本书的其后部分讲解怎样用模块化的方法设计和实现大型程序。它建立在前文有关abstraction和specification的材料的基础之上。 编写大型程序涵盖四个主要议题。首先讲解需求分析——怎样才能领悟程序中需要什么。本书讨论怎样实施需求分析，也讨论书写产生的需求规格的方式，通过使用一种描述程序的抽象阶段的数据模型。使用这种模型将产生一份更为正式的specification，同时它也使需求检查更加严格，这样可以更好的领悟需求。 编写大型程序的第二项议题是程序设计，这通常是一个循序渐进的过程。设计过程围绕构建有用的抽象来组织，这些抽象作为整个程序之中理想的构建组建。这些抽象在设计时被仔细的编写规格，这样当程序实现时，那些实现抽象的模块可以独立地开发。这种设计使用设计笔记编写文档，包括描述整个程序结构的模块间依赖性的图示。 第三项议题是实现和测试。本书讨论了前置设计分析对于实现的必要性，以及怎样进行设计复审。它同样讨论了设计和实现的顺序。这一部分比较了自顶而下与自底而上的组织方式，讨论如何使用驱动程序和占位程序 [2] (stub)，并且强调了制定一个事先的顺序策略的必要性，以满足开发组织和客户的需求。 本书以一章设计模式(design pattern)结束。一些模式在前面的章节介绍过，比如遍历抽象是算法的主要组建。最后的章节讨论前文中没有涉及到的模式。希望它作为这一教材的介绍。有兴趣的读者可以继续阅读其它书中更完善的讨论 [3] 。 [1] 译注：如果子类的specification包括了所有父类的specification，就是说父类的要求也是子类的要求，或者子类的要求更为严格，那么可以建立父子关系。而替换原则的说法是，对于具有父子关系的类，任何需要一个父类对象的地方，都可以替换为一个子类对象。 [2] 译注：在测试某一组建时，由于其余组建还未实现，这一组建与其余组建的接口衔接部分无法工作。此时可以针对这一组建编写其余组建的占位程序(stub)，预留出接口的衔接代码。占位代码通常不做任何有价值的事情，只报告组建的衔接部位工作正常。 [3] 译注：作者指的是设计模式的开山之作——《Design Patterns—Elements of Reusable Object-Oriented Software》,作者为设计模式界著名的\"四人帮\"GoF(Gang of Four)。此书详尽讨论了三大类共23个广泛使用的设计模式的适用范围、依存关系、实现细节以及已有的应用领域等问题。书中以C++和Smalltalk为示例语言，不过书中所涉及的模式适用于所有面向对象的语言。","tags":"import","title":"Program Development in Java Preface"},{"url":"//farseerfc.me/zhs/c-tricks-3-2-label-goto-and-implementation-of-switch.html","text":"从 farseerfc.wordpress.com 导入 3.2 标号、goto，以及switch的实现 goto语句及标号(label)是最古老的C语言特性，也是最早被人们抛弃的语言特性之一。像汇编语言中的jmp指令一样，goto语句可以跳转到同一函数体中任何标号位置： void f() {int i=0; Loop: //A label ++i; if(i<10)goto Loop; //Jump to the label } 在原始而和谐的早期Fortran和Basic时代，我们没有if then else，没有for和while，甚至没有函数的概念，一切控制结构都靠goto(带条件的或无条件的)构件。软件工程师将这样的代码称作\"意大利面条\"代码。实践证明这样的代码极容易造成混乱。 自从证明了结构化的程序可以做意大利面条做到的任何事情，人们就开始不遗余力地推广结构化设计思想，将goto像猛兽一般囚禁在牢笼，标号也因此消失。 标号唯一散发余热的地方，是在switch中控制分支流程。 很多人不甚了解switch存在的意义，认为它只是大型嵌套if then else结构的缩略形式，并且比if语句多了很多\"不合理\"的限制。如果你了解到switch在编译器内部的实现机制，就不难理解强加在switch之上的诸多限制，比如case后只能跟一个编译期整型常量，比如用break结束每一个case。首先看一个switch实例： switch (shape.getAngle()) { case 3: cout<<\"Triangle\";break; case 4: cout<<\"Square\";break; case 0:case1: cout<<\"Not a sharp!\";break; default: cout<<\"Polygon\"; } 任何程序员都可以写出与之对应的if结构： int i= getAngle(shape); if (i==3) cout<<\"Triangle\"; else if(i==4) cout<<\"Square\"; else if(i==0||i==1) cout<<\"Not a sharp!\"; else cout<<\"Polygon\"; 看起来这两段代码在语义上是完全一样的，不是么？ 不！或许代码的执行结果完全一样，但是就执行效率而言，switch版本的更快！ 要了解为什么switch的更快，我们需要知道编译器是怎样生成switch的实现代码的： 首先，保留switch之后由{}括起来的语具体，仅将其中case、default和break替换为真正的标号： switch (getAngle(shape)) { _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 随后，对于所有出现在case之后的常量，列出一张只有goto的跳转表，其顺序按case后的常量排列： goto _case_0; goto _case_1; goto _case_3; goto _case_4; 然后，计算case之后的常量与跳转表地址之间的关系，如有需要，在跳转表中插入空缺的项目： 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; //因为没有case 2，所以插入此项以条转到default 100120: goto _case_3; 100125: goto _case_4; 假设一个goto语句占用5个字节，那么在本例中，goto的地址=case后的常量*5+100105 之后，生成跳转代码，在其余条件下跳转至default，在已知范围内按照公式跳转，全部的实现如下： { int i= getAngle(shape); if (i<0||i>=5)goto _default; i=i*5+100105; //按照得出的公式算出跳转地址 goto i; //伪代码，C中不允许跳转到整数，但是汇编允许 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; 100120: goto _case_3; 100125: goto _case_4; _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 经过这样处理整个switch结构，使得无论switch后的变量为何值，都可以通过最多两次跳转到达目标代码。相比之下if版本的代码则采用线性的比较和跳转，在case语句很多的情况下效率极低。 由此,我们也可以知道,为什么case后跟的一定是编译期整型常数，因为编译器需要根据这个值制作跳转表。我们可以明白为什么case与case之间应该用break分隔，因为编译器不改变switch语句体的结构，case其本身只是一个具有语义的标号而已，要想跳出switch，就必须用break语句。","tags":"import","title":"C++ Tricks 3.2 标号、goto，以及switch的实现"},{"url":"//farseerfc.me/zhs/c-tricks-3-1-lvalue-rvalue-constant.html","text":"从 farseerfc.wordpress.com 导入 3.1 左值右值与常量性(lvalue，rvalue & constant) 首先要搞清楚的是，什么是左值，什么是右值。这里给出左值右值的定义： 1、左值是可以出现在等号(=)左边的值，右值是只能出现在等号右边的值。 2、左值是可读可写的值，右值是只读的值。 3、左值有地址，右值没有地址。 根据左值右值的第二定义，值的左右性就是值的常量性——常量是右值，非常量是左值。比如： 1=1;//Error 这个复制操作在C++中是语法错误，MSVC给出的错误提示为\"error C2106: '=' : left operand must be l-value\"，就是说'='的左操作数必须是一个左值，而字面常数1是一个右值。可见，严格的区分左值右值可以从语法分析的角度找出程序的逻辑错误。 根据第二定义，一个左值也是一个右值，因为左值也可读，而一个右值不是一个左值，因为右值不可写。 通常情况下，声明的变量是一个左值，除非你指定const将它变成一个右值： int lv=1; const int rv=lv; 由于右值的值在程序执行期间不能改变，所以必须用另一个右值初始化它。 一个普通变量只能用右值初始化，如果你想传递左值，必须声明一个引用或一个指针： int & ref=lv;//用引用传递左值 int * plv=&lv;//传递指针以间接传递左值 必须用左值初始化引用，然而，可以用右值初始化常量引用： int & r1=1; //Error! const int & r2=1; //OK 这实际上相当于： int _r2=1; const int & r2=_r2; 这样的写法在函数体内没什么作用，但是在传递函数参数时，它可以避免潜在的(传递左值时的)复制操作，同时又可以接受右值。 通常情况下，函数的参数和返回值都只传回右值，除非你明确的通过引用传递左值。 明确了左值与右值的区别，有助于我们写函数时确定什么时候应该有const，什么时候不该有。比如，我们写了一个代表数学中复数的类Complex： class Complex; 然后，我们写针对Complex的运算符重载：operator+和operator=。问题在于，参数和返回值应该是什么类型，可选类型有四种： Complex、const Complex、Complex&、const Complex&。 对于operator+，我们不会改变参数的值，所以可以通过const Complex&传递参数。至于返回值类型，由于int类型的加法返回右值，所以根据Do as the ints do的原则，返回值类型为const Complex： const Complex operator+(const Complex&,const Complex&); 对于operator=，同样要思考这些问题。我们写入第一个参数，所以第一个参数为Complex&，我们只读取第二个参数，所以第二个参数为const Complex&。至于返回值，还是Do as the ints do。int的赋值返回左值，不信你可以试一试： int i; (i=1)=2; 虽然比较傻，先将i赋为1，再将其改为2，但是这是被C++语法支持的做法，我们就理应遵守。所以返回第一个参数的左值： Complex& operator=(Complex&,const Complex&); const是C++引入的语言特性，也被ANSI C99借鉴，在经典版本的C语言中是没有的。关于const的历史，有几点值得玩味。最初Bjarne Stroustrup引入const时，可写性是和可读性分开的。那时使用关键字readonly和writeonly。这个特点被首先提交到C的ANSI标准化委员会(当时还没有C++标准化的计划)，但是ANSI C标准只接受了readonly的概念，并将其命名为const。随后，有人发现在多线程同步的环境下，有些变量的值会在编译器的预料之外改变，为了防止过度优化破坏这些变量，C++又引入关键字violate。从语义特点来看，violate是const的反义词，因为const表示不会变的量，而violate表示会不按照预期自行变化的量。从语法特点而言，violate与const是极为相似的，适用于const的一切语法规则同样适用于violate。 值的常量性可以被划分为两种：编译期常量和运行期常量。C++语法并没有严格区分这两种常量，导致了少许混乱： const int i=5;const int * pi=&i; const_cast<int&>i=1;//对于运行期常量，在需要时可以去除它的常量性 int a[i];//对于编译期常量，可以用它来指定数组大小 cout<<i<<sizeof(a)/sizeof(a[0])<<*pi; 这种将编译期与运行期常量的特性混用的方法，势必导致语义的混乱。数组a的大小最终是5，因为采用了i的编译期值，而不管i在运行期是否被改变了值。最后一句代码将（有可能）输出551，第一个i的值作为一种优化在编译期绑定，第二个值标明了a的大小，第三个值通过指针显示地输出i的运行期真实值。 在C++的近亲C#的语法中，这两种常量被严格地区分开：编译期常量由const指定，只能是内建类型变量；运行期常量由readonly指定，可以是任何类型。永远不会改变的常量，如圆周率pi的值，应该用const声明；而其它有可能改变的常量，皆由readonly声明。 C++中的const的特点更倾向于C#中的readonly，虽然语法上允许使用const的编译期常量性，但正如上文所展示的，这容易造成混乱。为了得到C#中const的语义，在C++中，我们不必回归恶魔#define的怀抱，可以使用所谓\"匿名enum技巧\"。当匿名声明一个enum类型时，其中的枚举值就是一个int类型的编译期常量，比如： enum{Size=5;}; int a[Size]; 这种使用匿名enum来声明编译期常量的做法，被广泛应用于STL、boost等模板库的实现代码中。","tags":"import","title":"C++ Tricks 3.1 左值右值与常量性(lvalue，rvalue & constant)"},{"url":"//farseerfc.me/zhs/c-tricks-2-2-i386-memory-layout.html","text":"从 farseerfc.wordpress.com 导入 2.2 I386平台的内存布局 众所周知，I386是32位体系结构。因此对于绝大多数I386平台的C++编译器而言，sizeof(int)=sizeof(long)=sizeof(void*)=4。当然C++标准对此没有任何保证，我们也不应该试图编写依赖于此的代码。 32位指针的可寻址空间为4GB。为充分利用这么大的寻址空间，也是为了支持其它更先进的技术比如多任务技术或者动态链接库技术，WinNT使用虚拟内存技术，给与每个应用程序全部4GB的内存空间。4GB的地址被一分为二，前2GB供应用程序自己使用，后2GB由系统内核分配和管理。这2GB的内存地址，通常被划分成3种内存区使用： 1 代码及静态数据区 由代码加载器从动态链接库镜像(通常是exe或dll文件)加载，通常定位到镜像文件中指定的基址开始的内存区。如果基址所在内存已被占用，动态连接器会将代码或数据重定向到其它可用地址。 在C++中，静态数据包括：名字空间(namespace)和全局(global)对象、函数的static对象、类的static数据成员。这些静态数据由编译器分配地址(但可能被重定向)，由静态连接器写入代码文件(通常是exe或dll)的静态数据区段。所以标准说，这些静态数据在编译期就已经具有地址。 2 栈(Stack) 栈是最常用的动态数据存储区，所有函数的non-static对象和函数参数都在程序运行期在栈上分配内存。在数据结构中，术语\"栈(Stack)\"意指先进后出(FILO，First In Last Out)，与\"队列(Queue)\"所指的FIFO相对。相对于基于堆的对象分配技术，默认使用栈的对象分配有两点优势： 一、栈的FILO与人的思维方式相同 现实生活中有许多事例都使用FILO的方式，比如人们必须先提起话筒再拨打号码，而后挂断电话之后再放下话筒。使用FILO的栈，可以保证事物的销毁顺序以其诞生顺序相反的顺序进行，不会产生在挂断电话之前就放下话筒的尴尬。 二、栈的分配管理仅需要两个额外指针：栈顶(esp)和栈底(ebp)指针 从实现的技术层面而言，栈的管理比其它动态分配技术要简单很多。I386平台上的动态栈管理，仅需要栈顶和栈底两个指针。这两个指针的存储显然不能放置于栈中，置于静态数据区又有损效率。I386平台为管理动态栈专门预留了两个通用寄存器变量esp与ebp，分别代表栈顶(esp,Extended Stack Pointer)与栈底(Extended Bottom Pointer)指针。其中的extended代表它们是32位指针，以区分16位的sp和bp寄存器。 栈是动态存储区的特点，表明它的内存占用将随着程序的运行而变化。I386平台上WinNT将应用程序的栈置于程序空间，向下增长。程序初始化时，由操作系统将esp指向系统分配的栈空间的顶部。当程序需要在栈上分配变量时，就将esp减去变量所需字节数，这被称作\"压栈(Push)\"；随后又要销毁变量时，就将esp加上变量所需字节数，这被称作\"弹出(Pop)\"。esp与ebp两者之间所夹的空间，就是当前函数正在使用的栈空间。由于栈向下增长，esp(栈顶)的值总是小于ebp(栈底)的值，新分配的变量地址总是小于旧变量的地址。 3 堆(Heap)和自由存储区 栈中的变量对于分配与释放的顺序有特定要求，这在一定程度上限制了栈的适用范围。面向对象(OO，Object Oriented)的程序设计思想也要求能自由地控制变量的分配与销毁。由此，现代操作系统都提供了被称作\"堆(Heap)\"的自由存储区，以允许由程序员控制的对象创建和销毁过程。C标准库函数malloc和free则是对操作系统提供的堆操作的封装。C++提供的自由存储区运算符new和delete则通常是malloc和free的又一层封装。 操作系统经由malloc和free控制对堆的访问。堆的存储管理技术各不相同，简单的使用双链表管理，复杂的可以比拟一个完整的文件系统。 由于额外的管理需求，使用系统提供的通用分配器在堆上分配和销毁变量的代价，无论从空间角度还是效率角度而言，都比在栈上分配对象要高昂很多。对于sizeof上百的大型对象，这样的高昂代价还是可以接受的，但是对于sizeof只有个位数的小对象，这样的代价通常是一个数量级的差距。正因为这个原因，STL不使用new和delete，转而使用分配子(alllocor)分配对象。","tags":"import","title":"C++ Tricks 2.2 I386平台的内存布局"},{"url":"//farseerfc.me/zhs/c-tricks.html","text":"从 farseerfc.wordpress.com 导入 C++ Tricks By FarseerFc 从今天起，我再将在 Live Space 和 QQZone 同时发表一系列文章，暂定名为\"C++Tricks\"。 本文旨在记录和阐述一些本人学习C++时所得的心得、技巧。总体来看，本文涉及的内容是每一个C++程序员都应该知道的，但是很少见诸C++教材。希望对各位同仁学习C++有所帮助。 也可以通过QQ或MSN向我索要此文的DOC版或PDF版，会比网页上的更新的快一点。 1 词法问题(Lexical Problems) 1.1 条件运算符(?:) 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱 2 X86体系结构 2.1 X86概述 2.2 I386平台的内存布局 2.3 I386平台C函数内部的栈分配 2.4 I386平台C函数调用边界的栈分配 2.5 I386平台的边界对齐(Align) 2.6 I386平台C函数的可变参数表(Variable Arguments) 2.7 I386平台的其它函数调用模型 3 过程式编程 3.1 左值右值与常量性(lvalue，rvalue & constant) 3.2 标号、goto，以及switch的实现","tags":"import","title":"C++ Tricks"},{"url":"//farseerfc.me/zhs/c-tricks-2-3-i386-stack-allocation-in-c-functions.html","text":"从 farseerfc.wordpress.com 导入 2.3 I386平台C函数内部的栈分配 函数使用栈来保存局部变量，传递函数参数。进入函数时，函数在栈上为函数中的变量统一预留栈空间，将esp减去相应字节数。当函数执行流程途径变量声明语句时，如有需要就调用相应构造函数将变量初始化。当执行流程即将离开声明所在代码块时，以初始化的顺序的相反顺序逐一调用析构函数。当执行流程离开函数体时，将esp加上相应字节数，归还栈空间。 为了访问函数变量，必须有方法定位每一个变量。变量相对于栈顶esp的位置在进入函数体时就已确定，但是由于esp会在函数执行期变动，所以将esp的值保存在ebp中，并事先将ebp的值压栈。随后，在函数体中通过ebp减去偏移量来访问变量。以一个最简单的函数为例： void f() { int a=0; //a的地址被分配为ebp-4 char c=1; //c的地址被分配为ebp-8 } 产生的汇编代码为： push ebp ;将ebp压栈 mov ebp,esp ;ebp=esp 用栈底备份栈顶指针 sub esp,8 ;esp-=8，为a和c预留空间，包括边界对齐 mov dword ptr[ebp-4],0 ;a=0 mov byte ptr[ebp-8],1 ;c=1 add esp,8 ;esp+=8，归还a和c的空间 mov esp,ebp ;esp=ebp 从栈底恢复栈顶指针 pop ebp ;恢复ebp ret ;返回 相应的内存布局是这样： 09992:c=1 <-esp 09996:a=0 10000:旧ebp <-ebp 10004:…… 注:汇编中的pop、push、call、ret语句是栈操作指令，其功能可以用普通指令替换 push ebp相当于: add esp,4 mov dword ptr[esp],ebp pop ebp相当于： mov ebp,dword ptr[esp] sub esp,4 call fun_address相当于： push eip jmp fun_address ret相当于 add esp,4 jmp dword ptr[esp-4] 带参数的ret ret 8相当于 add esp,12 jmp dword ptr[esp-4] 所有局部变量都在栈中由函数统一分配，形成了类似逆序数组的结构，可以通过指针逐一访问。这一特点具有很多有趣性质，比如，考虑如下函数，找出其中的错误及其造成的结果： void f() { int i,a[10]; for(i=0;i<=10;++i)a[i]=0;/An error occurs here! } 这个函数中包含的错误，即使是C++新手也很容易发现，这是老生常谈的越界访问问题。但是这个错误造成的结果，是很多人没有想到的。这次的越界访问，并不会像很多新手预料的那样造成一个\"非法操作\"消息，也不会像很多老手估计的那样会默不作声，而是导致一个，呃，死循环！ 错误的本质显而易见，我们访问了a[10]，但是a[10]并不存在。C++标准对于越界访问只是说\"未定义操作\"。我们知道，a[10]是数组a所在位置之后的一个位置，但问题是，是谁在这个位置上。是i! 根据前面的讨论，i在数组a之前被声明，所以在a之前分配在栈上。但是，I386上栈是向下增长的，所以，a的地址低于i的地址。其结果是在循环的最后，a[i]引用到了i自己！接下来的事情就不难预见了，a[i]，也就是i，被重置为0，然后继续循环的条件仍然成立……这个循环会一直继续下去，直到在你的帐单上产生高额电费，直到耗光地球电能，直到太阳停止燃烧……呵呵，或者直到聪明的你把程序Kill了……","tags":"import","title":"C++ Tricks 2.3 I386平台C函数内部的栈分配"},{"url":"//farseerfc.me/zhs/c-tricks-2-4-i386-stack-allocation-accross-function-invocation.html","text":"从 farseerfc.wordpress.com 导入 2.4 I386平台C函数调用边界的栈分配 当调用一个函数时，主调函数将参数以声明中相反的顺序压栈，然后将当前的代码执行指针(eip)压栈，然后跳转到被调函数的入口点。在被调函数中，通过将ebp加上一个偏移量来访问函数参数，以声明中的顺序(即压栈的相反顺序)来确定参数偏移量。被调函数返回时，弹出主调函数压在栈中的代码执行指针，跳回主调函数。再由主调函数恢复到调用前的栈。 函数的返回值不同于函数参数，通过寄存器传递。如果返回值类型可以放入32位变量，比如int、short、char、指针等类型，通过eax寄存器传递。如果返回值类型是64位变量，如_int64，同过edx+eax传递，edx存储高32位，eax存储低32位。如果返回值是浮点类型，如float和double，通过专用的浮点数寄存器栈的栈顶返回。如果返回值类型是用户自定义结构，或C++类类型，通过修改函数签名，以引用型参数的形式传回。 同样以最简单的函数为例： void f(){ int i=g(1,2); } int g(int a,int b){ int c=a+b； return c; } 产生的汇编代码如下： f: push ebp ;备份ebp mov ebp,esp ;建立栈底 sub esp,4 ;为i分配空间 mov eax,2 ;准备参数b的值2 push eax ;将b压栈 mov eax,1 ;准备参数a的值1 push eax ;将a压栈 call g ;调用g add esp,8 ;将a和b一起弹出，恢复调用前的栈 mov dword ptr[ebp-4],eax ;将返回值保存进变量i mov esp,ebp ;恢复栈顶 pop ebp ;恢复栈底 g: push ebp ;备份ebp mov ebp,esp ;建立栈底 sub esp,4 ;为局部变量c在栈中分配内存 mov eax,dword ptr[ebp+8] ;通过ebp间接读取参数a的值 mov ebx,dword ptr[ebp+12] ;通过ebp间接读取参数b的值 add eax,ebx ;将a和b的值相加，之和存在eax中 mov dword ptr[ebp-4],eax ;将和存入变量c mov eax,dword ptr[ebp-4] ;将c作为返回值，代码优化后会删除此句 add esp,4 ;销毁c的内存 mov esp,ebp ;恢复栈顶 pop ebp ;恢复栈底 ret ;返回函数f 栈的内存布局如下： 100076:c <- g的esp 100080:f的ebp=100100 <- g的ebp 100084:f的eip 100088:a=1 100092:b=2 100096:i 100100:旧ebp <-f的ebp 100104:…… 注意在函数g的汇编代码中，访问函数的局部变量和访问函数参数的区别。局部变量总是通过将ebp减去偏移量来访问，函数参数总是通过将ebp加上偏移量来访问。对于32位变量而言，第一个局部变量位于ebp-4，第二个位于ebp-8，以此类推，32位局部变量在栈中形成一个逆序数组；第一个函数参数位于ebp+8，第二个位于ebp+12，以此类推，32位函数参数在栈中形成一个正序数组。 由于函数返回值通过寄存器返回，不需要空间分配等操作，所以返回值的代价很低。基于这个原因，旧的C语法约定，不写明返回值类型的函数，返回值类型为int。这一规则与现行的C++语法相违背，因为C++中，不写明返回值类型的函数返回值类型为void，表示不返回值。这种语法不兼容性是为了加强C++的类型安全，但同时也带来了一些问题。","tags":"import","title":"C++ Tricks 2.4 I386平台C函数调用边界的栈分配"},{"url":"//farseerfc.me/zhs/c-tricks-2-5-address-alignment.html","text":"从 farseerfc.wordpress.com 导入 2.5 I386平台的边界对齐(Align) 首先提问，既然I386上sizeof(int)==4、sizeof(char)==1，那么如下结构(struct)A的sizeof是多少？ struct A{int i;char c;}; 答案是sizeof(A)==8……1+5=8？ 呵呵，这就是I386上的边界对齐问题。我们知道，I386上有整整4GB的地址空间，不过并不是每一个字节上都可以放置任何东西的。由于内存总线带宽等等的技术原因，很多体系结构都要求内存中的变量被放置于某一个边界的地址上。如果违反这个要求，重则导致停机出错，轻则减慢运行速度。对于I386平台而言，类型为T的变量必须放置在sizeof(T)的整数倍的地址上，char可以随便放置，short必须放在2的整数倍的地址上，int必须放在4的整数倍的地址上，double必须放在8的整数倍的地址上。如果违反边界对齐要求，从内存中读取数据必须进行两次，然后将独到的两半数据拼接起来，这会严重影响效率。 由于边界对齐问题的要求，在计算struct的sizeof的时候，编译器必须算入额外的字节填充，以保证每一个变量都能自然对齐。比如如下声明的struct: struct WASTE { char c1; int i; char c2; } 实际上相当于声明了这样一个结构： struct WASTE { char c1; char _filling1 [3];//三个字节填充，保证下一个int的对齐 int i; char c2； char _filling2 [3];//又三个字节填充 } 值得注意的是尾部的3个字节填充，这是为了可以在一个数组中声明WASTE变量，并且每一个都自然对齐。因为有了这些填充，所以sizeof(WASTE)==12。这是一种浪费，因为只要我们重新安排变量的声明，就可以减少sizeof： struct WASTE { int i; char c1,c2; } 像这样的安排，sizeof就减少到8，只有2个字节的额外填充。为了与汇编代码相兼容，C语言语法规定，编译器无权擅自安排结构体内变量的布局顺序，必须从左向右逐一排列。所以，妥当安排成员顺序以避免内存空间的浪费，就成了我们程序员的责任之一。一般的，总是将结构体的成员按照其sizeof从大到小排列，double在最前，char在最后，这样总可以将结构的字节填充降至最小。 C++继承了C语言关于结构体布局的规定，所以以上的布局准则也适用于C++的class的成员变量。C++进一步扩展了布局规定，同一访问区段(private、public、protected)中的变量，编译器无权重新排列，不过编译器有权排列访问区段的前后顺序。基于这个规则，C++中有的程序员建议给每一个成员变量放在单独区段，在每一个成员声明之前都加上private:、public:、protected:标志，这可以最大限度的利用编译器的决策优势。 在栈中按顺序分配的变量，其边界也受到对齐要求的限制。与在结构中不同的是，栈中的变量还必须保证其后续变量无论是何种类型都可以自由对齐，所以在栈中的变量通常都有平台相关的对齐最小值。在MSVC编译器上，这个最小值可以由宏_INTSIZEOF(T)查询： #define _INTSIZEOF(T) ( (sizeof(T) + sizeof(int) - 1) & ~(sizeof(int) - 1) ) _INTSIZEOF(T)会将sizeof(T)进位到sizeof(int)的整数倍。 由于在栈中分配变量使用_INTSIZEOF而不是sizeof，在栈上连续分配多个小变量(sizeof小于int的变量)会造成内存浪费，不如使用结构(struct)或数组。也就是说： char c1,c2,c3,c4;//使用16字节 char c[4];//使用4字节 当然，使用数组的方法在访问数组变量(比如c[1])时有一次额外的指针运算和提领(dereference)操作，这会有执行效率的损失。这又是一种空间(内存占用)vs时间(执行效率)的折中，需要程序员自己根据情况权衡利弊。 sizeof的大小可能比我们预期的大，也可能比我们预期的小。对于空类： class Empty {}; 在通常情况下，sizeof(Empty)至少为1。这是因为C++语法规定，对于任何实体类型的两个变量，都必须具有不同的地址。为了符合语法要求，编译器会给Empty加入1字节的填充。所以sizeof()的值不可能出现0的情况。可是对于以下的类声明： class A:public Empty{vitual ~A(){}}; sizeof(A)有可能是6，也有可能是5，也有可能是4！必不可少的四个字节是一个指向虚函数表的指针。一个可能有的字节是Empty的大小，这是是因为编译器在特定情况下会将Empty视作一个\"空基类\"，从而实施\"空基类优化\"，省掉那毫无作用的一字节填充。另一个字节是A的一字节填充，因为从语法上讲，A没有成员声明，理应有1字节填充，而从语义上讲，编译器给A的声明加入了一个指向虚函数表的指针，从而A就不再是一个\"空类\"，是否实施这个优化，要看编译器作者对语法措词的理解。也就是说，sizeof也会出现4+1+1=4的情况。具体要看编译器有没有实施\"空基类优化\"和\"含虚函数表的空类优化\"。 结构和类的空间中可能有填充的字节，这意味着填充字节中可能有数值，虽然这数值并不影响结构的逻辑状态，但是它也可能不知不觉中影响到你。比如说，你手头正好有一组依赖于底层硬件(比如多处理器)的函数，他们在操纵连续字节时比手动编码要快很多，而你想充分利用这种硬件优势： bool BitCompare(void* begin,void* end,void* another); 这个函数将区间[begin,end)之间的字节与another开始的字节相比较，如果有一位不同就返回false，否则返回true。 比如你想将这个函数用于你自己的类的operator==中，这样可以利用硬件加快速度。不过你在动手前要充分考虑，你的class是否真的要比较每一位。如果在类的成员中存在编译器填充的字节数，那么应用以上的函数就是不正确的，因为填充的字节中可以有不同的值。为了保证你可以用Bitwise Compare，你必须确保填充的字节中的值也是相同的。这不仅要求你在类的构造函数中初始化类的每一bit而不是每一个成员，也要求你在复制初始化和复制赋值函数中也同时保证bitwise copy语义，而不是编译器默认产生的memberwise语义。当然，你可能通过与BitCompare一同提供的BitCopy来完成这个艰巨的任务。","tags":"import","title":"C++ Tricks 2.5 I386平台的边界对齐(Align)"},{"url":"//farseerfc.me/zhs/c-tricks-2-6-i386-variable-arguments.html","text":"从 farseerfc.wordpress.com 导入 2.6 I386平台C函数的可变参数表(Variable Arguments) 基于前文(2.4节)分析，我们可以不通过函数签名，直接通过指针运算，来得到函数的参数。由于参数的压栈和弹出操作都由主调函数进行，所以被调函数对于参数的真实数量不需要知晓。因此，函数签名中的变量声明不是必需的。为了支持这种参数使用形式，C语言提供可变参数表。可变参数表的语法形式是在参数表末尾添加三个句点形成的省略号\"...\"： void g(int a,char* c,...); 省略号之前的逗号是可选的，并不影响词法语法分析。上面的函数g可以接受2个或2个以上的参数，前两个参数的类型固定，其后的参数类型未知，参数的个数也未知。为了知道参数个数，我们必须通过其他方法，比如通过第一个参数传递： g(3,\"Hello\",2,4,5);//调用g并传递5个参数，其中后3个为可变参数。 在函数的实现代码中，可以通过2.4节叙述的，参数在栈中的排列顺序，来访问位于可变参数表的参数。比如: void g(int a,char* c...){ void *pc=&c;int* pi=static_cast<int*>(pc)+1;//将pi指向首个可变参数 for(int i=0;i<a;i++)std::cout<<pi[i]<<\" \"； std::cout<<c<<std::endl; } 我们甚至可以让一个函数的所有参数都是可变参数，只要有办法获知参数的数量即可。比如，我们约定，在传递给addAll的参数都是int，并且最后一个以0结束： int addAll(...); int a=f(1,4,2,5,7,0); 那么addAll可以这样实现： int addAll(...){ int sum=0;int *p=&sum; //p指向第一个局部变量 p+=3; //跳过sum，ebp，eip，现在p指向第一个参数 for(;*p;++p) //如果p不指向0就继续循环 sum+=*p; return sum; } 可变参数表的最广泛应用是C的标准库函数中的格式化输入输出：printf和scanf。 void printf(char *c,...); void scanf(char *c,...); 两者都通过它的首个参数指出后续参数表中的参数类型和参数数量。 如果可变参数表中的参数类型不一样，那么操纵可变参数表就需要复杂的指针运算，并且还要时刻注意边界对齐(align)问题，非常令人头痛。好在C标准库提供了用于操纵可变参数表的宏(macro)和结构(struct)，他们被定义在库文件stdarg.h中: typedef struct {char *p;int offset;} va_list; #define va_start(valist,arg) #define va_arg(valist,type) #define va_end(valist) 其中结构va_list用于指示参数在栈中的位置，宏va_start接受一个va_list和函数的可变参数表之前的参数，通过第一个参数初始化va_list中的相应数据，因此要使用stdarg.h中的宏，你的可变参数表的函数必须至少有一个具名参数。va_arg返回下一个类型为type的参数，va_end结束可变参数表的使用。还是以上文的addAll为例，这次写出它的使用标准宏的版本： int addAll(int i,...) { va_list vl; //定义一个va_list结构 va_start(vl,i); //用省略号之前的参数初始化vl if(i=0)return 0; //如果第一个参数就是0，返回 int sum=i; //将第一个参数加入sum for(;;){ i=va_arg(vl,int); //取得下一个参数，类型是sum if(i==0)break; //如果参数是0，跳出循环 sum+=i; } va_end(vl); return sum; } 可以看出，如果参数类型一致，使用标准库要多些几行代码。不过如果参数类型不一致或者未知(printf的情况)，使用标准库就要方便很多，因为我们很难猜出编译器处置边界对齐(align)等汇编代码的细节。使用标准库的代码是可以移植的，而使用上文所述的其它方法操纵可变参数表都是不可移植的，仅限于在I386平台上使用。 纵使可变参数表有使用上的便利性，它的缺陷也有很多，不可移植性和平台依赖性只是其一，最大的问题在于它的类型不安全性。使用可变参数表就意味着编译器不对参数作任何类型检查，这在C中算是一言难尽的历史遗留问题，在C++中就意味着恶魔reinterpret_cast被你唤醒。C的可变参数表是C++代码错误频发的根源之一，以至于C++标准将可变参数表列为即将被废除的C语言遗留特性。C++语法中的许多新特性，比如重载函数、默认参数值、模板，都可以一定程度上替代可变参数表，并且比可变参数表更加安全。 可变参数表在C++中惟一值得嘉奖的贡献，是在模板元编程(TMP)的SFINAE技术中利用可变参数表制作最差匹配重载。根据C++标准中有关函数重载决议的规则，具有可变参数表的函数总是最差匹配，编译器在被逼无奈走头无路时才会选择可变参数表。利用这一点，我们可以精心制作重载函数来提取类型信息。比如，要判断一个通过模板传递来的类型是不是int： long isIntImp(int); char isIntImp(...); template<typename T> struct isInt { enum{value=sizeof(isIntImp(T()))==sizeof(long);} } 然后，在一个具有模板参数T的函数中，我们就可以写 if(isInt<T>::value)//... 在这个(不怎么精致的)例子中，如果T是int，那么isIntImp的第一个重载版本就会被选中，返回值类型就是long，这样value就为1。否则，编译器只能选中第二个具有可变参数表的重载版本，返回值类型成为char，这样value就为0。把它说得再明白一些，上文的代码所表达的意思是：如果类型T是int，那它就是int，否则它就不是int，呵呵简单吧。这种通过重载决议规则来提取类型信息的技术，在模板元编程中被称作SFINAE，它和其它模板元编程技术被广泛运用于STL、Boost等模板库的开发实现之中。 值得注意的是，在上文SFINAE的运用中，isIntImp并没有出现定义而只提供了声明，因为我们并没有实际调用isIntImp函数，而只是让它参与重载决议并用sizeof判断其返回值类型。这是C++的一个设计准则的完美体现：不需要的东西可以不出现。由于这一准则，我们避免了在C++中调用具有可变参数表的函数这一危险举动，而仅仅利用了可变参数表在语法分析过程中的特殊地位，这种对于危险语言特性的巧妙利用是善意而无害的。","tags":"import","title":"C++ Tricks 2.6 I386平台C函数的可变参数表(Variable Arguments)"},{"url":"//farseerfc.me/zhs/c-tricks-2-7-i386-calling-conventions.html","text":"从 farseerfc.wordpress.com 导入 2.7 I386平台的其它函数调用模型 上文介绍的只是I386平台上C函数调用的标准模型，被称作__cdecl。事实上，Microsoft Visual C++编译器还支持其它一些函数调用模型，所有调用模型名称皆以双下划线开头，下面列出所有函数调用模型的异同： 1 __cdecl 参数压栈顺序：逆序(从右至左) 参数堆栈恢复者：主调函数(caller) __cdecl明确地指出函数使用C函数调用模型，这是默认的调用模型。 2 __stdcall 参数压栈顺序：逆序(从右至左) 参数堆栈恢复者：被调函数(callee) __stdcall是微软所谓的标准调用模型。可惜的是它与__cdecl不兼容。几乎所有的Win32API函数使用这种函数调用模型，希望在DLL之间，或者在程序和WinNT操作系统之间传递函数指针的函数也应该使用这种模型。与__cdecl模型的不同之处在于，__stdcall模型下由被调函数恢复堆栈。主调函数在call语句之后，不需要再加上add语句。而被调函数的ret语句则被添加一个参数，代表函数参数堆栈的长度。因此，被调函数需要明确的知晓函数参数的数量和类型，所以在__stdcall模型下不支持可变参数表，所有参数必须写明。 3 __thiscall 参数压栈顺序：逆序(从右至左)，this用ecx传递。 参数堆栈恢复者：被调函数(callee) __thiscall是VC编译器中类的非静态成员函数(non-static member functon)的默认调用模型。但是如果此成员函数有可变参数表，VC编译器会使用__cdecl。和__stdcall一样，__thiscall由被调函数恢复堆栈。比较独特的是__thiscall会通过ecx寄存器传递成员函数的this指针，而__cdecl下this指针是通过在参数表最前面增加一个函数参数来传递的。__thiscall是VC编译器对this指针的使用的一种优化，大大提高了面向对象程序的效率。在VC2003及之前的编译器上__thiscall不是一个关键字，不能被显式指定。但可以给成员函数显式指定__cdecl来避免使用__thiscall。 4 __fastcall 参数压栈顺序：逆序(从右至左)，前两个32位函数参数放入ecx和edx中 参数堆栈恢复者：被调函数(callee) 快速函数调用模型，将前两个32位函数参数放入ecx和edx中，其余参数再逆序压栈。使用的是和__thiscall类似的优化技术，加快函数调用，适合运用在小型inline函数上。同样使用__stdcall形式的被调函数恢复堆栈，所以不支持可变参数表。 5 __pascal 参数压栈顺序：正序(从左至右) 参数堆栈恢复者：被调函数(callee) 过程式编程语言Pascal所使用的函数调用模型，由此得名。也是16位版本的Windows使用的API模型，过时的模型，现在已经废弃且禁止使用。你会看到有些书本仍会不时提到它，所以需要注意。__pascal是正序压栈，这与大部分I386函数模型都不相同。与__stdcall一样，由被调者恢复堆栈，不支持可变参数表。历史上曾有过的别名PASCAL、pascal、_pascal(单下划线)，现在都改成了__stdcall的别名，与__pascal(双下划线)不同。 6 其它函数调用模型，以及模型别名。 __syscall：操作系统内部使用的函数调用模型，由用户模式向核心模式跳转时使用的模型。由于用户模式和核心模式使用不同的栈，所以没办法使用栈来传递参数，所有参数通过寄存器传递，这限制了参数的数量。用户模式编程中不允许使用。 __fortran：数学运算语言fortran使用的函数模型，由此得名。在C中调用由fortran编译的函数时使用。 __clrcall：微软.Net框架使用的函数模型，托管(Managed)C++默认使用，也可以从非托管代码调用托管函数时使用。参数在托管栈上正序(从左至右)压栈，不使用普通栈。 CALLBACK、PASCAL、WINAPI、APIENTRY、APIPRIVATE：I386平台上是__stdcall的别名 WINAPIV：I386平台上是__cdecl的别名 7 函数调用模型的指定 函数调用模型的指定方式和inline关键字的指定方式相同，事实上，inline可以被看作是C++语言内建的一种函数调用模型。唯一不同的是，声明函数指针时，也要指明函数调用模型，而inline的指针是不能指明的，根本不存在指向inline函数的指针。比如： int CALLBACK GetVersion(); int (CALLBACK * pf)()=GetVersion;","tags":"import","title":"C++ Tricks 2.7 I386平台的其它函数调用模型"},{"url":"//farseerfc.me/zhs/c-tricks-2-1-x86-architecture.html","text":"从 farseerfc.wordpress.com 导入 2.1 X86概述 所谓X86体系结构，是指以Intel 8086芯片为首的芯片所沿袭的CPU结构，一些文档中又被称作IA32体系结构。包括的芯片有但不限于:Intel 8086至 80486，奔腾(Pentium)系列处理器1至4，赛扬系列处理器，酷睿系列处理器，以及AMD的相应型号产品。X86体系结构在早期属于16位处理器，自80386之后扩展为32位处理器，所以一些文档中又把80386之后的32位处理器体系称作I386。自Pentium4后期，AMD的Athlon64开始，I386被进一步扩充为64位处理器，含有64位寻址能力的X86体系结构被称作X86-64或IA32-64。总之，市售的个人电脑用CPU，除苹果的Macintosh之外，全部采用X86体系结构芯片。 在X86早期，16位的寻址能力只支持64KB(2&#94;16=64K)内存，这显然是不够的。Intel采用分段寻址的方法，用4位段位+16位偏移量，提供了总共1MB(2&#94;20=1M)的寻址能力。所以在X86的16位编程中，有两种指针类型：长指针(lp,long pointer)和短指针(sp,short pointer)，长指针(20位)提供整个内存空间寻址能力，短指针(16位)仅支持同一段中的寻址。在\"古代\"DOS及Win3.x编程过程中，两种类型的指针，以及总共1MB的内存大小，常常把程序员们折腾得焦头烂额。 自I386之后，CPU才开始提供32位的寻址能力。有了整整4GB(2&#94;32=4G)的寻址空间，所有指针统一为长指针(32位)。时至今日，我们仍可以看到微软文档中指针变量的lp前缀。由于内存管理的需要，分段机制被保留下来，但这一次不是因为地址空间太小，而是因为地址空间远大于实际内存容量，从而采用了虚拟内存机制。 在从16位结构向32位结构转变的过程中，由于向下兼容的历史原因，曾一度长时间出现硬件32位(I386)、软件16位(Win3.x)的情况。同样也是为了兼容16位软件，Win9x操作系统(Win95、Win98、WinME)保留了16位代码和32位代码。混合代码的设计使得Win9x及其混乱和不稳定。直到完全32位内核的操作系统WinNT(以及构建于其上的Win2000，WinXP，Win2003)的出现，X86平台上内存布局混乱的局面才得以改善。有了从16位至32位移植的经验和准备，现今的从32位到64位的操作系统移植显得平稳顺利很多。WinXP和WinVista系统都同时发布了32位版本和64位版本，并且其x86-64系统都实现了对32位软件的无缝衔接支持。","tags":"import","title":"C++ Tricks 2.1 X86概述"},{"url":"//farseerfc.me/zhs/c-tricks-1-2-trap-in-comma-logical-operator.html","text":"从 farseerfc.wordpress.com 导入 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱 很多人甚至不知道逗号(,)也是个C++运算符。与语法上要求出现的逗号(比如分隔函数参数的逗号)不同的是，出现在表达式中的逗号运算符在语义上表示多个表达式操作的连续执行，类似于分隔多语句的分号。比如： for ( int i=0,j=9;i<10;++i , --j)std::cout<<i<<\"+\"<<j<<\"=9\\n\"; 在这句语句中，出现了两个逗号，其中前者是语法上用来分隔声明的变量的，并非逗号运算符，而后者则是一个逗号运算符。根据C++标准，逗号运算符的执行顺序为从左到右依次执行，返回最后一个子表达式的结果。由于只有最后一个表达式返回结果，所以对于一个语义正常的逗号表达式而言，前几个子表达式必须具有副作用。同时，从语言的定义中也可以看出，逗号表达式对求值的顺序有严格要求。 对求值顺序有要求的，除了逗号表达式和条件表达式(参见1.1)，在C++中还有逻辑运算符(&&和||)。逻辑运算相较于数学运算和位运算而言，有个显著的不同点：逻辑运算在计算到一半时，就有可能已经得到结果，这样继续运算另一半就不是必需的。对于A&&B，如果A=false，那么无论B为何值，整个的结果都是false；同样的A||B，如果A=true，那么不考虑B，结果一定是true。 C++标准规定，如果逻辑运算到一半(算出A)时，就已经可以确定运算的结果，那么就不运算剩下的另一半(B)。这种执行语义被称作\"短路\"。在其它一些编程语言中，短路语义是可以选择的：在Ada里非短路的逻辑运算符为and和or，短路的逻辑运算符为and_then和or_else。但是在C++中，逻辑运算符的短路语义是语法上强制的，我们没有非短路版本的运算符。如果确实需要非短路语义，我们总是可以通过增加一个bool中间变量加以解决。有时，短路对于保证正确执行是必须的，比如： char *p=getString(); if (p && *p)std::cout<<p; 这段代码在得到了一个字符串后，在字符串不为空时输出它。在C++中判断一个字符串不为空需要两个步骤：判断指针是否为0，以及指针不为0时判断指针指向的内容是否为''。就像条件表达式中讨论到的(参见1.1)，在p为空时提领p是个极其危险的操作。逻辑运算符的短路语义则避免了这种危险。 以上对逗号运算符与逻辑运算符的讨论，仅限于C++标准所定义的运算符语义。为什么这样说呢？这是因为在C++中，运算符的语义是可以由程序员自行定义的，这种机制叫做运算符重载(operator overload)。运算符重载可以将人们熟悉的运算符表达式转换成函数调用，使编程灵活而直观，是个方便的语言特性。不过有时运算符重载也会使人困扰，那就是当运算符重载遇到求值顺序问题时。 C++中，并不是所有合法运算符都可以被合法地重载。条件运算符虽然对求值顺序有要求，但它并不在可重载运算符之列，所以运算符重载机制对它没有影响。问题在于，逗号运算符和逻辑运算符都可以被合法地重载： class BadThing{/* Some Bad and Stupid Thing*/}; BadThing& operator ,(BadThing&, BadThing&);//重载了逗号运算符 bool operator &&(BadThing&, BadThing&);//重载了&& BadThing b1,b2; if (b1&&b2)b1,b2;//被替换成如下形式： if ( operator &&(b1,b2)) operator ,(b1,b2); 可以看到，重载了运算符之后，对运算符的使用被替换为相应的函数调用形式。因此，旧有的运算符的执行顺序不再适用，取而代之的是函数参数的压栈顺序。 根据C++标准规定，任何参数必须在进入函数之前压栈，所以在进入 operator &&之前，b1、b2就会被求值，这里不再有短路规则，任何依赖于短路语义的不知不觉间操作BadThing的代码(可能通过模板)都会混乱。 短路语义只是一个方面，更重要的在于压栈顺序。鉴于执行效率和旧代码兼容性等细节问题，C++标准在压栈顺序上给编译器的开发者留有很大自主性。标准的说辞是，编译器可能以任何它觉得方便的顺序将参数压栈，从左到右，从右到左，甚至从中间到两边，在这一点上我们不能安全地做任何假设。在上面的例子中，编译器生成的代码可能先计算b1再计算b2，也可能是相反的顺序。再看看编译器的实际情况，在我试过的所有基于X86体系结构的编译器中，参数都是以逆向压栈，即从右到左，有悖于大多数人的阅读习惯和直觉(别说你是来自伊斯兰的……)。 在C时代使用函数调用时，压栈顺序并不是什么大问题，毕竟大多数人会在函数调用的边界稍稍小心一些。但是到了C++中，事情变得有些复杂，因为简单如a+b的使用，就有可能被运算符重载机制替换为函数调用。更何况有模板参与之后，我们写代码时不能确定对象的真实类型，也就无法预知一个运算符是否真的被重载过，唯一稳妥的方法是，假定任何有可能被重载的运算符的使用都是函数调用。 <p style=\"margin:0;\"> 回到上文的示例中，由于,和&&都被替换为函数调用，程序的执行顺序将成为压栈顺序，在X86上很有可能是从右到左，与标准定义的运算符的顺序正好相反。逗号运算符原本就含有\"先…后…\"的语义，这种颠倒的执行顺序势必造成程序和程序员的混乱。以我的经验而言，含有 operator ,的类，完全没有办法和STL或者iostream相互协作，反而会导致巨量的错误报告(什么叫巨量的错误报告有概念么？如果没有，那说明你还没玩过范式编程(GP, Generic Programming)。去玩玩GP吧，看看你的编译器对巨量的定义。在我手头，针对3.5KB的代码文件倾泻出3.8 MB 的错误信息的编译器不在少数……)。有鉴于此，我的结论是，除非你有充足的依据支持你这么做(比如你的粗暴上司的键盘上只剩下逗号能用)，并且你清楚的了解这么做的后果的严重性(比如至少要看过此文)，否则我奉劝你，永远不要碰 operator ,、 operator &&以及 operator ||！","tags":"import","title":"C++ Tricks 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱"},{"url":"//farseerfc.me/zhs/c-tricks-1-1-conditional-operator.html","text":"从 farseerfc.wordpress.com 导入 1.1 条件运算符(?:) 条件运算符(?:)是C++中唯一的三目运算符(trinary operator)，用于在表达式中作条件判断，通常可以替换if语句，与Visual Basic中的iif函数、Excel中的if函数有同样的作用。语法形式如下： condition ? true_value : false_value 其中 condition *条件是任何可以转换为bool类型的表达式，包括但不仅限于**bool* 、 int 、指针。与 if 和 while 的条件部分稍显不同的是，这里不能定义变量，否则会导致语法错误。 另外，条件语句会切实地控制执行流程，而不仅仅是控制返回值。也就是说，两个返回值表达式中永远只有一个会被求值，在表达式的执行顺序很重要时，这点尤为值得注意。比如： int *pi=getInt(); int i=pi ? *pi : 0; 这里，只有当pi的值不为0时，它才会被提领(dereference)。这种语义保证了程序的正确性，因为提领一个空指针将导致致命的运行期错误(通常是非法操作的警告)。同时，正因为条件运算符控制运算流程的特点，使得它不能用类似iif的普通函数来模拟： int iif( int con, int t, int f){ if (c) return t; return f;}//试图模拟?: …//in some function int *pi=getInt(); int i=iif(pi,*pi,0);//Error! 这段代码会导致上文提到的致命运行期错误。C/C++标准规定，参数在被传递给函数之前求值，因此无论pi为何值，都会被提领。又因为函数传回一个空指针的情况比较少见，所以这样的错误在调试时很难被发现，一旦发生又势必造成重大灾难。这样的代码在实践中应尽量避免。 有时，条件运算符控制流程的特点会不知不觉影响我们的代码。在C时代，最大值MAX通常用宏实现： #define MAX(a,b) ((a)>(b) ? (a) : (b)) 需要用额外的括号将宏参数和宏本体保护起来，以免运算符优先级扰乱逻辑，这是宏丑陋的特点之一，这里暂且不提。矛盾在于，用具有副作用的表达式调用宏时，会出现问题： int i=5,j=6;//… int a=MAX(++i,++j); 代码的作者原意显然是想先将i,j分别递增，再将其中较大的一个赋给a。执行这段代码，当i=5,j=6时，a=8，知道为什么吗？通过宏展开，赋值语句成这样： int a=(++i)>(++j) ? (++i) : (++j);//删除了多余括号 在判断之前，i、j被分别自增一次，然后舍弃:之前的部分，j又被自增一次。执行之后，i=6,j=8。 MAX的更正确更安全的实现，是利用模板将类型参数化。STL标准算法中就有一个这样的工具级模版函数std::max。 条件运算符是表达式而不是语句，这使得它可以出现在任何需要表达式的地方，这扩大了它的适用范围。在那些语法上只能出现表达式而不能出现语句的地方（比如变量初始化），条件运算符有着不可替代的作用。 条件运算符优于 if 语句的另一个场合是\"模板元编程\"(TMP, Template MetaProgramming)。在TMP这个古怪奇异的编译期运算编程技术中，一切旧有的技术和法则被全线击破，我们所能仰仗的工具，只有模板特化(Specialization)、 typedef s、函数声明(无法调用它们)、以及编译期常量运算。已经有人很深入地论证过，仅有以上这些，就已经形成了一个\"图灵完善\"的计算机语言。我们可以用模板特化技术，来模拟条件分支，循环迭代等一系列复杂的语言结构。由于可以参与编译期常量运算，条件运算符在TMP世界中很自然地扮演起重要角色。 比如，给与类型T的一个变量t，我们想声明一个缓冲区存放t和一个int，缓冲区的大小不小于sizeof(T)也不小于sizeif(int)，我们可以这样写： char buffer[sizeof(T)>sizeof(int)? sizeof(T): sizeof(int)]; 我们不能用一个if语句替换这个运算： int i; if(sizeof(T)>sizeof(int))i=sizeof(T); else i=sizeof(int); char buffer[i];//语法错误! 原因在于数组声明中的下标必须是一个编译期常量，而不是一个运行期的值，条件表达式的运算可以在编译期进行，if语句就只能在执行期执行。","tags":"import","title":"C++ Tricks 1.1  条件运算符(?:)"},{"url":"//farseerfc.me/zhs/filling-believings-calling-conscience.html","text":"从 farseerfc.wordpress.com 导入 填补信仰、唤醒良知 我们听尽了呼吁与号召，对于良知，我不必谴责丧失它的国人，不必盛赞良知的美好。我只想讨论，丧失了良知的原因——空缺的信仰。 一、空缺信仰丧失良知 现代的国人缺少信仰，以至于丧失良知。曾几何时，中华民族由良好的信仰凝聚而成。三皇五帝时，族民们以炎黄为信仰；春秋战国时，士大夫之族以周制礼乐为信仰；汉代以后，百姓延习孔孟之说、老聃之道，以儒家学说为信仰；自大唐起，以佛教为首的现代宗教纷纷传入中原，人民开始以它们作为信仰。 直至鸦片战争、五四运动，西方文化入侵中华，国人开始抛弃国学，转而去研究科学；文化大革命，十年文化浩劫，人们批判旧的信仰，却没有合适的新的信仰前来填补。从此，国人的信仰出现空缺，国人的良知也被一块块蚕食殆尽。 二、信仰、科学、迷信 在许多国人的心目中，信仰就等于迷信。从小到大的教育告诉我们，信奉宗教是愚昧而又无知的表现，科学与信仰是矛盾的。是么？ 我们无法保证社会上的每一个人都接受过良好的教育，我们无法确信最前沿的科学素养能在民众中普及。在科普与教育力不从心的社会死角，在科学技术尚不能及的文化盲区，我们依旧需要信仰的规范与限制，我们的良知需要信仰！ 信仰不等于迷信。信仰本身无所谓谜与不迷，迷信是持有信仰的人误解了信仰，盲目遵从的结果。以为烧过香就可以免遭祸患，以为捐了钱就可以升入天堂，以为引火自焚就可以功德圆满，这便是迷信了。希特勒曾经的人类完善计划，依照遗传学的原理，将科学家与运动员强行结为夫妇孕育生命，希望得到最优秀的人类种族，这便是对科学这种信仰的迷信！ 由此可见，科学与信仰并不是矛盾的硬币的两面，从某种意义而言科学本身也是信仰的一种。虽然历史上宗教往往作为科学发展的阻碍，可信奉真理的信念一直是推动科学发展的动力。牛顿就曾说过，对自然规律的探询是为了更接近上帝。由此可见，信仰与真理，与良知毫无矛盾。 三、信仰唤醒良知 很少有人仔细思考过，良知的缺失是由信仰的缺失造成的。信仰是人思想的寄托与依靠，是人行动处世的准则。没有了信仰的人，思想行为就缺少了约束的标准，人就更容易因为一时不成熟的冲动，背叛良知、铸成错误。 泰国人以佛教为信仰，泰国的寺庙每天都会有成千上万人顶礼膜拜。寺庙有一个人尽皆知的不成文规定：不得穿鞋进入。于是在寺庙之外，游客们可以看到千百双各式的鞋子有序的摆放在门口。国人每每看到此景，总会诧异地问：没有人会偷鞋么？得到的答案极为简单：庙前偷鞋会遭报应。由于拥有信仰，泰国人作了坏事会受到良知的谴责，泰国商人售出假货会彻夜难眠。二战期间，无数犹太难民被天主教会收留藏匿从而侥幸逃生，这同样是出于，天主教徒们被自己信奉的教义\"众生生来平等\"，所唤醒的良知。 天下无贼的世界，不能仅靠科普说教来营造。如果脱离了信仰，纵使是教育也无法培养良知。我问过许多修化学的同学，学习化学的意义，结论竟是为了考试。如果没有对科学的信仰，我们可以牢记公式定理，却质疑它们是真理；如果没有对社会公德的信仰，我们可以熟背交通规则，却正大光明地闯红灯；如果没有对医疗道德的信仰，医生可以放任伤口发炎，从而留住病人继续治疗…… 国人需要信仰的约束，需要填补信仰的空白，从而唤醒那深埋于每个国人内心深处的良知！","tags":"import","title":"填补信仰、唤醒良知"}]}