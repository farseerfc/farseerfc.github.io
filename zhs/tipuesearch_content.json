{"pages":[{"url":"//farseerfc.me/zhs/about.html","text":"关于这个Blog 我会尽量用中文(Chinese, zh)，日语(Japanese, jp)，英语(English, en)这 三门语言同时写这个blog，在有意义的情况下。中文有繁体(zh)与简体(zhs) 之分，我以繁体撰写，再以 OpenCC 将繁体转化为对应的简体。 近况 我叫 杨嘉晨 1989年6月生 目前就读于 大阪大学大学院 情报科学研究科 计算机科学专攻 博士3年级 ( http://sdl.ist.osaka-u.ac.jp/ ) 本科毕业于 上海交通大学 软件学院 软件工程专业 F0703701班 ( http://se.sjtu.edu.cn/ ) 联系方式 生活中你可以通过这些方式找到我： 手机（softbank）: 080-3853-2770 手机邮箱: jc-yang@softbank.ne.jp 网络上你可以通过这些方式找到我： Skype: farseerfc GMail: farseerfc@gmail.com twitter: http://twitter.com/farseerfc Github: https://github.com/farseerfc weibo(微博): http://weibo.com/farseerfc facebook: http://www.facebook.com/farseerfc telegram: http://telegram.me/farseerfc tox: https://toxme.se/u/farseerfc pgp: 4B1D E545 A801 D454 9BFD 3FEF 90CB 3D62 C13D 4796 关于现在用的头像 这个头像来自 HUG 大大 绘制的 十六夜 ( いざよい ) 咲夜 ( さくや ) ， pixiv id=41143207 因为实在太喜欢了所以就擅自拿来作为头像了。十六夜是东方系列正传 妖々梦 ( ようようむ ) 、 永夜抄 ( えいやしょう ) 和格斗类 绯想天 ( ひそうてん ) 、 非想天则 ( ひそうてんそく ) 等作里用得最顺手的角色。","tags":"pages","title":"关于"},{"url":"//farseerfc.me/zhs/links.html","text":"以下列出我在网上认识的好 朋友 ( jī yǒu ) 们，排名不分先后。欢迎交换友链。 lilydjwg 依云 百合仙子 #archlinuxcn 社区管理者之一。 felixonmars 火星猫大大 archlinux官方开发者， #archlinuxcn 社区管理者之一。 phoenixlzx 凤凰菊苣 #archlinuxcn 社区管理者之一， #nyaacat MC喵窝 管理员之一。 fixme 水源技站，本科同窗，内核贡献者。 LQYMGT ID是irc上的中文社区镇社之宝的可爱学弟。 quininer 纯JavaScript的帅气博客。 无奎宁妄言安全 。 acgtyrant 御宅暴君，维护着他个人的和Arch的两个博客。 przhu OS X 骨灰用户，Haskell大牛，好像什么都知道。 mazk 我的完整博客模板的第一个用户，似乎还是高中生，前途无量呀。 wicast TNT酱 Golang大大的漂亮Hugo博客。 LastAvengers 谷月轩 有 自己写的内核 的厉害的LA的博客。 ヨイツの贤狼ホロ 来自约伊兹的萌狼，博客 是用 MediaWiki 搭的 也换到 Pelican 啦 ，是个萌物。 Frantic1048 Chino Kafuu 萌萌的智乃，喜欢一切萌物，前端技艺精湛，C++ 作业都用 Emscripten 转换到前端去的高手。貌似正在构建新的博客框架，翘首以待中。 Peter Cai 颠倒的阿卡林型次元 PeterCxy 彼得蔡，据说高中用 AIDE 在手机上徒手撸出了 BlackLight 的大大，博客 用漂亮的 MD 主题 几经改版每一次都越来越漂亮 。 CS Slayer 老K 另一个博客是 恋符「Master Spark」 Fcitx 开发者 ， KDE 开发者， Chakra 开发者， ikde 社区 维护者。强悍的开源贡献实力无人能出其右。有个刚出生的小女儿叫 Alice （下一个叫 Marisa ） ，新博客是魔理沙主题的。 VOID 001 头像是夏娜，/dev/horo 绝赞开发中。 PoiScript 萌萌哒 Poi ，博客引擎是自己写的 Solomon 和我的博客是情侣色 。 不过不用 Arch 用 openSUSE。 南浦月 南老师，在线直播，声音甜美。アスナ粉，自称装机民工的 linux 桌面环境开发者。修了 powerline 的 fontpatcher 。 Xuanwo 漩涡的 Hugo 博客很干净也很技术，厉害的后端工程师！ 老婆是路人 。 艾雨寒 | 艾颖初 初等记忆体 文艺的工科生 ( 技术过硬的文科生 ) ，萌妹体质，温柔体贴会做饭，和很多来自 AOSC 的成员一样对 Arch Linux CN 社区贡献卓著。 告诉 ( 喂给 ) 我 很多人和事 ( 成吨的狗粮 ) ， 令人羡慕 。 桜庭 ( さくらば ) 雨音 ( あまね ) | 鸢一 ( とびいち ) 雨音 ( あまね ) 余忆留声机 中文说得比日文溜的日本土著，灵梦厨，日共党员毛派，军武知识丰富。被 雨寒 拉入社区前是单兵游勇的 Arch 用户，霊梦式 シェル使い ( shell编程师 ) 。 还有很多不符年龄迷之属性不过这里写不下了 ， 有归宿 。 新一 metal A-wing 前端 后端 全栈工程师！ 又是 一个夏娜厨，亲手打造了 lilac 的打包状态页 KISS2UI 。 AlynxZhou 电磁炮厨，Hexo 的博客也很漂亮，Arch Linux CN 社区中珍贵的 Gnome 用户。喜欢 C 语言甚至在 B站 直播教学。CS:GO 玩家。 OriginCode 小学 初中生，使用电脑的时间严重受限，想起我当年的水平完全自愧不如，前途无量。 NoirGif 深藏不露的 USTC 菊苣，似乎玩了很多 gal game，博客更新很勤奋并且双语。萌。","tags":"pages","title":"友情链接"},{"url":"//farseerfc.me/zhs/why-linus-torvalds-undermine-gplv3.html","text":"从 知乎 转载 和上篇文章一样，这篇也是来自一个知乎上我回答的问题。 原问题：为什么 Linus Torvalds 不愿意将 Linux 变成 GPLv3 授权？ 我的回答： 这里有段 Linus Torvalds 在 DebConf 14 上的 Q&A: https://youtu.be/1Mg5_gxNXTo?t=47m20s 其中关于 GPLv3 和协议的那一段在47:20开始到57:00左右。 里面 Linus 对自己的观点澄清得很清楚了。 看u2b或者听英语有困难的请留评论，我抽空可以试着翻译一下。 DebConf 14: Q&A with Linus Torvalds Youtube Youku 然后接下来就是我承诺的翻译了 Q: Do you agree that you undermine GPLv3? and ... 问：你是否同意说你贬低了 GPLv3 ? 以及…… L: Yes L: 是的 Q: How can we get you to stop? 问：我们如何才能让你别这么做？ L: What? L: 什么？ Q: How can we get you to stop? 问：我们如何才能让你别这么做？ L: Oh I hate GPLv3. I undermined it on purpose. I actually thought the GPLv3 extensions were horrible. I understand why people would want to do them but I think it should have been a completely new license. L: 哦我讨厌 GPLv3 ，我是在故意贬低它。实际上我觉得 GPLv3 的扩展非常可怕。 我能理解为什么人们想要做这个，但是我觉得它本应是一个全新的协议。 Emm my argument for liking version 2, and I still think version 2 is a great license, was that, \"I give you source code, you give me your changes back, we are even.\" Right? That's my take on GPL version 2, right, it's that simple. 嗯我喜欢版本 2 的那些理由，并且我仍然觉得版本 2 是一个非常棒的协议， 理由是：「我给你源代码，你给我你对它的修改，我们就扯平了」 对吧？这是我用 GPL 版本 2 的理由，就是这么简单。 And version 3 extended that in ways that I personally am really uncomfortable with, namely \"I give you source code, that means that if you use that source code, you can't use it on your device unless you follow my rules.\" And to me that's, that's a violation of everything version 2 stood for. And I understand why the FSF did it because I know what the FSF wants. But to me it's not the same license at all. 然后版本 3 的扩展在某些方面让我个人觉得非常不舒服，也就是说「我给你源代码， 这意味着你必须服从我的一些规则，否则你不能把它用在你的设备上。」 对我来说，这是违反了版本 2 协议所追求的所有目的。然而我理解为什么 FSF 要这么做， 因为我知道 FSF 想要达成什么，但是对我来说这完全是不同的协议了。 So I was very upset and made it very clear, and this was months before version 3 was actually published. There was a discussion about this long before... There was an earlier version of version 3, years before actually, where I said \"No, this is not gonna fly.\" And during that earlier discussion I had already added to the kernel that, \"Hey, I don't have the version 2 or later\". And there was no... And I was really happy then when version 3 came out, that I have done that something like 5 years before, because there was ever never any question about what the license for the kernel was. 所以我当时非常不安，并且表明了自己的观点，并且这是在版本 3 发布的数月之前。 在那很久之前曾经有过一场讨论……在版本 3 之前有一个早期的版本， 事实上几年之前，那时我就说过：「不，这不可能工作」。 并且在那个早期的讨论阶段我已经在内核里写好了「嘿，我可没有写过版本 2 或者更高版本」。所以之后也没有过（争议）……随后版本 3 出来的时候我非常开心， 因为我早在大概 5 年前做了预防，之后也就再也没有过关于内核的协议究竟是哪个 版本的讨论。 But I actually thought that version 3 is ... Uh, no ... I actually think version 3 is a FINE license, right. I'm a firm believer in, \"If you write your code, it is your choice to pick a license.\" And version 3 is a fine license. Version 3 was not a good ... \"Here we give you version 2, and then we tried to sneak in these new rules, and tried to force everybody to upgrade.\" That was the part I disliked. And the FSF did some really sneaky stuff, downright immoral in my opinion. 不过事实上我觉得版本 3 是……呃不……我事实上觉得版本 3 是个 不错 的协议， 对吧。我坚定地相信「如果是你写的代码，那么你有权利决定它应该用什么协议」。 并且版本 3 是个不错的选择。版本 3 不好的地方在……「我们给你了版本 2 ，然后我们试图偷偷混入这些新的规则，并且想逼着所有人都跟着升级」这是我不喜欢版本 3 的地方。并且 FSF 在其中做了很多见不得人的事情，我觉得做得很不道德。 Q: So you are talking about Tivoization ? 译注： 关于 Tivoization Tivoization 是 FSF 发明的一个词，表示 TiVo 的做法。 TiVo 是一个生产类似电视机顶盒之类的设备的厂商，他们在他们的设备中用到了 Linux 内核和很多别的开源组件，并且他们根据 GPLv2 协议开放了他们使用的组件的源代码。 然而他们在他们出售的设备中增加了数字签名，验证正在执行的系统和软件是他们自己 编制的软件，从而限制了用户修改运行软件的自由。这种做法在 FSF 看来是钻了 GPLv2 的法律上的空子，所以 FSF 提出了 GPLv3 封堵这种做法。 问：所以你在说 Tivoization 的事情么？ L: Ehmm, yeah the Tivoization is always my main, eh dislike of version 3. And, the FSF was being very dishonest thing. \"Hey, we actually allow you to invalidate the Tivoization clause\" and they tried to, they literally lied to people, and say \"Hey, so that means that you can use GPLv3 without the Tivoization part\", right. This is ... How many people heard this particular statement from the FSF? (Please raise your hands) L: 没错，Tivoization 的事情一直是我反对版本 3 的主要根据。并且，FSF 在这件事上表现得极不诚实。「嘿，其实我们允许你无效化 Tivoization 条款」，这样他们试图， 应该说他们是在明白着欺骗别人，并且说「嘿，这意味着你可以使用除去 Tivoization 部分的 GPLv3」。 这很……在场的诸位中有谁从 FSF 那儿听过这个说法？（请举手） Ok, maybe they only tried to convince me with that one. But they did try. And it was like, \"I'm not stupid\", right. Yes, you can ... The GPLv3 allows you to say \"Ok, Tivoization is not an issue for us\". But it allows somebody else to take the project, and say \"Hey, I ... The GPLv3 without Tivoization is compatible with the full GPLv3, so I will now make my own fork of this, and I will start doing drivers that use the full version of version 3\" And where am I stuck then? I am stuck saying \"Hey I give you the source code, and now I can't take it back your changes\". That's completely against the whole point of the license in the first place. 好吧，或许他们只试过对我用这套说辞，但是他们真的试过。我的反应是「我可不傻」，对吧。是的， 的确你可以…… GPLv3 允许你说「好， Tivoization 的事情对我们来说不是问题」， 但是它同时又允许别人接过这个项目，并且说「嘿，我觉得……去掉了 Tivoization 的 GPLv3 是兼容完整的 GPLv3 的，所以我可以 fork 这个项目，然后我将在自己的 fork 上用完整的 GPLv3 写驱动。」然后我就囧了。我的困境在于说「嘿，我给了你我的源代码，现在我却不能拿回你对它 的修改了」。这是彻底违背了我用这个协议最初的目的了。 So the FSF was, I mean the kind of stuff that was going on behind the scenes, ah, made me once and for all to decide to never had any thing to do with the FSF again. So if you wanted to give money to an organization that does good? Give it to the EFF. The FSF is full of crazy bittered people. That's just mine opinion. Uh, actually I have ... Ah ... I overstated that a bit, right. The FSF has a lot of nice people in it, but some of them are bit too extreme. 所以 FSF 是，我是说那时他们暗地里做的那些事情，让我当下决定永远不再和 FSF 有任何瓜葛。 所以如果你想捐钱给一个行善的组织，那就捐给 EFF 吧。FSF 充满了疯狂难处的人。这只是我的观点。 呃其实我……嗯……我说得有点过分了。FSF 里有很多不错的人，不过其中有些人有点过激。 Q: Well I wish the EFF care more about software freedom. But, uh, can you ... Do you think that Tivoization benefits me as a user somehow? 问: 嗯我也希望 EFF 能更多的关注于软件的自由方面。但是你能……你觉得 Tivoization 这种行为也能在某种方式上让我作为用户获益么？ L: No, no I don't. I mean that ... But that was never my argument. That was not why I selected the GPLv2. This is my whole point. It's not that I think Tivoization is necessarily something that you should strive for. But it is something that in my world view, it's your decision. If you make hardware that locks down the software, that's your decision as a hardware maker. That has no impact on my decision as a software maker to give you the software. Do you see where I am coming from? I don't like the locked down hardware, but at the same time that was never the social contract I intended with Linux. L: 不，我不觉得。我的意思是……这从来都不是我的论据，这不是我选择了 GPLv2 的理由。 并不是说我觉得 Tivoization 是某种值得你去争取的权利，而是说在我的世界观中，这是你的决定。 如果你生产硬件去锁住了其中的软件，这是你作为一个硬件提供者的决定。 这完全不影响我作为一个软件提供者给你软件的决定。你能看出我的立场在哪儿了么？ 我不喜欢上锁的硬件，但是同时这也从来不是我想要给 Linux 加上的的社会契约。 To me, umm, I mean, people may or may not realize GPLv2 wasn't even the first license for Linux. To me the important part was always \"I give you software, you can do whatever you want with it. If you making improvements, you have to give them back.\" That was the first version of the license. It also had a completely broken clause which was completely insane and I was stupid. Hey it happened. My origin license says that you can't make money change hands. And that was a mistake. That was clearly just wrong and bad because it really didn't have anything to do with what I wanted. But I was young, I was poor, I didn't realize that the whole money thing wasn't the important part. And I have saw the errors in my ways, I saw the GPLv2 and said \"Hey, that's the perfect license\". And I saw the GPLv3 and I said \"No, that's overreaching a lot, that's not what I wanted\". And so I made Linux GPLv2 only, right. 对我来说，呃我想说，大家可能知道或者不知道， GPLv2 并不是 Linux 的最初的协议。 对我来说重要的部分一直是「我给你软件，你可以用它做任何你想要做的事情。如果你做了任何改进， 你需要把它交还给我。」这是协议最初的样子。最早的协议还有一条完全错误的条款，写得完全不合理， 那时我很傻。嘿我也傻过。我最初的协议说你不能用它赚钱。这是失策，这明显是不对的不好的， 因为它和我真正想要做的事情没有任何关系。但是那时我很傻很天真， 我没意识到钱的事情在其中完全不重要。然后我发现了其中的问题，我看到了 GPLv2 然后说「嘿， 这是个完美的协议」。然后我看到了 GPLv3 我说「不，这做得过分了，这不是我想要的」 所以我让 Linux 成为了仅限 GPLv2 ，对吧。 Q: So do you think getting the patches back is as useful even if you can't modify the device that it is used on? 问: 所以你是否认为，即使你不能修改跑着这个软件的设备，拿回对软件的修改也还是同样重要的？ L: Yeah, absolutely. And I mean TiVo itself is actually an example of this. Their patches were kind of crafty but I mean they were basically running on a, originally a fairly standard MIPS thing. And their patches were working around bugs in the chipsets they used. And they were valid patches. The fact that they then felt that their hardware had to be locked down someway. I didn't like it. But as I have mentioned, I felt that that was their decision. L: 是的，当然。我想说 TiVo 它自己实际上就是一个例子。他们的修改有点复杂，但是我想说他们基本 是，一开始基本是运行在一套相当标准的 MIPS 设备上。然后他们的修改是想绕开他们用到的芯片上的 一些问题，并且这些是合格的修改。之后的事情是他们觉得他们需要锁住他们的硬件，我不喜欢这个。 但是就像我已经说的，我觉得这是他们的决定。 And they had real reasons for that. That's something people sometimes missed. There are sometimes reasons to do what TiVo did. Sometimes it's imposed on you by, wireless carriers. Sometimes it's imposed on you by Disney. Uh sometimes it's imposed on you by laws. The GPLv3 actually accepts the last one when it comes to things like medical equipment I think. But the point is that the whole Tivoization thing is, sometimes it's, there is a reason for it. And if you make ... I mean I am not a hardware designer. I think FPGA and stuff like that is really cool. But I always ... I mean I really don't want to impose my world view on anybody else. You don't have to use Linux. If you do use Linux, the only thing I asked for is source code back. And there is all these other verbiages in the GPLv2 about exact details, those aren't important. And that was always my standpoint. 并且他们有真正的理由去这么做。这是有时人们忽视的地方。有时是真的有理由去做 TiVo 他们做的事情。有时强加给你这种限制的是，无线运营商。有时强加给你的是迪士尼。 有时强加给你限制的甚至是法律。 GPLv3 在医疗设备之类的场合其实允许最后一种情况，我记得。 我的观点是，整个 Tivoization 的事情有时是有理由去这么做的。如果你生产…… 我是说我不是硬件设计者，我觉得 FPGA 之类的东西很酷，但是我……我的意思是我真的不想把我对世界的 看法强加给别人。你不是非得要用 Linux ，如果你想要用 Linux ，那么我唯一要求你做的事情是把源代码（变更）还给我。然后在 GPLv2 中还有很多繁文缛节规定了详细的细节，这些都不重要。这是我一直以来的观点。 Q: Ok, well I will stop my non-point of making noise now. 译注： 关于 ISC 协议 ISC 协议是一个开源软件协议，和两句的 BSD 协议功能相同。OpenBSD 项目选择尽量用 ISC 协议公开他们新写的代码。 问: 好吧那我就不浪费时间了。 L: I mean don't get me ... I mean I like other licenses too. I have used like the four, emmm... Which BSD license is the acceptable one? One of the BSD license is actually really nice. And it's actually the... What? L: 我的意思是别误解……我也喜欢别的协议。我用过……到底是哪个 BSD 协议是可以接受的？ 有一个 BSD 协议实际上非常不错。它实际上是……什么？ A: ISC 观众： ISC L: ISC? And I actually encourage people who don't care about the giving code back but care about the \"Hey, I did something cool, please use it\". I encourage people to use the BSD license for that. And I mean the BSD license is wonderful for that. It so happens that I thought that for my project the giving back is equally important so I, for me BSD is bad. But the point is for me . The GPLv3 maybe the perfect license for what you guys want to do. And that's fine. And then it's the license you should use. It's just that when somebody else wrote the code you don't get that choice. L: ISC？并且事实上我在鼓励那些不在意拿回修改但是在意「嘿，我做了一个很酷的东西，请用它」。 我鼓励这些人去用 BSD 协议做这些事情。我想说 BSD 协议在这种场合是完美的。 只是碰巧我觉得对于我的项目，拿回修改也同样重要，所以对我而言 BSD 不好。但是重点是 对我而言 。 GPLv3 可能对你们想要做的事情而言是完美的协议，这很好，并且这时你就应该去用 GPLv3 。只是当代码是别人写的时候，你没有这个选择权。","tags":"import","title":"为什么 Linus Torvalds 不愿意将 Linux 变成 GPLv3 授权？"},{"url":"//farseerfc.me/zhs/dot-and-arrow-in-c.html","text":"从 知乎 转载 转载几篇知乎上我自己的回答，因为不喜欢知乎的排版，所以在博客里重新排版一遍。 原问题：C语言中\".\"与\"->\"有什么区别？ 除了表达形式有些不同，功能可以说完全一样阿。那为何又要构造两个功能一样的运算符？ 效率有差异？可是现在编译器优化都那么强了，如果真是这样岂不是有些多此一举 刚刚翻了下书，说早期的C实现无法用结构直接当作参数在函数间传递，只能用指向结构的指针在函数间进行传递！我想这应该也是最直观的原因吧。 我的回答 首先 a->b 的含义是 (*a).b ，所以他们是不同的，不过的确 -> 可以用 * 和 . 实现，不需要单独一个运算符。 嗯，我这是说现代的标准化的 C 语义上来说， -> 可以用 * 和 . 的组合实现。 早期的 C 有一段时间的语义和现代的 C 的语义不太一样。 稍微有点汇编的基础的同学可能知道，在机器码和汇编的角度来看，不存在变量，不存在 struct 这种东西，只存在寄存器和一个叫做内存的大数组。 所以变量，是 C 对内存地址的一个抽象，它代表了一个位置。举个例子，C 里面我们写： a = b 其实在汇编的角度来看更像是 * A = * B 其中 A 和 B 各是两个内存地址，是指针。 好，以上是基本背景。 基于这个背景我们讨论一下 struct 是什么，以及 struct 的成员是什么。 假设我们有 struct Point { int x ; int y ; }; struct Point p ; struct Point * pp = & p ; 从现代语义上讲 p 就是一个结构体对象， x 和 y 各是其成员，嗯。 从汇编的语义上讲， p 是一个不完整的地址，或者说，半个地址，再或者说，一个指向的东西是虚构出来的地址。而 x 和 y 各是在 Point 结构中的地址偏移量。也就是说，必须有 p 和 x 或者 p 和 y 同时出现，才形成一个完整的地址，单独的一个 p 没有意义。 早期的 C 就是在这样的模型上建立的。所以对早期的 C 而言， *pp 没有意义，你取得了一个 struct ，而这个 struct 不能塞在任何一个寄存器里，编译器和 CPU 都无法表达这个东西。 这时候只有 p.x 和 p.y 有意义，它们有真实的地址。 早期的 C 就是这样一个看起来怪异的语义，而它更贴近机器的表达。 所以对早期的 C 而言，以下的代码是对的： p . x = 1 ; int * a ; a = & ( p . x ); 而以下代码是错的： ( * pp ). x = 1 ; 因为作为这个赋值的目标地址表达式的一部分， *pp ，这个中间结果没法直译到机器码。 所以对早期的 C 而言，对 pp 解引用的操作，必须和取成员的偏移的操作，这两者紧密结合起来变成一个单独的操作，其结果才有意义。 所以早期的 C 就发明了 -> ，表示这两个操作紧密结合的操作。于是才能写： pp -> x = 1 ; 嗯，这就是它存在的历史原因。 而这个历史原因现在已经不重要了，现代的符合标准的 C 编译器都知道 (*pp).x 和 pp->x 是等价的了。 说句题外话， C++ 里面还发明了 .* 和 ->* 这两个运算符（注意 ->* 不是单独的 -> 和 * 并排放的意思），关于为什么要发明这两个运算符，而不能直接说 a ->* b 的意思就是 a ->(*b) ，这个就作为课堂作业吧。","tags":"import","title":"C语言中\".\"与\"->\"有什么区别？"},{"url":"//farseerfc.me/zhs/github-issues-as-comments.html","text":"从今天起本博客将启用 GitHub Issue 作为留言系统。 原本使用的 Disqus 将继续保留一段时间，目前没有关闭的计划。 换用 GitHub Issue 是计划了好久的事情了，最初重做这个主题的时候就有考虑过。 这个想法的契机是看到了这篇 GitHub hosted comments for GitHub hosted blogs ，然后立马觉得这个想法很符合寄宿在 GitHub Pages 上的博客。 一个限制是要求评论者必须有 GitHub 账户，考虑到我的博客的受众这个要求估计不算太过分。 使用 GitHub Issue 的好处么，比如自带的 GFMD 富文本格式，邮件通知，还有订阅和取消订阅通知，邮件回复， 这些方面都不比第三方留言系统逊色。 换用 GitHub Issue 另一方面原因是最近听说 Disqus 被部分墙了，想必以后墙也会越来越高。之前曾经试过在这个博客换上多说， 然而效果我并不喜欢，多说喜欢侵入页面加很多奇怪的东西，比如用户的头像通常是 http 的……也试过结合新浪微博的评论，而新浪微博越来越封闭，API 也越来越不靠谱。 使用 GitHub Issue 作为评论的方式比较简单，上面那篇博客里面提到了，代码量不比 加载 Disqus 多多少，而且没有了 iframe 的困扰，唯一麻烦的地方就是要稍微设计一下布局方式让它融入 现有的页面布局。 我参考上面的实现在这里 。 这个加载代码使用两个变量加载 Issue Comments ，一个是在 pelicanconf.py 里的 GITHUB_REPO ，可以指向任何 Repo ，我指向 farseerfc/farseerfc.github.io 的这个 GitHub Page repo ，另一个变量是每篇文章里需要加上 issueid 的元数据，关连文章到每个 Issue 上。 还有一个稍微麻烦的事情是现在每写一篇文章之后都要新建一个 issue 了。 手动操作有点累人，于是我 写了个脚本 自动搜索 pelican 的 content 文件夹里面文章的 slug 并且对没有 issueid 关连的 文章创建 issue 。 好啦新的留言系统的外观样式还在测试中，希望大家多留言帮我测试一下！ 2016年8月7日19:30更新 新增了对 GitHub Issue comments 里面 reactions 的支持，套用 font-awesome 的图标（似乎没 GitHub 上的图标好看）。这个还属于 GitHub API 的实验性功能，要加入 Accept: application/vnd.github.squirrel-girl-preview HTTP 头才能拿到。 2016年8月7日23:16更新 感谢 @iovxw 的测试让我发现 github 的高亮回复和邮件回复是需要特殊处理的。 高亮回复用上了 这里的 CSS 邮件引言的展开事件直接用 jQuery 做了： $ ( \".email-hidden-toggle > a\" ). on ( \"click\" , function ( e ){ e . preventDefault (); $ ( \".email-hidden-reply\" , this . parent ). toggle (); }); 还得注意邮件的回复需要 CSS 里面 white-space: pre-wrap 。","tags":"tech","title":"启用 GitHub Issue 作为博客留言系统"},{"url":"//farseerfc.me/zhs/pacvis.html","text":"PacVis 我为什么要做 PacVis 我喜欢 Arch Linux ，大概是因为唯有 Arch Linux 能给我对整个系统「了如指掌」的感觉。 在 Arch Linux 里我能清楚地知道我安装的每一个包，能知道系统里任何一个文件是来自哪个包， 以及我为什么要装它。或许对 Debian/Fedora/openSUSE 足够熟悉了之后也能做到这两点， 不过他们的细致打包的结果通常是包的数量比 Arch 要多个 3 到 10 倍，并且打包的细节也比 Arch Linux 简单的 PKGBUILD 要复杂一个数量级。 每一个装过 Arch Linux 的人大概都知道，装了 Arch Linux 之后得到的系统非常朴素，按照 ArchWiki 上的流程一路走下来的话，最关键的一条命令就是 pacstrap /mnt base ， 它在 /mnt 里作为根调用 pacman -S base 装上了整个 base 组， 然后就没有然后了。这个系统一开始空无一物，你需要的任何东西都是后来一点点用 pacman 手动装出来的，没有累赘，按你所需。 然而时间长了，系统中难免会有一些包，是你装过用过然后忘记了， 然后这些包就堆在系统的角落里，就像家里陈年的老家具，占着地，落着灰。虽然 pacman -Qtd 能方便地帮你找出所有 曾经作为依赖被装进来，而现在不被任何包依赖 的包，但是对于那些你手动指定的包， 它就无能为力了。 于是我就一直在找一个工具能帮我梳理系统中包的关系，方便我： 找出那些曾经用过而现在不需要的包 找出那些体积大而且占地方的包 厘清系统中安装了的包之间的关系 Android 系统架构 关于最后一点「厘清包的关系」，我曾经看到过 macOS 系统架构图 和 Android 的系统架构图，对其中的层次化架构印象深刻，之后就一直在想，是否能画出现代 Linux 桌面系统上类似的架构图呢？又或者 Linux 桌面系统是否会展现完全不同的样貌？ 从维基百科或者别的渠道能找到 Linux 内核、或者 Linux 图形栈， 或者某个桌面环境的架构，但是没有找到覆盖一整个发行版的样貌的。 于是我便想，能不能从包的依赖关系中自动生成这样一张图呢。 PacVis的老前辈们 在开始写 PacVis 之前，我试过一些类似的工具，他们都或多或少能解决一部分我的需要， 又在某些方面有所不足。这些工具成为了 PacVis 的雏形，启发了 PacVis 应该做成什么样子。 pactree pactree 曾经是一个 独立的项目 ，现在则是 pacman 的一部分 了。 从手册页可以看出， pactree 的输出是由某个包开始的依赖树。 加上 --graph 参数之后 pactree 还能输出 dot 格式的矢量图描述，然后可以用 dot 画出依赖图： pactree pacvis-git -d3 --graph | dot -Tpng >pacvis-pactree.png $ pactree pacvis-git -d3 pacvis-git ├─python-tornado │ └─python │ ├─expat │ ├─bzip2 │ ├─gdbm │ ├─openssl │ ├─libffi │ └─zlib ├─pyalpm │ ├─python │ └─pacman │ ├─bash │ ├─glibc │ ├─libarchive │ ├─curl │ ├─gpgme │ ├─pacman-mirrorlist │ └─archlinux-keyring └─python-setuptools └─python-packaging ├─python-pyparsing └─python-six $ pactree pacvis-git -d3 --graph | dot -Tpng >pacvis-pactree.png 从画出的图可以看出，因为有共用的依赖，所以从一个包开始的依赖关系已经不再是一棵 图论意义上的树(Tree) 了。最初尝试做 PacVis 的早期实现的时候，就是试图用 bash/python 脚本解析 pactree 和 pacman 的输出，在 pactree 的基础上把整个系统中所有安装的包全都包含到一张图里。 当然后来画出的结果并不那么理想，首先由于图非常巨大，导致 dot 的自动布局要耗费数小时，最后画出的图也过于巨大基本上没法看。 然而不得不说没有 pactree 就不会有 PacVis ，甚至 pacman 被分离出 alpm 库也和 pactree 用 C 重写的过程有很大关系，而 PacVis 用来查询 pacman 数据库的库 pyalpm 正是 alpm 的 Python 绑定。因为 pactree 的需要而增加出的 alpm 库奠定了 PacVis 实现的基石。 pacgraph pacgraph 的输出 pacgraph 是一位 Arch Linux 的 Trusted User keenerd 写的程序，和 PacVis 一样也是用 Python 实现的。 比起 pactree ， pacgraph 明显更接近我的需求，它默认绘制整个系统的所有安装包， 并且用聪明的布局算法解决了 dot 布局的性能问题。 pacgraph 的输出是一个富有艺术感的依赖图，图中用不同的字体大小表示出了每个包占用 的磁盘空间。通过观察 pacgraph 的输出，我们可以清楚地把握系统全局的样貌， 比如一眼看出这是个桌面系统还是个服务器系统，并且可以很容易地发现那些占用磁盘空间 巨大的包，考虑清理这些包以节约空间。 更棒的是 pacgraph 还提供了一个交互性的 GUI 叫做 pacgraph-tk ，显然通过 tk 实现。 用这个 GUI 可以缩放观察整幅图的细节，或者选中某个包观察它和别的包的依赖关系。 pacgraph 还支持通过参数指定只绘制个别包的依赖关系，就像 pactree 那样。 不过 pacgraph 也不是完全满足我的需要。如我前面说过，我希望绘制出的图能反应 这个发行版的架构面貌 ，而 pacgraph 似乎并不区别「该包依赖的包」和「依赖该包的包」 这两种截然相反的依赖关系。换句话说 pacgraph 画出的是一张无向图， 而我更想要一张有向图，或者说是 有层次结构的依赖关系图 。 于是就有了 PacVis PacVis 刚打开的样子 总结了老前辈们的优势与不足，我便开始利用空余时间做我心目中的 PacVis 。 前后断断续续写了两个月，又分为两个阶段，第一阶段做了基本的功能和雏形， 第二阶段套用上 https://getmdl.io/ 的模板，总算有了能拿得出手给别人看的样子。 于是乎前两天在 AUR 上给 pacvis 打了个 pacvis-git 包，现在想在本地跑 pacvis 应该很方便了，用任何你熟悉的 aurhelper 就可以安装，也可以直接从 aur 下载 PKGBUILD 打包： ~$ git clone aur@aur.archlinux.org:pacvis-git.git ~$ cd pacvis-git ~/pacvis-git$ makepkg -si ~/pacvis-git$ pacvis Start PacVis at http://localhost:8888/ 按照提示说的，接下来打开浏览器访问 http://localhost:8888/ 就能看到 PacVis 的样子了。仅仅作为尝试也可以直接打开跑在我的服务器上的 demo: https://pacvis.farseerfc.me/ ，这个作为最小安装的服务器载入速度大概比普通的桌面系统快一点。 在 Windows msys2 跑 PacVis 另外补充一下，因为 PacVis 只依赖 pyalpm 和 tornado ，所以在别的基于 pacman 的系统上跑它应该也没有任何问题，包括 Windows 上的 msys2 里（尽管在 msys2 上编译 tornado 的包可能要花些功夫）。 PacVis 的图例和用法 操作上 PacVis 仿照地图程序比如 Google Maps 的用法，可以用滚轮或者触摸屏的手势 缩放、拖拽，右上角有个侧边栏，不需要的话可以点叉隐藏掉，右下角有缩放的按钮和 回到全局视图的按钮，用起来应该还算直观。 pacvis-git 包的依赖 先解释图形本身，整张图由很多小圆圈的节点，以及节点之间的箭头组成。 一个圆圈就代表一个软件包，而一条箭头代表一个依赖关系。缩放到细节的话， 能看到每个小圆圈的下方标注了这个软件包的名字，鼠标悬浮在圆圈上也会显示响应信息。 还可以点开软件包，在右侧的边栏里会有更详细的信息。 比如图例中显示了 pacvis-git 自己的依赖，它依赖 pyalpm, python-tornado 和 python-setuptools ，其中 pyalpm 又依赖 pacman 。图中用 紫色 表示手动安装的包， 橙色 表示被作为依赖安装的包， 箭头的颜色也随着包的颜色改变。 值得注意的是图中大多数箭头都是由下往上指的，这是因为 PacVis 按照包的依赖关系做 了拓扑排序，并且给每个包赋予了一个拓扑层级。比如 pacvis-git 位于 39 层，那么它依赖的 pyalpm 就位于 38 层，而 pyalpm 依赖的 pacman 就位于 37 层。根据层级关系排列包是 PacVis 于 pacgraph 之间最大的不同之处。 除了手动缩放， PacVis 还提供了搜索框，根据包名快速定位你感兴趣的包。 以及在右侧边栏中的 Dep 和 Req-By 等页中，包的依赖关系也是做成了按钮的形式， 可以由此探索包和包之间的关联。 最后稍微解释一下两个和实现相关的参数： Max Level 这是限制 PacVis 载入的最大拓扑层。系统包非常多的时候 PacVis 的布局算法会显得很慢，限制层数有助于加快载入，特别是在调试 PacVis 的时候比较有用。 Max Required-By 这是限制 PacVis 绘制的最大被依赖关系。稍微把玩一下 PacVis 就会发现系统内绝大多数 的包都直接依赖了 glibc 或者 gcc-libs 等个别的几个包，而要绘制这些依赖的话会导致 渲染出的图中有大量长直的依赖线，不便观察。于是可以通过限制这个值，使得 PacVis 不绘制被依赖太多的包的依赖关系，有助于让渲染出的图更易观察。 从 PacVis 能了解到的一些事实 一个 KDE 桌面的 PacVis 结果全图， 放大（17M） 稍微玩一下 PacVis 就能发现不少有趣现象，上述「绝大多数包依赖 glibc 」就是一例。 除此之外还有不少值得玩味的地方。 依赖层次 系统中安装的包被明显地分成了这样几个层次： glibc 等 C 库 Bash/Perl/Python 等脚本语言 coreutils/gcc/binutils 等核心工具 pacman / systemd 等较大的系统工具 gtk{2,3}/qt{4,5} 等 GUI toolkit chromium 等 GUI 应用 Plasma/Gnome 等桌面环境 大体上符合直观的感受，不过细节上有很多有意思的地方，比如 zsh 因为 gdbm 间接依赖了 bash，这也说明我们不可能在系统中用 zsh 完全替代掉 bash。 再比如 python （在 Arch Linux 中是 python3）和 python2 和 pypy 几乎在同一个拓扑层级。 zsh 因为 gdbm 间接依赖了 bash 不过偶尔显示的依赖层级不太符合直观，比如 qt5-base < qt4 < gtk2 < gtk3 。 qt5 因为被拆成了数个包所以比 qt4 更低级这可以理解，而 gtk 系比 qt 系更高级这一点是很多人（包括我）没有预料到的吧。 循环依赖 有些包的依赖关系形成了循环依赖，一个例子是 freetype2 和 harfbuzz，freetype2 是绘制字体的库，harfbuzz 是解析 OpenType 字形的库，两者对对方互相依赖。 另一个例子是 KDE 的 kio 和 kinit，前者提供类似 FUSE 的资源访问抽象层， 后者初始化 KDE 桌面环境。 freetype2 和 harfbuzz 之间的循环依赖 因为这些循环依赖的存在，使得 PacVis 在实现时不能直接拓扑排序，我采用环探测 算法找出有向图中所有的环，并且打破这些环，然后再使用拓扑排序。 因此我在图中用红色的箭头表示这些会导致环的依赖关系。 有些包没有依赖关系 man-pages 和 licenses 没有依赖关系 有些包既不被别的包依赖，也不依赖别的包，而是孤立在整张图中，比如 man-pages 和 licenses 。这些包在图中位于最顶端，拓扑层级是 0 ，我用 蓝色 正方形特别绘制它们。 只看依赖关系的话 Linux 内核完全不重要 所有用户空间的程序都依赖着 glibc ，而 glibc 则从定义良好的 syscall 调用内核。 因此理所当然地，如果只看用户空间的话， glibc 和别的 GNU 组件是整个 GNU/Linux 发行版的中心，而 Linux 则是位于依赖层次中很深的位置，甚至在我的 demo 服务器上 Linux 位于整个图中的最底端，因为它的安装脚本依赖 mkinitcpio 而后者依赖了系统中的众多组件。 pacman -Qtd 不能找到带有循环依赖的孤儿包 msys2 中带有循环依赖的孤儿包 这是我在 msys2 上测试 PacVis 的时候发现的，我看到在渲染的图中有一片群岛， 没有连上任何手动安装的包。这种情况很不正常，因为我一直在我的所有系统中跑 pacman -Qtd 找出孤儿包并删掉他们。放大之后我发现这些包中有一条循环依赖， 这说明 pacman -Qtd 不能像语言的垃圾回收机制那样找出有循环依赖的孤儿包。 PacVis 的未来 目前的 PacVis 基本上是我最初开始做的时候设想的样子，随着开发逐渐又增加了不少功能。 一些是迫于布局算法的性能而增加的（比如限制层数）。 今后准备再加入以下这些特性： 更合理的 optdeps 处理。目前只是把 optdeps 关系在图上画出来了。 更合理的 依赖关系抉择 。有时候包的依赖关系并不是直接根据包名，而是 provides 由一个包提供另一个包的依赖。目前 PacVis 用 alpm 提供的方式抉择这种依赖，于是这种关系并没有记录在图上。 目前的层级关系没有考虑包所在的仓库 (core/extra/community/...) 或者包所属的组。 加入这些关系能更清晰地表达依赖层次。 目前没有办法只显示一部分包的关系。以后准备加入像 pactree/pacgraph 一样显示部分包。 如果你希望 PacVis 出现某些有趣的用法和功能，也 请给我提 issue 。","tags":"tech","title":"PacVis: 可视化 pacman 本地数据库"},{"url":"//farseerfc.me/zhs/compositor-in-X-and-compositext.html","text":"在上篇文章 「桌面系统的混成器简史」 中我介绍了其它桌面系统中的混成器的发展史和工作原理， 话题回到我们的正题 Linux 系统上，来说说目前 X 中混成器是如何工作的。 这篇文章将比上一篇深入更多技术细节，不想看太多细节的可以直接跳过看 结论 。 原始的 X 的绘图模型 首先，没有混成器的时候 X 是这样画图的： X 的应用程序没有统一的绘图 API 。GTK+ 在 3.0 之后统一用 Cairo 绘图， 而 Cairo 则是基于 PDF 1.4 的绘图模型构建的， GTK 的 2.0 和之前的版本中也有很大一部分的绘图是用 Cairo 进行， 其余则通过 xlib 或者 xcb 调用 X 核心协议提供的绘图原语绘图。 QT 的情况也是类似，基本上用 QPaint 子系统绘制成位图然后交给 X 的显示服务器。 显示服务器拿到这些绘制请求之后，再在屏幕上的相应位置绘制整个屏幕。 当然还有很多老旧的不用 GTK 或者 QT 的程序，他们则直接调用 X 核心协议提供的绘图原语。 值得注意一点是 X 上除了没有统一的绘图模型，也没有统一的矢量图格式。 X 核心协议的绘图原语提供的是像素单位的绘图操作，没有类似 GDI+ 或者 Quartz 提供的 设备无关 ( Device Independence ) 的「点」的抽象。所以只用 X 的绘图原语的话，我们可以把 (1,1) 这个像素点涂黑，但是不能把 (0.5, 0.5) 这个点涂黑，这一设计缺陷在 Unix Hater's Handbook 中已经被吐槽过了。因为这个缺陷，所以直接用 X 绘图原语绘制的图像不能像 矢量图那样进行无损缩放。同样的缺陷导致 X 绘图原语绘制的字符不能做到 子像素级 ( subpixel-level ) 抗锯齿 ( anti-aliasing ) （这解释了默认配置下的 xterm 和 urxvt 中的字体渲染为什么难看 ）。相比之下 GDI 有对应的 WMF 矢量图格式， Quartz 有对应的 PDF 矢量图格式， 而 X 中没有这样的格式对应。因为没有统一的矢量图格式，所以无论是 Cairo 、QPaint 还是没有用这些绘图库但是同样在意字体和曲线渲染效果的程序（比如 Firefox 和 Chromium）都需要首先渲染到内部的 XPixMap 位图格式，做好子像素渲染和矢量缩放，然后再把渲染好的位图转交给 X 图形服务器。 通过 Composite 扩展重定向窗口输出 2004年发布的 X11R6.8 版本的 Xorg 引入了 Composite 扩展 。这个扩展背后的动机以及前因后果在一篇文章 The (Re)Architecture of the X Window System 中有详细的表述。Composite 扩展允许某个 X 程序做这几件事情： 通过 RedirectSubwindows 调用将一个窗口树中的所有窗口渲染重定向到 内部存储 ( off-screen storage ) 。重定向的时候可以指定让 X 自动更新窗口的内容到屏幕上或者由混成器手动更新。 通过 NameWindowPixmap 取得某个窗口的内部存储。 通过 GetOverlayWindow 获得一个特殊的用于绘图的窗口， 在这个窗口上绘制的图像将覆盖在屏幕的最上面。 通过 CreateRegionFromBorderClip 取得某个窗口的边界剪裁区域（不一定是矩形）。 有了 Composite 扩展，一个 X 程序就可以调用这些 API 实现混成器。 这里有篇 教学解释如何使用 Composite 扩展 。开启了混成的 X 是这样绘图的： 整个 X 的混成器模型与 Mac OS X 的混成器模型相比，有如下几点显著的区别： 混成的部分是交由外部的程序完成的，对混成的绘制方式和绘制普通窗口一样。 出于效率考虑，绝大多数 X 上的混成器额外使用了 XRender 扩展或者 OpenGL/EGL 来加速绘制贴图。不过即使如此，还是不能避免同样的位图（内容不一定完全一致， 比如 X 可以在窗口交给它的位图上加上边框然后再返还给混成器） 在不同的三个程序之间来回传递 。 RedirectSubwindows 调用针对的是一个窗口树，换句话说是一个窗口 及其全部子窗口，不同于 Mac OS X 中混成器会拿到全部窗口的输出。 这个特点其实并不算是限制，因为 X 中每个虚拟桌面都有一个根窗口，只要指定这个根窗口 就可以拿到整个虚拟桌面上的全部可见窗口输出了。 反而这个设计提供了一定的自由度，比如我们可以用这个调用实现一个截图程序， 拿到某个特定窗口的输出，而不用在意别的窗口。 为了让窗口有输出，窗口必须显示在当前桌面上，不能处于最小化 状态或者显示在别的虚拟桌面，用 X 的术语说就是窗口必须处于 被映射 ( mapped ) 的状态。因此直接用上述方法 不能得到没有显示的窗口的输出 ，比如不能对最小化的窗口 直接实现 Windows 7 中的 Aero Peak 之类的效果。这个限制可以想办法绕开， 比如在需要窗口输出的时候临时把窗口映射到桌面上，拿到输出之后再隐藏起来， 不过要实现这一点需要混成器和窗口管理器相互配合。 不像 Mac OS X 的基于 OpenGL Surface 的绘图模型是 设备无关 ( device independent ) 的，这里 X 的绘图模型是 设备相关 ( device dependent ) 的。 这既是优点也是缺点。从缺点方面而言，显示到 X 的位图输出因为设备相关性， 所以严格对应显示器的点阵，并不适合作为文档格式打印出来。当然无论是 Cairo 还是 QPaint 都提供了到 PostScript 或者 PDF 后端的输出，所以实用层面这个并不构成问题。 设备相关这一点的优点在于，绘制到 XPM 位图的时候，程序和绘图库是能拿到输出设备（显示器） 的特殊属性的，从而绘图库能考虑不同的色彩、分辨率、 DPI 或者 子像素布局 ( subpixel layout ) 这些属性以提供最好的渲染效果。 Mac OS X 10.4 在设计的时候也曾考虑过提供无极缩放的支持，而这种支持到了 Mac OS X 10.5 中就缩水变成了 Retina 的固定 2 倍缩放。这种局面在 X 上没有发生正是因为 X 的绘图模型的这种设备相关性，而 Mac OS X 的混成器采用的 OpenGL Surface 则无视了这些设备相关的属性。 输入事件的重定向，这可能做到么？ 通过上述 Composite 扩展提供的 API ，混成器可以把窗口的 输出 重定向到自己的窗口上。 但是仅仅重定向输出，整个 X 还不处于可用状态，因为 没有重定向输入 。 考虑一下用户试图用鼠标点击某个按钮或者文本框，这时鼠标处于的位置是在 OverlayWindow 上绘制的位置，这个鼠标事件会交给 OverlayWindow ，而用户期待这个事件被发送给他看到的按钮上。 需要重定向的事件主要有键盘和鼠标事件两大类（暂时先不考虑触摸屏之类的额外输入）。 由于 Composite 扩展并没有直接提供这方面的重定向 API ，这使得输入事件处理起来都比较麻烦， 假设要重定向键盘事件，混成器需要效仿输入法框架（fcitx, ibus, scim） 那样处理一部分按键事件并把其余事件转给具有输入焦点的程序。 看看现有的输入法框架和诸多程序间的问题，我们就能知道这里的坑有多深。 于是 大部分 X 的混成器都不处理键盘事件重定向 。再来看重定向鼠标事件，这边的坑比重定向键盘事件的坑更多， 因为不像重定向窗口输出那样只需要考虑 顶层 ( top-level ) 窗口， 重定向鼠标输入的时候要考虑所有子窗口（它们有独立的事件队列）， 以及要准确记录输入事件事件发生时的键盘组合键状态，还要正确实现 ICCCM/EWMH 中描述的转交窗口焦点的复杂规则，所有这些都已经在 X 中实现过的事情需要重新实现一遍。 由于坑太多难以实现，所以所有 X 下的混成器的实现方式都是直接忽略这个繁重的任务， 不重定向输入事件 而把它交给 X 处理。具体的实现方式就是通过 XFixes 扩展提供的 SetWindowShapeRegion API 将 OverlayWindow 的 输入区域 ShapeInput 设为空区域，从而忽略对这个 OverlayWindow 的一切鼠标键盘事件。 这样一来对 OverlayWindow 的点击会透过 OverlayWindow 直接作用到底下的窗口上。 因为选择了不重定向输入事件， X 下的混成器通常会处于以下两种状态： 选择状态下可以缩放窗口的大小，扭曲窗口的形状，并且可以把窗口绘制在任意想要绘制的位置上 （并不是移动窗口的位置）， 但是不能让用户与窗口的内容交互 。 正常状态下可以让用户与窗口的内容交互，但是 绘制的窗口位置、大小和形状必须严格地和 X 记录的窗口的位置、大小和形状保持一致 。持续时间短暂的动画效果可以允许位置和形状稍有偏差，但是在动画的过程中如果用户点击了 变形缩放过的窗口，那么鼠标事件将发往错误的（ X 记录中的而非显示出的）窗口元素上。 可以发现这两种状态就直接对应了 Gnome 3 的普通状态和缩略图状态（点击 活动 ( Activity ) 或者戳画面左上角之后显示的状态），这也解释了为什么尽管 Gnome 3 的窗口有硕大的关闭按钮，但是在缩略图状态下 Gnome 3 仍然需要给窗口加上额外的关闭按钮： 因为处于缩略状态下的窗口只是一张画而不能点 。 Composite 扩展的这些限制使得 X 下的混成器目前只能实现 Mac OS X 那样的 Exposé 效果，而不能实现 LG3D 那样直接在 3D 空间中操纵窗口内容。 解决重定向问题曾经的一缕曙光是 升阳公司 ( Sun Microsystems ) 在开发 LG3D 的过程中同时提议过另一个 X 扩展叫做 Event Interception 或者简称 XEvIE ，这个扩展的设计目的就是提供 API 让某个程序接收并操纵全部的键盘和鼠标事件。可惜这个扩展随着升阳公司本身的陨落而 处于无人维护的状态，这一点也在它的官方网页上说明了： It has been suggested that this extension should not be used because it is broken and maintainerless. Composite 扩展的不足 通过上面的介绍，我们就已经可以看到 Composite 扩展的不足之处了。 总结起来说，主要有两大不足： 绘图效率低。因为同样的位图从应用程序传到 Xorg ，再从 Xorg 传到混成器， 最后从混成器再绘制到屏幕上，绕了一个大弯。这就是为什么 Wayland 的开发者在他的slide the real story behind Wayland and X 里这么说： and what's the X server? really bad IPC 那么 X 服务器到底做了什么呢？ 非常糟糕的进程间通讯 没有重定向输入事件。如果我们要在 X 的混成器里做这个事情， 基本上我们要全部重写一遍 X 已经写好的窗口事件分发逻辑。 既然同样要重写，为什么不直接重写一遍 X 呢，扔掉那些历史负担，扔掉那些无用的 API ，重新设计可扩展的 API ，做好快速安全的 IPC —— 嗯，重写 X 就是 Wayland 的目的。 不过这么重写了的 Wayland 还是我们熟悉可爱的 X 么？它有哪些地方变样了？ 这将是我下一篇文章的内容。 附录：扩展阅读 我自己没有写过窗口管理器，没有写过混成器，没有写过 Wayland 程序，以上说的都是我从互联网上看到的整理出来的内容。写下本文的过程中我参考了这些文章： The (Re)Architecture of the X Window System 这篇2004年写的文章描述了 Composite 扩展出现的动机和历史，介绍了绘图库的实现情况，涉及了上面所说的那些 X 扩展被用到的情况和可能。 同时这篇文章还展望了很多现在的 X 已然实现了的功能，比如 OpenGL 和 X 的结合方面我们有了 GLX 和 AIGLX ，比如内核的显卡支持方面我们有了 DRI 和 KMS 。总之这是一篇描述 Linux 桌面未来的发展轨迹的非常有阅读价值的历史文献。 so you want to build a compositor 这是一篇 2008 年写的博文，介绍如何用 Clutter 实现一个最简单的混成器。 Composite tutorial 这是另一篇介绍如何实现一个简单的混成器的博文，用 Qt 实现，但是同样很底层。 unagi 这是一个可用的（但是已经长期没有开发的）类似 xcompmgr 的混成器。这个项目貌似 是一位研究生的硕士毕业设计，同时他公开了硕士学位的毕业论文 Master thesis: Writing an X compositing manager 其中也对实现一个简单的混成器做了详尽描述，包括介绍了相关的 X 扩展和调用。","tags":"tech","title":"X 中的混成器与 Composite 扩展"},{"url":"//farseerfc.me/zhs/brief-history-of-compositors-in-desktop-os.html","text":"（原本是想写篇关于 Wayland 的文章，后来越写越长感觉能形成一个系列， 于是就先把这篇背景介绍性质的部分发出来了。） Linux 系统上要迎来 Wayland 了，或许大家能从各种渠道打听到 Wayland 是一个混成器，替代 X 作为显示服务器。 那么 混成器 是个什么东西，桌面系统为什么需要它呢？ 要理解为什么桌面系统需要 混成器 （或者它的另一个叫法， 混成窗口管理器 ( Compositing Window Manager ) ），在这篇文章中我想回顾一下历史， 了解一下混成器出现的前因后果。 首先介绍一下混成器出现前主要的一类窗口管理器，也就是 栈式窗口管理器 ( Stacking Window Manager ) 的实现方式。 本文中所有桌面截图来自维基百科，不具有著作权保护。 早期的栈式窗口管理器 栈式窗口管理器的例子，Windows 3.11 的桌面 我们知道最初图形界面的应用程序是全屏的，独占整个显示器（现在很多游戏机和手持设备的实现仍旧如此）。 所有程序都全屏并且任何时刻只能看到一个程序的输出，这个限制显然不能满足人们使用计算机的需求， 于是就有了 窗口 的概念，有了 桌面隐喻 。 在 桌面隐喻 ( Desktop Metaphor ) 中每个窗口只占用显示面积的一小部分， 有其显示的位置和大小，可以互相遮盖。于是栈式窗口管理器就是在图形界面中实现桌面隐喻的核心功能， 其实现方式大体就是：给每个窗口一个相对的\"高度\"或者说\"远近\"，比较高的窗口显得距离用户比较近， 会覆盖其下比较低的窗口。绘图的时候窗口管理器会从把窗口按高低排序，按照从低到高的顺序使用 画家算法 绘制整个屏幕。 这里还要补充一点说明，在当时图形界面的概念刚刚普及的时候，绘图操作是非常\"昂贵\"的。 可以想象一下 800x600 像素的显示器输出下，每帧 真彩色 位图就要占掉 \\(800 \\times 600 \\times 3 \\approx 1.4 \\text{MiB}\\) 的内存大小，30Hz 的刷新率（也就是30FPS）下每秒从 CPU 传往绘图设备的数据单单位图就需要 \\(1.4 \\times 30 = 41 \\text{MiB}\\) 的带宽。对比一下当时的 VESA 接口 总的数据传输能力也就是 \\(25 \\text{MHz} \\times 32 \\text{bits} = 100 \\text{MiB/s}\\) 左右， 而 Windows 3.1 的最低内存需求是 1MB，对当时的硬件而言无论是显示设备、内存或是CPU， 这无疑都是一个庞大的负担。 于是在当时的硬件条件下采用栈式窗口管理器有一个巨大 优势 ：如果正确地采用画家算法， 并且合理地控制重绘时 只绘制没有被别的窗口覆盖的部分 ，那么无论有多少窗口互相 遮盖，都可以保证每次绘制屏幕的最大面积不会超过整个显示器的面积。 同样因为实现方式栈式窗口管理器也有一些难以回避的 限制 ： 窗口必须是矩形的，不能支持不规则形状的窗口。 不支持透明或者半透明的颜色。 为了优化效率，在缩放窗口和移动窗口的过程中，窗口的内容不会得到重绘请求， 必须等到缩放或者移动命令结束之后窗口才会重绘。 以上这些限制在早期的 X11 窗口管理器比如 twm 以及 XP 之前经典主题的 Windows 或者经典的 Mac OS 上都能看到。 在这些早期的窗口环境中，如果你拖动或者缩放一个窗口，那么将显示变化后的窗口边界， 这些用来预览的边界用快速的位图反转方式绘制。当你放开鼠标的时候才会触发窗口的 重绘事件。 虽然有很多方法或者说技巧能绕过这些限制，比如 Windows XP 上就支持了实时的 重绘事件和不规则形状的窗口剪裁，不过这些技巧都是一连串的 hack ，难以扩展。 NeXTSTEP 与 Mac OS X 中混成器的发展 NeXTSTEP 桌面 转眼进入了千禧年， Windows 称霸了 PC 产业，苹果为重振 Macintosh 请回了 Jobs 基于 NeXTSTEP 开发 Mac OSX 。 NeXTSTEP 在当时提供的 GUI 界面技术相比较于同年代的 X 和 Windows 有一个很特别的地方： 拖动滚动条或者移动窗口的时候，窗口的内容是 实时更新 的，这比只显示一个缩放大小的框框来说被认为更直观。 而实现这个特性的基础是在 NeXTSTEP 中运用了 Display PostScript (DPS) 技术，简单地说，就是每个窗口并非直接输出到显示设备，而是把内容输出到 (Display) PostScript 格式交给窗口管理器，然后窗口管理器再在需要的时候把 PostScript 用软件解释器解释成位图显示在屏幕上。 比起让窗口直接绘制，这种方案在滚动和移动窗口的时候不需要重新渲染保存好的 DPS ， 所以能实现实时渲染。到了实现 Mac OS X 的时候，为了同时兼容老的 Mac 程序 API (carbon) 以及更快的渲染速度，以及考虑到 Adobe 对苹果收取的高昂的 Display PostScript 授权费， Mac OS X 的 Quartz 技术在矢量图的 PDF 描述模型和最终渲染之间又插入了一层抽象： Mission Control 也就是说在 Mac OS X 中无论窗口用何种方式绘图，都会绘制输出成一副内存中的位图交给混成器， 而后者再在需要的时候将位图混成在屏幕上。这种设计使得 2001年3月发布的 Mac OS X v10.0 成为了第一个广泛使用的具有软件混成器的操作系统。 到了 Mac OS X v10.2 的时候，苹果又引入了 Quartz Extreme 让最后的混成渲染这一步发生在 显卡上。然后在 2003年1月公开亮相的 Mac OS X v10.3 中，他们公布了 Exposé (后来改名为 Mission Control) 功能，把窗口的缩略图（而不是事先绘制的图标）并排显示在桌面上， 方便用户挑选打开的窗口。 由于有了混成器的这种实现方式，使得可能把窗口渲染的图像做进一步加工，添加阴影、三维和动画效果。 这使得 Mac OS X 有了美轮美奂的动画效果和 Exposé 这样的方便易用的功能。 或许对于乔布斯而言，更重要的是因为有了混成器，窗口的形状终于能显示为他 梦寐以求 的 圆角矩形 了！ 插曲：昙花一现的 Project Looking Glass 3D 在苹果那边刚刚开始使用混成器渲染窗口的 2003 年，昔日的 升阳公司 ( Sun Microsystems ) 则在 Linux 和 Solaris 上用 Java3D 作出了另一个炫酷到没有朋友的东西，被他们命名为 Project Looking Glass 3D （缩写LG3D，别和 Google 的 Project Glass 混淆呀）。这个项目的炫酷实在难以用言语描述， 好在还能找到两段视频展示它的效果。 Youtube Youku Youtube Youku LG3D 如视频中展示的那样， LG3D 完全突破了传统的栈式窗口管理方式， 在三维空间中操纵二维的窗口平面，不仅像传统的窗口管理器那样可以缩放和移动窗口， 还能够旋转角度甚至翻转到背面去。从视频中难以体会到的一点是， LG3D 在实现方式上与 Mac OS X 中的混成器有一个本质上的不同，那就是处于（静止或动画中）缩放或旋转状态 下的窗口是 可以接受输入事件 的。这一重要区别在后面 Wayland 的说明中还会提到。 LG3D 项目展示了窗口管理器将如何突破传统的栈式管理的框架，可以说代表了窗口管理器的未来发展趋势。 LG3D 虽然以 GPL 放出了实现的源代码，不过整个项目已经停滞开发许久了。 官方曾经放出过一个 预览版的 LiveCD 。可惜时隔久远（12年前了）在我的 VirtualBox 上已经不能跑起来这个 LiveCD 了…… 更为可惜的是，就在这个项目刚刚公开展示出来的时候，乔布斯就致电升阳， 说如果继续商业化这个产品，升阳公司将涉嫌侵犯苹果的知识产权 （时间顺序上来看，苹果最初展示 Exposé 是在 2003年6月23日的 Apple Worldwide Developers Conference ，而升阳最初展示 LG3D 是在 2003年8月5日的 LinuxWorld Expo）。 虽然和乔布斯的指控无关，升阳公司本身的业务也着重于服务器端的业务， 后来随着升阳的财政困难，这个项目也就停止开发并不了了之了。 Windows 中的混成器 Longhorn 中的 Wobbly 效果 Youtube Youku 上面说到， Windows 系列中到 XP 为止都还没有使用混成器绘制窗口。 看着 Mac OS X 上有了美轮美奂的动画效果， Windows 这边自然不甘示弱。 于是同样在 2003 年展示的 Project Longhorn 中就演示了 wobbly 效果的窗口， 并且跳票推迟多年之后的 Windows Vista 中实现了完整的混成器 Desktop Window Manager (DWM) 。整个 DWM 的架构和 Mac OS X 上看到的很像： 和 Mac OS X 的情况类似， Windows Vista 之后的应用程序有两套主要的绘图库，一套是从早期 Win32API 就沿用至今的 GDI（以及GDI+），另一套是随着 Longhorn 计划开发出的 WPF 。 WPF 的所有用户界面控件都绘制在 DirectX 贴图上，所以使用了 WPF 的程序也可以看作是 DirectX 程序。而对老旧的 GDI 程序而言，它们并不是直接绘制到 DirectX 贴图的。首先每一个 GDI 的绘图操作都对应一条 Windows Metafile (WMF) 记录，所以 WMF 就可以看作是 Mac OS X 的 Quartz 内部用的 PDF 或者 NeXTSTEP 内部用的 DPS，它们都是矢量图描述。随后，这些 WMF 绘图操作被通过一个 Canonical Display Driver (cdd.dll) 的内部组建转换到 DirectX 平面，并且保存起来交给 DWM。最后， DWM 拿到来自 CDD 或者 DirectX 的平面，把它们混合起来绘制在屏幕上。 值得注意的细节是，WPF 底层的绘图库几乎肯定有 C/C++ 绑定对应， Windows 自带的不少应用程序 和 Office 2007 用了 Ribbon 之后的版本都采用这套绘图引擎，不过微软没有公开这套绘图库的 C/C++ 实现的底层细节，而只能通过 .Net 框架的 WPF 访问它。这一点和 OS X 上只能通过 Objective-C 下的 Cocoa API 调用 Quartz 的情况类似。 另外需要注意的细节是 DirectX 的单窗口限制在 Windows Vista 之后被放开了，或者严格的说是 基于 WDDM 规范下的显卡驱动支持了多个 DirectX 绘图平面。 在早期的 Windows 包括 XP 上，整个桌面上同一时刻只能有一个程序的窗口处于 DirectX 的 直接绘制 模式，而别的窗口如果想用 DirectX 的话，要么必须改用软件渲染要么就不能工作。 这种现象可以通过打开多个播放器或者窗口化的游戏界面观察到。 而在 WDDM 规范的 Vista 中，所有窗口最终都绘制到 DirectX 平面上，换句话说每个窗口都是 DirectX 窗口。又或者我们可以认为，整个界面上只有一个真正的窗口也就是 DWM 绘制的全屏窗口， 只有 DWM 处于 DirectX 的直接渲染模式下，而别的窗口都输出到 DirectX 平面里（可能通过了硬件加速）。 由 DWM 的这种实现方式，可以解释为什么 窗口模式下的游戏总是显得比较慢 ，原因是整个桌面有很多不同的窗口都需要 DWM 最后混成，而如果在全屏模式下，只有游戏 处于 DirectX 的直接渲染方式，从而不会浪费对游戏而言宝贵的 GPU 资源。 由于 DWM 实现了混成器，使得 Vista 和随后的 Windows 7 有了 Aero Glass 的界面风格， 有了 Flip 3D 、Aero Peek 等等的这些辅助功能和动画效果。 这套渲染方式延续到 Windows 8 之后，虽然 Windows 8 还提出了 Modern UI 不过传统桌面上的渲染仍旧是依靠混成器来做的。 这就结束了？ Linux 桌面呢？ 别急，我写这些文章的目的是想聊聊 Linux 中的混成器，尤其是 X 下现有的混成器和 Wayland ，这篇文章只是个背景介绍。关于 X 中混成器的实现方式和限制，且听我下回分解。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdnjscn.b0.upaiyun.com/libs/mathjax/2.4.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","title":"桌面系统的混成器简史"},{"url":"//farseerfc.me/zhs/stop-write-simply.html","text":"我的 RSS 订阅着一个博客叫 The Old New Thing ，作者是Windows开发者之一的 Raymond Chen ，记录 Windows 中的很多有趣的技术细节。 这个博客中的一些精彩内容还被他写成了一本书，中文名叫《Windows编程启示录》 (ISBN: 978-7-111-21919-4 ) 而英文书名就叫 The Old New Thing — Practical Development Throughout the Evolution of Windows (ISBN: 978-0-321-44030-3 )。 今天看到这个博客的一篇文章说 你用「简单地」次数越多我越怀疑你不懂这个词的意思 ， 描述他看到某个博客上指导读者打开命令行、执行某条魔法命令、从命令输出抽取参数、 改写配置文件、用魔法命令重启服务，并把这些工作描述为「简单地」。 的确正如 Raymond 指出，一个人觉得简单的事情对别人并不一定是简单的。 搜了一下我自己写的东西，的确很多地方写了「简单」二字，这的确对读者不友好。 从今往后避免用「简单」来描述。","tags":"life","title":"避免在博文中写「简单地」"},{"url":"//farseerfc.me/zhs/travis-push-to-github-pages-blog.html","text":"2015年2月21日更新 上次介绍过 这个博客改换了主题 ， 本以为这个话题可以告一段落了，没想到还能继续写呢。 寄宿在 Github Pages 上的静态博客通常有两种方案，其一是使用 Jekyll 方式撰写，这可以利用 Github Pages 原本就有的 Jekyll支持 生成静态网站。另一种是在 本地 也就是自己的电脑上生成好，然后把生成的 HTML 网站 push 到 Github Pages ，这种情况下 Github Pages 就完全只是一个静态页面宿主环境。 我用 Pelican 生成博客，当然就只能选择后一种方式了。这带来一些不便，比如本地配置 pelican 还是有一点点复杂的，所以不能随便找台电脑就开始写博客。有的时候只是想修正一两个错别字， 这时候必须打开某台特定的电脑才能编辑博客就显得不太方便了。再比如 pelican 本身虽然是 python 写的所以跨平台，但是具体到博客的配置方面， Windows 环境和 Linux/OSX/Unix-like 环境下还是有 些许出入 的。还有就是没有像 wordpress 那样的基于 web 的编辑环境，在手机上就不能随便写一篇博客发表出来（不知道有没有勇士尝试过在 Android 的 SL4A 环境下的 python 中跑 pelican ，还要配合一个 Android 上的 git 客户端 ）。 当然并不是因此就束手无策了，感谢 Travis-CI 提供了免费的 持续整合 ( Continuous integration ) 虚拟机环境， 通过它全自动生成静态博客成为了可能。 关于 Travis-CI 持续整合 原本是 敏捷开发 ( Agile Development ) 或者 极限编程 ( Extreme Programming ) 中提到的概念，大意就是说在开发的过程中， 一旦有微小的变更，就全自动地 持续 合并到主线中， 整合 变更的内容到发布版本里。 这里的 整合 实际上可以理解为 全自动测试 加上 生成最终产品 。 可以看到 持续整合 实际强调 全自动 ，于是需要有一个服务器不断地监听主线开发的变更内容， 一旦有任何变更（可以理解为 git commit ）就自动调用测试和部署脚本。 于是要用持续整合就需要一个整合服务器，幸而 Travis-CI 对 github 上的公开 repo 提供了免费的整合服务器虚拟机服务，和 github 的整合非常自然。所以我们就可以用它提供的虚拟机 为博客生成静态网站。 启用 Travis-CI 自动编译 这一步很简单，访问 https://travis-ci.org/ 并用你的 Github 账户登录， 授权它访问你的账户信息就可以了。然后在 https://travis-ci.org/repositories 里开启 需要编译的 repo ，这样 Travis-CI 就会监视对这个 repo 的所有 push 操作，并且对 每个 push 调用测试了。 在 Travis-CI 中开启对 Github Repo 的持续整合 然后在 repo 的根目录放一个 .travis.yml 文件描述编译的步骤。 暂时 测试的目的下我写的 .travis.yml 大概是下面这样。 language : python python : - \"2.7\" before_install : - sudo apt-add-repository ppa:chris-lea/node.js -y - sudo apt-get update - sudo apt-get install nodejs ditaa doxygen parallel install : - sudo pip install pelican - sudo pip install jinja2 - sudo pip install babel - sudo pip install beautifulsoup4 - sudo pip install markdown - sudo npm install -g less - wget \"http://downloads.sourceforge.net/project/plantuml/plantuml.jar?r=&ts=1424308684&use_mirror=jaist\" -O plantuml.jar - sudo mkdir -p /opt/plantuml - sudo cp plantuml.jar /opt/plantuml - echo \"#! /bin/sh\" > plantuml - echo 'exec java -jar /opt/plantuml/plantuml.jar \"$@\"' >> plantuml - sudo install -m 755 -D plantuml /usr/bin/plantuml - wget https://bintray.com/artifact/download/byvoid/opencc/opencc-1.0.2.tar.gz - tar xf opencc-1.0.2.tar.gz - cd opencc-1.0.2 && make && sudo make install && cd .. - sudo locale-gen zh_CN.UTF-8 - sudo locale-gen zh_HK.UTF-8 - sudo locale-gen en_US.UTF-8 - sudo locale-gen ja_JP.UTF-8 script : - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - mkdir output - env SITEURL=\"farseerfc.me\" make publish Travis-CI 提供的虚拟机是比较标准的 Ubuntu 12.04 LTS ，打上了最新的补丁，并且根据你指定的 语言选项会把相应的解释器和编译器升级到最新版（或者指定的版本）。这里用 python 语言的配置， 所以 python 是 2.7 的最新版并且有 pip 可以直接用。 配置中的 before_install 和 install 的区别其实不大，其中任何一个失败的话算作 build errored 而不是 build fail ，而如果在 script 里失败的话算作 build fail 。 为了编译我的模板，还需要比较新的 less.js ，所以添加了 ppa 装了个最新的 nodejs 并用它装上了 less 。 还从源码编译安装上了最新版的 opencc 1.0.2 ，因为 Ubuntu 源里的 opencc 的版本比较老(0.4)， 然后 doxygen 作为 opencc 的编译依赖也装上了。 其它安装的东西么，除了 pelican 之外都是插件们需要的。以及我还需要生成 4 个语言的 locale 所以调用了 4 次 locale-gen 。由于是比较标准的 Ubuntu 环境，所以基本上编译的步骤和在本地 Linux 环境中是一样的，同样的这套配置应该可以直接用于本地 Ubuntu 下编译我的博客。 写好 .travis.yml 之后把它 push 到 github ，然后 travis 这边就会自动 clone 下来开始编译。 travis 上能看到编译的完整过程和输出，一切正常的话编译结束之后 build 的状态就会变成 passing ，比如 我的这次的build 。 从 Travis-CI 推往 Github 上面的测试编译通过了之后，下一步就是让 travis-ci 编译的结果自动推到 Github Pages 并发布出来。要推往 Github 自然需要设置 Github 用户的身份，在本地设置的时候是把 ssh key 添加到 github 账户就可以了，在编译细节都通过 github repo 公开了的 travis 上 当然不能放推送用的私有 key ，所以我们需要另外一种方案传递密码。 Github 上创建 Personal Access Token 好在 Github 支持通过 Personal Access Token 的方式验证，这个和 App Token 一样可以随时吊销，同时完全是个人创建的。另一方面 Travis-CI 支持加密一些私密数据，通过环境变量的方式传递给编译脚本，避免公开密码这样的关键数据。 首先创建一个 Personal Access Token ，这里需要勾选一些给这个 Token 的权限，我只给予了最小的 public_repo 权限，如侧边里的图。 生成之后会得到一长串 Token 的散列码。 如果你不能使用 travis 命令 2015年2月21日更新 使用 travis encrypt 命令来加密重要数据最方便，不过如果有任何原因， 比如 ruby 版本太低或者安装不方便之类的，那么不用担心，我们直接通过 travis api 也能加密数据。 第一步用这个命令得到你的repo的 pubkey ： curl -H \"Accept: application/vnd.travis-ci.2+json\" https://api.travis-ci.org/repos/<github-id/repo>/key | python2 -m json.tool | grep key | sed 's/.*\"key\": \"\\(.*\\)\"/\\1/' | xargs -0 echo -en | sed 's/ RSA//' > travis.pem 其中的 <github-id/repo> 替换成 github 上的 用户名/repo名， 比如我的是 farseerfc/farseer 。travis api 获得的结果是一个 json ，所以还用 python 的 json 模块处理了一下，然后把其中包含 key 的行用 grep 提取出来，用 sed 匹配出 key 的字符串本身，然后 xargs -0 echo -en 解释掉转义字符，然后删掉其中的 \"<空格>RSA\" 几个字（否则 openssl 不能读）， 最后保存在名为 travis.pem 的文件里。 有了 pubkey 之后用 openssl 加密我们需要加密的东西并用 base64 编码： echo -n 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' | openssl rsautl -encrypt -pubin -inkey travis.pem | base64 -w0 替换了相应的身份信息和token之后，这行得到的结果就是 secure 里要写的加密过的内容。 然后我们需要 travis 命令来加密这个 token ， archlinux 用户可以安装 aur/ruby-travis ，其它用户可以用 gems 安装： $ gem install travis 装好之后，在设定了 Travis-CI 的 repo 的目录中执行一下 travis status ， 命令会指导你登录 Travis-CI 并验证 repo 。正常的话会显示最新的 build 状态。 然后同样在这个 repo 目录下执行： $ travis encrypt 'GIT_NAME=\"Jiachen Yang\" GIT_EMAIL=farseerfc@gmail.com GH_TOKEN=<Personal Access Token>' 当然上面一行里的相应信息替换为个人的信息，作为这个命令的执行结果会得到另一长串散列码， 把这串散列写入刚才的 .travis.yml 文件： env : - secure : \"long secure base64 string\" 有了这段声明之后， Travis-CI 就会在每次编译之前，设置上面加密的环境变量。 然后在编译脚本中利用这些环境变量来生成博客： script : - git config --global user.email \"$GIT_EMAIL\" - git config --global user.name \"$GIT_NAME\" - git config --global push.default simple - git clone --depth 1 https://github.com/farseerfc/pelican-plugins plugins - git clone --depth 1 https://github.com/farseerfc/pelican-bootstrap3 theme - git clone --depth 1 https://$GH_TOKEN@github.com/farseerfc/farseerfc.github.io output - env SITEURL=\"farseerfc.me\" make publish after_success : - cd output - git add -A . - git commit -m \"update from travis\" - git push --quiet 这里要注意最后 git push 的时候一定要加上 --quiet ，因为默认不加的时候会把 代入了 $GH_TOKEN 的 URL 显示出来，从而上面的加密工作就前功尽弃了…… 根据 travis 的文档 ， after_success 里写的步骤只有在 script 里的全都完全无错执行完之后才会执行，这正是我们 push 的条件。目前 after_success 的成功与否不会影响到 build 的状态。 具体我用的配置见 这里的最新版 。 在我的 make github 中 调用了 git push 命令，从而执行了 make github 之后就会自动部署到 github 上。 用 Web 编辑并发布静态博客 经过以上设置之后，一切正常的话，每次对主 repo 推送更新的同时， Travis-CI 就会自动 拉来更新然后编译并发布了。可以放置这样的图标 在项目的 Readme.md 中显示编译状态。 这样设置之后的另一个好处就在于可以利用 Github 的 Web 界面编辑文章内容。在 Github 里 编辑和保存之后会自动作为一个 commit 提交，所以也会触发 Travis-CI 的自动编译。 在 Github 的 Web 界面中直接编辑文章内容 以及虽然目前还没有好用的 Github 的手机客户端，不过直接用 Android/iPhone 的浏览器登录 github 并编辑文章的可用性也还不错，所以同样的方式也可以直接在手机上发布博文了。 That is all, happy blogging ~","tags":"tech","title":"用 Travis-CI 生成 Github Pages 博客"},{"url":"//farseerfc.me/zhs/weather-forcast-academic-in-japan.html","text":"最近 mazk 说我 life 分类里的文章太少 ，所以想了想写了这篇。 很多人问过我为什么要来日本留学，嘛原因之一是我英语太差了，相对而言日语比较好。 另一方面，我比较喜欢日本的学术氛围。这个当然是主观体会，而不是客观的评价，只是我 觉得相对于 欧美喜欢研究基础架构技术 ， 日本则偏向实用层面 。 说个具体一点例子，最近看到这篇新闻说 卢布贬值影响中央气象台预报准确率？ ，其中提到： 因为卢布贬值，天气预报的准确率会有所降低 也说道： 不过经我多年的观察，中国中央气象台的预报准确率实在是不怎么样，具体到我生活的地区， 实际天气状况和中国中央气象台预报的出入较大…… 相信不少人也有类似的体会。 天气预报是事关人们生活的重要信息，其准确度对生产生活当然有很大影响。 说到增加天气预报的准确度，人们自然会想到高性能的超级计算机比如 天河二号 ，想到环绕在地球高空的 气象卫星 ，想到遍布世界各地的气象站观测台。想想这么多耗资不菲的高尖端项目被国家投入， 用来改善天气预报的准确程度，看起来这的确是一个困难的科研课题。 话说回来，准确预测气温、气压、湿度、降水概率等等这些事情对于生产生活固然重要， 不过对一般民众而言，天气预报最重要的作用就只是回答 明天我该穿多厚的衣服，出门是否需要打伞 这种问题。一年四季换衣服的时机其实并不那么频繁，气温提升五度或者降低两度这种程度下人们估计也 不能感觉得到，大体上只要根据「昨天穿什么衣服，昨天觉得冷不冷」就能作出判断。另一方面， 出门是否需要打伞 这样的问题的确只能依靠天气预报来回答。 那么解决 出门是否需要打伞 这个问题需要那么高尖端的技术么？ 我所在的大阪大学情报科学研究科有个已经毕业的学长 今城 健太郎 ( いまじょう けんたろう ) 就对此作出了解答。他的专业不是气象预测，而是图像分析处理，纯粹的计算机科学学科。 而他的本科毕业设计就着眼于「仅仅分析气象云图，能否高精度预测降水概率」， 其研究成果，就是一个叫 ないんたん 的降水概率预测系统 。 这个系统有数个会卖萌的Twitter机器人 @ninetan ，每时每刻对 其预测地区的降水情况做播报，同时也有详细的降水概率曲线图对 大阪 ( @ninetan_osaka )， 京都 ( @ninetan_kyoto )， 东京 ( @ninetan_tokyo )， 兵库 ( @ninetan_hyogo )， 和歌山 ( @ninetan_wakayam ) 的各个大学所在校区 两个半小时内做精确的降水概率预测。比如今天晚上大阪大学三个校区的降水概率图如下： 今天晚上大阪大学三个校区的降水概率图 从上面的图可以看出这个系统的预测精度是以 分为单位 的，可以看到 两个半小时内各地的降水量的大小。比如我可以根据这张图看出，我所在的吹田校区 将在 21时35分 开始有微弱的概率下起 0.1mm/h~1mm/h 的毛毛雨，到 22时05分 左右这个降水概率 爬升到最高大约45%，从而作出判断： 我最好在晚上九点左右离开学校回家，避免淋雨。 自从研究室的前辈给我介绍这个天气预报系统开始，我用了它两三年了，直观感觉是 这个系统的预测精度惊人得准确，基本上能接近 《魔法的禁书目录》中的「树形图设计者」 能做的天气预报的程度， 它说何时会下雨就一定下雨，它说何时雨停就一定雨停。同学们出门和回家的时候一般都会 看一眼这个天气预报然后决定是否出门。「啊今天晚上9点开始下雨所以早点回家」 或者「啊还有30分钟雨就停了，再在研究室里留一会儿」。 这只是一个本科生的毕业设计，所以覆盖面小（只有5所大学的十几个校区，只能预测 未来两个多小时的降水概率），不过仅此而已能做到如此的精度以至于实用，实在让我 惊讶。系统的测试之初就有人说： 最近ないんたん予报あたりすぎてないんたんが雨降らせてるんじゃないかという疑惑 — すみのネコ歩き (@sumi_eee) 2011 7月 6日 最近ないんたん预告实在太准了，甚至让人怀疑是不是ないんたん把雨招来的。 不过最近身边的日本人似乎已经把这个系统的准确当作习以为常了，就像日本的电车 掐着秒表准点到站一样，理所当然。 把天气预报这种高尖端的技术做到如此实用的地步，这基本上可以代表我对 日本学术界研究方式和研究目的的总体印象了。 嗯今天就写这么多，9点到了，我要按照天气预报的预测，准时回家了。 ——写于2015羊年除夕夜，9点。","tags":"life","title":"从天气预报谈谈日本的学术氛围"},{"url":"//farseerfc.me/zhs/arch-chrome-remote-desktop.html","text":"透明计算 具体是什么，因为他们没有公开技术细节所以我并不知道，只是看 公开出来的演示视频 ，感觉似乎只要能从手机上远程登录系统桌面，就能算是透明计算了。 如果透明计算真是这个意思，那么我似乎已经用着这个技术很多年了嘛。 Xorg 上常用的远程桌面工具有很多，基于 VNC 协议的、基于NX的和基于 RDP 协议的都能找到， 直接 ssh X forwarding 效果也不错。只是这些方案的一个 不太易用 的地方在于，需要 通过 ip 访问到远程的电脑，所以在跨越 NAT 之类的情况下不太容易使用。 于是今天介绍一个使用方便设置也简单的方法： 通过 chrome-remote-desktop 在 archlinux 上使用远程桌面。这个方案的优势在于，借助 Google 的云端服务器（内部貌似是XMPP协议下的握手） 方便地实现了 NAT 穿透，无论什么网络环境基本都能使用。当然，要支持远程登录， 位于远端的登录的计算机必须一直开着 Chrome Remote Desktop 的后台服务。 Chrome Remote Desktop 插件 Chrome Remote Desktop 的客户端 虽然可能有很多人不知道，不过 Chrome 内包括远程桌面的功能很久了。只是这个功能的界面默认 没有提供界面，要使用它需要安装 Google 官方出品的 remote-desktop 插件 。 装好之后远程桌面的客户端就准备好，可以用来远程访问别的计算机桌面了（无论是 Windows/OS X 还是 Linux 都支持）。并且不光可以自己远程访问自己账户的桌面，还可以远程协助朋友的桌面。 Archlinux 上设置远程登录的服务器 有了客户端之后还要设置一下才能让桌面作为远程登录的服务器。Windows 和 OS X 上 Chrome 会自动下载需要的安装包，无脑下一步就能装好了。Linux上由于发行版众多，桌面配置各异， 所以需要一点手动配置。官方的设置步骤记载在 这里 其中给出了 debian 用的二进制包和 Ubuntu 12.10 上的设置方式，以下设置是参考官方步骤。 首先要安装 chrome-remote-desktop 这个包，这个包实际上对应了 Windows/OS X 上用安装程序 安装的 Remote Desktop Host Controller。 archlinux 上开启了 [archlinuxcn] 仓库的话，可以直接安装打好的包。或者可以从 AUR 装。 $ pacman -Ss chrome-remote-desktop archlinuxcn/ chrome-remote-desktop 40.0.2214.44-1 Allows you to securely access your computer over the Internet through Chrome. 装好之后从会说这么一段话： groupadd：无效的组 ID \"chrome-remote-desktop\" Please create ~/.config/chrome-remote-desktop folder manually, if it doesn't exist, or else you can't use CRD. The needed files are created by the Chrome app, inside the chrome-remote-desktop folder, after Enabling Remote Connections. To {enable,start} the service use systemctl --user {enable,start} chrome-remote-desktop You may need to create a ~/.chrome-remote-desktop-session file with commands to start your session Go to https://support.google.com/chrome/answer/1649523 for more information. 那句报错是 AUR 里打的包还没跟上上游 Google 的更改导致的错误， 首先我们需要把远程登录的用户添加入 chrome-remote-desktop 这个用户组里。 新版本的 chrome remote desktop 提供了一个命令做这个事情，所以执行以下命令就可以了： $ /opt/google/chrome-remote-desktop/chrome-remote-desktop --add-user 然后我们需要手动创建 ~/.config/chrome-remote-desktop 这个文件夹，内容是空的 就好了，随后 chrome 会往这里面放 host#.json 文件用于身份验证。 $ mkdir ~/.config/chrome-remote-desktop 然后我们要创建一个 shell 脚本 ~/.chrome-remote-desktop-session ，这是远程 登录时的 .xinitrc ，内容么就是启动你想在远程登录时用的桌面环境。 这里可以指定一个和你正在登录的 WM/DE 不同的桌面，比如我启动 xfce4： $ cat ~/.chrome-remote-desktop-session # !/bin/bash startxfce4 $ chmod 755 .chrome-remote-desktop-session 接下来需要从 Chrome 的插件里启用远程桌面。打开 Chrome 的 Remote Desktop 插件，这时 应该可以看到一个「启用远程链接」的按钮。 Chrome Remote Desktop 插件中「启用远程链接」的按钮 在撰写本文的时候， Archlinux 官方源里的 chromium 的版本和 aur/google-chrome 的版本尚且还是 40.0.2214.111 ，而 Chrome Web Store 中提供的 Chrome Remote Desktop 的插件的版本是 41.0.2272.41 。虽然通常并不要求两者版本一致，不过貌似最近 Chrome 内部的 Remoting 功能更改了 API 导致可能出问题。如果你找不到 「启用远程链接」的按钮，请尝试一下新版本的 Chrome 比如 google-chrome-dev 。 在这一步启用之后，老版本的 chrome 应该也就能使用远程桌面了。 在32位的 Linux 版本上，最近更新的 Chrome Remote Desktop 插件可能无法正确识别 Host 的版本，具体 参考这个 bug 。 点击「启用远程链接」，设定一个 PIN 密码（不需要很复杂，这里首先有 Google 帐号验证保证只有 你才能访问），然后就能看到这套电脑的 hostname 出现在「我的电脑」列表里。 启用远程链接之后的样子 同时，启用了远程链接之后，可以在刚刚创建的 ~/.config/chrome-remote-desktop 文件夹中找到记录了验证信息的文件。 $ ls .config/chrome-remote-desktop chrome-profile host#8cfe7ecfd6bb17955c1ea22f77d0d800.json pulseaudio#8cfe7ecfd6 然后就可以启动对应的 systemd 用户服务了，如果想自动启动服务要记得 systemctl --user enable ： $ systemctl --user start chrome-remote-desktop.service 如果上面的设置一切正常，就可以看到 chrome-remote-desktop 启动了另外一个 Xorg 执行你 刚刚指定的桌面环境： htop 中看到的 chrome-remote-desktop 启动的另外一个 Xorg 然后就可以试着通过 Remote Desktop 插件登录到这个新开的 Xorg 了： 「远程」登录到新的 XFCE4 Linux 版本的 Chrome远程桌面 和 Windows/ OS X 上的区别 通过上面的设置步骤也可以看出，Linux版本的远程桌面会在后台开一个独立的 X 会话，而不能 复用现在已有的 X 会话。对远程登录的用法而言这还能接受，对远程协助的功能而言有点问题， 因为正在使用的人不能观察协助者做了什么，协助者也不能继续请求协助的人的操作。 当然目前 Chrome 远程桌面的 Linux Host Controller 还只是 beta 版本，官方只测试支持 Ubuntu 12.04 和 12.10 （14.04之后似乎有 Bug ），所以不能要求太多。希望以后能改善吧。 Bonus： 手机远程登录 手机上的 Chrome 远程桌面 App 通过上面的设置就可以从任何一个 Chrome 远程桌面客户端登录刚刚设置的这台电脑了。 因为 Chrome 在三大桌面系统 Windows / OS X / Linux 上都有，所以应该能覆盖大多数桌面 系统了。 除了桌面的 Chrome 之外还有一个客户端是 Android 上的 Chrome 远程桌面 App 经过上面的设置之后，从这个 App 也能看到并登录： 手机远程登录 好啦，开始享受国家自然科学一等奖的透明计算技术吧！","tags":"tech","title":"archlinux 上用 chrome 实现 透明计算 远程登录"},{"url":"//farseerfc.me/zhs/switch-to-farseerfc-dot-me-domain.html","text":"上个月就在 狗爹 ( godaddy ) 上买了个自己的域名 farseerfc.me 准备用在这个 博客上，当时试着转到过这个域名，发现 自定义域名 ( custom domain ) 只支持 http 不支持 https ，想着还要买自己的证书，于是就扔在了一旁。不用自定义域名的话， 放在 github.io 上是可以用 HTTPS 的。 今天在 #archlinux-cn 上受大牛 quininer 和 lilydjwg 点播， 发现 cloudflare 有提供 免费的支持 SSL 的 CDN 服务 赶快去申请了一个，感觉非常赞，于是就换过来了。 设置的方法按照 这篇博文 说的一步步做下来，如它所述，用 CloudFlare 的优点如下： CDN 加速 SSL (HTTPS) 加密 支持 SPDY 协议 支持 IPv6 2015年12月29日更新 现在不光支持 SPDY 而且支持 HTTP/2 了。 然后 免费账户 的一些缺点有： CloudFlare 和 github.io 之间的数据不是加密的，因为 github 自定义域名 ( custom domain ) 还不支持使用自己的证书。这也是一开始我没用 自定义域名的原因嘛，这没有办法…… CloudFlare 给免费账户签名的 SSL 证书比较新，不支持一些老的设备和浏览器，比如不支持 老的 XP 系统的 IE 或者 2.x 的 Android。这种情况下没办法只能用没有加密的 HTTP 了。 不支持 HSTS 头 ，所以不能从服务器这边强制浏览器用 HTTPS。当然可以放个 javascript 跳转， 也可以用 HTTPSEverywhere 这种方案。 2015年12月29日更新 如评论中 提到的 现在支持 HSTS 了。 设置步骤 基本按照默认的选项下一步就可以了。 和那个博主一样我把 安全级别 ( Security profile ) 降到了 Low ，即使是可疑流量也 不会要求输入 CAPTCHA 。 把 SSL 方式开在 Flexible SSL，访客到 CloudFlare 是加密的，而 CloudFlare 到 github.io 是不加密的。 把 CDN 开到了 CDT+Full Optimization ，可以对访问加速。由于是完全静态的博客，没有 动态变化的内容，所以应该比较安全。 服务器设置的一步需要将 域名解析服务器 ( DNS nameservers ) 从狗爹的服务器改到 CloudFlare 的，如下图： 更改狗爹的域名服务器 申请好之后就由 CloudFlare 接管域名解析了，接下来在 CloudFlare 的 DNS 设置添加一条 A 类规则指向 github pages 的 IP 。 更改CloudFlare的DNS规则 等一切都反映到 DNS 服务器上就设置完成了，接下来给 farseerfc.github.io push 一个 CNAME 文件 写上我的域名就可以了。我用 Makefile 配合我的 pelican 配置做这个： publish : rmdrafts cc clean theme [ ! -d $( OUTPUTDIR ) ] || find $( OUTPUTDIR ) -mindepth 1 -not -wholename \"*/.git*\" -delete rm -rf cache echo $( SITEURL ) > content/static/CNAME $( PELICAN ) $( INPUTDIR ) -o $( OUTPUTDIR ) -s $( PUBLISHCONF ) $( PELICANOPTS ) $( MAKE ) rsthtml github : ( cd $( OUTPUTDIR ) && git checkout master ) env SITEURL = \"farseerfc.me\" $( MAKE ) publish ( cd $( OUTPUTDIR ) && git add . && git commit -m \"update\" && git push ) SITEURL = '//' + getenv ( \"SITEURL\" , default = 'localhost:8000' ) STATIC_PATHS = [ 'static' , 'images' , 'uml' , 'images/favicon.ico' , 'static/CNAME' ] EXTRA_PATH_METADATA = { 'images/favicon.ico' : { 'path' : 'favicon.ico' }, 'static/CNAME' : { 'path' : 'CNAME' } } 然后把生成的静态网站 push 到 github 之后可以从项目设置里看到域名的变化： Github 配置好自定义域名之后的变化 最后把Disqus的评论也迁移到新的域名，disqus有方便的迁移向导，一直下一步就可以了。 这样就一切都设置妥当了。 致谢 最后要感谢提供消息的 quininer 和 lilydjwg ，感谢撰写设置步骤的 Jonathan J Hunt ， 感谢 CloudFlare 提供免费 SSL CDN 服务，感谢 Github 提供 方便免费的 Pages 托管。","tags":"tech","title":"换到 farseerfc.me 域名"},{"url":"//farseerfc.me/zhs/redesign-pelican-theme.html","text":"2015年2月14日更新 前言: 新天新地，将一切都更新了 [1] 不知不觉间放任这边长草很久了，从上次 折腾主题 到现在都快三年了， 而从上次 写了篇告白信 到现在也有快两年了。 这期间曾经把主题配色从 Bootstrap 2 默认的 白底黑字改成了让眼睛更舒适的黑底白字，也不过是用 drop-in 的配色方案而已，没有本质上的改进。 洞中一日世上千载，两年里 Bootstrap 已经升上 v3.3 , 而 Pelican 则已经升到 3.5 了。 早就眼馋 Bootstrap 和 Pelican 中的诸多新功能新设计，不过无奈于时间有限只能饱饱眼福。 近日想写的东西越积越多，终于下定决心花了前前后后 两个月 的时间重新设计了一遍 Pelican 的主题，配合一些我觉得有用的插件。于是本博客就变成你们现在看到的样子了。 （以及本篇博文也用了两个月的时间写完，其间还发了几篇别的短文，算是恢复写博客的尝试吧。） 在迈阿密参加 ICSR 2015 的时候 拍到的街边一家叫 Pelican 的旅馆 Bootstrap 3 的新设计 全新的 优先移动设备 ( mobile-first ) 响应式 ( responsive ) 设计。 原本Bootstrap 2虽然有响应式设计， 不过诸多细节不能符合我的需求，最终还是得手工 hack @media 查询去微调。 现在的 优先移动设备 ( mobile-first ) 响应式 ( responsive ) 栅格系统 ( grid system ) 则相对显得科学很多了，也终于能在手持 设备上看起来舒服一些。诸位可以尝试改变窗口宽度，或者在不同的手持设备上打开这个 blog ，体验一下这个页面在不同显示器大小中的效果。如果仍有问题欢迎 发 Issue 给我 。 科学的 导航栏 ( Navbar ) 。 比 Bootstrap 2 那个科学很多了。无论是 保持 ( sticky ) 在上端还是跟着浮动， 或者像这边这样 自动隐藏 都很简单。 更多细节参考 Bootstrap 3 主页 。 Pelican 3.5 的新功能 Python 2 和 Python 3 统一代码： 再没有恼人的 unicode 相关的问题了。这对 blog 系统来说相当重要啊。 而且还能方便切换 pypy 等不同的解释器。 全新的插件系统：非常多功能强大的 插件 等着你。 增强了导入系统：嗯总算可以导入我的中文的 wordpress 博客了。（虽然那边长草更久了……） 站内链接 ：不用 硬编码 ( hard code ) 目标页面的链接了，可以直接写源文件的位置然后让 pelican 处理，这样能简化各种 插件 ( plugin ) 和 主题 ( theme ) 的实现。 更多细节参考 Pelican 文档 。 新的文件夹布局 Pelican 的新文件夹布局 . ├── cache 生成页面的 pickle 缓存 ├── content 读取的全部内容 │ ├── <categories> 按分类存放的文章 │ ├── pages 像 About 这样的固定页面 │ └── static 文章内用到的静态内容 ├── drafts 文章的草稿箱 ├── Makefile 生成用的 makefile ├── pelicanconf.py 测试时用的快速 Pelican 配置 ├── publishconf.py 部署时用的耗时 Pelican 配置 ├── output -> ../farseerfc.github.io ├── plugins -> ../pelican-plugins └── theme -> ../pelican-bootstrap3 之前的博客 仍然留在 github 上，其中的内容完全搬过来了。开始写老博客的时候 Pelican 版本较早，没有形成好的 文件夹布局，导致生成的文章、使用的模板和撰写的内容全都混在一起，非常难以管理， 于是趁改版之际用了新的文件夹布局方式，并分为 4 个 git repo 分别管理历史。 首先是存放 总的博客内容的 repo ， 其布局是如图那样的。这样将生成的静态网站和生成网站用的配置啦内容啦分开之后，顿时清晰了很多。 然后这个内容 repo 中的三个符号链接分别指向三个子 repo（没用 git submodule 管理纯粹是因为偷懒）。 theme 指向 pelican-bootstrap3 ，是我修改过的 pelican 主题。 plugins 指向 pelican-plugins ，由于 plugins 的质量有些参差不齐，其中不少 plugin 都按我的需要做了些许修改，一些是功能改进，另一些则是修bug（比如不少plugin只支持 python 2）。 最后 output 指向 farseerfc.github.io 也就是发布的静态网站啦。 接下来从 主题 和 插件 两个方面介绍一下改版的细节。 主题： Material Design 风格的 Bootstrap 3 上篇 博文 就总结了我为了这个博客寻找了一堆 CSS 框架，并且最终决定用 bootstrap-material-design , DandyDev/pelican-bootstrap3 和 Bootstrap 3 这三个项目结合的方式实现这个模板的主题。 这三个项目都或多或少经过了我的修改，修改后的项目以 pelican-bootstrap3 为基础放在 这里 ，包括 Bootstrap3 样式 和 Material 样式 。 对 Bootstrap 3 的定制 由于架构完善，修改 Bootstrap 3 感觉非常简单。另一方面我在 Web 前端技术上的技能点也不多， 所以修改的地方非常有限，只能按我自己的需求定制而已。 响应式设备的大小 修改了 Bootstrap 3 响应式设备的大小 @ screen-xs : 320px ; @ screen-sm : 598px ; /* 768px; */ @ screen-md : 952px ; /* 992px; */ @ screen-lg : 1350px ; /* 1200px; */ @ screen-xl : 2030px ; @ container-sm : 582px ; /* 750px; */ @ container-md : 930px ; /* 970px; */ @ container-lg : 1320px ; /* 1170px; */ @ container-xl : 1990px ; 首先把 Bootstrap 3 默认适配的几个 响应式设备的大小 改成了我需要的大小。 xs 和 sm 的大小分别按照我的手机屏幕 竖屏 和 横屏 时候的浏览器页面宽度来算， md 是想兼容 Nexus 7 横屏 960 的宽度以及 一个常见上网本 1024 的宽度。 lg 的大小则按照常见的笔记本 1366 宽的屏幕来适配。 这里 Bootstrap 3 支持的设备大小的一个问题是，它最多考虑到 1200 像素宽的显示器，而更宽的 比如 1600、 2048 甚至 2560 像素宽的显示器现在也并不少见，其结果就是页面中左右两侧 有很大的空间被浪费掉了。作为深受这一问题困扰的用户之一，我用 这里介绍的方法 给 bootstrap 增加了一类「 比大更大 ( bigger than bigger ) 」的 xl 响应式设备尺寸，宽度设为支持 2048 像素宽的显示器，具体的修改反映在 variables.less 文件里。 根据宽度自动分栏和瀑布式布局 接下来目标是让主页的文章列表像 Google+ 主页那样根据显示器宽度自动调整分栏，使得宽度不同的 显示器上每个分栏的宽度接近。想要达到的效果是，根据上面定义的屏幕宽度尺寸： xs 用单栏 流动 ( fluid ) 布局 sm 用上方单栏文章列表、下方双栏 侧边栏 ( sidebar ) 固定布局 md 用单栏文章列表、单栏 侧边栏 固定布局 导航栏 ( Navbar ) 文章 侧边栏 底栏 导航栏 文章 侧边栏 1 侧边栏 2 底栏 ( footer ) 导航栏 文章 1 侧边栏 1 文章 2 侧边栏 2 底栏 ( footer ) lg 用双栏文章列表、单栏 侧边栏 固定布局 xl 用三栏文章列表、双栏 侧边栏 固定布局 导航栏 文章 1 文章 3 侧边栏 1 文章 2 文章 4 侧边栏 2 底栏 ( footer ) 导航栏 文章 1 文章 3 文章 5 侧边栏 1 文章 2 文章 4 文章 6 侧边栏 2 底栏 ( footer ) 一开始纯粹用 Bootstrap3 的响应式栅格实现这个分栏布局，结果发现效果不太理想， 因为文章列表和侧边栏的高度是变化的，会导致栅格间留下大片空白。后来改用 这里示范的纯CSS瀑布式布局 实现文章和侧边栏的布局，具体的实现代码在 waterfall.less ，总算达到了想要的布局了。 正文的样式 最最重要的是文章正文的样式。这里我想要达到的效果是，在大屏幕上用更大的字号，让读者 看起来更舒适，同时在小屏幕上用比较小的字号，最终保证基本上「一行」的文字数接近。这个修改 主要针对 .jumbotron ， 用了 不太科学的方式 代码太长就不贴全了。 一些细微的定制 把主题配色改成了现在这样的淡紫色 @brand-primary: darken(#6B5594, 6.5%); ，配合我的头像风格， 这个修改只需要一行。 接着删掉了 .btn 的 white-space: nowrap; 让按钮的文字可以换行， 这也只是一行修改。 2015年1月29日更新 另外我也不太喜欢 Bootstrap 3 默认在手机上的 折叠导航栏 ( collapsed navbar ) ， 折叠之后的操作不够直观方便而且依赖 javascript 所以有 bug …… 于是我把它关掉了， 具体方式是在 variables.less 把 @grid-float-breakpoint 和 @grid-float-breakpoint-max 都设为0就可以了。 对 bootstrap-material-design 的定制 这里定制的地方不多。原样式中一个不太科学的做法是所有 .btn 都强制加上了阴影 效果，这在已经有阴影的环境里用的话非常碍眼，像是 Win9x 风格的厚重睫毛膏。既然可以单独 给每个样式加阴影，于是就把 .btn 强制的阴影去掉了，只保留鼠标悬停之后强调的阴影。 其它定制的细节么就是统一配色风格，修补漏洞错误，微调响应式效果而已，这里不细说。 将以上两者整合在 pelican-bootstrap3 里 Pelican 实现显示源代码按钮 显示源代码按钮借用了 Pelican 配置中自带的 OUTPUT_SOURCES 选项将源文件复制到输出文件夹： OUTPUT_SOURCES = True OUTPUT_SOURCES_EXTENSION = '.rst' 然后在 Makefile 里用 pygmentize 把所有源代码文件着色： find -iname \"*.rst\" | parallel -I@ pygmentize -f html -o @.html @ 最后在按钮按下的时候用 jQuery 载入源代码： < a onclick = \"$.get('{{SITEURL}}/{{article.slug}}.rst.html', function(data){$('#source-code').html(data)});$('#article-content').toggle();$('#source-content').toggle();\" > 虽然难看的 hack 比较多，但是能用！ 虽说 pelican-bootstrap3 是我 fork 出来的，不过由于我修改的地方实在太多，代码看来基本上 接近重写了一份。好在之前有给 pelican 写 bootstrap 2 主题的经验，这次修改算得上驾轻就熟。 可以对比一下 上游作者的博客 和这里的样子体会一下感觉。 具体修改过的地方包括： 套用 bootstrap-material-design 的各个元素样式。 在文章列表模板应用上面提到的 Bootstrap 3 的栅格布局和瀑布式布局。 翻译到多个语言，这里在后面的 i18n-subsite 插件里详述。 套用后面会介绍到的各种插件。 统一侧边栏的样式到一个模板里。 添加 Atom 订阅按钮和 breadcrumb 条。 对正文中出现的插图，添加点击放大的功能，通过 Bootstrap 的 modal 实现。 上面提到的用 这个bootstrap插件 让导航栏自动隐藏。 显示源代码按钮 ，也就是每篇文章信息栏中的 按钮。 插件: 发挥 Pelican 和 reStructuredText 的优势 先列举一下我目前用到的所有插件： PLUGINS = [ \"i18n_subsites\" , \"plantuml\" , \"youku\" , \"youtube\" , 'tipue_search' , 'neighbors' , 'series' , 'bootstrapify' , 'twitter_bootstrap_rst_directives' , \"render_math\" , 'extract_toc' , 'summary' ] 嗯其实不算多。接下来逐一介绍一下这些各具特色的插件。 i18n-subsites 这个插件的目的是创建 国际化 ( internationalization ) 子站 ( subsite ) 。 之前介绍 Pelican 配置的时候就提到过， 原本的 Pelican 就支持一篇文章用多种语言书写，有 lang 属性注明这篇文章使用的 语言，以及 slug 属性注明多语言的翻译之间的关联，换句话说同一篇文章的多个语言 版本应该有相同的 slug 和不同的 lang 。然后原本 Pelican 里对多语言的 实现方式是，首先有一个 主语言 是模板和大部分文章采用的语言，文章列表中会优先列出 用 主语言 撰写的文章，然后从 主语言 的文章链接到别的翻译版本。 很多博客系统和CMS对多语言的支持都是这样的，这种处理方式的缺点也显而易见：作为 主语言 的语言必须足够通用，才能让进来的人找到合适的翻译版本，所以通常 主语言 都是英语。 而这个插件做的事情描述起来很简单：将文章按语言属性分到多个子站，每个子站独立放在各自的文件夹。 比如主站是 https://farseerfc.github.io/ 的话，那么英语的子站就可以是 https://farseerfc.github.io/en/ 。 然后分别对多个子站生成静态页面。具体的实现方式是对 pelican 的页面生成步骤做了拆分： pelican 按正常情况读入文章，生成元信息。 i18n-subsites 针对每个语言，覆盖掉 pelican 的一些选项设置比如路径和 URL ， 分别调用 pelican 的页面生成器按模板生成文章。 对共用的静态内容比如模板的 js 和 css 文件，只在主站中生成，子站中的相应链接全部链回主站。 虽然描述起来简单，但是这个插件可以说最大化利用了 Pelican 的插件系统，实现细节相对比较 复杂，大概是我用的这些插件里面最复杂的了。不夸张的说 Pelican 3.4 支持的新插件 API 和 站内链接功能基本上就是为了配合这个插件的。至于具体它会覆盖哪些 Pelican 的配置，请参阅它的 README.md文件 。 按内容拆分多语言子站的做法只解决了问题的一半，还留下另一半的问题，也即对模板的翻译。 对这个问题， i18n-subsites 提供了两套方案供选择： 用覆盖配置路径的方式让每个子站套用不同的模板。这配置起来简单，但是对模板维护起来有点困难。 用 jinja2 的 i18n 插件，配合 Python 的 gettext 库实现内容翻译。这个方案 配置起来比较复杂 ，但是配置好之后用起来就很方便了。 只是要记得每次修改了模板都要更新翻译，处理 *.po 和 *.mo 文件等等琐碎事宜。 这里我用 jinja2 的 i18n 插件的方式实现了模板的翻译， 各个语言的翻译在这里 ， 然后用 这里的 SCons 脚本 根据内容是否变化自动更新 po 和 mo 文件。 配置好这一套方案之后，还要注意在模板和文章中处理好链接。用 Pelican 3.4 之后推荐的 新的文章间链接的写法以及将 SITEURL 设置为实际 URL 并且关闭 RELATIVE_URLS 之后，应该就不会出没什么问题了（可能还要考虑使用的模板和插件的兼容性，大部分都是写死了 URL 的问题）。 plantuml 嵌入 PlantUML 的示例 PlantUML 是一个Java实现的， 用接近文字描述的语言绘制 UML 图或者 GUI 界面图的工具，非常适合嵌入在 Markdown、 reStructuredText、 AsciiDoc 等这种轻量级标记语言里。 然后么这个 plantuml 插件就是定义了一个新的 reStructuredText 指示符 ( directive ) .. uml:: ，把嵌入的内容提取出来调用 plantuml 命令处理 成图像然后再插入到文章中。 比如示例里的这个 UML 图就是用这样一段简单的文字描述生成的： .. uml :: Object <|-- ArrayList Object : equals() ArrayList : Object[] elementData ArrayList : size() 实际用起来这个插件实现上稍微有点小问题：首先它只支持 python2，所以我把它改写成了 python 2 和 3 都通用的语法；其次它原本输出的文件夹似乎会被 pelican 删掉，所以把它改了个位置； 然后它输出的 URL 也和 i18n-subsites 插件间有不兼容的问题，也顺带修掉了。 修改之后的代码在这里 。 2015年1月30日更新 嵌入 Ditaa 的示例 plantuml 是绘制UML的，除此之外还有一个类似的工具是绘制一般的 流程图 ( diagram ) 的，叫 ditaa ，和 plantuml 非常像，也比较像 reStructuredText 的表格。 于是我也照猫画虎实现了一个 ditaa 的 指示符 ( directive ) ，用起来类似这样： .. ditaa :: +-------------+ | ditaa |-------+ | Diagram | | +-------------+ | PNG out &#94; | | ditaa in | | v +--------+ +--------+----+ /----------------\\ | | --+ Pelican +--> | | | Text | +-------------+ | Beautiful Blog | |Document| | !magic! | | | | {d}| | | | | +---+----+ +-------------+ \\----------------/ : &#94; | Lots of work | +-----------------------------------+ render-math 嵌入公式的示例 示范行内公式 \\(A_\\text{c} = (\\pi/4) d&#94;2\\) . 整行公式 \\begin{equation*} \\alpha{}_t(i) = P(O_1, O_2, \\ldots O_t, q_t = S_i \\lambda{}) \\end{equation*} 这个插件提供在 reStructuredText 中用 LaTeX 语法插入数学公式的能力，定义了 :math: 行内角色 ( role ) 和 .. math:: 指示符 ( directive ) 。 实际工作的渲染库当然是大名鼎鼎的 MathJax ，这个插件 会用 MathJax 的 CDN 载入，所以也没有额外的依赖文件。（只是不知道是否会被国内墙掉， 如果公式显示不正常请 务必 告诉我。） youtube 和 youku 顾名思义，这两个插件分别实现嵌入 youtube 和 youku 视频。其中 youtube 是原本就有的插件， youku 是我照猫画虎抄的。 之前写了一篇 KDE5 Plasma 之跳动卖萌的活动按钮 用到了这两个插件。 tipue_search Tipue search 是一个非常有意思也很强大的搜索工具， 通过 jQuery 实现静态博客的站内搜索功能。实现方式是，它需要你写一个 json 文件，包含 整个网站的 全部 文章的标题和文字内容，然后在搜索的时候读入这个 json 做搜索（是不是有点耍赖）。 虽然听起来会有性能问题，但是应用在小型的静态博客上效果意外很不错，比如本站的所有文章内容 放在一起的 json 也只有 300KiB 左右。 这个插件就是自动在 pelican 输出完全部静态网页之后，调用 beautifulsoup4 从所有网页中抽取出 纯文本，产生这个 json 给 Tipue 用。 neighbors 和 series 这两个插件比较类似也都比较简单， neighbors 提供一篇文章的前后文章信息， 在主题模板里可以用来制作 上一篇 和 下一篇 按钮。 series 提供将多篇文章归类为一个 系列 的支持，当然也需要在 主题模板中定义显示「文章系列」的列表。这两个插件的效果都能在本文末尾，评论区上方的部分看到。 bootstrapify 和 twitter_bootstrap_rst_directives 这两个插件让文章的 正文 套用上 Bootstrap 的样式。 bootstrapify 这个插件实现得比较简单，用 beautifulsoup4 在静态网页的结果里面过滤元素， 对 table , img , embed , iframe , video , object 这几个标签套用上 响应式嵌入对象的类 让他们更美观。 twitter_bootstrap_rst_directives 这个插件则是增加了几个 reStructuredText 的 行内角色 ( role ) 和 指示符 ( directive ) 。 它实现的 行内角色 ( role ) 包括： 用 :kbd: 实现如 Ctrl+C 这样的键盘快捷键， 用 :code: 嵌入代码片段，用 :glyph: 嵌入字符图标。 它实现的 指示符 ( directive ) 包括： labels 行内标签 ， alerts 提示段落 ， panels 嵌入面板 ， 以及还有一个 media 混排图标 。 对其中的 panel 我改写了它在文章正文中的样式，在 lg 或者 xl 的屏幕宽度下，分别用 \\(\\frac{1}{2}\\) 和 \\(\\frac{1}{3}\\) 大小的嵌入面板， 简单实现和正文文字的图文混排。 除此以外我还在 twitter_bootstrap_rst_directives 这个插件里套用它的框架实现了两个额外 的 行内角色 ( role ) ， 分别是 :ruby: ：通过 html5 的 <ruby> 标签实现文字上方的注音（firefox下 不支持 ，会使用文字后的括号显示）， 以及 :html: ：在 行内插入 裸 ( raw ) html 标签（这属于 Markdown 的基本功能，在 reStructuredText 这边由于要考虑多种输出格式于是就比较麻烦了）。这两个 行内角色 ( role ) 的 实现代码在这里 。 2015年2月3日更新 今天又在 twitter_bootstrap_rst_directives 里增加了两个 行内角色 ( role ) 。 一个是 :twi: 用来写 twitter 用户的链接，比如 @farseerfc ，另一个是 :irc: 用来指向 freenode 的 channel ，比如 #yssyd3 。 2015年2月14日更新 今天增加了 .. friend:: 用来写好友链接，以及 fref 用来引用好友， 比如 LQYMGT 这样。 extract_toc 和 summary 最后是这两个有点「名不副实」的插件。 reStructuredText 原本就有自动生成 目录 ( toc ) 的功能，用起来也非常简单，只需要在想要插入目录的地方写一行 .. contents:: ，剩下的都由 docutils 自动生成了。 只是当然这样生成的目录肯定会插入在文章的正文里，而 extract_toc 这个插件的作用就是简单地 把这个目录抽取出来，让模板能在别的地方放置这个目录。比如我这里就把目录放在了一个 panel 里。 然后 Pelican 也原本就有从文章中抽取 总结 ( summary ) 显示在文章列表的功能。 Pelican 原始的实现似乎是按照文字数抽取前半段，不总是适合作为总结。 于是这个 summary 插件的作用其实是允许在正文中以特殊的注释的方式标注哪些部分应该被抽出来作为总结。 summary 这个插件原本的实现只允许抽取一段文字，我又对它的实现做了少许扩充，允许标注多段 文字合并起来作为总结。 2015年1月29日更新 今天在 extract_toc 插件的帮助下，在侧边栏里放了一个 Bootstrap affix 的目录， 它保持在页面的右侧位置不变，方便导航到文章的各个地方。具体实现方法除了 Bootstrap 3 的 Affix 文档 ，还参考了 这篇更详细的说明 。 结语 这个博客的配置都可以在 github 上找到 ，包括用来 自动生成整个博客的 Makefile ，由于比较长，这里就不再贴了。 折腾这个主题前后历时两个月，期间学会了不少东西，也算是不错的收获吧。 现在既然基础打好了，接下来就要开始多写博客了。（希望拖延症不会再犯……） 最近发现除了我的博客之外还有一个网站 Kansas Linux Fest fork 了我的主题，不过他们用了我修改的早期版本，还是原本的 Bootstrap 3 和 bootstrap-material-design 样式。自己草草修改的东西被别人用到果然还是有点小激动呢， 以及接下来不能马马虎虎地写 commit 消息了。 [1] 赛65:17「看哪！我造新天新地」启21:5「我将一切都更新了。」 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdnjscn.b0.upaiyun.com/libs/mathjax/2.4.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","title":"重新设计了 Pelican 的主题与插件"},{"url":"//farseerfc.me/zhs/summarize-material-design-css-framework.html","text":"现在这里的界面风格要从 Google 在 I/O 2014 大会 上公布Android L 也即 后来的 Lollipop 说起。 他们在谈论界面设计的时候公布了他们的 设计准则： Material Design ( 中文非官方翻译 )。 当然这只是一些准则，总结并描述了之前在 Web 设计和移动端 App 界面设计方面的一些规范， 并且用材料的类比来形象化的比喻这个准则。关于 Material Design 的更多中文资料可 参考这里 。 看到 Material Design 之后就觉得这个设计风格非常符合直觉，于是想在这边也用上 Material Design。 但是我在 Web 前端科技树上没点多少技能点，所以想找找别人实现好的模板 或者框架直接套用上。在网络上搜索数日找到了这几个： Polymer Paper Elements Polymer Polymer logo Google 官方提供的参考实现应该是 Polymer 中的 Paper Elements 。 由于是 官方参考实现 ，这个框架的确非常忠实地实现了 Material Design 的设计，但是同时 由于它基于 HTML5 Web Components 构建，相关技术我还 不太懂，浏览器兼容性和其余 HTML 技术的兼容性也还不太完善的样子…… 并且对于我这个 Web 开发的半吊子来说，Polymer 只是提供了一组设计组建，没有完善的 响应式 (responsive) 布局支持，也没有 Navbar 这种常见的框架组建，真的要用起来的话还 需要手工实现不少东西。于是口水了半天之后只好放弃……以后可能真的会换用这个，只是目前需要学 的东西太多了。 Angular Material Design AngularJS AngularJS 是 Google 对 Web Components 技术的另一个 尝试。而这额 Angular Material Design 项目 就是基于 AngularJS 构建的Material Design 库啦，同样是 Google 出品所以应该算得上半个 官方实现吧。 相比于 Polymer, AngularJS 算是实用了很多，提供了基于 CSS Flexbox 的布局。有人对这两者的评价是， 如果说 Polymer 代表了 未来趋势 ，那么 AngularJS 就是 眼下可用 的 Web Components 实现了。 只不过同样是因为它是 Components 的框架，对 WebApp 的支持很丰富，大量采用 Ajax 等 JavaScript 技术， 对于我这个静态博客来说仍然稍显高级了……非常担心还不支持 HTML5 的浏览器 比如 w3m 甚至 cURL 对它的支持程度。 于是最终也没有使用它。 Materialize Materialize Materialize 这是一批(自称?)熟悉 Android 上 Material Design 的设计师们新近出炉的框架，试图提供一个接近 Bootstrap 的方案。 最早是在 Reddit 上看到对它的讨论的，立刻觉得这个想法不错。 体验一下官网的设计就可以看出，他们的动画效果非常接近 Polymer 的感觉，响应式设计的布局 也还不错。 只是同样体验一下他们现在的官网就可以看出，他们目前的 bug 还比较多 ，甚至一些 bug 在他们自己的主页上也有显现。 虽然不想给这个新出炉的项目泼凉水，不过看来要达到他们声称的接近 Bootstrap 的易用度还任重而道远…… bootstrap-material-design + bootstrap3 这是我最终选择的方案。这个方案将三个项目组合在了一起，分别是 bootstrap-material-design , pelican-bootstrap3 和 Bootstrap 3 。 Bootstrap 3 想必不用再介绍了，很多网站都在使用这套框架，定制性很高。 bootstrap-material-design 是在 Bootstrap 3 的基础上套用 Material Design 风格 制作的一套 CSS 库，当然也不是很完善并且在不断改进中，一些细节其实并不是很符合我的要求。 最后 pelican-bootstrap3 是用 Bootstrap 3 做的 pelican 模板。 这三个项目或多或少都有点不合我的口味，于是嘛就把 pelican-bootstrap3 fork了一套放在 这里 ，其中还包括我自己改 过的 Bootstrap3 样式 和 Material 样式 ，需要的可以自取。 至于细节上我定制了哪些地方，敬请听下回分解……","tags":"tech","title":"总结一下 Material Design 的 CSS 框架"},{"url":"//farseerfc.me/zhs/from-unbuffered-stdin-to-history-of-linux-tty.html","text":"这篇也是源自于水源C板上板友的一个问题，涉及Linux上的控制台的实现方式和历史原因。因为内容比较长，所以在这里再排版一下发出来。 原帖在这里 。 可以设置不带缓冲的标准输入流吗？ WaterElement(UnChanged) 于 2014年12月09日23:29:51 星期二 问到： 请问对于标准输入流可以设置不带缓冲吗？比如以下程序 #include <stdio.h> #include <unistd.h> int main ( int argc , char * argv []) { FILE * fp = fdopen ( STDIN_FILENO , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 似乎还是需要在命令行输入后按回车才会让 fgets 返回，不带缓冲究竟体现在哪里？ 这和缓存无关，是控制台的实现方式的问题。 再讲细节一点，这里有很多个程序和设备。以下按 linux 的情况讲： 终端模拟器窗口（比如xterm）收到键盘事件 终端模拟器(xterm)把键盘事件发给虚拟终端 pty1 pty1 检查目前的输入状态，把键盘事件转换成 stdin 的输入，发给你的程序 你的程序的 c 库从 stdin 读入一个输入，处理 标准库说的输入缓存是在 4 的这一步进行的。而行输入是在 3 的这一步被缓存起来的。 终端pty有多种状态，一般控制台程序所在的状态叫「回显行缓存」状态，这个状态的意思是: 所有普通字符的按键，会回显到屏幕上，同时记录在行缓存区里。 处理退格( BackSpace )，删除( Delete )按键为删掉字符，左右按键移动光标。 收到回车的时候把整个一行的内容发给stdin。 参考： http://en.wikipedia.org/wiki/Cooked_mode 同时在Linux/Unix下可以发特殊控制符号给pty让它进入「raw」状态，这种状态下按键 不会被回显，显示什么内容都靠你程序自己控制。 如果你想得到每一个按键事件需要用raw状态，这需要自己控制回显自己处理缓冲， 简单点的方法是用 readline 这样的库（基本就是「回显行缓存」的高级扩展，支持了 Home/End，支持历史）或者 ncurses 这样的库（在raw状态下实现了一个简单的窗口/ 事件处理框架）。 参考： http://en.wikipedia.org/wiki/POSIX_terminal_interface#History 除此之外， Ctrl-C 转换到 SIGINT ， Ctrl-D 转换到 EOF 这种也是在 3 这一步做的。 以及，有些终端模拟器提供的 Ctrl-Shift-C 表示复制这种是在 2 这一步做的。 以上是 Linux/unix 的方式。 Windows的情况大体类似，只是细节上有很多地方不一样： 窗口事件的接收者是创建 cmd 窗口的 Win32 子系统。 Win32子系统接收到事件之后，传递给位于 命令行子系统 的 cmd 程序 cmd 程序再传递给你的程序。 Windows上同样有类似行缓存模式和raw模式的区别，只不过实现细节不太一样。 strace查看了下 WaterElement(UnChanged) 于 2014年12月10日21:53:54 星期三 回复： 感谢FC的详尽解答。 用strace查看了下，设置标准输入没有缓存的话读每个字符都会调用一次 read 系统调用， 比如输入abc： read(0, abc \"a\", 1) = 1 read(0, \"b\", 1) = 1 read(0, \"c\", 1) = 1 read(0, \"\\n\", 1) = 1 如果有缓存的话就只调用一次了 read 系统调用了： read(0, abc \"abc\\n\", 1024) = 4 如果想感受一下 raw mode 没错，这个是你的进程内C库做的缓存，tty属于字符设备所以是一个一个字符塞给你的 程序的。 如果想感受一下 raw mode 可以试试下面这段程序（没有检测错误返回值） #include <stdio.h> #include <unistd.h> #include <termios.h> static int ttyfd = STDIN_FILENO ; static struct termios orig_termios ; /* reset tty - useful also for restoring the terminal when this process wishes to temporarily relinquish the tty */ int tty_reset ( void ){ /* flush and reset */ if ( tcsetattr ( ttyfd , TCSAFLUSH , & orig_termios ) < 0 ) return - 1 ; return 0 ; } /* put terminal in raw mode - see termio(7I) for modes */ void tty_raw ( void ) { struct termios raw ; raw = orig_termios ; /* copy original and then modify below */ /* input modes - clear indicated ones giving: no break, no CR to NL, no parity check, no strip char, no start/stop output (sic) control */ raw . c_iflag &= ~ ( BRKINT | ICRNL | INPCK | ISTRIP | IXON ); /* output modes - clear giving: no post processing such as NL to CR+NL */ raw . c_oflag &= ~ ( OPOST ); /* control modes - set 8 bit chars */ raw . c_cflag |= ( CS8 ); /* local modes - clear giving: echoing off, canonical off (no erase with backspace, &#94;U,...), no extended functions, no signal chars (&#94;Z,&#94;C) */ raw . c_lflag &= ~ ( ECHO | ICANON | IEXTEN | ISIG ); /* control chars - set return condition: min number of bytes and timer */ raw . c_cc [ VMIN ] = 5 ; raw . c_cc [ VTIME ] = 8 ; /* after 5 bytes or .8 seconds after first byte seen */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 0 ; /* immediate - anything */ raw . c_cc [ VMIN ] = 2 ; raw . c_cc [ VTIME ] = 0 ; /* after two bytes, no timer */ raw . c_cc [ VMIN ] = 0 ; raw . c_cc [ VTIME ] = 8 ; /* after a byte or .8 seconds */ /* put terminal in raw mode after flushing */ tcsetattr ( ttyfd , TCSAFLUSH , & raw ); } int main ( int argc , char * argv []) { atexit ( tty_reset ); tty_raw (); FILE * fp = fdopen ( ttyfd , \"r\" ); setvbuf ( fp , NULL , _IONBF , 0 ); char buffer [ 20 ]; buffer [ 0 ] = 0 ; fgets ( buffer , 20 , fp ); printf ( \"buffer is:%s\" , buffer ); return 0 ; } 终端上的字符编程 vander(大青蛙) 于 2014年12月12日08:52:20 星期五 问到： 学习了！ 进一步想请教一下fc大神。如果我在Linux上做终端上的字符编程，是否除了用ncurses库 之外，也可以不用该库而直接与终端打交道，就是你所说的直接在raw模式？ 另外，终端类型vt100和linux的差别在哪里？为什么Kevin Boone的KBox配置手册里面说必 须把终端类型设成linux，而且要加上terminfo文件，才能让终端上的vim正常工作？term info文件又是干什么的？ Linux控制台的历史 嗯理论上可以不用 ncurses 库直接在 raw 模式操纵终端。 这里稍微聊一下terminfo/termcap的历史，详细的历史和吐槽参考 Unix hater's Handbook 第6章 Terminal Insanity。 首先一个真正意义上的终端就是一个输入设备（通常是键盘）加上一个输出设备（打印 机或者显示器）。很显然不同的终端的能力不同，比如如果输出设备是打印机的话，显 示出来的字符就不能删掉了（但是能覆盖），而且输出了一行之后就不能回到那一行了 。再比如显示器终端有的支持粗体和下划线，有的支持颜色，而有的什么都不支持。 早期Unix工作在电传打字机（TeleTYpe）终端上，后来Unix被port到越来越多的机器上 ，然后越来越多类型的终端会被连到Unix上，很可能同一台Unix主机连了多个不同类型 的终端。由于是不同厂商提供的不同的终端，能力各有不同，自然控制他们工作的方式 也是不一样的。所有终端都支持回显行编辑模式，所以一般的面向行的程序还比较好写 ，但是那时候要撰写支持所有终端的「全屏」程序就非常痛苦，这种情况就像现在浏览 器没有统一标准下写HTML要测试各种浏览器兼容性一样。 通常的做法是 使用最小功能子集 假设终端是某个特殊设备，不管别的设备。 水源的代码源头 Firebird2000 就是那样的一个程序，只支持固定大小的vt102终端。 这时有一个划时代意义的程序出现了，就是 vi，试图要做到「全屏可视化编辑」。这在 现在看起来很简单，但是在当时基本是天方夜谭。 vi 的做法是提出一层抽象，记录它所需要的所有终端操作，然后有一个终端类型数据库 ，把那些操作映射到终端类型的具体指令上。当然并不是所有操作在所有终端类型上都 支持，所以会有一堆 fallback，比如要「强调」某段文字，在彩色终端上可能 fallback 到红色，在黑白终端上可能 fallback 到粗体。 vi 一出现大家都觉得好顶赞，然后想要写更多类似 vi 这样的全屏程序。然后 vi 的作 者就把终端抽象的这部分数据库放出来形成一个单独的项目，叫 termcap （Terminal Capibility），对应的描述终端的数据库就是 termcap 格式。然后 termcap 只是一个 数据库（所以无状态）还不够方便易用，所以后来又有人用 termcap 实现了 curses 。 再后来大家用 curses/termcap 的时候渐渐发现这个数据库有一点不足：它是为 vi 设 计的，所以只实现了 vi 需要的那部分终端能力。然后对它改进的努力就形成了新的 terminfo 数据库和 pcurses 和后来的 ncurses 。 然后 VIM 出现了自然也用 terminfo 实现这部分终端操作。 然后么就是 X 出现了， xterm 出现了，大家都用显示器了，然后 xterm 为了兼容各种 老程序加入了各种老终端的模拟模式。不过因为最普及的终端是 vt100 所以 xterm 默 认是工作在兼容 vt100 的模式下。然后接下来各种新程序（偷懒不用*curses的那些） 都以 xterm/vt100 的方式写。 嗯到此为止是 Unix 世界的黑历史。 知道这段历史的话就可以明白为什么需要 TERM 变量配合 terminfo 数据库才能用一些 Unix 下的全屏程序了。类比一下的话这就是现代浏览器的 user-agent。 然后话题回到 Linux 。 大家知道 Linux 早期代码不是一个 OS， 而是 Linus 大神想 在他的崭新蹭亮的 386-PC 上远程登录他学校的 Unix 主机，接收邮件和逛水源（咳咳 ）。于是 Linux 最早的那部分代码并不是一个通用 OS 而只是一个 bootloader 加一个 终端模拟器。所以现在 Linux 内核里还留有他当年实现的终端模拟器的部分代码，而这 个终端模拟器的终端类型就是 linux 啦。然后他当时是为了逛水源嘛所以 linux 终端 基本上是 vt102 的一个接近完整子集。 说到这里脉络大概应该清晰了， xterm终端类型基本模拟 vt100，linux终端类型基本模 拟 vt102。这两个的区别其实很细微，都是同一个厂商的两代产品嘛。有差别的地方差 不多就是 Home / End / PageUp / PageDown / Delete 这些不在 ASCII 控制字符表里的按键的映射关系不同。 嗯这也就解释了为什么在linux环境的图形界面的终端里 telnet 上水源的话，上面这些 按键会错乱…… 如果设置终端类型是 linux/vt102 的话就不会乱了。在 linux 的 TTY 里 telnet 也不会乱的样子。 写到这里才发现貌似有点长…… 总之可以参考 Unix hater's Handbook 里的相关历史评论和吐槽，那一段非常有意思。","tags":"tech","title":"从非缓冲输入流到 Linux 控制台的历史"},{"url":"//farseerfc.me/zhs/jumping-kde5-plasma-activities-button.html","text":"今天尝试 KDE5 Plasma 的活动的时候无意间发现这个现象。 只要把活动按钮拖出桌面，它就会在桌面边缘来回跳动。 视频如下： Youtube Youku 当然你可以把它再拖回来，所以这个问题还无伤大雅，只是卖萌。 比比之前 Gnome3 那个跳动的界面真是好太多了： Youtube Youku 顺便，今天还看到一个卖萌的 KDE5 Plasma 静音图标的翻译： KDE5のミュート画面の中国语翻訳、「静音」のはずだが「镜音」になっている。Vocaloidファンのネタだか、単なる入力ミスだか分からない。 pic.twitter.com/ipyHjXMscR — Jiachen YANG (@farseerfc) 2014 12月 8日","tags":"tech","title":"KDE5 Plasma 之跳动卖萌的活动按钮"},{"url":"//farseerfc.me/zhs/marry-me.html","text":"渲染的样子 可以玩的是下面这个： * 用 WASD←→ 移动，需要 WebGL 支持","tags":"life","title":"嫁给我好么"},{"url":"//farseerfc.me/zhs/icse2012.html","text":"June 6 Keynote 1 没怎么听懂，只记得讲到了finance is not money但是没听懂这个和软件有什么关系。 Cost Estimation for Distributed Software Project 讲到他们试图改善现有的模型去更精确地评估软件开发的开销。 他们会给PM建议之前的项目的历史数据，然后对于新项目，他们建议历史上已有 的项目的数据，从而帮助PM得到更精确的评估。他们试图尽量减少项目评估对PM 的经验的需求，从而帮助即使经验很少的PM也能准确评估项目的开销。 他们的观点： Context-specfic solutions needed! 我们需要更上下文相关的解决方案！ Early user paticipation is key! 早期用户的参与是关键 Characterizing Logging Practices in Open-Source Software Common mistakes in logging messages 在日志记录中容易犯的错误 他们学习了历史上的log记录，然后试图找到重复修改的输出log的语句，确定log 中存在的问题。他们首先确定修改是事后修改。 通常的修改的比例（9027个修改） 45% 静态文本 27% 打印出的变量 26% 调试等级verbosity 2% 日志输出的位置 他们发现有调试等级的变化，是因为安全漏洞之类的原因，或者在开销和数据 之间的权衡。 大多数对log的变量的修改都是为了增加一个参数。他们之前的LogEnhancer是为了 解决这个问题而提出的，通过静态检查，提醒程序员是否忘记了某个参数 对text的修改是因为要改掉过时的代码信息，避免误导用户。 他们的实验是采用了基于code clone 的技术，找到所有log语句，然后找不一致 的clone，然后自动提出建议。 Combine Functional and Imperative Pgrm for Multicore Sw: Scala & Java 趋势：到处都是多核，但是并发程序呢？ 他们研究的对象是Scala和Java，因为可以编译后确认JVM字节码的语义。 Java: 共享内存 显示创建的线程 手动同步 Wait/Notify机制 Scala: 高阶函数 Actors, 消息传递 lists, filters, iterators while 共享状态, OO import java.* 能从java导入任何库 auto type inferance 自动类型推导 实验的参与者都经过4周的训练，实验项目是工业等级的开发项目 结果： scala 的项目平均比java多花38%的时间，主要都是花在Test和debug上的时间。 程序员的经验和总体时间相关，但是对test和debug没有显著影响。 scala的为了让编程更有效率的设计，导致debug更困难。比如类型推导，debug 的时候需要手动推导，来理解正在发生什么。 scala的程序比java小，中位数2.6%，平均15.2% 性能比较： 单核：scala的线性程序的性能比java好 4核： scala 7s @ 4 threads java 4si @ 8 threads median 83s scala 98s java 32core: best scala 34s @ 64 threads 结论 java有更好的scalability scala类型推导 45%说对携带码有帮助 85%说导致程序错误 调试 23%认为scala简单 77%认为java简单 multi-paradigram are better Sound Empirical Evidence in Software Testing Test data generation 测试数据自动生成 Large Empirical Studies - not always possible For open source software - big enough Identifing Linux Bug Fixing Patch current practice: manual Current research: keywords in commits link bug reports in bugzilla Try to solve classification problem issue pre-identified post-identified data from commit log feature extraction text pre-process stemmed non-stop words model learning research questions Active Refinement of Clone Anomaly Reports motivating code clones, clone groups clone used to detect bugs anomaly : inconsistent clone group many anomaly clone are note bug, high false positive approach reorder by sorted bug reports June7 Keynotes 2: Sustainability with Software - An Industrial Perspective Sustainability Classic View: Idenpendent view with overlap Social Environment Economic Nested viw Environment Social Economic Triple bottom line economic -global business, networks , global econ env natural res, climate change, population grow social awareness, connectivity, accountability Green IT reduce IT energy more than 50% cooling - doing nothing mini e-waste: not properly recycled 80% in EU 75% in US foster dematerialization In-Memory Technology: Expected Sustainable Benefits What can we do? consider all software lifecycle phases in your design avoid energy expensive behavior in your codes design lean architectures Green by IT 2% green IT 98% green IT On How Often code is cloned across repositories Line based hashing code clone detection never do anything harder than sorting hashing a window of 5 lines of normalized (tokenized) code, dropping 3/4 of the hashing 把ccfinder一个月的工作缩短到了3, 4天。没有比较presion和recall。 14% type1 16% type2 17% type3 (not really type2) Graph-based analysis and prediction for sw evolution graph are everywhere internet topology social net chemistry biology in sw - func call graph - module dependency graph developer interaction graph - commit logs - bug reports experiment 11 oss, 27~171 release, > 9 years predictors NodeRank similar to pagerank of google measure relative importance of each node func call graph with noderank compare rank with severity scale on bugzilla correlation between noderank and BugSeverity func level 0.48 ~ 0.86 varies among projects. model level > func level ModularityRatio cohesion/coupling ratio: IntraDep(M)/InterDep(M) forecast mantencance effort use for identify modules that need redesign or refactoring EditDistance bug-based developer collaboration graphs ED(G1,G2)=|V1|+|V2|-2|V1交V2|+|E1|+|E2|-2|E1交E2| use for release planning resource allocation graph metrics graph diameter average node degree indicates reuse clustering coefficient assortativity num of cycles Conclusion \"Actionable intelligence\" from graph evolution studie 11 large long-live projs predictors identify pivotal moments in evolution What make long term contributors: willingness and opportunity in OSS OSS don't work without contributors form community mozilla (2000-2008) 10&#94;2.2 LTC <- 2 order -> 10&#94;4.2 new contributors <- 3.5 order -> 10&#94;7.7 users gnome (1999-2007) 10&#94;2.5 LTC <- 1.5 order -> 10&#94;4.0 new contributors <- 3.5 order -> 10&#94;6.5 users approach read issues of 20 LTC and 20 non-LTC suvery 56 (36 non-LTC and 20 LTC) extract practices published on project web sites summeray Ability/Willingness distinguishes LTCs Environment macro-climate popularity micro-climate attention bumber of peers performance of peers regression model newcomers to LTC conversion drops actions in first month predicts LTCs 24% recall 37% precision develop of auxiliary functions: should you be agile? a empirial assessment of pair programming and test-first programming can agile help auxiliary functions? experiment pair vs solo test-first vs test-last students vs professors research questions r1: can pair help obtain more correct impl r2: can test-first r3: dst test1 encourage the impl or more test cases? r4: does test1 course more coverage result test-first higher coverage non change with correctness pair improve on correctness longer total programming time Static Detection of Resource Contention Problems in Server-side script Addressed the race condition of accessing database or filesystem of PHP Amplifying Tests to Validate Exception Handling Code 异常处理的代码不但难写，而且难以验证。各种组合情况难以估计，尤其是手机 系统上。 A tactic-centric approach automating traceability of quality concerns tactic traceability information models","tags":"life","title":"ICSE 2012"},{"url":"//farseerfc.me/zhs/msr2012.html","text":"Mining Software Repository 2012 @ ICSE 参加了今年的MSR，会场在University of Zurich。一大早来到大学，注册有点 小插曲，显然瑞士人搞不清楚中国人的名字，3个杨（Yang）姓的中国人的名牌 被搞错了。然后堀田学长的所属被写作了\"Japan, Japan\"，成为了全日本的代表。 MSR(MicroSoft Research) talk @ MSR(Mining Software Repositories) 首先是来自微软亚洲研究院（MicroSoft Research @ Asia, MSR Asia）的Keynots， 于是就变成了MSR在MSR的演讲。MSR的张冬梅（Dongmei Zhang）女士的演讲 分为关于Software Analysis和XIAO的两部分。XIAO是MSRA开发的Code Clone Detector，似乎我要给井上研做的就是这个。想更多了解Xiao的细节，不过张女士 演讲结束的时候的鼓掌导致了话筒的小故障。 Towards Improving BTS with Game Mechanisms 感觉这篇的内容基本上就是关于 http://www.joelonsoftware.com/items/2008/09/15.html 这里写到的东西，然后说同样的理论是否可以用于Issue Tracking之类的事情上。 个人感觉这个意义不大，stackoverflow之所以成功是因为它把开源社区本身就 具有的名誉体系具现化了，本着大家都喜欢被别人奉为大牛的心态，就如同 wikipedia一样。同样的理论如果用于公司内部的Issue Tracking系统上，会得到 完全不同的东西吧。就像MSDN的组织方式虽然和wikipedia是一样的，但是在MSDN 里找信息的感觉和在wikipedia完全不一样。个人不太看好这个方向。 GHTorrent 这篇的slide在这里可以看到： http://www.slideshare.net/gousiosg/ghtorrent-githubs-data-from-a-firehose-13184524 Data exporter for github. Github的主要数据，代码，已经可以通过git接口 获得了，wiki是git的形式保存的。所以这个项目的目的就是暴露别的数据，主要 是issue tracking，code comments，这种。代码访问github api，然后用分布式 实现以克服api的限制，然后提供torrents形式的history下载。github api获得 的json数据以bson的形式保存在MongoDB里，解析过的有了Schema之后的数据保存 在MySQL里并可以导出SQL。 个人的想法，觉得数据如果能够更统一，全部存在Git里或许更好，像Wiki一样。 同样是要暴露全部历史记录的目的，用Torrent自己实现的历史远不如用Git的 接口实现的历史记录方便吧，git blame之类的也更方便追踪code comment之类的 作者信息。当然对git的raw date直接读写，需要对git的内部原理有足够的理解， 或许只有github的人有这种能力了。 Topic Mining 用得两个参数， DE 和 AIC，完全不能理解，过后研究。实验针对了Firefox, Mylyn, Eclipse三个软件。试图从Repo中分析源代码的identifier和comments， 找到topic和bug之间的关系，比如怎样的topic更容易导致bug。得出的结论似乎 也很暧昧，只是说核心功能被报告的bug更多，但是不知道原因。这只能表示核心 功能受到更多关注和更多测试吧，并不能说明核心功能就容易产生bug。 不过这个的Slide做得很漂亮，很容易理解。 SeCold A linked data platform for mining software repositories 没听懂这个项目的目的。 The evolution of software 第二天的Keynotes，关于将Social Media和Software Development相结合的想法。 或许就是Github赖以成功的基础。讲到代码中的comment, Tags, uBlog, blog之类 的social的特性和IDE的融合的趋势。 Do Faster Releases Imporve Software Quality? 使用Firefox作为例子。 结论是快速发布导致bug更多，更容易crash，但是bug更快得到修复，并且用户 更快转向新的发布。 Security vs Performance Bugs in Firefox Performance bugs are regression, blocks release. 一些感想 基于自然语义分析的commit分割 经常工具（比如git）的使用者并没有按照工具设计者的意图使用工具，这给MSR 带来很多困难。举个例子，git有非常完美的branch系统，通常期望git的使用者 能够在一次commit里commit一个功能，比如一个bug的修复，或者一个feature的 添加，但是事实上经常有很多逻辑上的commit被合并在一个里面了。 或许这不是使用者的错，而是工具仍然不够人性的表现。或许我们可以自动把 一次的commit按照语义分割成多个。 分割之后，可以更容易地把issue和commit关联，也更容易组织更多的研究。 关于这次发表中大家用的slides系统 题目为``Incorporating Version Histories in Information Retrieval Based Bug Localization''的人用的slide是beamer的。公式很多，overlay很多，列表 很多，图片很少，典型的beamer做出的slide。思维导图用得很不错。今天一天 有至少3个slide是用beamer做的。 题目为``Towards Improving Bug Tracking Systems with Game Mechanisms'' 的人用了prezi，图片很多，过度很多。但是比如没有页号没有页眉页脚，正式 会议的场合不太方便。 至少有六个以上用了Apple Keynotes，Keynotes做出来的东西真的和Powerpoint 做出来的很难区别，其中两个人用了初始的主题所以才看出来。 剩下的自然是PPT。MSRA的张女士做的虽然是PPT，倒是有很多beamer的感觉， 比如页眉页脚和overlay的用法。这些如果都是PPT做出来的，会多很多额外的 人力吧。 值得一提的是有一个题目为``Green Mining: A Methodology of Relating Software Change to Power Consumption''的人的slide全是``劣质''的手绘漫画， 效果意外地好，很低碳很环保很绿色很可爱。具体效果可以参考下面的动画，虽然 现场看到的不是一个版本： http://softwareprocess.es/a/greenmining-presentatation-at-queens-20120522.ogv 微软是个腹黑娘！ 嘛虽然这也不是什么新闻了。MSR2012的Mining Challenge的赞助商是微软，管理 组织者来自微软研究院，奖品是Xbox和Kinect。然后今年的题目是： Mining Android Bug 我看到了微软满满的怨气……","tags":"life","title":"MSR 2012 @ ICSE"},{"url":"//farseerfc.me/zhs/pyssy.html","text":"简介 Pyssy 是用于 上海交通大学 饮水思源站 的一系列 Python 脚本和工具。 Pyssy 被有意设计为既可以托管寄宿在 SAE [1] 上，也可以在单机上独立使用。 项目地址： http://pyssy.sinaapp.com/ Github上的源代码地址： https://github.com/yssy-d3/pyssy [1] Sina App Engine ，新浪云平台，类似 Google App Engine 的东西。 依赖关系 Pyssy 使用 Flask 作为网页服务器， 并且使用 Memcached 或者 Redis 作为抓取 水源Web 的缓存。 SAE Python 环境下请开启 Memcached 支持。 本地环境下请安装 Redis-py 并运行 redis-server 服务器程序。","tags":"tech","title":"Pyssy 项目"},{"url":"//farseerfc.me/zhs/mix-ruby.html","text":"今天在GitHub上闲逛的时候看到一个叫做 PyRuby 的项目。项目的Readme说得很好： PyRuby - Some Ruby for your Python! PyRuby is a simple way to leverage the power of Ruby to make your Python code more readable and beautiful. Usage All you have to do is import the ruby module: import ruby From now on you should be able to write Ruby code within a regular Python module. An example: 1.upto(10) { |n| puts n } 甚至 PyPI 上还有这个项目的包。 一开始我还以为这又是一个野心勃勃的基于PyPy的Ruby实现，或者某种trick在Python里面直接调用Ruby解释器。 然后我想看看这个的源代码 只有一个ruby.py文件，内容是： # -*- coding: utf-8 -*- print ( \"\"\" `.-:/+ossyhhddmmmmNNNNNNNmmmmmdddddhhhyyyyhhhyo:` .:+sydNNNmmdhhysso++/+++++++////::::::-.```......--/oymms. `:ohmdys+//::/::--::::////:-.```......`````.://:-` `/dNs. .+hNds:`-:-:///::------::///++///:--....--::///::-`.///. `oMm/ /hNmo.` `` `....``````````` ...------:::-:/+/-.:/:` /NMs oMd/` `::::--.---://+` //` `````-:::::+/-`::.` :NM+ yN` -+.` `/` o. ``::.-:. `` :NN: :Nm - ./ : `.-://///:-. `-` `` :NN- /NM/ .-:::-.` `/ `:sdmdhyMMMMMMNNmy/` :mNo` :hMd: /dmddddNNmdy+-. `smmy/-```hMMMMMMMhydm/ `-.`` `...:mMm+. -hNd/-/o/-..-::`.ydmmmmNMMMMMMNh:/+- dMN-`-+hmmmmdhhhhdddmMN-`-/o: .-::::/oydms- oNMo:+/::. ``...--:/+ohNMNhs- :hNmmdyo:..``yo-```.--. `-`-+shdddhs+-` `.//yms. .MMo:/`o:.:+sso+:-` sM+ ./-` /mNh+-....-/ymNNdo::--/shd+` -`:mm: /MM-o ./ ohhsooohNmy::sh. `yM/ `:oyyyyyyhys+:.` hy `/Nh` : -NN. -MM// -: `` y: odddhh+ -omNh- `--.` `` ```` .:ohMMs. +Ms / yMo hMoo .+. :Mh ```` `/hNd/.` ohdddy::...`..` `-/sdmdyo+NMNh+- :Mh / sMs .mmh:..:. :NMm `-/dMNM+ ./+++/:`.hM:`.````.` `-/shmNmh+-` /Mmooso.hM/ .: `mM/ .mNs://: .NMNMs- -:-.`/+-sms. ` `shyyyhy`sNd` `.:+sdmmmdMM-. .oNM+ :m/ `s``yMh -mMo . sMNdMNNh+-. .ydyoyy` ``+o::+shdddhs+:-.:MM.`.-+hNMMh- `.`-/::dNs` -NM- mMMMh:MMdNmhs+:-..```-ohs-`...-:/+syhddmMMs:-.` `/mMMdmmddNMm+` ..-/hNh- sMy NMMM`:Mh`-/mMmmmdddddddddhhhdNNdhyo+:--.yMs `..:+ymMMMMd+--yNh. `+hNh: -Mm NMMM/yMh -NM-`..--:NMo:--.`+My :MNoydmNMMNmhdMh` -dNs` `yMd: `MN mMMMMMMMyshMN+:---.-MN-.....+My...-:/oyhdMMMMNmdy+-` +Mh:sNm/ yMy` MN yMMMMMMMMMMMMMMMMMNMMMMNNNNNMMMNNNMMMMMNmhMM/-. `yMMNs. /My `MN :MMmMMMMMMMMMMMMMMMMMMMMMMMMMMMMNmmdy+:-``NM- ./hNNy- /Nd` -Mh dMydMmsNMNdNNMMmmmNMMMdddhys+yMo`` /Nm: `:yNNdo. .sNd. +Ms .mMsMN::NN:.:MN: `.+NM. +Mo +Mm+ymNdo- .omm+` yM: .hNMd+:sMN. oMm. oMo +Mh ```.:+shMNmy+-``.-:-..-//-`:yNmo` mM. :ohmNNMMdhyMMdo//+Mm//////sMNhyhhdmNNmhs/-``./+/:--+so/-:smNy/` .Mm `` .-:/+osyyhhddddddddddhhyysoo+/:-. `./+//--+oo/--+ymmy/. :Mh .: `+:` `.------------` ```-////:/++/:../ydNdo:` +Ms `/` :+o+:-``` ``..-::///++///:-.`-+ydNdo:` oMs :/:.`` `..---.``` ````````..-:/:::---.` `-ohmmh+:` /Mh .://///:::-----.-----.......` `-+hmmy+- sMy` ``````-+ydmy+- /mNs-` `./ohmNMNNNmy+- /yNmho/:.``````````.-:/+syhdNmdyso+/-.` `:+ydmNMNNNNNNNNNmdhys+/:.` ``.....` LOL U MAD? \"\"\" ) import sys sys . exit ( 1 ) 是的……的确……这种尝试把Python和Ruby放在一起的想法绝对是疯了……","tags":"tech","title":"PyRuby"},{"url":"//farseerfc.me/zhs/discuss-cpp-template-downcast.html","text":"这两天在饮水思源的C板，关于C++模板的类型转换的一个讨论，后面是我的解答。 讨论地址 http://bbs.sjtu.edu.cn/bbstcon,board,C,reid,1330078933,file,M.1330078933.A.html 原问题 今天在书上看到模板演绎的时候可以允许cast-down，于是我写了个东西： template < bool _Test , class _Type = void > struct enable_if { }; template < class _Type > struct enable_if < true , _Type > { typedef _Type type ; }; class A { }; class B : A { }; template < typename T > struct traits { static int const value = false ; }; template <> struct traits < A > { static int const value = true ; }; template < typename T > void f ( T , typename enable_if < traits < T >:: value >:: type * = 0 ) { } template <> void f < A > ( A , enable_if < traits < A >:: value >:: type * ) { } template < typename T > class BB {}; template < typename T > class DD : public BB < T > {}; template < typename T > void ff ( BB < T > ) {}; int main ( int argc , char * argv []) { A a ; B b ; DD < long > dd ; //f(b); ff ( dd ); } 奇怪的是重载决议的时候， f 的情况下它就不让我特化的 f<A> 进来。 但是在 ff 的情况下， ff<BB<long>> 却进来了。 在VC10和GCC3.4下测试 我的解答 我们来设身处地地作为编译器，看一遍到底发生了什么。 约定符号 # : A#B 是把 B 带入 A<T> 的参数 T 之后实例化得到的结果。 首先看ff的情况。 DD < long > dd ; 处理到这句的时候，编译器看到了 DD<long> 的实例化，于是去实例化 DD#long ，继而实例 化了 BB#long 。 ff ( dd ); 这句，首先计算重载函数集合。 第一步，需要从参数 DD#long -> BB<T> 推断 ff<T> 的 T 。根据函数模板参数推断规则： :code:`class_template_name<T>` 类型的参数，可以用于推断 :code:`T` 。 于是编译器推断 T 为 long 。这里就算不是 BB 而是完全无关的 CC 都可以推断成功，只要 CC 也 是一个 CC<T> 形式的模板。 第二步，模板特化匹配。因为只有一个模板，所以匹配了最泛化的 ff<T> 。 第三步，模板实例化。 推断了 long -> T 之后，编译器实例化 ff#long 。 重载函数集合： {ff#long} 然后重载抉择找到唯一的可匹配的实例 ff#long ，检查实际参数 DD#long 可以隐式转换到 形式参数 BB#long ，从而生成了这次函数调用。 再来看f的情况。 f ( b ); 计算候选重载函数集合。 第一步，对所有 f 模板推断实参。根据函数模板参数推断规则： 带有 :code:`T` 类型的参数，可以用于推断 :code:`T` 。 于是 B -> T 被推断出来了。 第二步，模板特化匹配。 这里 B 不是 A ，所以不能用 f<A> 特化，只能用 f<T> 模板。 第三步，模板实例化。 B 带入 f<T> 实例化成 f#B 的过程中，实例化 traits#B 。 由于没有针对 B 的特化，所以用 traits<T> 模板， traits#B::value=false ，进而 enable_if#false 没有 type ，出错。 唯一的模板匹配出错，重载函数集合为空，SFINAE原则不能找到合适的匹配，于是报错。","tags":"tech","title":"关于C++模板的类型转换的讨论"},{"url":"//farseerfc.me/zhs/try-pelican.html","text":"似乎一夜之间所有的 极客们 都 有了 自己 的 Github主页 和 Octopress 博客。就像所有人在他们的博客中指出的，静态博客的确比传统的WordPress方式具有更多优势。 自从看到这些 我就一直在想着自己搭一个 Octopress 。 但是似乎 Octopress 不适合我 一上手就被 Octopress的搭建步骤 烦到了。 RVM 是什么？ rbenv 又是什么？ 看来 Ruby 社区的快节奏发展已经超过了我的想象，他们似乎需要一套发行版管理器来调和不同版本之间的 Ruby 的兼容性问题。 虽然同样的兼容性问题在 Python 社区也有 [1] ，不过总觉得 Python 至少还没到需要一个发行版管理器的程度 [2] 。 真正的问题是我手上还没有一个可以让我随便玩的 Linux 环境（真的想要……）。 而无论是 RVM 还是 rbenv 似乎都只支持 Unix/Linux/MacOSX 。 身为极客就注定不能用 Windows 么？（或许是的……）。 剩下的问题就是 Ruby 和 Python 两大阵营的对立问题了。我不熟悉 Markdown ， 相对来说比较喜欢 ReST 。 似乎无论哪边都要 依赖 Pygments 作为代码着色器，那么其实 Rubyist 也至少需要安装 Python 。 我倾向于不依赖任何 Ruby 组件，最好没有 C 扩展 的纯 Python 实现。 于是我开始在 Github 上找 Python 的静态博客引擎。 Flask 的作者 mitsuhiko 写的 rstblog 看起来不错，不过似乎没有多少人在用。 Hyde 似乎很完善，不过默认的标记语言是 MarkDown ， 又依赖于几个 Ruby 组建，而且官方网站的设计实在太前卫。 最终我看到了 Pelican 。 [1] 比如 Python 2.x 与 3.x 之间看似难以跨越的鸿沟，以及 PyPy 、 CPython 、 Stackless 、 Cython 等各个实现之间的微妙差别。 [2] 是的，我们有 easy_install ，我们有 pip ， 不过这些都是包管理器，都是装好特定的Python实现之后的事情。 Python实现本身还不需要包管理器来管理。 Python 的版本问题基本上也只需要 2to3.py 和 3to2.py 这样的轻量级转换器就可以了，你不需要为了安装多个软件而在硬盘里留下多个不同版本的 Python 。 如果为了引用的稳定性，你可以用 virtualenv ，不过这又是另一回事情了。 那么就 Pelican 吧 对我而言， Pelican 相比于 Octopress 有几个好处： 纯 Python 实现。 这意味着我可以换用任何 Python 解释器而不必担心兼容性问题。比如我就换成了 PyPy 。 多语言支持。因为 Pelican 的作者似乎是个法国人。不过这个似乎大部分人不需要…… 我是想尽量把一篇博客写成三种语言作为锻炼吧。 ReST 。这样我就可以用 Leo 的 @auto-rst 直接写 ReST了。简单方便快捷有效。 不过似乎 Pelican 的关注度不如 Octopress 那么高，现在一些部分还有细微的问题： pelican-import 从 WordPress 导入的时候对中文、日文的支持似乎很成问题。 日期格式、时区、字符集、和多语言功能的结合度还不够。 我在尝试改善它。 模板还不够丰富。 插件也不够多…… 希望这么优秀的工具能够受到更多关注，以上这些问题都是增加关注度之后很快就能解决的问题。 我的设置 settings.py 安装 Pelican 很容易，一句话就够了： $ pip install pelican 然后把文章写成ReST的格式，放在`pages`文件夹里面。(重新)生成只要： $ pelican -s settings.py 上传到 Github: $ git commit -am \"Commit message\" $ git push 就这么简单。附上我的配置文件： # -*- coding: utf-8 -*- TIMEZONE = 'Asia/Tokyo' DATE_FORMATS = { 'en' :( 'usa' , '%a, %d %b %Y' ), 'zh' :( 'chs' , '%Y-%m- %d , %a' ), 'jp' :( 'jpn' , '%Y/%m/ %d (%a)' ), } # windows locale: http://msdn.microsoft.com/en-us/library/cdax410z%28VS.71%29.aspx LOCALE = [ 'usa' , 'chs' , 'jpn' , # windows 'en_US' , 'zh_CN' , 'ja_JP' ] # Unix/Linux DEFAULT_LANG = 'zh' SITENAME = 'Farseerfc Blog' AUTHOR = 'Jiachen Yang' DISQUS_SITENAME = 'farseerfcgithub' GITHUB_URL = 'https://github.com/farseerfc' SITEURL = 'http://farseerfc.github.com' TAG_FEED = 'feeds/ %s .atom.xml' SOCIAL = (( 'twitter' , 'http://twitter.com/farseerfc' ), ( 'github' , 'https://github.com/farseerfc' ), ( 'facebook' , 'http://www.facebook.com/farseerfc' ), ( 'weibo' , 'http://weibo.com/farseerfc' ), ( 'renren' , 'http://www.renren.com/farseer' ), ) TWITTER_USERNAME = 'farseerfc' THEME = 'notmyidea' CSS_FILE = \"wide.css\" DEFAULT_CATEGORY = 'Others' OUTPUT_PATH = '.' PATH = 'posts'","tags":"tech","title":"尝试一下 Pelican"},{"url":"//farseerfc.me/zhs/about-my-blogs.html","text":"从 farseerfc.wordpress.com 导入 很久没有写过blog或者之类的东西了。这边一直荒废着。 由于国内被墙的原因，另一个wordpress： http://fchome.sinaapp.com/ 应该会同步更新这里的内容。 抽空写点什么吧。","tags":"import","title":"关于我的Blogs"},{"url":"//farseerfc.me/zhs/if-we-do-this-work.html","text":"导入自 renren From: Bill Gates '-- Sent: Sunday, January 24, 1999 8:41 AM Jeff Westorinon; Ben Fathi ; TO: Carl Stork (Exchange); Nathan Myhrvofd; Eric Rudder Subject: ACPI extensions One thing I find myself wondering about is whether we shouldn't try and make the \"ACPI\" extensions somehow Windows specific. It seems unfortunate if we do this work and get our partners to do the work and the result is that Linux works great without having to do the work . Maybe there is no way to avoid this problem but it does bother me. Maybe we could define the APIs so that they work well with NT and not the others even if they are open. Or maybe we could patent something relaled to this. From: http://antitrust.slated.org/www.iowaconsumercase.org/011607/3000/PX03020.pdf 如果这就是我至今在Xen4.0上得不到ACPI 3.0的完善支持的原因，那么我诅咒Bill Gates！","tags":"import","title":"\"…if we do this work … \" --Bill Gates"},{"url":"//farseerfc.me/zhs/zz-introducing-scholarzhang.html","text":"从 farseerfc.wordpress.com 导入 好神奇的想法，先存着，以后慢慢研究 原文： http://blog.youxu.info/2010/03/14/west- chamber/ 待月西厢下，迎风户半开。隔墙花影动，疑是玉人来。 最近推上最流行的一个关键词是\"西厢计划\", 这个计划名字取得很浪漫，客户端叫做张生，对，就是西厢记里面那个翻墙去见崔莺莺小姐的张生；显然，服务器端必然叫做崔莺莺。客户端的张生是最重要的部件，可以不依赖于服务端工作。因为西厢计划的作者只是简要的介绍了一下原理，其他报道又语焉不详，我当时就觉得很好奇，花了昨天一个晚上详细读了一下源代码，终于知道怎么回事了，觉得原理非常漂亮，所以写篇文章介绍总结一下。 先说大方向。大家都知道，连接被重置的本质，是因为收到了破坏连接的一个 TCP Reset 包。以前剑桥大学有人实验过，客户端和服务器都忽略 Reset, 则通信可以不受影响。但是这个方法其实只有理论价值，因为绝大多数服务器都不可能忽略 Reset 的 (比如 Linux, 需要 root 权限配置iptables, 而且这本身也把正常的 Reset 给忽略了)。只要服务器不忽略 Reset, 客户端再怎么弄都没用，因为服务器会停止发送数据，Reset 这条连接。所以，很多报道说西厢计划是忽略 Reset, 我从源代码来看应该不是这样。在我看来，西厢计划是利用了墙的一个可能的弱点–墙只在连接发起的时候把一个 TCP 连接加入监听序列，如果墙认为这个连接终止了，就会从监听序列中去掉这条记录，这样，这条连接上后续的包就不会被监听。西厢计划就是让墙\"认为\"这个连接终止的一个绝妙的方法。只要墙认为这个连接两端都是死老虎，墙就不会触发关键词检测，其后所有的数据，都不存在连接被重置的问题了。 如何让一个连接置之死地而后生，就是西厢计划那帮黑客神奇的地方了。这也不是一日之功。 首先，这帮牛人发现，墙的是一个入侵检测系统，把含有关键字的包当成一种\"入侵\"来对待。采取这种设计有很多好处，但缺点是入侵检测系统可能具有的问题，墙都可能有。西厢计划主页上那篇著名的论文就是讲这些七七八八的漏洞的。可以说处理这些七七八八的漏洞是非常困难的，迫使墙的设计者\"拆东墙，补西墙\"。这样补来补去，外表看起来好像很牛逼的墙，其实有很多本质上无法简单修补的漏洞，其中有一个致命的，就是 TCP 连接状态的判定问题。 出于入侵检测系统这种设计的局限，墙没有，也没办法准确判定一条 TCP 连接的状态，而只是根据两边收到的数据来\"推测\"连接的状态。而所有的关键词检测功能，都是基于\"连接还活着\"的这个推测的结果的。因为墙的规则是在连接发起的时候开始对这条连接的检测，在连接终止的时候停止对这条连接的检测，所以，一旦对连接的状态推测错误，把还活着的连接当成已经关闭的连接，墙就会放弃对这条连接上随后所有的包的检测，他们都会都透明的穿过墙的入侵检测。 上面只是想法，具体到 TCP 协议实现这一层，就要只迷惑墙，还不能触及我要通信的服务器。最理想的情况下，在任何有效通信之前，就能让墙出现错误判断，这些，就需要对 TCP 协议有深刻理解了。西厢计划的那帮黑客，居然真的去读 TCP 几百页的 RFC，还居然就发现了方法（这里我假设读者都知道 TCP 的三次握手过程和序列号每次加一的规则）。 我们都知道，三次握手的时候，在收到服务器的 SYN/ACK 的时候，客户端如果发送 ACK 并且序列号+1 就算建立连接了，但是客户端如果发送一个序列号没 +1 的 FIN （表示连接终止，但是服务器知道，这时候连接还没建立呢， FIN 这个包状态是错的，加上序列号也是错的，服务器自己一判断，就知道这个包是坏包，按照标准协议，服务器随手丢弃了这个包）, 但这个包，过墙的时候，在墙看来，是表示连接终止的(墙是 ma de in china, 是比较山寨的，不维护连接状态，并且，墙并没有记下刚才服务器出去的 SYN/ACK 的序列号，所以墙不知道序列号错了）。所以，墙很高兴的理解为连接终止，舒了一口气去重置其他连接了， 而这个连接，就成了僵尸，墙不管你客户端了，而这时候，好戏才刚刚开始。 事实上，墙是双向检测的（或者说对每个包都检测的），因此，对服务器和客户端实现相同的对待方法，所以，墙不管客户端还不行，假如服务端有关键词传给客户端，墙还是有可能要发飙的（这里说有可能，因为我也不知道）。所以，最好的办法就是，让服务端也给墙一个终止连接的标志就好了。可是这个说起来简单，做起来难，怎么能让不受自己控制的服务器发一个自己想要的包呢？ 西厢计划的那帮黑客，再次去读几百页的 RFC, 令人惊讶的发现，他们居然在 RFC 上发现了一个可以用的特性。我们上面说了，三次握手的时候，在收到 SYN/ACK 后，客户端要给服务器发送一个序列号+1 的ACK，可是，假如我不+1呢，直接发 ACK 包给服务器。 墙已经认为你客户端是死老虎了，不理你了，不知道你搞什么飞机，让这个 ACK 过了。可是服务器一看，不对啊，你给我的不是我期待的那个序列号， RFC 上说了，TCP 包如果序列号错了的话，就回复一个 Reset. 所以，服务器就回复了一个 Reset。这个 Reset 过墙的时候，墙一看乐了，服务器也终止连接了，好吧，两边都是死老虎了，我就不监听这条连接了。而至于客户端，这个服务器过来的 Reset 非常好识别，忽略就是。随后，客户端开始正确的发送 ACK, 至此，三次握手成功，真正的好戏开始，而墙则认为客户端和服务器都是死老虎，直接放过。所以，张生就这样透明的过了墙。 至于过墙以后所有的事情，《西厢记》里面都有记载，各位读者自行买书学习。 现在的西厢计划客户端，即\"张生\"模块的防连接重置的原理就是这样，服务器端，即莺莺模块的实现也是类似的。防DNS那个，不懂 DNS 协议，所以看不懂。我猜想，因为开发人员都是黑客，所以自然喜欢用最经得起折腾和高度定制的 Linux 开发。 现在看西厢计划的实现，因为依赖于 Linux 内核模块 netfilter, 在 Linux 上如鱼得水，但往其他平台的移植可能是个亟待解决的问题。 我觉得，在其他平台上，可以通过 libpcap 和 libnet ，在用户态实现相同的功能，就是有点麻烦而已，有兴趣的懂网络的可以照西厢计划原理，在家自行做出此功能；当然，全中国人民都用 Linux 最好 :) PS 1: 据说是西厢计划一个作者画的原理图： http://img.ly/DIi PS 2: 我对 TCP 的理解仅限于课本，如果上面的对技术的理解有错，请大家指出。 PS 3: 有些漏洞，可能是设计上本质缺陷，不是那么容易修复的。 PS 4: 除了最后一个图，本文没有其他相关链接，如需相关资料，自行Google。","tags":"import","title":"[zz]\"西厢计划\"原理小解"},{"url":"//farseerfc.me/zhs/sine-cpu.html","text":"导入自 renren 据说是一道微软的面试题。如题，写程序，让Windows的任务管理器中的性能监视器呈现正弦曲线。 潜心钻研良久，得代码：（java） public class sincpu { private static final int cycle = 1024 , tick = 256 ; public static void main ( String [] args ) throws InterruptedException { for ( int i = 0 ;; i ++){ work ( calcNextSleep ( i % cycle )); sleep ( tick - calcNextSleep ( i % cycle )); } } private static long calcNextSleep ( long i ){ return ( int )( Math . sin (( double ) i * 2 * Math . PI / cycle ) * tick + tick ) / 2 ; } private static void sleep ( long sleepTime ) throws InterruptedException { if ( sleepTime < 2 ) Thread . yield (); else Thread . sleep ( sleepTime ); } private static void work ( long period ) { long start = System . currentTimeMillis (); for (;;){ Math . sin ( 1 ); if ( System . currentTimeMillis () - start >= period ) break ; } } } 多核CPU上测试时要注意关掉一个CPU：","tags":"import","title":"写程序让CPU占用率保持正弦函数"},{"url":"//farseerfc.me/zhs/some-thought-on-creationism.html","text":"导入自 renren 看到陈骉同学很有感想的一篇神创论与命运日志，觉得近日很久没有看到这样的评论了。想说几句自己的观点。 首先我认为，神创论与宿命论没有多少关联，甚至进化论者相较于神创论者更容易接受宿命论的观点。因为神创论主张意志的存在，人所具有的个体意志与神的意志，因此在神创论者的眼中事件的结果是可以通过意志来改变的，亦即如果我从物理楼11楼跳下，那么我就可以改变自己死亡时间的宿命。上帝的意志同样可以左右事件的结果，也就是所谓的宿命不复存在。而进化论者不承认意志独立于物质世界的存在，你我的思考、行为，都受到物理学法则诸如量子力学的约束，这就引出了北大物理系教授的那句\"宇宙中的一切都是可以计算的\"，亦即宿命论。如我我选择现在从物理楼上跳下，我这一行为并不是处于个人的独立意志，乃是想证明这一点，亦即我跳楼这一举动是有其背后的动机与原因的，就如同计算机的输入必然导致了输出，宿命的必然终结于此。 其次，关于事件的复杂度所导致的随机化，在大量混沌随机中也存在着如统计学和随机分形学这样的规律，并不是否认宿命的充分理由。 关于神创论的合理性问题。我认为是否相信神的存在只是一个boolean二值问题，它为true为false本身并不重要，重要的是确定它的取值之后得到的推论与结果。如果否认神的存在，如现代数学这样的完美又何以存在，进化论者的解释是事物最终会向着更好更高级的方向发展，产生现代数学乃至现代科学是发展的必然。而这种论调显然有悖于物理中以热力学第二定律为首的，预言事物会随时间推演愈发混乱的论断。更进一步，甚至整个人类、整个生物系统的存在都是有悖于热力学推论的现象，是某种理论只能以\"小概率事件\"解释的现象。 神创论的核心观点之一，是神的唯一存在性，按照邹恒明的比喻，这就如同数学中集合中元素的的唯一性一般至关重要。数学乃至近代科学的发展，其起源在于这种对神性的探求，而不仅仅是好奇心就可以解释的。反观东方文化中数学的发展，开始时领先于西方科学千余每年，但是始终作为一种craft-oriented的实用主义学科。可以说没有了神的唯一性支持，人们就不能确信自己能找到这样一种完美高效的学科，只能在实用的基础上发展其基础算数。可以想象，没有神的完美与唯一性，数学必将发展成现代化学或者微软软件这样，庞大而充满特例，到处都是修补与查表，怎么会像现在的完美、简洁与和谐。 神创论者并不是将难题推与\"神\"然后放任不管，他们相信神是最为理智的存在，创人时人同样得到了神的智慧和理智，也就是神可以用人的理智来理解。 引用牛顿《自然哲学的数学原理》中终章的话\"太阳、恒星、行星的这个极精致的结构不可能存在，除非通过一个有理智的和有权能的存在的设计和主宰……他不是作为宇宙的灵魂，而是作为一切的主宰而统治所有……\" 以上…… (发现最近的哲理思维果然慢了不少，写作思绪也一片混乱&#94;_&#94;)","tags":"import","title":"关于神创论的一些见解"},{"url":"//farseerfc.me/zhs/9-thoughts-about-oop-from-wrongly-insert-memory-stick.html","text":"从 farseerfc.wordpress.com 导入 故障描述: MMC Memory Stick Duo记忆棒未经Adapter适配器，直接插入SD Reader，致使MMC卡入SD Reader中。 栈展开： 某日下午，无课。 忙于数分作业，想查询用手机拍摄的板书照片。 取出手机中的MMC。 未经装配Adapter，直接插入SD Reader。 (A runtime exception was thrown.) 尝试翻转笔记本机身，倒出MMC，未果。(rethrow) 尝试用手指甲取出，未果。(rethrow) 考虑到有\"推入反弹\"机制，尝试将MMC推入更深，反弹机制由于类型不匹配而失效，未果。(rethrow) (The exception spread across the border of the model.) 电脑维修技师接手(catch) 技师未能发现问题所在，由我解说原委。 (Because the exception lose the information, RTTI was asked to recall the information) 技师发现问题，尝试用镊子镊出MMC，未果。 技师开解机箱(expose the data structure) 技师制作钩子，勾出MMC(hooker link to the structure) 取出MMC，故障解除 故障总结 1.接收到没有完全了解、或没有适当工具解决的exception时，不要尝试用不成熟的技术解决，应尽快寻求能解决它的代码。否则，被反复rethrow的exception，尤其是通过模块边界的exception，有可能由subclass退化为superclass，并因此而丧失一些信息。尽量不要让exception丢失信息，必要时，通过RTTI机制寻回信息。 2.超负荷运转，多线程执行，这种种复杂性都有可能导致错误，应避免。无论你有多么信任你的代码或能力。 3.在设计class的interface时，相匹配的interface应该满足is-a的关系。因此，任何能插入SD Reader的object，即任何实现了SD interface的object，都应该is-a SD card。这次故障中，interface接受了MMC，但MMC不是SD。即使这种情况下throw an exception，都不能使事态缓和。能提供compile-time error时，尽量让错误以compile-time error的形式展现，并在事先解决。类型匹配问题是应该能在事先解决的问题。 4.Design patterns中的Adapter pattern应该只是迫不得已情况之下的解决方案。只有当你无权改变现状时，才能使用Adapter。如果能改变现状，应该改变设计以符合interface。 5.因为上条，所有相似功能的对象应具有相同的interface，不同的interface是本次故障的根源所在。 6.特殊情况下，破坏封装机制并expose the data structure是必要的，应该有方法支持这种做法。C的指针和C#的Reflection技术都以不同的方式支持这种做法。其他的一些语言机制，比如serializing(序列化)或streaming(流化)，也可以以某种方式间接支持这一做法。当然，机制还应避免这种做法被滥用。 7.相反功能具有相同操作的设计，容易造成使用的混乱，应适当避免。比如SD Reader的推入反弹设计，即插入和弹出使用同一个向里推的操作的设计。同样的设计还包括，C++中的setNewHandle使用同一个函数，同时设置和返回handle。以及有些书中提倡的，使用同名函数重载的方式，实现setter/getter的设计。 8.特殊工具(hooker)对于解决特定问题，通常比手工解决有效。不要嫌麻烦而不愿意构造特殊工具。 9.栈语义，即FILO顺序，总在不知不觉中影响我们。违反了FILO顺序的操作极易造成混乱。本故障发生时正确的处理顺序为： 装配Adapter 插入SD Reader 读取数据 停用设备 拔出SD Reader 拆解Adapter 本次故障的原因就是违反了FILO顺序，违反了栈语义。","tags":"import","title":"由记忆棒误差故障引发的关于面向对象设计的九点思考"},{"url":"//farseerfc.me/zhs/program-development-in-java-preface.html","text":"从 farseerfc.wordpress.com 导入 程序开发原理 ——抽象、规格与面向对象设计 Barbara Liskov 、John Guttag 著 杨嘉晨 等译 关于翻译风格： 多年来阅读计算机类的著作及译作，感觉总体的困难在于一大堆没有标准译名的技术术语。由于通行于工业界和学术界的还是英文原名和术语，我决定保留大量的英文术语。这样的翻译风格借鉴于台湾著名的译者和作者侯捷先生。对于译与不译的权衡，主要考虑阅读的流畅，以及读者的理解能力，或许难免带有一些主观色彩。 前言 Preface 构建产品级质量的程序——可以在很长一段时间内使用的程序——众所周知是极其困难的。本书的目标就是改善程序员解决这项任务的效率。我希望读者在阅读本书之后成为一名好程序员。我相信本书的成功在于改善编程技巧，因为我的学生告诉我这已经发生在他们身上。 怎么才算是一名好程序员？是产生整个程序产品的效率。关键是要在每一阶段减少浪费掉的努力。解决的方法包括：在开始编写代码之前就仔细考虑你的实现方案，通过未雨绸缪的方法来编写代码，使用严格的测试在早期发现错误，以及仔细注意模块化编程，这样当错误出现时，只需要改动极少数代码就可以修正整个程序。本书涉及所有这些领域的技术。 模块化编程(Modularity)是编写好程序的关键。把程序分解成许多小模块，每一个模块通过良好定义的狭窄接口和别的模块交互作用(interact)。有了模块化，可以修正一部分程序中的错误而不考虑程序的其他部分，而且可以仅仅理解一部分程序而不必理解整个程序。没有模块化，程序是一大堆有着错综复杂的相互关系的部分的拼凑。很难去领悟和修改这样一个程序，同样也很难让它正常工作。 因此本书的重点在于创建模块化的程序：怎样把程序组织成一系列精心挑选的模块。本书认为模块化就是抽象(abstraction)。每一个模块意味着一个抽象，比如说指引一系列文档中的关键字的目录，或者在文档中使用目录来查找匹配某个问题的文档的过程。着重强调面向对象编程思想——在程序中使用数据抽象和对象的思想。 这本书使用Java作为它的编程示例的语言。我们没有假定读者已经熟悉Java。尽管可能没什么价值，但是本书中的思想是语言无关的，并且可以在任何语言的编程中使用。 怎样使用这本书？ How Can the Book Be Used 本书《程序开发原理》有两种使用方法。其一是作为课本教材，讲述如何用面向对象的方法来设计和实现复杂系统；其二是编程专家使用，帮助他们改善编程技能，增进他们的关于模块化和Object-Oriented(面向对象)设计的知识。 作为教材使用时，本书一般作为第二或第三门程序设计课程。我们已经在MIT使用本书很多年，给大一大二的本科生教授第二门编程课。在这一阶段，学生们已经知道怎样编写小程序。课程在两方面利用这一点：让学生更仔细地思考小程序，以及教他们如何利用小程序作为组件构建大型程序。这本书也可以在专业（如软件工程）后期教学中使用。 建立在本书基础上的课程适合于所有计算机科学专业。尽管许多学生可能永远不会成为真正的大型程序的设计师，他们可以在开发部门工作，在那儿他们负责设计和实现能与整个结构耦合的子系统。模块化设计的子系统是这种任务中心，这对那些从事大型程序设计任务的人来说也同样重要。 这本书讲什么？What Is This Book About 通观全篇三分之二的书致力于讨论在构建独立的程序模块时产生的问题，剩下的部分讨论怎样运用这些模块构建大型程序。 程序模块Program Modules 这一部分的书集中讨论抽象机制(abstraction mechanism)。它讨论procedure(子程序)和exception(异常)，数据抽象，遍历(iteration)抽象，数据抽象系列(family)以及多态(polymorphic)抽象。 在对抽象的讨论中，三个步骤是重要的。首先是决定被抽象的东西到底是什么：它提供给它的用户哪些行为。创造抽象是设计的关键，因此本书讨论如何在众多选择中挑选，以及怎样才能创造出好的抽象。 第二步是通过为一个抽象制定一个规格(specification)来获取它的意义。如果没有一些描述，一个抽象就会含糊不清，而变得没有使用价值。specification则提供了需要的描述。本书定义了一种specification的格式，讨论了一份好的specification应有的属性，并且提供了许多示例。 第三步是实现抽象。本书讨论怎样设计一份实现，以及在简洁性和执行性能之间怎样权衡利弊。书中强调封装(encapsulation)的重要性以及在一份实现中履行规格中定义的行为的重要性。书中同样提供一些技术——尤其是不变式断言(representation invariant)和抽象函数(abstraction function)——来帮助读者理解代码和它的原因。不变式断言和抽象函数都实现到尽可能的程度，这对于除错和调试很有用。 关于类型层次(type hierarchy)的材料注重讨论使用它作为抽象的技术——一种把相关联的一组数据抽象归入同一系列的技术。这里很重要的一点是，是否应当将一个类型作为另一个类型的子类。本书定义了替换原则——通过比较子类和父类的specification，来决定是否建立子类关系的方法 [1] 。 本书同样涉及除错和调试。书中讨论怎样得到足够数量的测试情况，来准备通过黑箱和白箱测试，它同样强调了复查(regression)测试的重要性。 编写大型程序 Programming in the Large 本书的其后部分讲解怎样用模块化的方法设计和实现大型程序。它建立在前文有关abstraction和specification的材料的基础之上。 编写大型程序涵盖四个主要议题。首先讲解需求分析——怎样才能领悟程序中需要什么。本书讨论怎样实施需求分析，也讨论书写产生的需求规格的方式，通过使用一种描述程序的抽象阶段的数据模型。使用这种模型将产生一份更为正式的specification，同时它也使需求检查更加严格，这样可以更好的领悟需求。 编写大型程序的第二项议题是程序设计，这通常是一个循序渐进的过程。设计过程围绕构建有用的抽象来组织，这些抽象作为整个程序之中理想的构建组建。这些抽象在设计时被仔细的编写规格，这样当程序实现时，那些实现抽象的模块可以独立地开发。这种设计使用设计笔记编写文档，包括描述整个程序结构的模块间依赖性的图示。 第三项议题是实现和测试。本书讨论了前置设计分析对于实现的必要性，以及怎样进行设计复审。它同样讨论了设计和实现的顺序。这一部分比较了自顶而下与自底而上的组织方式，讨论如何使用驱动程序和占位程序 [2] (stub)，并且强调了制定一个事先的顺序策略的必要性，以满足开发组织和客户的需求。 本书以一章设计模式(design pattern)结束。一些模式在前面的章节介绍过，比如遍历抽象是算法的主要组建。最后的章节讨论前文中没有涉及到的模式。希望它作为这一教材的介绍。有兴趣的读者可以继续阅读其它书中更完善的讨论 [3] 。 [1] 译注：如果子类的specification包括了所有父类的specification，就是说父类的要求也是子类的要求，或者子类的要求更为严格，那么可以建立父子关系。而替换原则的说法是，对于具有父子关系的类，任何需要一个父类对象的地方，都可以替换为一个子类对象。 [2] 译注：在测试某一组建时，由于其余组建还未实现，这一组建与其余组建的接口衔接部分无法工作。此时可以针对这一组建编写其余组建的占位程序(stub)，预留出接口的衔接代码。占位代码通常不做任何有价值的事情，只报告组建的衔接部位工作正常。 [3] 译注：作者指的是设计模式的开山之作——《Design Patterns—Elements of Reusable Object-Oriented Software》,作者为设计模式界著名的\"四人帮\"GoF(Gang of Four)。此书详尽讨论了三大类共23个广泛使用的设计模式的适用范围、依存关系、实现细节以及已有的应用领域等问题。书中以C++和Smalltalk为示例语言，不过书中所涉及的模式适用于所有面向对象的语言。","tags":"import","title":"Program Development in Java Preface"},{"url":"//farseerfc.me/zhs/c-tricks-3-2-label-goto-and-implementation-of-switch.html","text":"从 farseerfc.wordpress.com 导入 3.2 标号、goto，以及switch的实现 goto语句及标号(label)是最古老的C语言特性，也是最早被人们抛弃的语言特性之一。像汇编语言中的jmp指令一样，goto语句可以跳转到同一函数体中任何标号位置： void f() {int i=0; Loop: //A label ++i; if(i<10)goto Loop; //Jump to the label } 在原始而和谐的早期Fortran和Basic时代，我们没有if then else，没有for和while，甚至没有函数的概念，一切控制结构都靠goto(带条件的或无条件的)构件。软件工程师将这样的代码称作\"意大利面条\"代码。实践证明这样的代码极容易造成混乱。 自从证明了结构化的程序可以做意大利面条做到的任何事情，人们就开始不遗余力地推广结构化设计思想，将goto像猛兽一般囚禁在牢笼，标号也因此消失。 标号唯一散发余热的地方，是在switch中控制分支流程。 很多人不甚了解switch存在的意义，认为它只是大型嵌套if then else结构的缩略形式，并且比if语句多了很多\"不合理\"的限制。如果你了解到switch在编译器内部的实现机制，就不难理解强加在switch之上的诸多限制，比如case后只能跟一个编译期整型常量，比如用break结束每一个case。首先看一个switch实例： switch (shape.getAngle()) { case 3: cout<<\"Triangle\";break; case 4: cout<<\"Square\";break; case 0:case1: cout<<\"Not a sharp!\";break; default: cout<<\"Polygon\"; } 任何程序员都可以写出与之对应的if结构： int i= getAngle(shape); if (i==3) cout<<\"Triangle\"; else if(i==4) cout<<\"Square\"; else if(i==0||i==1) cout<<\"Not a sharp!\"; else cout<<\"Polygon\"; 看起来这两段代码在语义上是完全一样的，不是么？ 不！或许代码的执行结果完全一样，但是就执行效率而言，switch版本的更快！ 要了解为什么switch的更快，我们需要知道编译器是怎样生成switch的实现代码的： 首先，保留switch之后由{}括起来的语具体，仅将其中case、default和break替换为真正的标号： switch (getAngle(shape)) { _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 随后，对于所有出现在case之后的常量，列出一张只有goto的跳转表，其顺序按case后的常量排列： goto _case_0; goto _case_1; goto _case_3; goto _case_4; 然后，计算case之后的常量与跳转表地址之间的关系，如有需要，在跳转表中插入空缺的项目： 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; //因为没有case 2，所以插入此项以条转到default 100120: goto _case_3; 100125: goto _case_4; 假设一个goto语句占用5个字节，那么在本例中，goto的地址=case后的常量*5+100105 之后，生成跳转代码，在其余条件下跳转至default，在已知范围内按照公式跳转，全部的实现如下： { int i= getAngle(shape); if (i<0||i>=5)goto _default; i=i*5+100105; //按照得出的公式算出跳转地址 goto i; //伪代码，C中不允许跳转到整数，但是汇编允许 100105: goto _case_0; 100110: goto _case_1; 100115: goto _default; 100120: goto _case_3; 100125: goto _case_4; _case_3: cout<<\"Triangle\";goto _break; _case_4: cout<<\"Square\"; goto _break; _case_0:_case_1: cout<<\"Not a sharp!\"; goto _break; _default: cout<<\"Polygon\"; _break: } 经过这样处理整个switch结构，使得无论switch后的变量为何值，都可以通过最多两次跳转到达目标代码。相比之下if版本的代码则采用线性的比较和跳转，在case语句很多的情况下效率极低。 由此,我们也可以知道,为什么case后跟的一定是编译期整型常数，因为编译器需要根据这个值制作跳转表。我们可以明白为什么case与case之间应该用break分隔，因为编译器不改变switch语句体的结构，case其本身只是一个具有语义的标号而已，要想跳出switch，就必须用break语句。","tags":"import","title":"C++ Tricks 3.2 标号、goto，以及switch的实现"},{"url":"//farseerfc.me/zhs/c-tricks-3-1-lvalue-rvalue-constant.html","text":"从 farseerfc.wordpress.com 导入 3.1 左值右值与常量性(lvalue，rvalue & constant) 首先要搞清楚的是，什么是左值，什么是右值。这里给出左值右值的定义： 1、左值是可以出现在等号(=)左边的值，右值是只能出现在等号右边的值。 2、左值是可读可写的值，右值是只读的值。 3、左值有地址，右值没有地址。 根据左值右值的第二定义，值的左右性就是值的常量性——常量是右值，非常量是左值。比如： 1=1;//Error 这个复制操作在C++中是语法错误，MSVC给出的错误提示为\"error C2106: '=' : left operand must be l-value\"，就是说'='的左操作数必须是一个左值，而字面常数1是一个右值。可见，严格的区分左值右值可以从语法分析的角度找出程序的逻辑错误。 根据第二定义，一个左值也是一个右值，因为左值也可读，而一个右值不是一个左值，因为右值不可写。 通常情况下，声明的变量是一个左值，除非你指定const将它变成一个右值： int lv=1; const int rv=lv; 由于右值的值在程序执行期间不能改变，所以必须用另一个右值初始化它。 一个普通变量只能用右值初始化，如果你想传递左值，必须声明一个引用或一个指针： int & ref=lv;//用引用传递左值 int * plv=&lv;//传递指针以间接传递左值 必须用左值初始化引用，然而，可以用右值初始化常量引用： int & r1=1; //Error! const int & r2=1; //OK 这实际上相当于： int _r2=1; const int & r2=_r2; 这样的写法在函数体内没什么作用，但是在传递函数参数时，它可以避免潜在的(传递左值时的)复制操作，同时又可以接受右值。 通常情况下，函数的参数和返回值都只传回右值，除非你明确的通过引用传递左值。 明确了左值与右值的区别，有助于我们写函数时确定什么时候应该有const，什么时候不该有。比如，我们写了一个代表数学中复数的类Complex： class Complex; 然后，我们写针对Complex的运算符重载：operator+和operator=。问题在于，参数和返回值应该是什么类型，可选类型有四种： Complex、const Complex、Complex&、const Complex&。 对于operator+，我们不会改变参数的值，所以可以通过const Complex&传递参数。至于返回值类型，由于int类型的加法返回右值，所以根据Do as the ints do的原则，返回值类型为const Complex： const Complex operator+(const Complex&,const Complex&); 对于operator=，同样要思考这些问题。我们写入第一个参数，所以第一个参数为Complex&，我们只读取第二个参数，所以第二个参数为const Complex&。至于返回值，还是Do as the ints do。int的赋值返回左值，不信你可以试一试： int i; (i=1)=2; 虽然比较傻，先将i赋为1，再将其改为2，但是这是被C++语法支持的做法，我们就理应遵守。所以返回第一个参数的左值： Complex& operator=(Complex&,const Complex&); const是C++引入的语言特性，也被ANSI C99借鉴，在经典版本的C语言中是没有的。关于const的历史，有几点值得玩味。最初Bjarne Stroustrup引入const时，可写性是和可读性分开的。那时使用关键字readonly和writeonly。这个特点被首先提交到C的ANSI标准化委员会(当时还没有C++标准化的计划)，但是ANSI C标准只接受了readonly的概念，并将其命名为const。随后，有人发现在多线程同步的环境下，有些变量的值会在编译器的预料之外改变，为了防止过度优化破坏这些变量，C++又引入关键字violate。从语义特点来看，violate是const的反义词，因为const表示不会变的量，而violate表示会不按照预期自行变化的量。从语法特点而言，violate与const是极为相似的，适用于const的一切语法规则同样适用于violate。 值的常量性可以被划分为两种：编译期常量和运行期常量。C++语法并没有严格区分这两种常量，导致了少许混乱： const int i=5;const int * pi=&i; const_cast<int&>i=1;//对于运行期常量，在需要时可以去除它的常量性 int a[i];//对于编译期常量，可以用它来指定数组大小 cout<<i<<sizeof(a)/sizeof(a[0])<<*pi; 这种将编译期与运行期常量的特性混用的方法，势必导致语义的混乱。数组a的大小最终是5，因为采用了i的编译期值，而不管i在运行期是否被改变了值。最后一句代码将（有可能）输出551，第一个i的值作为一种优化在编译期绑定，第二个值标明了a的大小，第三个值通过指针显示地输出i的运行期真实值。 在C++的近亲C#的语法中，这两种常量被严格地区分开：编译期常量由const指定，只能是内建类型变量；运行期常量由readonly指定，可以是任何类型。永远不会改变的常量，如圆周率pi的值，应该用const声明；而其它有可能改变的常量，皆由readonly声明。 C++中的const的特点更倾向于C#中的readonly，虽然语法上允许使用const的编译期常量性，但正如上文所展示的，这容易造成混乱。为了得到C#中const的语义，在C++中，我们不必回归恶魔#define的怀抱，可以使用所谓\"匿名enum技巧\"。当匿名声明一个enum类型时，其中的枚举值就是一个int类型的编译期常量，比如： enum{Size=5;}; int a[Size]; 这种使用匿名enum来声明编译期常量的做法，被广泛应用于STL、boost等模板库的实现代码中。","tags":"import","title":"C++ Tricks 3.1 左值右值与常量性(lvalue，rvalue & constant)"},{"url":"//farseerfc.me/zhs/c-tricks-2-2-i386-memory-layout.html","text":"从 farseerfc.wordpress.com 导入 2.2 I386平台的内存布局 众所周知，I386是32位体系结构。因此对于绝大多数I386平台的C++编译器而言，sizeof(int)=sizeof(long)=sizeof(void*)=4。当然C++标准对此没有任何保证，我们也不应该试图编写依赖于此的代码。 32位指针的可寻址空间为4GB。为充分利用这么大的寻址空间，也是为了支持其它更先进的技术比如多任务技术或者动态链接库技术，WinNT使用虚拟内存技术，给与每个应用程序全部4GB的内存空间。4GB的地址被一分为二，前2GB供应用程序自己使用，后2GB由系统内核分配和管理。这2GB的内存地址，通常被划分成3种内存区使用： 1 代码及静态数据区 由代码加载器从动态链接库镜像(通常是exe或dll文件)加载，通常定位到镜像文件中指定的基址开始的内存区。如果基址所在内存已被占用，动态连接器会将代码或数据重定向到其它可用地址。 在C++中，静态数据包括：名字空间(namespace)和全局(global)对象、函数的static对象、类的static数据成员。这些静态数据由编译器分配地址(但可能被重定向)，由静态连接器写入代码文件(通常是exe或dll)的静态数据区段。所以标准说，这些静态数据在编译期就已经具有地址。 2 栈(Stack) 栈是最常用的动态数据存储区，所有函数的non-static对象和函数参数都在程序运行期在栈上分配内存。在数据结构中，术语\"栈(Stack)\"意指先进后出(FILO，First In Last Out)，与\"队列(Queue)\"所指的FIFO相对。相对于基于堆的对象分配技术，默认使用栈的对象分配有两点优势： 一、栈的FILO与人的思维方式相同 现实生活中有许多事例都使用FILO的方式，比如人们必须先提起话筒再拨打号码，而后挂断电话之后再放下话筒。使用FILO的栈，可以保证事物的销毁顺序以其诞生顺序相反的顺序进行，不会产生在挂断电话之前就放下话筒的尴尬。 二、栈的分配管理仅需要两个额外指针：栈顶(esp)和栈底(ebp)指针 从实现的技术层面而言，栈的管理比其它动态分配技术要简单很多。I386平台上的动态栈管理，仅需要栈顶和栈底两个指针。这两个指针的存储显然不能放置于栈中，置于静态数据区又有损效率。I386平台为管理动态栈专门预留了两个通用寄存器变量esp与ebp，分别代表栈顶(esp,Extended Stack Pointer)与栈底(Extended Bottom Pointer)指针。其中的extended代表它们是32位指针，以区分16位的sp和bp寄存器。 栈是动态存储区的特点，表明它的内存占用将随着程序的运行而变化。I386平台上WinNT将应用程序的栈置于程序空间，向下增长。程序初始化时，由操作系统将esp指向系统分配的栈空间的顶部。当程序需要在栈上分配变量时，就将esp减去变量所需字节数，这被称作\"压栈(Push)\"；随后又要销毁变量时，就将esp加上变量所需字节数，这被称作\"弹出(Pop)\"。esp与ebp两者之间所夹的空间，就是当前函数正在使用的栈空间。由于栈向下增长，esp(栈顶)的值总是小于ebp(栈底)的值，新分配的变量地址总是小于旧变量的地址。 3 堆(Heap)和自由存储区 栈中的变量对于分配与释放的顺序有特定要求，这在一定程度上限制了栈的适用范围。面向对象(OO，Object Oriented)的程序设计思想也要求能自由地控制变量的分配与销毁。由此，现代操作系统都提供了被称作\"堆(Heap)\"的自由存储区，以允许由程序员控制的对象创建和销毁过程。C标准库函数malloc和free则是对操作系统提供的堆操作的封装。C++提供的自由存储区运算符new和delete则通常是malloc和free的又一层封装。 操作系统经由malloc和free控制对堆的访问。堆的存储管理技术各不相同，简单的使用双链表管理，复杂的可以比拟一个完整的文件系统。 由于额外的管理需求，使用系统提供的通用分配器在堆上分配和销毁变量的代价，无论从空间角度还是效率角度而言，都比在栈上分配对象要高昂很多。对于sizeof上百的大型对象，这样的高昂代价还是可以接受的，但是对于sizeof只有个位数的小对象，这样的代价通常是一个数量级的差距。正因为这个原因，STL不使用new和delete，转而使用分配子(alllocor)分配对象。","tags":"import","title":"C++ Tricks 2.2 I386平台的内存布局"},{"url":"//farseerfc.me/zhs/c-tricks-2-3-i386-stack-allocation-in-c-functions.html","text":"从 farseerfc.wordpress.com 导入 2.3 I386平台C函数内部的栈分配 函数使用栈来保存局部变量，传递函数参数。进入函数时，函数在栈上为函数中的变量统一预留栈空间，将esp减去相应字节数。当函数执行流程途径变量声明语句时，如有需要就调用相应构造函数将变量初始化。当执行流程即将离开声明所在代码块时，以初始化的顺序的相反顺序逐一调用析构函数。当执行流程离开函数体时，将esp加上相应字节数，归还栈空间。 为了访问函数变量，必须有方法定位每一个变量。变量相对于栈顶esp的位置在进入函数体时就已确定，但是由于esp会在函数执行期变动，所以将esp的值保存在ebp中，并事先将ebp的值压栈。随后，在函数体中通过ebp减去偏移量来访问变量。以一个最简单的函数为例： void f() { int a=0; //a的地址被分配为ebp-4 char c=1; //c的地址被分配为ebp-8 } 产生的汇编代码为： push ebp ;将ebp压栈 mov ebp,esp ;ebp=esp 用栈底备份栈顶指针 sub esp,8 ;esp-=8，为a和c预留空间，包括边界对齐 mov dword ptr[ebp-4],0 ;a=0 mov byte ptr[ebp-8],1 ;c=1 add esp,8 ;esp+=8，归还a和c的空间 mov esp,ebp ;esp=ebp 从栈底恢复栈顶指针 pop ebp ;恢复ebp ret ;返回 相应的内存布局是这样： 09992:c=1 <-esp 09996:a=0 10000:旧ebp <-ebp 10004:…… 注:汇编中的pop、push、call、ret语句是栈操作指令，其功能可以用普通指令替换 push ebp相当于: add esp,4 mov dword ptr[esp],ebp pop ebp相当于： mov ebp,dword ptr[esp] sub esp,4 call fun_address相当于： push eip jmp fun_address ret相当于 add esp,4 jmp dword ptr[esp-4] 带参数的ret ret 8相当于 add esp,12 jmp dword ptr[esp-4] 所有局部变量都在栈中由函数统一分配，形成了类似逆序数组的结构，可以通过指针逐一访问。这一特点具有很多有趣性质，比如，考虑如下函数，找出其中的错误及其造成的结果： void f() { int i,a[10]; for(i=0;i<=10;++i)a[i]=0;/An error occurs here! } 这个函数中包含的错误，即使是C++新手也很容易发现，这是老生常谈的越界访问问题。但是这个错误造成的结果，是很多人没有想到的。这次的越界访问，并不会像很多新手预料的那样造成一个\"非法操作\"消息，也不会像很多老手估计的那样会默不作声，而是导致一个，呃，死循环！ 错误的本质显而易见，我们访问了a[10]，但是a[10]并不存在。C++标准对于越界访问只是说\"未定义操作\"。我们知道，a[10]是数组a所在位置之后的一个位置，但问题是，是谁在这个位置上。是i! 根据前面的讨论，i在数组a之前被声明，所以在a之前分配在栈上。但是，I386上栈是向下增长的，所以，a的地址低于i的地址。其结果是在循环的最后，a[i]引用到了i自己！接下来的事情就不难预见了，a[i]，也就是i，被重置为0，然后继续循环的条件仍然成立……这个循环会一直继续下去，直到在你的帐单上产生高额电费，直到耗光地球电能，直到太阳停止燃烧……呵呵，或者直到聪明的你把程序Kill了……","tags":"import","title":"C++ Tricks 2.3 I386平台C函数内部的栈分配"},{"url":"//farseerfc.me/zhs/c-tricks-2-4-i386-stack-allocation-accross-function-invocation.html","text":"从 farseerfc.wordpress.com 导入 2.4 I386平台C函数调用边界的栈分配 当调用一个函数时，主调函数将参数以声明中相反的顺序压栈，然后将当前的代码执行指针(eip)压栈，然后跳转到被调函数的入口点。在被调函数中，通过将ebp加上一个偏移量来访问函数参数，以声明中的顺序(即压栈的相反顺序)来确定参数偏移量。被调函数返回时，弹出主调函数压在栈中的代码执行指针，跳回主调函数。再由主调函数恢复到调用前的栈。 函数的返回值不同于函数参数，通过寄存器传递。如果返回值类型可以放入32位变量，比如int、short、char、指针等类型，通过eax寄存器传递。如果返回值类型是64位变量，如_int64，同过edx+eax传递，edx存储高32位，eax存储低32位。如果返回值是浮点类型，如float和double，通过专用的浮点数寄存器栈的栈顶返回。如果返回值类型是用户自定义结构，或C++类类型，通过修改函数签名，以引用型参数的形式传回。 同样以最简单的函数为例： void f(){ int i=g(1,2); } int g(int a,int b){ int c=a+b； return c; } 产生的汇编代码如下： f: push ebp ;备份ebp mov ebp,esp ;建立栈底 sub esp,4 ;为i分配空间 mov eax,2 ;准备参数b的值2 push eax ;将b压栈 mov eax,1 ;准备参数a的值1 push eax ;将a压栈 call g ;调用g add esp,8 ;将a和b一起弹出，恢复调用前的栈 mov dword ptr[ebp-4],eax ;将返回值保存进变量i mov esp,ebp ;恢复栈顶 pop ebp ;恢复栈底 g: push ebp ;备份ebp mov ebp,esp ;建立栈底 sub esp,4 ;为局部变量c在栈中分配内存 mov eax,dword ptr[ebp+8] ;通过ebp间接读取参数a的值 mov ebx,dword ptr[ebp+12] ;通过ebp间接读取参数b的值 add eax,ebx ;将a和b的值相加，之和存在eax中 mov dword ptr[ebp-4],eax ;将和存入变量c mov eax,dword ptr[ebp-4] ;将c作为返回值，代码优化后会删除此句 add esp,4 ;销毁c的内存 mov esp,ebp ;恢复栈顶 pop ebp ;恢复栈底 ret ;返回函数f 栈的内存布局如下： 100076:c <- g的esp 100080:f的ebp=100100 <- g的ebp 100084:f的eip 100088:a=1 100092:b=2 100096:i 100100:旧ebp <-f的ebp 100104:…… 注意在函数g的汇编代码中，访问函数的局部变量和访问函数参数的区别。局部变量总是通过将ebp减去偏移量来访问，函数参数总是通过将ebp加上偏移量来访问。对于32位变量而言，第一个局部变量位于ebp-4，第二个位于ebp-8，以此类推，32位局部变量在栈中形成一个逆序数组；第一个函数参数位于ebp+8，第二个位于ebp+12，以此类推，32位函数参数在栈中形成一个正序数组。 由于函数返回值通过寄存器返回，不需要空间分配等操作，所以返回值的代价很低。基于这个原因，旧的C语法约定，不写明返回值类型的函数，返回值类型为int。这一规则与现行的C++语法相违背，因为C++中，不写明返回值类型的函数返回值类型为void，表示不返回值。这种语法不兼容性是为了加强C++的类型安全，但同时也带来了一些问题。","tags":"import","title":"C++ Tricks 2.4 I386平台C函数调用边界的栈分配"},{"url":"//farseerfc.me/zhs/c-tricks-2-5-address-alignment.html","text":"从 farseerfc.wordpress.com 导入 2.5 I386平台的边界对齐(Align) 首先提问，既然I386上sizeof(int)==4、sizeof(char)==1，那么如下结构(struct)A的sizeof是多少？ struct A{int i;char c;}; 答案是sizeof(A)==8……1+5=8？ 呵呵，这就是I386上的边界对齐问题。我们知道，I386上有整整4GB的地址空间，不过并不是每一个字节上都可以放置任何东西的。由于内存总线带宽等等的技术原因，很多体系结构都要求内存中的变量被放置于某一个边界的地址上。如果违反这个要求，重则导致停机出错，轻则减慢运行速度。对于I386平台而言，类型为T的变量必须放置在sizeof(T)的整数倍的地址上，char可以随便放置，short必须放在2的整数倍的地址上，int必须放在4的整数倍的地址上，double必须放在8的整数倍的地址上。如果违反边界对齐要求，从内存中读取数据必须进行两次，然后将独到的两半数据拼接起来，这会严重影响效率。 由于边界对齐问题的要求，在计算struct的sizeof的时候，编译器必须算入额外的字节填充，以保证每一个变量都能自然对齐。比如如下声明的struct: struct WASTE { char c1; int i; char c2; } 实际上相当于声明了这样一个结构： struct WASTE { char c1; char _filling1 [3];//三个字节填充，保证下一个int的对齐 int i; char c2； char _filling2 [3];//又三个字节填充 } 值得注意的是尾部的3个字节填充，这是为了可以在一个数组中声明WASTE变量，并且每一个都自然对齐。因为有了这些填充，所以sizeof(WASTE)==12。这是一种浪费，因为只要我们重新安排变量的声明，就可以减少sizeof： struct WASTE { int i; char c1,c2; } 像这样的安排，sizeof就减少到8，只有2个字节的额外填充。为了与汇编代码相兼容，C语言语法规定，编译器无权擅自安排结构体内变量的布局顺序，必须从左向右逐一排列。所以，妥当安排成员顺序以避免内存空间的浪费，就成了我们程序员的责任之一。一般的，总是将结构体的成员按照其sizeof从大到小排列，double在最前，char在最后，这样总可以将结构的字节填充降至最小。 C++继承了C语言关于结构体布局的规定，所以以上的布局准则也适用于C++的class的成员变量。C++进一步扩展了布局规定，同一访问区段(private、public、protected)中的变量，编译器无权重新排列，不过编译器有权排列访问区段的前后顺序。基于这个规则，C++中有的程序员建议给每一个成员变量放在单独区段，在每一个成员声明之前都加上private:、public:、protected:标志，这可以最大限度的利用编译器的决策优势。 在栈中按顺序分配的变量，其边界也受到对齐要求的限制。与在结构中不同的是，栈中的变量还必须保证其后续变量无论是何种类型都可以自由对齐，所以在栈中的变量通常都有平台相关的对齐最小值。在MSVC编译器上，这个最小值可以由宏_INTSIZEOF(T)查询： #define _INTSIZEOF(T) ( (sizeof(T) + sizeof(int) - 1) & ~(sizeof(int) - 1) ) _INTSIZEOF(T)会将sizeof(T)进位到sizeof(int)的整数倍。 由于在栈中分配变量使用_INTSIZEOF而不是sizeof，在栈上连续分配多个小变量(sizeof小于int的变量)会造成内存浪费，不如使用结构(struct)或数组。也就是说： char c1,c2,c3,c4;//使用16字节 char c[4];//使用4字节 当然，使用数组的方法在访问数组变量(比如c[1])时有一次额外的指针运算和提领(dereference)操作，这会有执行效率的损失。这又是一种空间(内存占用)vs时间(执行效率)的折中，需要程序员自己根据情况权衡利弊。 sizeof的大小可能比我们预期的大，也可能比我们预期的小。对于空类： class Empty {}; 在通常情况下，sizeof(Empty)至少为1。这是因为C++语法规定，对于任何实体类型的两个变量，都必须具有不同的地址。为了符合语法要求，编译器会给Empty加入1字节的填充。所以sizeof()的值不可能出现0的情况。可是对于以下的类声明： class A:public Empty{vitual ~A(){}}; sizeof(A)有可能是6，也有可能是5，也有可能是4！必不可少的四个字节是一个指向虚函数表的指针。一个可能有的字节是Empty的大小，这是是因为编译器在特定情况下会将Empty视作一个\"空基类\"，从而实施\"空基类优化\"，省掉那毫无作用的一字节填充。另一个字节是A的一字节填充，因为从语法上讲，A没有成员声明，理应有1字节填充，而从语义上讲，编译器给A的声明加入了一个指向虚函数表的指针，从而A就不再是一个\"空类\"，是否实施这个优化，要看编译器作者对语法措词的理解。也就是说，sizeof也会出现4+1+1=4的情况。具体要看编译器有没有实施\"空基类优化\"和\"含虚函数表的空类优化\"。 结构和类的空间中可能有填充的字节，这意味着填充字节中可能有数值，虽然这数值并不影响结构的逻辑状态，但是它也可能不知不觉中影响到你。比如说，你手头正好有一组依赖于底层硬件(比如多处理器)的函数，他们在操纵连续字节时比手动编码要快很多，而你想充分利用这种硬件优势： bool BitCompare(void* begin,void* end,void* another); 这个函数将区间[begin,end)之间的字节与another开始的字节相比较，如果有一位不同就返回false，否则返回true。 比如你想将这个函数用于你自己的类的operator==中，这样可以利用硬件加快速度。不过你在动手前要充分考虑，你的class是否真的要比较每一位。如果在类的成员中存在编译器填充的字节数，那么应用以上的函数就是不正确的，因为填充的字节中可以有不同的值。为了保证你可以用Bitwise Compare，你必须确保填充的字节中的值也是相同的。这不仅要求你在类的构造函数中初始化类的每一bit而不是每一个成员，也要求你在复制初始化和复制赋值函数中也同时保证bitwise copy语义，而不是编译器默认产生的memberwise语义。当然，你可能通过与BitCompare一同提供的BitCopy来完成这个艰巨的任务。","tags":"import","title":"C++ Tricks 2.5 I386平台的边界对齐(Align)"},{"url":"//farseerfc.me/zhs/c-tricks-2-6-i386-variable-arguments.html","text":"从 farseerfc.wordpress.com 导入 2.6 I386平台C函数的可变参数表(Variable Arguments) 基于前文(2.4节)分析，我们可以不通过函数签名，直接通过指针运算，来得到函数的参数。由于参数的压栈和弹出操作都由主调函数进行，所以被调函数对于参数的真实数量不需要知晓。因此，函数签名中的变量声明不是必需的。为了支持这种参数使用形式，C语言提供可变参数表。可变参数表的语法形式是在参数表末尾添加三个句点形成的省略号\"...\"： void g(int a,char* c,...); 省略号之前的逗号是可选的，并不影响词法语法分析。上面的函数g可以接受2个或2个以上的参数，前两个参数的类型固定，其后的参数类型未知，参数的个数也未知。为了知道参数个数，我们必须通过其他方法，比如通过第一个参数传递： g(3,\"Hello\",2,4,5);//调用g并传递5个参数，其中后3个为可变参数。 在函数的实现代码中，可以通过2.4节叙述的，参数在栈中的排列顺序，来访问位于可变参数表的参数。比如: void g(int a,char* c...){ void *pc=&c;int* pi=static_cast<int*>(pc)+1;//将pi指向首个可变参数 for(int i=0;i<a;i++)std::cout<<pi[i]<<\" \"； std::cout<<c<<std::endl; } 我们甚至可以让一个函数的所有参数都是可变参数，只要有办法获知参数的数量即可。比如，我们约定，在传递给addAll的参数都是int，并且最后一个以0结束： int addAll(...); int a=f(1,4,2,5,7,0); 那么addAll可以这样实现： int addAll(...){ int sum=0;int *p=&sum; //p指向第一个局部变量 p+=3; //跳过sum，ebp，eip，现在p指向第一个参数 for(;*p;++p) //如果p不指向0就继续循环 sum+=*p; return sum; } 可变参数表的最广泛应用是C的标准库函数中的格式化输入输出：printf和scanf。 void printf(char *c,...); void scanf(char *c,...); 两者都通过它的首个参数指出后续参数表中的参数类型和参数数量。 如果可变参数表中的参数类型不一样，那么操纵可变参数表就需要复杂的指针运算，并且还要时刻注意边界对齐(align)问题，非常令人头痛。好在C标准库提供了用于操纵可变参数表的宏(macro)和结构(struct)，他们被定义在库文件stdarg.h中: typedef struct {char *p;int offset;} va_list; #define va_start(valist,arg) #define va_arg(valist,type) #define va_end(valist) 其中结构va_list用于指示参数在栈中的位置，宏va_start接受一个va_list和函数的可变参数表之前的参数，通过第一个参数初始化va_list中的相应数据，因此要使用stdarg.h中的宏，你的可变参数表的函数必须至少有一个具名参数。va_arg返回下一个类型为type的参数，va_end结束可变参数表的使用。还是以上文的addAll为例，这次写出它的使用标准宏的版本： int addAll(int i,...) { va_list vl; //定义一个va_list结构 va_start(vl,i); //用省略号之前的参数初始化vl if(i=0)return 0; //如果第一个参数就是0，返回 int sum=i; //将第一个参数加入sum for(;;){ i=va_arg(vl,int); //取得下一个参数，类型是sum if(i==0)break; //如果参数是0，跳出循环 sum+=i; } va_end(vl); return sum; } 可以看出，如果参数类型一致，使用标准库要多些几行代码。不过如果参数类型不一致或者未知(printf的情况)，使用标准库就要方便很多，因为我们很难猜出编译器处置边界对齐(align)等汇编代码的细节。使用标准库的代码是可以移植的，而使用上文所述的其它方法操纵可变参数表都是不可移植的，仅限于在I386平台上使用。 纵使可变参数表有使用上的便利性，它的缺陷也有很多，不可移植性和平台依赖性只是其一，最大的问题在于它的类型不安全性。使用可变参数表就意味着编译器不对参数作任何类型检查，这在C中算是一言难尽的历史遗留问题，在C++中就意味着恶魔reinterpret_cast被你唤醒。C的可变参数表是C++代码错误频发的根源之一，以至于C++标准将可变参数表列为即将被废除的C语言遗留特性。C++语法中的许多新特性，比如重载函数、默认参数值、模板，都可以一定程度上替代可变参数表，并且比可变参数表更加安全。 可变参数表在C++中惟一值得嘉奖的贡献，是在模板元编程(TMP)的SFINAE技术中利用可变参数表制作最差匹配重载。根据C++标准中有关函数重载决议的规则，具有可变参数表的函数总是最差匹配，编译器在被逼无奈走头无路时才会选择可变参数表。利用这一点，我们可以精心制作重载函数来提取类型信息。比如，要判断一个通过模板传递来的类型是不是int： long isIntImp(int); char isIntImp(...); template<typename T> struct isInt { enum{value=sizeof(isIntImp(T()))==sizeof(long);} } 然后，在一个具有模板参数T的函数中，我们就可以写 if(isInt<T>::value)//... 在这个(不怎么精致的)例子中，如果T是int，那么isIntImp的第一个重载版本就会被选中，返回值类型就是long，这样value就为1。否则，编译器只能选中第二个具有可变参数表的重载版本，返回值类型成为char，这样value就为0。把它说得再明白一些，上文的代码所表达的意思是：如果类型T是int，那它就是int，否则它就不是int，呵呵简单吧。这种通过重载决议规则来提取类型信息的技术，在模板元编程中被称作SFINAE，它和其它模板元编程技术被广泛运用于STL、Boost等模板库的开发实现之中。 值得注意的是，在上文SFINAE的运用中，isIntImp并没有出现定义而只提供了声明，因为我们并没有实际调用isIntImp函数，而只是让它参与重载决议并用sizeof判断其返回值类型。这是C++的一个设计准则的完美体现：不需要的东西可以不出现。由于这一准则，我们避免了在C++中调用具有可变参数表的函数这一危险举动，而仅仅利用了可变参数表在语法分析过程中的特殊地位，这种对于危险语言特性的巧妙利用是善意而无害的。","tags":"import","title":"C++ Tricks 2.6 I386平台C函数的可变参数表(Variable Arguments)"},{"url":"//farseerfc.me/zhs/c-tricks-2-7-i386-calling-conventions.html","text":"从 farseerfc.wordpress.com 导入 2.7 I386平台的其它函数调用模型 上文介绍的只是I386平台上C函数调用的标准模型，被称作__cdecl。事实上，Microsoft Visual C++编译器还支持其它一些函数调用模型，所有调用模型名称皆以双下划线开头，下面列出所有函数调用模型的异同： 1 __cdecl 参数压栈顺序：逆序(从右至左) 参数堆栈恢复者：主调函数(caller) __cdecl明确地指出函数使用C函数调用模型，这是默认的调用模型。 2 __stdcall 参数压栈顺序：逆序(从右至左) 参数堆栈恢复者：被调函数(callee) __stdcall是微软所谓的标准调用模型。可惜的是它与__cdecl不兼容。几乎所有的Win32API函数使用这种函数调用模型，希望在DLL之间，或者在程序和WinNT操作系统之间传递函数指针的函数也应该使用这种模型。与__cdecl模型的不同之处在于，__stdcall模型下由被调函数恢复堆栈。主调函数在call语句之后，不需要再加上add语句。而被调函数的ret语句则被添加一个参数，代表函数参数堆栈的长度。因此，被调函数需要明确的知晓函数参数的数量和类型，所以在__stdcall模型下不支持可变参数表，所有参数必须写明。 3 __thiscall 参数压栈顺序：逆序(从右至左)，this用ecx传递。 参数堆栈恢复者：被调函数(callee) __thiscall是VC编译器中类的非静态成员函数(non-static member functon)的默认调用模型。但是如果此成员函数有可变参数表，VC编译器会使用__cdecl。和__stdcall一样，__thiscall由被调函数恢复堆栈。比较独特的是__thiscall会通过ecx寄存器传递成员函数的this指针，而__cdecl下this指针是通过在参数表最前面增加一个函数参数来传递的。__thiscall是VC编译器对this指针的使用的一种优化，大大提高了面向对象程序的效率。在VC2003及之前的编译器上__thiscall不是一个关键字，不能被显式指定。但可以给成员函数显式指定__cdecl来避免使用__thiscall。 4 __fastcall 参数压栈顺序：逆序(从右至左)，前两个32位函数参数放入ecx和edx中 参数堆栈恢复者：被调函数(callee) 快速函数调用模型，将前两个32位函数参数放入ecx和edx中，其余参数再逆序压栈。使用的是和__thiscall类似的优化技术，加快函数调用，适合运用在小型inline函数上。同样使用__stdcall形式的被调函数恢复堆栈，所以不支持可变参数表。 5 __pascal 参数压栈顺序：正序(从左至右) 参数堆栈恢复者：被调函数(callee) 过程式编程语言Pascal所使用的函数调用模型，由此得名。也是16位版本的Windows使用的API模型，过时的模型，现在已经废弃且禁止使用。你会看到有些书本仍会不时提到它，所以需要注意。__pascal是正序压栈，这与大部分I386函数模型都不相同。与__stdcall一样，由被调者恢复堆栈，不支持可变参数表。历史上曾有过的别名PASCAL、pascal、_pascal(单下划线)，现在都改成了__stdcall的别名，与__pascal(双下划线)不同。 6 其它函数调用模型，以及模型别名。 __syscall：操作系统内部使用的函数调用模型，由用户模式向核心模式跳转时使用的模型。由于用户模式和核心模式使用不同的栈，所以没办法使用栈来传递参数，所有参数通过寄存器传递，这限制了参数的数量。用户模式编程中不允许使用。 __fortran：数学运算语言fortran使用的函数模型，由此得名。在C中调用由fortran编译的函数时使用。 __clrcall：微软.Net框架使用的函数模型，托管(Managed)C++默认使用，也可以从非托管代码调用托管函数时使用。参数在托管栈上正序(从左至右)压栈，不使用普通栈。 CALLBACK、PASCAL、WINAPI、APIENTRY、APIPRIVATE：I386平台上是__stdcall的别名 WINAPIV：I386平台上是__cdecl的别名 7 函数调用模型的指定 函数调用模型的指定方式和inline关键字的指定方式相同，事实上，inline可以被看作是C++语言内建的一种函数调用模型。唯一不同的是，声明函数指针时，也要指明函数调用模型，而inline的指针是不能指明的，根本不存在指向inline函数的指针。比如： int CALLBACK GetVersion(); int (CALLBACK * pf)()=GetVersion;","tags":"import","title":"C++ Tricks 2.7 I386平台的其它函数调用模型"},{"url":"//farseerfc.me/zhs/c-tricks.html","text":"从 farseerfc.wordpress.com 导入 C++ Tricks By FarseerFc 从今天起，我再将在 Live Space 和 QQZone 同时发表一系列文章，暂定名为\"C++Tricks\"。 本文旨在记录和阐述一些本人学习C++时所得的心得、技巧。总体来看，本文涉及的内容是每一个C++程序员都应该知道的，但是很少见诸C++教材。希望对各位同仁学习C++有所帮助。 也可以通过QQ或MSN向我索要此文的DOC版或PDF版，会比网页上的更新的快一点。 1 词法问题(Lexical Problems) 1.1 条件运算符(?:) 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱 2 X86体系结构 2.1 X86概述 2.2 I386平台的内存布局 2.3 I386平台C函数内部的栈分配 2.4 I386平台C函数调用边界的栈分配 2.5 I386平台的边界对齐(Align) 2.6 I386平台C函数的可变参数表(Variable Arguments) 2.7 I386平台的其它函数调用模型 3 过程式编程 3.1 左值右值与常量性(lvalue，rvalue & constant) 3.2 标号、goto，以及switch的实现","tags":"import","title":"C++ Tricks"},{"url":"//farseerfc.me/zhs/c-tricks-2-1-x86-architecture.html","text":"从 farseerfc.wordpress.com 导入 2.1 X86概述 所谓X86体系结构，是指以Intel 8086芯片为首的芯片所沿袭的CPU结构，一些文档中又被称作IA32体系结构。包括的芯片有但不限于:Intel 8086至 80486，奔腾(Pentium)系列处理器1至4，赛扬系列处理器，酷睿系列处理器，以及AMD的相应型号产品。X86体系结构在早期属于16位处理器，自80386之后扩展为32位处理器，所以一些文档中又把80386之后的32位处理器体系称作I386。自Pentium4后期，AMD的Athlon64开始，I386被进一步扩充为64位处理器，含有64位寻址能力的X86体系结构被称作X86-64或IA32-64。总之，市售的个人电脑用CPU，除苹果的Macintosh之外，全部采用X86体系结构芯片。 在X86早期，16位的寻址能力只支持64KB(2&#94;16=64K)内存，这显然是不够的。Intel采用分段寻址的方法，用4位段位+16位偏移量，提供了总共1MB(2&#94;20=1M)的寻址能力。所以在X86的16位编程中，有两种指针类型：长指针(lp,long pointer)和短指针(sp,short pointer)，长指针(20位)提供整个内存空间寻址能力，短指针(16位)仅支持同一段中的寻址。在\"古代\"DOS及Win3.x编程过程中，两种类型的指针，以及总共1MB的内存大小，常常把程序员们折腾得焦头烂额。 自I386之后，CPU才开始提供32位的寻址能力。有了整整4GB(2&#94;32=4G)的寻址空间，所有指针统一为长指针(32位)。时至今日，我们仍可以看到微软文档中指针变量的lp前缀。由于内存管理的需要，分段机制被保留下来，但这一次不是因为地址空间太小，而是因为地址空间远大于实际内存容量，从而采用了虚拟内存机制。 在从16位结构向32位结构转变的过程中，由于向下兼容的历史原因，曾一度长时间出现硬件32位(I386)、软件16位(Win3.x)的情况。同样也是为了兼容16位软件，Win9x操作系统(Win95、Win98、WinME)保留了16位代码和32位代码。混合代码的设计使得Win9x及其混乱和不稳定。直到完全32位内核的操作系统WinNT(以及构建于其上的Win2000，WinXP，Win2003)的出现，X86平台上内存布局混乱的局面才得以改善。有了从16位至32位移植的经验和准备，现今的从32位到64位的操作系统移植显得平稳顺利很多。WinXP和WinVista系统都同时发布了32位版本和64位版本，并且其x86-64系统都实现了对32位软件的无缝衔接支持。","tags":"import","title":"C++ Tricks 2.1 X86概述"},{"url":"//farseerfc.me/zhs/c-tricks-1-2-trap-in-comma-logical-operator.html","text":"从 farseerfc.wordpress.com 导入 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱 很多人甚至不知道逗号(,)也是个C++运算符。与语法上要求出现的逗号(比如分隔函数参数的逗号)不同的是，出现在表达式中的逗号运算符在语义上表示多个表达式操作的连续执行，类似于分隔多语句的分号。比如： for ( int i=0,j=9;i<10;++i , --j)std::cout<<i<<\"+\"<<j<<\"=9\\n\"; 在这句语句中，出现了两个逗号，其中前者是语法上用来分隔声明的变量的，并非逗号运算符，而后者则是一个逗号运算符。根据C++标准，逗号运算符的执行顺序为从左到右依次执行，返回最后一个子表达式的结果。由于只有最后一个表达式返回结果，所以对于一个语义正常的逗号表达式而言，前几个子表达式必须具有副作用。同时，从语言的定义中也可以看出，逗号表达式对求值的顺序有严格要求。 对求值顺序有要求的，除了逗号表达式和条件表达式(参见1.1)，在C++中还有逻辑运算符(&&和||)。逻辑运算相较于数学运算和位运算而言，有个显著的不同点：逻辑运算在计算到一半时，就有可能已经得到结果，这样继续运算另一半就不是必需的。对于A&&B，如果A=false，那么无论B为何值，整个的结果都是false；同样的A||B，如果A=true，那么不考虑B，结果一定是true。 C++标准规定，如果逻辑运算到一半(算出A)时，就已经可以确定运算的结果，那么就不运算剩下的另一半(B)。这种执行语义被称作\"短路\"。在其它一些编程语言中，短路语义是可以选择的：在Ada里非短路的逻辑运算符为and和or，短路的逻辑运算符为and_then和or_else。但是在C++中，逻辑运算符的短路语义是语法上强制的，我们没有非短路版本的运算符。如果确实需要非短路语义，我们总是可以通过增加一个bool中间变量加以解决。有时，短路对于保证正确执行是必须的，比如： char *p=getString(); if (p && *p)std::cout<<p; 这段代码在得到了一个字符串后，在字符串不为空时输出它。在C++中判断一个字符串不为空需要两个步骤：判断指针是否为0，以及指针不为0时判断指针指向的内容是否为''。就像条件表达式中讨论到的(参见1.1)，在p为空时提领p是个极其危险的操作。逻辑运算符的短路语义则避免了这种危险。 以上对逗号运算符与逻辑运算符的讨论，仅限于C++标准所定义的运算符语义。为什么这样说呢？这是因为在C++中，运算符的语义是可以由程序员自行定义的，这种机制叫做运算符重载(operator overload)。运算符重载可以将人们熟悉的运算符表达式转换成函数调用，使编程灵活而直观，是个方便的语言特性。不过有时运算符重载也会使人困扰，那就是当运算符重载遇到求值顺序问题时。 C++中，并不是所有合法运算符都可以被合法地重载。条件运算符虽然对求值顺序有要求，但它并不在可重载运算符之列，所以运算符重载机制对它没有影响。问题在于，逗号运算符和逻辑运算符都可以被合法地重载： class BadThing{/* Some Bad and Stupid Thing*/}; BadThing& operator ,(BadThing&, BadThing&);//重载了逗号运算符 bool operator &&(BadThing&, BadThing&);//重载了&& BadThing b1,b2; if (b1&&b2)b1,b2;//被替换成如下形式： if ( operator &&(b1,b2)) operator ,(b1,b2); 可以看到，重载了运算符之后，对运算符的使用被替换为相应的函数调用形式。因此，旧有的运算符的执行顺序不再适用，取而代之的是函数参数的压栈顺序。 根据C++标准规定，任何参数必须在进入函数之前压栈，所以在进入 operator &&之前，b1、b2就会被求值，这里不再有短路规则，任何依赖于短路语义的不知不觉间操作BadThing的代码(可能通过模板)都会混乱。 短路语义只是一个方面，更重要的在于压栈顺序。鉴于执行效率和旧代码兼容性等细节问题，C++标准在压栈顺序上给编译器的开发者留有很大自主性。标准的说辞是，编译器可能以任何它觉得方便的顺序将参数压栈，从左到右，从右到左，甚至从中间到两边，在这一点上我们不能安全地做任何假设。在上面的例子中，编译器生成的代码可能先计算b1再计算b2，也可能是相反的顺序。再看看编译器的实际情况，在我试过的所有基于X86体系结构的编译器中，参数都是以逆向压栈，即从右到左，有悖于大多数人的阅读习惯和直觉(别说你是来自伊斯兰的……)。 在C时代使用函数调用时，压栈顺序并不是什么大问题，毕竟大多数人会在函数调用的边界稍稍小心一些。但是到了C++中，事情变得有些复杂，因为简单如a+b的使用，就有可能被运算符重载机制替换为函数调用。更何况有模板参与之后，我们写代码时不能确定对象的真实类型，也就无法预知一个运算符是否真的被重载过，唯一稳妥的方法是，假定任何有可能被重载的运算符的使用都是函数调用。 <p style=\"margin:0;\"> 回到上文的示例中，由于,和&&都被替换为函数调用，程序的执行顺序将成为压栈顺序，在X86上很有可能是从右到左，与标准定义的运算符的顺序正好相反。逗号运算符原本就含有\"先…后…\"的语义，这种颠倒的执行顺序势必造成程序和程序员的混乱。以我的经验而言，含有 operator ,的类，完全没有办法和STL或者iostream相互协作，反而会导致巨量的错误报告(什么叫巨量的错误报告有概念么？如果没有，那说明你还没玩过范式编程(GP, Generic Programming)。去玩玩GP吧，看看你的编译器对巨量的定义。在我手头，针对3.5KB的代码文件倾泻出3.8 MB 的错误信息的编译器不在少数……)。有鉴于此，我的结论是，除非你有充足的依据支持你这么做(比如你的粗暴上司的键盘上只剩下逗号能用)，并且你清楚的了解这么做的后果的严重性(比如至少要看过此文)，否则我奉劝你，永远不要碰 operator ,、 operator &&以及 operator ||！","tags":"import","title":"C++ Tricks 1.2 逗号运算符(,)、逻辑运算符(&&,||)与运算符重载的陷阱"},{"url":"//farseerfc.me/zhs/c-tricks-1-1-conditional-operator.html","text":"从 farseerfc.wordpress.com 导入 1.1 条件运算符(?:) 条件运算符(?:)是C++中唯一的三目运算符(trinary operator)，用于在表达式中作条件判断，通常可以替换if语句，与Visual Basic中的iif函数、Excel中的if函数有同样的作用。语法形式如下： condition ? true_value : false_value 其中 condition *条件是任何可以转换为bool类型的表达式，包括但不仅限于**bool* 、 int 、指针。与 if 和 while 的条件部分稍显不同的是，这里不能定义变量，否则会导致语法错误。 另外，条件语句会切实地控制执行流程，而不仅仅是控制返回值。也就是说，两个返回值表达式中永远只有一个会被求值，在表达式的执行顺序很重要时，这点尤为值得注意。比如： int *pi=getInt(); int i=pi ? *pi : 0; 这里，只有当pi的值不为0时，它才会被提领(dereference)。这种语义保证了程序的正确性，因为提领一个空指针将导致致命的运行期错误(通常是非法操作的警告)。同时，正因为条件运算符控制运算流程的特点，使得它不能用类似iif的普通函数来模拟： int iif( int con, int t, int f){ if (c) return t; return f;}//试图模拟?: …//in some function int *pi=getInt(); int i=iif(pi,*pi,0);//Error! 这段代码会导致上文提到的致命运行期错误。C/C++标准规定，参数在被传递给函数之前求值，因此无论pi为何值，都会被提领。又因为函数传回一个空指针的情况比较少见，所以这样的错误在调试时很难被发现，一旦发生又势必造成重大灾难。这样的代码在实践中应尽量避免。 有时，条件运算符控制流程的特点会不知不觉影响我们的代码。在C时代，最大值MAX通常用宏实现： #define MAX(a,b) ((a)>(b) ? (a) : (b)) 需要用额外的括号将宏参数和宏本体保护起来，以免运算符优先级扰乱逻辑，这是宏丑陋的特点之一，这里暂且不提。矛盾在于，用具有副作用的表达式调用宏时，会出现问题： int i=5,j=6;//… int a=MAX(++i,++j); 代码的作者原意显然是想先将i,j分别递增，再将其中较大的一个赋给a。执行这段代码，当i=5,j=6时，a=8，知道为什么吗？通过宏展开，赋值语句成这样： int a=(++i)>(++j) ? (++i) : (++j);//删除了多余括号 在判断之前，i、j被分别自增一次，然后舍弃:之前的部分，j又被自增一次。执行之后，i=6,j=8。 MAX的更正确更安全的实现，是利用模板将类型参数化。STL标准算法中就有一个这样的工具级模版函数std::max。 条件运算符是表达式而不是语句，这使得它可以出现在任何需要表达式的地方，这扩大了它的适用范围。在那些语法上只能出现表达式而不能出现语句的地方（比如变量初始化），条件运算符有着不可替代的作用。 条件运算符优于 if 语句的另一个场合是\"模板元编程\"(TMP, Template MetaProgramming)。在TMP这个古怪奇异的编译期运算编程技术中，一切旧有的技术和法则被全线击破，我们所能仰仗的工具，只有模板特化(Specialization)、 typedef s、函数声明(无法调用它们)、以及编译期常量运算。已经有人很深入地论证过，仅有以上这些，就已经形成了一个\"图灵完善\"的计算机语言。我们可以用模板特化技术，来模拟条件分支，循环迭代等一系列复杂的语言结构。由于可以参与编译期常量运算，条件运算符在TMP世界中很自然地扮演起重要角色。 比如，给与类型T的一个变量t，我们想声明一个缓冲区存放t和一个int，缓冲区的大小不小于sizeof(T)也不小于sizeif(int)，我们可以这样写： char buffer[sizeof(T)>sizeof(int)? sizeof(T): sizeof(int)]; 我们不能用一个if语句替换这个运算： int i; if(sizeof(T)>sizeof(int))i=sizeof(T); else i=sizeof(int); char buffer[i];//语法错误! 原因在于数组声明中的下标必须是一个编译期常量，而不是一个运行期的值，条件表达式的运算可以在编译期进行，if语句就只能在执行期执行。","tags":"import","title":"C++ Tricks 1.1  条件运算符(?:)"},{"url":"//farseerfc.me/zhs/filling-believings-calling-conscience.html","text":"从 farseerfc.wordpress.com 导入 填补信仰、唤醒良知 我们听尽了呼吁与号召，对于良知，我不必谴责丧失它的国人，不必盛赞良知的美好。我只想讨论，丧失了良知的原因——空缺的信仰。 一、空缺信仰丧失良知 现代的国人缺少信仰，以至于丧失良知。曾几何时，中华民族由良好的信仰凝聚而成。三皇五帝时，族民们以炎黄为信仰；春秋战国时，士大夫之族以周制礼乐为信仰；汉代以后，百姓延习孔孟之说、老聃之道，以儒家学说为信仰；自大唐起，以佛教为首的现代宗教纷纷传入中原，人民开始以它们作为信仰。 直至鸦片战争、五四运动，西方文化入侵中华，国人开始抛弃国学，转而去研究科学；文化大革命，十年文化浩劫，人们批判旧的信仰，却没有合适的新的信仰前来填补。从此，国人的信仰出现空缺，国人的良知也被一块块蚕食殆尽。 二、信仰、科学、迷信 在许多国人的心目中，信仰就等于迷信。从小到大的教育告诉我们，信奉宗教是愚昧而又无知的表现，科学与信仰是矛盾的。是么？ 我们无法保证社会上的每一个人都接受过良好的教育，我们无法确信最前沿的科学素养能在民众中普及。在科普与教育力不从心的社会死角，在科学技术尚不能及的文化盲区，我们依旧需要信仰的规范与限制，我们的良知需要信仰！ 信仰不等于迷信。信仰本身无所谓谜与不迷，迷信是持有信仰的人误解了信仰，盲目遵从的结果。以为烧过香就可以免遭祸患，以为捐了钱就可以升入天堂，以为引火自焚就可以功德圆满，这便是迷信了。希特勒曾经的人类完善计划，依照遗传学的原理，将科学家与运动员强行结为夫妇孕育生命，希望得到最优秀的人类种族，这便是对科学这种信仰的迷信！ 由此可见，科学与信仰并不是矛盾的硬币的两面，从某种意义而言科学本身也是信仰的一种。虽然历史上宗教往往作为科学发展的阻碍，可信奉真理的信念一直是推动科学发展的动力。牛顿就曾说过，对自然规律的探询是为了更接近上帝。由此可见，信仰与真理，与良知毫无矛盾。 三、信仰唤醒良知 很少有人仔细思考过，良知的缺失是由信仰的缺失造成的。信仰是人思想的寄托与依靠，是人行动处世的准则。没有了信仰的人，思想行为就缺少了约束的标准，人就更容易因为一时不成熟的冲动，背叛良知、铸成错误。 泰国人以佛教为信仰，泰国的寺庙每天都会有成千上万人顶礼膜拜。寺庙有一个人尽皆知的不成文规定：不得穿鞋进入。于是在寺庙之外，游客们可以看到千百双各式的鞋子有序的摆放在门口。国人每每看到此景，总会诧异地问：没有人会偷鞋么？得到的答案极为简单：庙前偷鞋会遭报应。由于拥有信仰，泰国人作了坏事会受到良知的谴责，泰国商人售出假货会彻夜难眠。二战期间，无数犹太难民被天主教会收留藏匿从而侥幸逃生，这同样是出于，天主教徒们被自己信奉的教义\"众生生来平等\"，所唤醒的良知。 天下无贼的世界，不能仅靠科普说教来营造。如果脱离了信仰，纵使是教育也无法培养良知。我问过许多修化学的同学，学习化学的意义，结论竟是为了考试。如果没有对科学的信仰，我们可以牢记公式定理，却质疑它们是真理；如果没有对社会公德的信仰，我们可以熟背交通规则，却正大光明地闯红灯；如果没有对医疗道德的信仰，医生可以放任伤口发炎，从而留住病人继续治疗…… 国人需要信仰的约束，需要填补信仰的空白，从而唤醒那深埋于每个国人内心深处的良知！","tags":"import","title":"填补信仰、唤醒良知"}]}